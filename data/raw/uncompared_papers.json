{
    "uncompared_papers": [
        {
            "id": "R8245",
            "label": "Knowledge base shipping to the linked open data cloud",
            "doi": "10.1145/2814864.2814885",
            "research_field": {
                "id": "R134",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R8248",
                    "label": "Deployment Knowledgebases"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "popular knowledge bases that provide sparql endpoints for the web are usually experiencing a high number of requests, which often results in low availability of their interfaces. a common approach to counter the availability issue is to run a local mirror of the knowledge base. running a sparql endpoint is currently a complex task which requires a lot of effort and technical support for domain experts who just want to use the sparql interface. with our approach of containerised knowledge base shipping we are introducing a simple to setup methodology for running a local mirror of an rdf knowledge base and sparql endpoint with interchangeable exploration components. the flexibility of the presented approach further helps maintaining the publication infrastructure for dataset projects. we are demonstrating and evaluating the presented methodology at the example of the dataset projects dbpedia, catalogus professorum lipsiensium and s\u00e4chsisches pfarrerbuch."
        },
        {
            "id": "R107933",
            "label": "The Ontology-based Business Architecture Engineering Framework",
            "doi": "10.3233/978-1-60750-831-1-233",
            "research_field": {
                "id": "R134",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R108294",
                    "label": "Enterprise engineering"
                },
                {
                    "id": "R110463",
                    "label": "Business architecture development"
                },
                {
                    "id": "R110464",
                    "label": "Enterprise transformation: IT and methodology support "
                },
                {
                    "id": "R110465",
                    "label": "Enterprise modeling"
                }
            ],
            "abstract": "business architecture became a well-known tool for business transformations. according to a recent study by forrester, 50 percent of the companies polled claimed to have an active business architecture initiative, whereas 20 percent were planning to engage in business architecture work in the near future. however, despite the high interest in ba, there is not yet a common understanding of the main concepts. there is a lack for the business architecture framework which provides a complete metamodel, suggests methodology for business architecture development and enables tool support for it. the org- master framework is designed to solve this problem using the ontology as a core of the metamodel. this paper describes the org-master framework, its implementation and dissemination."
        },
        {
            "id": "R108224",
            "label": "Linking Business Goals to Process Models in Semantic Business Process Modeling",
            "doi": "10.1109/edoc.2008.43",
            "research_field": {
                "id": "R134",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R108294",
                    "label": "Enterprise engineering"
                },
                {
                    "id": "R110463",
                    "label": "Business architecture development"
                },
                {
                    "id": "R110464",
                    "label": "Enterprise transformation: IT and methodology support "
                },
                {
                    "id": "R110465",
                    "label": "Enterprise modeling"
                }
            ],
            "abstract": "broad knowledge is required when a business process is modeled by a business analyst. we argue that existing business process management methodologies do not consider business goals at the appropriate level. in this paper we present an approach to integrate business goals and business process models. we design a business goal ontology for modeling business goals. furthermore, we devise a modeling pattern for linking the goals to process models and show how the ontology can be used in query answering. in this way, we integrate the intentional perspective into our business process ontology framework, enriching the process description and enabling new types of business process analysis."
        },
        {
            "id": "R110487",
            "label": "An analysis of Service Level Agreement parameters and scheduling in Multi-Tenant Cloud Systems",
            "doi": "",
            "research_field": {
                "id": "R134",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in cloud systems it usually the case that there exists a multi-tenancy of cloud service customers meaning that some cloud service customers applications share the same cloud infrastructure. in this situation there must exist a service level agreement (sla) contract between the multi-tenant cloud service provider (mtcsp) and the cloud service customers (cscs). in this article we discuss about the parameters of an sla in the cloud and we particularize it in the case of multi-tenancy. we analyze and implement two algorithms with the purpose of optimizing the scheduling of tasks from the tenants of the multi-tenant cloud service. the results show that the algorithms can be used in different situations with good results."
        },
        {
            "id": "R78214",
            "label": "Textural and Heavy Minerals Characterization of Coastal Sediments in Ibeno and Eastern Obolo Local Government Areas of Akwa Ibom State \u2013 Nigeria",
            "doi": "10.12691/jgg-7-4-4",
            "research_field": {
                "id": "R146",
                "label": "Geology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "textural characterization and heavy mineral studies of beach sediments in ibeno and eastern obolo local government areas of akwa ibom state were carried out in the present study. the main aim was to infer their provenance, transport history and environment of deposition. sediment samples were collected at the water\u2013sediment contact along the shoreline at an interval of about 3m. ten samples were collected from study location 1 (ibeno beach) and twelve samples were collected from study location 2 (eastern obolo beach). a total of twenty\u2013two samples were collected from the field and brought to the laboratory for textural and compositional analyses. the results showed that the value of graphic mean size ranged from 1.70\u0444 to 2.83\u0444, sorting values ranged from 0.39\u0444 \u2013 0.60\u0444, skewness values ranged from -0.02 to 0.10 while kurtosis values ranged from 1.02 to 2.46, indicating medium to fine grained and well sorted sediments. this suggested that the sediments have been transported far from their source. longshore current and onshore\u2013offshore movements of sediment are primarily responsible in sorting of the heavy minerals. the histogram charts for the different samples and standard deviation versus skewness indicated a beach environment of deposition. this implies that the sediments are dominated by one class of grain size; a phenomenon characteristic of beach environments. the heavy mineral assemblages identified in this research work were rutile, zircon, tourmaline, hornblende, apatite, diopside, glauconite, pumpellyite, cassiterite, epidote, garnet, augite, enstatite, andalusite and opaque minerals. the zircon-tourmaline-rutile (ztr) index ranged from 47.30% to 87.00% with most of the samples showing a ztr index greater than 50%. these indicated that the sediments were mineralogically sub-mature and have been transported far from their source. the heavy minerals identified are indicative of being products of reworked sediments of both metamorphic (high rank) and igneous (both mafic and sialic) origin probably derived from the basement rocks of the oban massif as well as reworked sediments of the benue trough. therefore, findings from the present study indicated that erosion, accretion, and stability of beaches are controlled by strong hydrodynamic and hydraulic processes."
        },
        {
            "id": "R109216",
            "label": "Principal Component Analysis for Alteration Mapping",
            "doi": "",
            "research_field": {
                "id": "R146",
                "label": "Geology"
            },
            "research_problems": [
                {
                    "id": "R109215",
                    "label": "Redundancy in high volume image datasets"
                }
            ],
            "abstract": "reducing the number of image bands input for principal component analysis (pca) ensures that certain materials will not be mapped and increases the likelihood that others will be unequivocally mapped into only one of the principal component images. in arid terrain, pca of four tm bands will avoid iron-oxide and thus more reliably detect hydroxyl-bearing minerals if only one input band is from the visible spectrum. pca for iron-oxide mapping will avoid hydroxyls if only one of the swir bands is used. a simple principal component color composite image can then be created in which anomalous concentrations of hydroxyl, hydroxyl plus iron-oxide, and iron-oxide are displayed brightly in red-green-blue (rgb) color space. this composite allows qualitative inferences on alteration type and intensity to be made which can be widely applied."
        },
        {
            "id": "R109219",
            "label": "Comparison of three principal component analysis techniques to porphyry copper alteration mapping: A case study, meiduk area, kerman, iran)",
            "doi": "10.1080/07038992.2001.10854931",
            "research_field": {
                "id": "R146",
                "label": "Geology"
            },
            "research_problems": [
                {
                    "id": "R109218",
                    "label": "Alteration mapping in metallogenic provinces using remote sensing techniques"
                }
            ],
            "abstract": "\"r\u00e9sum\u00e9 la m\u00e9thode d'analyse en composantes principales est utilis\u00e9e couramment pour la cartographie des alt\u00e9rations dans les provinces m\u00e9tallog\u00e9niques. trois techniques d'analyse en composantes principales sont utilis\u00e9es pour la cartographie des alt\u00e9rations autour d'intrusions porphyriques dans la zone de meiduk: la m\u00e9thode s\u00e9lective, la m\u00e9thode s\u00e9lective d\u00e9velopp\u00e9e ou crosta et la m\u00e9thode standard. dans cette \u00e9tude, on compare les r\u00e9sultats de l'application de ces trois techniques diff\u00e9rentes sur les bandes landsat tm. la comparaison est bas\u00e9e principalement sur l'analyse visuelle et les observations des r\u00e9sultats sur le terrain. l'analyse en composantes principales s\u00e9lective utilisant les bandes 5 et 7 de tm est la plus ad\u00e9quate pour la cartographie des alt\u00e9rations. toutefois, les zones v\u00e9g\u00e9tales sont aussi mises en \u00e9vidence dans l'image pc2. l'application de la m\u00e9thode s\u00e9lective d\u00e9velopp\u00e9e sur les bandes 1, 4, 5 et 7 de tm pour la cartographie des hydroxyles met en \u00e9vidence des halos d'alt\u00e9ration autour des intrusions, mais son application \u00e0 la cartographie des oxydes de fer permet de distinguer une zone \u00e9tendue avec lithologie s\u00e9dimentaire. la m\u00e9thode d'analyse en composantes principales standard par contre permet de rehausser les alt\u00e9rations dans l'image pc5, mais elle est laborieuse en termes de temps machine. la cartographie des hydroxyles utilisant la technique s\u00e9lective d\u00e9velopp\u00e9e ou crosta est plus appropri\u00e9e pour la cartographie des alt\u00e9rations autour des masses intrusives porphyriques.\""
        },
        {
            "id": "R138411",
            "label": "Organic Nutrients Support High Primary Production in the Bay of Bengal",
            "doi": "10.1029/2019GL082262",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R138352",
                    "label": "Primary production assessment in the Bay of Bengal"
                }
            ],
            "abstract": "the bay of bengal (bob) is known to experience low productivity but high sinking carbon fluxes to the bottom, and this paradox is attributed to mineral ballast of organic matter. we found for the first time that primary production in the bob is higher, and it is supported by dissolved organic nitrogen (don) and phosphorus (dop) transported from the shelf regions through eddies. both don and dop contribute up to 70\u201399% to the total dissolved nutrients in the waters above the thermocline. don and dop displayed positive relationship with primary production in the upper 25 m of water column, suggesting that organic nutrients significantly support primary producers. primary production and export production in the bob is comparable to that in the arabian sea, in contrast to the earlier belief that it has low production due to lack of inorganic nutrients caused by strong salinity stratification."
        },
        {
            "id": "R138479",
            "label": "Enhanced chlorophyllaand primary production in the northern Arabian Sea during the spring intermonsoon due to greenNoctilucascintillansbloom",
            "doi": "10.1080/17451000.2011.605143",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R138403",
                    "label": "Primary production assessment in the Arabian Sea"
                }
            ],
            "abstract": "abstract the surface waters of the northeastern arabian sea sustained relatively high chlorophyll a (average 0.81\u00b10.80 mg m\u20133) and primary production (average 29.5\u00b123.6 mgc m\u20133 d\u20131) during the early spring intermonsoon 2000. this was caused primarily by a thick algal bloom spread over a vast area between 17\u201321\u00b0n and 66\u201370\u00b0e. satellite images showed exceptionally high concentration of chlorophyll a in the bloom area, representing the annually occurring \u2018spring blooms\u2019 during february\u2013march. the causative organism of the bloom was the dinoflagellate, noctiluca scintillans (dinophyceae: noctilucidea), symbiotically associated with an autotrophic prasinophyte pedinomonas noctilucae. the symbiosis between n. scintillans and p. noctilucae is most likely responsible for their explosive growth (average 3 million cells l\u20131) over an extensive area, making the northeastern arabian sea highly productive (average 607\u00b1338 mgc m\u20132 d\u20131) even during an oligotrophic period such as spring intermonsoon."
        },
        {
            "id": "R138486",
            "label": "First direct measurements of N2fixation during aTrichodesmiumbloom in the eastern Arabian Sea: N2FIXATION IN THE ARABIAN SEA",
            "doi": "10.1029/2010GB003970",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R138485",
                    "label": "Primary production assessment during blooming period in the Arabian Sea"
                }
            ],
            "abstract": "we report the first direct estimates of n2 fixation rates measured during the spring, 2009 using the 15n2 gas tracer technique in the eastern arabian sea, which is well known for significant loss of nitrogen due to intense denitrification. carbon uptake rates are also concurrently estimated using the 13c tracer technique. the n2 fixation rates vary from \u223c0.1 to 34 mmol n m\u22122d\u22121 after correcting for the isotopic under\u2010equilibrium with dissolved air in the samples. these higher n2 fixation rates are consistent with higher chlorophyll a and low \u03b415n of natural particulate organic nitrogen. our estimates of n2 fixation is a useful step toward reducing the uncertainty in the nitrogen budget."
        },
        {
            "id": "R141328",
            "label": "High new production in the Bay of Bengal: Possible causes and implications",
            "doi": "10.1029/2004GL021005",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R140582",
                    "label": "Nitrogen uptake rates assessment in the Indian Ocean"
                }
            ],
            "abstract": "we report the first measurements of new production (15n tracer technique), the component of primary production that sustains on extraneous nutrient inputs to the euphotic zone, in the bay of bengal. experiments done in two different seasons consistently show high new production (averaging around 4 mmol n m\u22122 d\u22121 during post monsoon and 5.4 mmol n m\u22122 d\u22121 during pre monsoon), validating the earlier conjecture of high new production, based on pco2 measurements, in the bay. averaged over annual time scales, higher new production could cause higher rate of removal of organic carbon. this could also be one of the reasons for comparable organic carbon fluxes observed in the sediment traps of the bay of bengal and the eastern arabian sea. thus, oceanic regions like bay of bengal may play a more significant role in removing the excess co2 from the atmosphere than hitherto believed."
        },
        {
            "id": "R141337",
            "label": "Nitrogen Uptake in the Northeastern Arabian Sea during Winter Cooling",
            "doi": "10.1155/2010/819029",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R140582",
                    "label": "Nitrogen uptake rates assessment in the Indian Ocean"
                }
            ],
            "abstract": "the uptake of dissolved inorganic nitrogen by phytoplankton is an important aspect of the nitrogen cycle of oceans. here, we present nitrate ( n o 3 - ) and ammonium ( n h 4 + ) uptake rates in the northeastern arabian sea using 15 n tracer technique. in this relatively underexplored region, productivity is high during winter due to supply of nutrients by convective mixing caused by the cooling of the surface by the northeast monsoon winds. studies done during different months (january and late february-early march) of the northeast monsoon 2003 revealed a fivefold increase in the average euphotic zone integrated n o 3 - uptake from january (2.3\\u2009mmoln m \u2212 2 d \u2212 1 ) to late february-early march (12.7\\u2009mmoln m \u2212 2 d \u2212 1 ). the f -ratio during january appeared to be affected by the winter cooling effect and increased by more than 50% from the southernmost station to the northern open ocean stations, indicating hydrographic and meteorological control. estimates of n o 3 - residence time suggested that n o 3 - entrained in the water column during january contributed to the development of blooms during late february-early march."
        },
        {
            "id": "R141340",
            "label": "Quantification of new production during a winterNoctiluca scintillansbloom in the Arabian Sea",
            "doi": "10.1029/2008GL033819",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R140582",
                    "label": "Nitrogen uptake rates assessment in the Indian Ocean"
                }
            ],
            "abstract": "we present new data on the nitrate (new production), ammonium, urea uptake rates and f\u2010ratios for the eastern arabian sea (10\u00b0 to 22\u00b0n) during the late winter (northeast) monsoon, 2004, including regions of green noctilucascintillans bloom. a comparison of n\u2010uptake rates of the noctiluca dominated northern zone to the southern non\u2010bloom zone indicates the presence of two biogeochemical regimes during the late winter monsoon: highly productive north and less productive south. the conservative estimates of photic zone\u2010integrated total n\u2010uptake and f\u2010ratio are high in the north (\u223c19 mmolnm\u22122d\u22121 and 0.82, respectively) during the bloom and low (\u223c5.5 mmolnm\u22122d\u22121 and 0.38 respectively) in the south. the present and earlier data imply persistence of high n\u2010uptake and f\u2010ratio during blooms year after year. this quantification of the enhanced seasonal sequestration of carbon is an important input to global biogeochemical models."
        },
        {
            "id": "R3000",
            "label": "A model for contextual data sharing in smartphone applications",
            "doi": "10.1108/ijpcc-06-2016-0030",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R3006",
                    "label": "contextual data"
                }
            ],
            "abstract": "\\n purpose \\n the purpose of this paper is to introduce a model for identifying, storing and sharing contextual information across smartphone apps that uses the native device services. the authors present the idea of using user input and interaction within an app as contextual information, and how each app can identify and store contextual information. \\n \\n \\n design/methodology/approach \\n contexts are modeled as hierarchical objects that can be stored and shared by applications using native mechanisms. a proof-of-concept implementation of the model for the android platform demonstrates contexts modelled as hierarchical objects stored and shared by applications using native mechanisms. \\n \\n \\n findings \\n the model was found to be practically viable by implemented sample apps that share context and through a performance analysis of the system. \\n \\n \\n practical implications \\n the contextual data-sharing model enables the creation of smart apps and services without being tied to any vendor\u2019s cloud services. \\n \\n \\n originality/value \\n this paper introduces a new approach for sharing context in smartphone applications that does not require cloud services. \\n"
        },
        {
            "id": "R3021",
            "label": "TIB's Portal for Audiovisual Media: Combining Manual and Automatic Indexing",
            "doi": "10.1080/01639374.2014.917135",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R74000",
                    "label": "Multimedia indexing"
                }
            ],
            "abstract": "\"the german national library of science and technology (tib) developed a web-based platform for audiovisual media. the audiovisual portal optimizes access to scientific videos such as computer animations and lecture and conference recordings. tib's av-portal combines traditional cataloging and automatic indexing of audiovisual media. the article describes metadata standards for audiovisual media and introduces the tib's metadata schema in comparison to other metadata standards for non-textual materials. additionally, we give an overview of multimedia retrieval technologies used for the portal and present the av-portal in detail as well as the additional value for libraries and their users.\""
        },
        {
            "id": "R34944",
            "label": "A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications",
            "doi": "10.1109/TKDE.2018.2807452",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R34952",
                    "label": "Problem settings of graph embedding"
                },
                {
                    "id": "R34953",
                    "label": "Graph embedding techniques"
                },
                {
                    "id": "R34954",
                    "label": "Graph embedding enabled applications"
                }
            ],
            "abstract": "graph is an important data representation which appears in a wide diversity of real-world scenarios. effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. however, most graph analytics methods suffer the high computation and space cost. graph embedding is an effective yet efficient way to solve the graph analytics problem. it converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. in this survey, we conduct a comprehensive review of the literature in graph embedding. we first introduce the formal definition of graph embedding as well as the related concepts. after that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work addresses these challenges in their solutions. finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques, and application scenarios."
        },
        {
            "id": "R36001",
            "label": "SemEval-2018 Task 7: Semantic Relation Extraction and Classification\n            in Scientific Papers",
            "doi": "10.18653/v1/s18-1111",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R36007",
                    "label": "scientific relation classification"
                },
                {
                    "id": "R36008",
                    "label": "scientific relation extraction"
                },
                {
                    "id": "R36009",
                    "label": "scientific relation identification"
                }
            ],
            "abstract": "this paper describes the first task on semantic relation extraction and classification in scientific paper abstracts at semeval 2018. the challenge focuses on domain-specific semantic relations and includes three different subtasks. the subtasks were designed so as to compare and quantify the effect of different pre-processing steps on the relation classification results. we expect the task to be relevant for a broad range of researchers working on extracting specialized knowledge from domain corpora, for example but not limited to scientific or bio-medical information extraction. the task attracted a total of 32 participants, with 158 submissions across different scenarios."
        },
        {
            "id": "R38016",
            "label": "SMDM: enhancing enterprise-wide master data management using semantic web technologies",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"motivated by evolving business requirements and novel enterprise applications, we propose and implement the semantic master data management (smdm), a semantics-level enhancement to the existing mdm solutions. the smdm system publishes relational-based master data as virtual rdf store, and injects instantaneous reasoning capabilities into semantic queries. two kinds of ontologies are introduced to the system, the core mdm ontology and the external imported domain ontology. smdm enables data linking among multi-domains, implicit relationship discovery, and declarative definition and extension of business policies and entities. based on these functions, modern companies can customize their applications and services on demand within the mdm hub. in the demonstration, we build the system environment based on ibm's mdm solution, and run the use cases on the master data of an insurance company.\""
        },
        {
            "id": "R38043",
            "label": "Semantic federation of product information from structured and unstructured sources",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "product-related information can be found in various data sources and formats across the product lifecycle. effectively exploiting this information requires the federation of these sources, the extraction of implicit information, and the efficient access to this comprehensive knowledge base. existing solutions for product information management (pim) are usually restricted to structured information, but most of the business-critical information resides in unstructured documents. we present a generic architecture for federating heterogeneous information from various sources, including the internet of things, and argue how this process benefits from using semantic representations. a reference implementation tailor-made to business users is explained and evaluated. we also discuss several issues we experienced that we believe to be valuable for researchers and implementers of semantic information systems, as well as the information retrieval community."
        },
        {
            "id": "R38049",
            "label": "Explorations in the use of semantic web technologies for product information management",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "master data refers to core business entities a company uses repeatedly across many business processes and systems (such as lists or hierarchies of customers, suppliers, accounts, products, or organizational units). product information is the most important kind of master data and product information management (pim) is becoming critical for modern enterprises because it provides a rich business context for various applications. existing pim systems are less flexible and scalable for on-demand business, as well as too weak to completely capture and use the semantics of master data. this paper explores how to use semantic web technologies to enhance a collaborative pim system by simplifying modeling and representation while preserving enough dynamic flexibility. furthermore, we build a semantic pim system using one of the state-of-art ontology repositories and summarize the challenges we encountered based on our experimental results, especially on performance and scalability. we believe that our study and experiences are valuable for both semantic web community and master data management community."
        },
        {
            "id": "R38066",
            "label": "Ontology-based exchange of product data semantics",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "an increasing trend toward product development in a collaborative environment has resulted in the use of various software tools to enhance the product design. this requires a meaningful representation and exchange of product data semantics across different application domains. this paper proposes an ontology-based framework to enable such semantic interoperability. a standards-based approach is used to develop a product semantic representation language (psrl). formal description logic (daml+oil) is used to encode the psrl. mathematical logic and corresponding reasoning is used to determine semantic equivalences between an application ontology and the psrl. the semantic equivalence matrix enables resolution of ambiguities created due to differences in syntaxes and meanings associated with terminologies in different application domains. successful semantic interoperability will form the basis of seamless communication and thereby enable better integration of product development systems. note to practitioners-semantic interoperability of product information refers to automating the exchange of meaning associated with the data, among information resources throughout the product development. this research is motivated by the problems in enabling such semantic interoperability. first, product information is formalized into an explicit, extensible, and comprehensive product semantics representation language (psrl). the psrl is open and based on standard w3c constructs. next, in order to enable semantic translation, the paper describes a procedure to semi-automatically determine mappings between exactly equivalent concepts across representations of the interacting applications. the paper demonstrates that this approach to translation is feasible, but it has not yet been implemented commercially. current limitations and the directions for further research are discussed. future research addresses the determination of semantic similarities (not exact equivalences) between the interacting information resources."
        },
        {
            "id": "R38074",
            "label": "OntoIMM: An Ontology for Product Intelligent Master Model",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "information organizing principle is one of the key issues of intelligent master model (imm), which is an enhancement of the master model (mm) based on kbe (knowledge-based engineering). despite the fact that the core product model (cpm) has been confirmed to be an organizing mechanism for product master model, the key issue of supporting the information organizing for imm is not yet well addressed, mainly due to the following two reasons; (1) lack of representation of complete information and knowledge with regard to product and process, including the know-why, know-how, and know-what information and knowledge, and (2) lack of semantic richness. therefore, a multiaspect extension to cpm was first defined, and then an ontology was constructed to represent the information and design knowledge. the extension refers to adding a design process model, context model, product control structure model, and design rationale model to cpm concerning the enhancement of master model, which is to comprehensively represent the reason, process, and result information and knowledge of theproduct. the ontology construction refers to representing the concepts, relationships among these concepts and consistency rules of imm information structure. finally, an example of barrel design and analysis process is illustrated to verify the effectiveness of proposed method."
        },
        {
            "id": "R38493",
            "label": "Current Challenges for Studying Search as Learning Processes",
            "doi": "10.2352/issn.2470-1173.2017.6.mobmu-302",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "search of resources and information is among the most frequent activities on the web. while established information retrieval approaches address the relevance of search results to an information need, the actual learning scope of a user is normally disregarded. recent research in the search as learning (sal) area has recognized the importance of learning scopes and focused on observing and detecting learning needs. the article at hand takes a critical look at existing works in sal and related research disciplines. it aims to give a concise, interdisplinary overview which allows for the deduction of possible directions and necessary actions for prospective research works. it becomes apparent that past research employs a strong emphasis on textual resources, neglecting the diversity of online multimedia contents for learning and the impact of multimodal features on the learning process. we argue that exploring multimodal learning resources should be one focus of future sal projects."
        },
        {
            "id": "R12186",
            "label": "Direct Electrolytic Reduction of Solid Silicon Dioxide in Molten LiCl\u2013KCl\u2013CaCl[sub 2] at 773\u2002K",
            "doi": "10.1149/1.2042910",
            "research_field": {
                "id": "R128",
                "label": "Inorganic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R12190",
                    "label": "SiO2 deoxidation"
                }
            ],
            "abstract": "we investigated electrolytic reduction of solid sio 2 by a contacting electrode method in molten licl-kcl-cacl 2 at 773 k. the results of cyclic voltammetry indicated that reduction of sio 2 occurs at potential more negative than 0.85 v (vs ca 2 + , li + /ca-li). samples were prepared by potentiostatic electrolysis for 2 h at 0.25, 0.50, 0.70, and 1.00 v. energy dispersive x-ray analysis and raman spectra clarified that the reduction products at 0.50 and 0.70 v are composed of amorphous si and microcrystalline si. scanning electron microscope (sem) observations revealed that the morphology of the produced si is spongelike with a particle size smaller than 50 nm. the mechanism of si formation was discussed by comparing the sem observations and the raman spectra of the si samples prepared at 773 and 1123 k. the reduction mechanism of the direct electrolytic reduction of sio 2 at lower temperature was also discussed."
        },
        {
            "id": "R160606",
            "label": "Etching Silicon with Aqueous Acidic Ozone Solutions: Reactivity Studies and Surface Investigations",
            "doi": "10.1021/acs.jpcc.6b06332",
            "research_field": {
                "id": "R128",
                "label": "Inorganic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R160610",
                    "label": "Etching of silicon"
                }
            ],
            "abstract": "aqueous acidic ozone (o3)-containing solutions are increasingly used for silicon treatment in photovoltaic and semiconductor industries. we studied the behavior of aqueous hydrofluoric acid (hf)-containing solutions (i.e., hf\u2013o3, hf\u2013h2so4\u2013o3, and hf\u2013hcl\u2013o3 mixtures) toward boron-doped solar-grade (100) silicon wafers. the solubility of o3 and etching rates at 20 \u00b0c were investigated. the mixtures were analyzed for the potential oxidizing species by uv\u2013vis and raman spectroscopy. concentrations of o3\\xa0(aq), o3\\xa0(g), and cl2\\xa0(aq) were determined by titrimetric volumetric analysis. f\u2013, cl\u2013, and so42\u2013 ion contents were determined by ion chromatography. model experiments were performed to investigate the oxidation of h-terminated silicon surfaces by h2o\u2013o2, h2o\u2013o3, h2o\u2013h2so4\u2013o3, and h2o\u2013hcl\u2013o3 mixtures. the oxidation was monitored by diffuse reflection infrared fourier transformation (drift) spectroscopy. the resulting surfaces were examined by scanning electron microscopy (sem) and x-ray photoelectron spectrosc..."
        },
        {
            "id": "R160677",
            "label": "An improved TMAH Si-etching solution without attacking exposed aluminum",
            "doi": "10.1016/s0924-4247(00)00546-x",
            "research_field": {
                "id": "R128",
                "label": "Inorganic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R160610",
                    "label": "Etching of silicon"
                }
            ],
            "abstract": "in this paper, an improved tetramethyl ammonium hydroxide (tmah) etching method is reported. the process features higher silicon etching rate and results in smooth silicon surface and at the same time, no significant aluminum etching is observed. we believe that after tmah etching the aluminum surface is protected by the coating of by-products, which prevents etching of the underlying aluminum films by the tmah solution. the etchant used in the study consists of 5 wt.% tmah solution, 1.4 wt.% (or above) dissolved silicon, and 0.4-0.7 wt.% (nh/sub 4/)/sub 2/s/sub 2/o/sub 8/ oxidant additive. silicon etching rate of 0.9-1.0 /spl mu/m/min and zero aluminum etching rate is be achieved using the process. moreover the silicon surface remains smooth after etching. the etching process demonstration in this work is readily applicable to mems device fabrication such as polysilicon like sacrificial layer removal after metallization is completed."
        },
        {
            "id": "R43000",
            "label": "Pattern Based Model Reuse Using Colored Petri Nets",
            "doi": "10.1109/iccsa.2019.000-7",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R43003",
                    "label": "Model Composability"
                }
            ],
            "abstract": "colored petri net (cpn) is a graphical modeling language for simulation and modeling and for verification of discrete event systems. cpn allows developers to define a model in the form of reusable components. a model component is an independent element, which is specified using a formalized description, can conform to a certain component standard, has a well-defined interface, and encapsulates certain behavior. modern components can help the developer reuse existing models according to their requirement as it reduces the cost and time of development. composability is the capability to select and integrate various components to fulfill user requirements. composability provides the means to achieve reusability where \"reuse\" is the ability of a simulation component to be reclaimed for various applications. we propose a verification framework for developers to select and assemble cpn-based components and verify their composability. the goal of this paper is to provide a pattern which helps developer in making models of concurrent systems. we present a case study of a restaurant model as proof of concept. a verified composition affirms reuse of model components in a meaningful manner by satisfying given requirement specifications."
        },
        {
            "id": "R49480",
            "label": "Software Architecture Optimization Methods: A Systematic Literature Review",
            "doi": "10.1109/tse.2012.64",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R49485",
                    "label": "Automated design space exploration"
                },
                {
                    "id": "R49487",
                    "label": "Software architecture optimization"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "due to significant industrial demands toward software systems with increasing complexity and challenging quality requirements, software architecture design has become an important development activity and the research domain is rapidly evolving. in the last decades, software architecture optimization methods, which aim to automate the search for an optimal architecture design with respect to a (set of) quality attribute(s), have proliferated. however, the reported results are fragmented over different research communities, multiple system domains, and multiple quality attributes. to integrate the existing research results, we have performed a systematic literature review and analyzed the results of 188 research papers from the different research communities. based on this survey, a taxonomy has been created which is used to classify the existing research. furthermore, the systematic analysis of the research literature provided in this review aims to help the research community in consolidating the existing research efforts and deriving a research agenda for future developments."
        },
        {
            "id": "R53034",
            "label": "MODELING SAFEST AND OPTIMAL EMERGENCY EVACUATION PLAN FOR LARGE-SCALE PEDESTRIANS ENVIRONMENTS",
            "doi": "10.1109/wsc.2018.8632418",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R53039",
                    "label": "crowd safety"
                }
            ],
            "abstract": "large-scale events are always vulnerable to natural disasters and man-made chaos which poses great threat to crowd safety. such events need an appropriate evacuation plan to alleviate the risk of causalities. we propose a modeling framework for large-scale evacuation of pedestrians during emergency situation. proposed framework presents optimal and safest path evacuation for a hypothetical large-scale crowd scenario. the main aim is to provide the safest and nearest evacuation path because during disastrous situations there is possibility of exit gate blockade and directions of evacuees may have to be changed at run time. for this purpose run time diversions are given to evacuees to ensure their quick and safest exit. in this work, different evacuation algorithms are implemented and compared to determine the optimal solution in terms of evacuation time and crowd safety. the recommended framework incorporates anylogic simulation environment to design complex spatial environment for large-scale pedestrians as agents."
        },
        {
            "id": "R152014",
            "label": "From scenario modeling to scenario programming for reactive systems with dynamic topology",
            "doi": "10.1145/3106237.3122827",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "software-intensive systems often consist of cooperating reactive components. in mobile and reconfigurable systems, their topology changes at run-time, which influences how the components must cooperate. the scenario modeling language (sml) offers a formal approach for specifying the reactive behavior such systems that aligns with how humans conceive and communicate behavioral requirements. simulation and formal checks can find specification flaws early. we present a framework for the scenario-based programming (sbp) that reflects the concepts of sml in java and makes the scenario modeling approach available for programming. sbp code can also be generated from sml and extended with platform-specific code, thus streamlining the transition from design to implementation. as an example serves a car-to-x communication system. demo video and artifact: http://scenariotools.org/esecfse-2017-tool-demo/"
        },
        {
            "id": "R152020",
            "label": "A Scenario-based MDE Process for Developing Reactive Systems: A Cleaning Robot Example",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper presents the scenariotools solution for developing a cleaning robot system, an instance of the rover problem of the mde tools challenge 2017. we present an mde process that consists of (1) the modeling of the system behavior as a scenario-based assume-guarantee specification with sml (scenario modeling language), (2) the formal realizabilitychecking and verification of the specification, (3) the generation of sbp (scenario-based programming) java code from the sml specification, and, finally, (4) adding platform-specific code to connect specification-level events with platform-level sensorand actuator-events. the resulting code can be executed on a raspberrypi-based robot. the approach is suited for developing reactive systems with multiple cooperating components. its strength is that the scenario-based modeling corresponds closely to how humans conceive and communicate behavioral requirements. sml in particular supports the modeling of environment assumptions and dynamic component structures. the formal checks ensure that the system satisfies its specification."
        },
        {
            "id": "R159789",
            "label": "The Potential of Using Vision Videos for CrowdRE: Video Comments as a Source of Feedback",
            "doi": "10.1109/REW53955.2021.00053",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "vision videos are established for soliciting feedback and stimulating discussions in requirements engineering (re) practices such as focus groups. different researchers motivated the transfer of these benefits into crowd-based re (crowdre) by using vision videos on social media platforms. so far, however, little research explored the potential of using vision videos for crowdre in detail. in this paper, we analyze and assess this potential, in particular, focusing on video comments as a source of feedback. in a case study, we analyzed 4505 comments on a vision video from youtube. we found that the video solicited 2770 comments from 2660 viewers in four days. this is more than 50% of all comments the video received in four years. even though only a certain fraction of these comments are relevant to re, the relevant comments address typical intentions and topics of user feedback, such as feature request or problem report. besides the typical user feedback categories, we found more than 300 comments that address the topic safety which has not appeared in previous analyses of user feedback. in an automated analysis, we compared the performance of three machine learning algorithms on classifying the video comments. despite certain differences, the algorithms classified the video comments well. based on these findings, we conclude that the use of vision videos for crowdre has a large potential. despite the preliminary nature of the case study, we are optimistic that vision videos can motivate stakeholders to actively participate in a crowd and solicit numerous of video comments as a valuable source of feedback."
        },
        {
            "id": "R159793",
            "label": "Viewing Vision Videos Online: Opportunities for Distributed Stakeholders",
            "doi": "10.1109/rew53955.2021.00054",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "creating shared understanding between stakeholders is essential for the success of software projects. conflicting requirements originating from misaligned mental models can hinder the development process. the use of videos to present abstract system visions is one approach to counteract this problem. these videos are usually shown in in-person meetings. however, face-to-face meetings are not suited to every situation and every stakeholder, for example due to scheduling constraints. methods for the use of vision videos in online settings are necessary. furthermore, methods enabling an asynchronous use of vision videos are needed for cases when conjoined meetings are impossible even in an online setting.in this paper, we compare synchronous and asynchronous viewings of vision videos in online settings. the two methods are piloted in a preliminary experiment. the results show a difference in the amount of arguments regarding the presented visions. on average, participants who took part in asynchronous meetings stated more arguments. our results point to multiple advantages and disadvantages as well as use cases for each type. for example, a synchronous meeting could be chosen when all involved stakeholders can attend the appointment to discuss the vision and to quickly resolve ambiguities. an asynchronous meeting could be held if a joint meeting is not feasible due to time constraints. we also discuss how our findings can be applied to the elicitation of requirements from a crowd of stakeholders."
        },
        {
            "id": "R74509",
            "label": "Mapping human values and scrum roles: a study on students' preferences",
            "doi": "10.1145/3387940.3391467",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R74528",
                    "label": "connection of human values and Scrum roles"
                }
            ],
            "abstract": "\"despite the long tradition on the study of human values, the impact of this field in the software engineering domain is rarely studied. to these regards, this study focuses on applying human values to agile software development process, more specifically to scrum roles. thus, the goal of the study is to explore possible associations between human values and scrum roles preferences among students. questionnaires are designed by employing the short schwartz's value survey and are distributed among 57 students. the results of the quantitative analysis process consisting of descriptive statistics, linear regression models and pearson correlation coefficients, revealed that values such as power and self-direction influence the preference for the product owner role, the value of hedonism influences the preference for scrum masters and self-direction is associated with team members' preference.\""
        },
        {
            "id": "R74516",
            "label": "Measuring human values in software engineering",
            "doi": "10.1145/3239235.3267427",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R74524",
                    "label": "measuring human values in software engineering"
                }
            ],
            "abstract": "\"background: human values, such as prestige, social justice, and financial success, influence software production decision-making processes. while their subjectivity makes some values difficult to measure, their impact on software motivates our research. aim: to contribute to the scientific understanding and the empirical investigation of human values in software engineering (se). approach: drawing from social psychology, we consider values as mental representations to be investigated on three levels: at a system (l1), personal (l2), and instantiation level (l3). method: we design and develop a selection of tools for the investigation of values at each level, and focus on the design, development, and use of the values q-sort. results: from our study with 12 software practitioners, it is possible to extract three values `prototypes' indicative of an emergent typology of values considerations in se. conclusions: the values q-sort generates quantitative values prototypes indicating values relations (l1) as well as rich personal narratives (l2) that reflect specific software practices (l3). it thus offers a systematic, empirical approach to capturing values in se.\""
        },
        {
            "id": "R74547",
            "label": "Supporting Requirements Elicitation by Tool-Supported Video Analysis",
            "doi": "10.1109/re.2016.10",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R74566",
                    "label": "Applying videos as a by-product of requirements engineering practices"
                },
                {
                    "id": "R74627",
                    "label": "Validating the benefit of videos as a by-product of requirements engineering practices"
                },
                {
                    "id": "R172543",
                    "label": "Video production and application"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"workshops are an established technique for requirements elicitation. a lot of information is revealed during a workshop, which is generally captured via textual minutes. the scribe suffers from a cognitive overload due to the difficulty of gathering all information, listening and writing at the same time. video recording is used as additional option to capture more information, including non-verbal gestures. since a workshop can take several hours, the recorded video will be long and may be disconnected from the scribe's notes. therefore, the weak and unclear structure of the video complicates the access to the recorded information, for example in subsequent requirements engineering activities. we propose the combination of textual minutes and video with a software tool. our objective is connecting textual notes with the corresponding part of the video. by highlighting relevant sections of a video and attaching notes that summarize those sections, a more useful structure can be achieved. this structure allows an easy and fast access to the relevant information and their corresponding video context. thus, a scribe's overload can be mitigated and further use of a video can be simplified. tool-supported analysis of such an enriched video can facilitate the access to all communicated information of a workshop. this allows an easier elicitation of high-quality requirements. we performed a preliminary evaluation of our approach in an experimental set-up with 12 participants. they were able to elicit higher-quality requirements with our software tool.\""
        },
        {
            "id": "R74688",
            "label": "Video as a By-Product of Digital Prototyping: Capturing the Dynamic Aspect of Interaction",
            "doi": "10.1109/rew.2017.16",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R74566",
                    "label": "Applying videos as a by-product of requirements engineering practices"
                },
                {
                    "id": "R74627",
                    "label": "Validating the benefit of videos as a by-product of requirements engineering practices"
                },
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "requirements engineering provides several practices to analyze how a user wants to interact with a future software. mockups, prototypes, and scenarios are suitable to understand usability issues and user requirements early. nevertheless, users are often dissatisfied with the usability of a resulting software. apparently, previously explored information was lost or no longer accessible during the development phase.scenarios are one effective practice to describe behavior. however, they are commonly notated in natural language which is often improper to capture and communicate interaction knowledge comprehensible to developers and users. the dynamic aspect of interaction is lost if only static descriptions are used. digital prototyping enables the creation of interactive prototypes by adding responsive controls to hand-or digitally drawn mockups. we propose to capture the events of these controls to obtain a representation of the interaction. from this data, we generate videos, which demonstrate interaction sequences, as additional support for textual scenarios.variants of scenarios can be created by modifying the captured event sequences and mockups. any change is unproblematic since videos only need to be regenerated. thus, we achieve video as a by-product of digital prototyping. this reduces the effort compared to video recording such as screencasts. a first evaluation showed that such a generated video supports a faster understanding of a textual scenario compared to static mockups."
        },
        {
            "id": "R75426",
            "label": "Security and Cryptographic Challenges for Authentication Based on Biometrics Data",
            "doi": "10.3390/cryptography2040039",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R46008",
                    "label": "Programming computers to recognize human Faces"
                },
                {
                    "id": "R46031",
                    "label": "Deepl Learning in 3D face recognition"
                },
                {
                    "id": "R53453",
                    "label": "How can we adopt machine learning and/or artificial intelligence to analyze the data for Earth science and applications?"
                },
                {
                    "id": "R68417",
                    "label": "to update the exist findings about the face-to-face and online methods to provide infomraiton literacy training in universities"
                },
                {
                    "id": "R75091",
                    "label": "state-of-the-art approaches and a variety of applications"
                }
            ],
            "abstract": "authentication systems based on biometrics characteristics and data represents one of the most important trend in the evolution of the society, e.g., smart city, internet-of-things (iot), cloud computing, big data. in the near future, biometrics systems will be everywhere in the society, such as government, education, smart cities, banks etc. due to its uniqueness, characteristic, biometrics systems will become more and more vulnerable, privacy being one of the most important challenges. the classic cryptographic primitives are not sufficient to assure a strong level of secureness for privacy. the current paper has several objectives. the main objective consists in creating a framework based on cryptographic modules which can be applied in systems with biometric authentication methods. the technologies used in creating the framework are: c#, java, c++, python, and haskell. the wide range of technologies for developing the algorithms give the readers the possibility and not only, to choose the proper modules for their own research or business direction. the cryptographic modules contain algorithms based on machine learning and modern cryptographic algorithms: aes (advanced encryption system), sha-256, rc4, rc5, rc6, mars, blowfish, twofish, threefish, rsa (rivest-shamir-adleman), elliptic curve, and diffie hellman. as methods for implementing with success the cryptographic modules, we will propose a methodology which can be used as a how-to guide. the article will focus only on the first category, machine learning, and data clustering, algorithms with applicability in the cloud computing environment. for tests we have used a virtual machine (virtual box) with apache hadoop and a biometric analysis tool. the weakness of the algorithms and methods implemented within the framework will be evaluated and presented in order for the reader to acknowledge the latest status of the security analysis and the vulnerabilities founded in the mentioned algorithms. another important result of the authors consists in creating a scheme for biometric enrollment (in results). the purpose of the scheme is to give a big overview on how to use it, step by step, in real life, and how to use the algorithms. in the end, as a conclusion, the current work paper gives a comprehensive background on the most important and challenging aspects on how to design and implement an authentication system based on biometrics characteristics."
        },
        {
            "id": "R75435",
            "label": "MapReduce: simplified data processing on large clusters",
            "doi": "10.1145/1327452.1327492",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\" \\n mapreduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. users specify the computation in terms of a\\n map \\n and a\\n reduce \\n function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. programmers find the system easy to use: more than ten thousand distinct mapreduce programs have been implemented internally at google over the past four years, and an average of one hundred thousand mapreduce jobs are executed on google's clusters every day, processing a total of more than twenty petabytes of data per day.\\n \""
        },
        {
            "id": "R76341",
            "label": "The Crowd in Requirements Engineering: The Landscape and Challenges",
            "doi": "10.1109/ms.2017.33",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R76156",
                    "label": "Focus of Crowd-based Requirements Engineering"
                }
            ],
            "abstract": "crowd-based requirements engineering (crowdre) could significantly change re. performing re activities such as elicitation with the crowd of stakeholders turns re into a participatory effort, leads to more accurate requirements, and ultimately boosts software quality. although any stakeholder in the crowd can contribute, crowdre emphasizes one stakeholder group whose role is often trivialized: users. crowdre empowers the management of requirements, such as their prioritization and segmentation, in a dynamic, evolved style through collecting and harnessing a continuous flow of user feedback and monitoring data on the usage context. to analyze the large amount of data obtained from the crowd, automated approaches are key. this article presents current research topics in crowdre; discusses the benefits, challenges, and lessons learned from projects and experiments; and assesses how to apply the methods and tools in industrial contexts. this article is part of a special issue on crowdsourcing for software engineering."
        },
        {
            "id": "R108344",
            "label": "How We Refactor, and How We Know It",
            "doi": "10.1109/tse.2011.41",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R108353",
                    "label": "How frequently are refactoring operations applied?"
                },
                {
                    "id": "R108354",
                    "label": "How frequently are refactoring operations applied manually versus with automated tools?"
                }
            ],
            "abstract": "much of what we know about how programmers refactor in the wild is based on studies that examine just a few software projects. researchers have rarely taken the time to replicate these studies in other contexts or to examine the assumptions on which they are based. to help put refactoring research on a sound scientific basis, we draw conclusions using four data sets spanning more than 13 000 developers, 240 000 tool-assisted refactorings, 2500 developer hours, and 3400 version control commits. using these data, we cast doubt on several previously stated assumptions about how programmers refactor, while validating others. for example, we find that programmers frequently do not indicate refactoring activity in commit logs, which contradicts assumptions made by several previous researchers. in contrast, we were able to confirm the assumption that programmers do frequently intersperse refactoring with other program changes. by confirming assumptions and replicating studies made by other researchers, we can have greater confidence that those researchers' conclusions are generalizable."
        },
        {
            "id": "R108347",
            "label": "The Usability (or Not) of Refactoring Tools",
            "doi": "10.1109/saner50967.2021.00030",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R108355",
                    "label": "How can the usability of refactoring tools be improved?"
                }
            ],
            "abstract": "although software developers typically have access to numerous refactoring tools, most developers avoid using these tools despite their benefits. researchers have identified many reasons for the disuse of refactoring tools, including a lack of awareness by the developers, a lack of predictability of the tools, and a lack of need for the tools. in this paper, we build on this earlier work and employ the iso 9241-11 definition of usability to develop a theory of usability for refactoring tools. we investigate existing refactoring tools using this theory by analyzing how 17 developers experience refactoring tools in three software change tasks we asked them to perform. we analyze qualitatively the resulting interview transcripts based on our theory and report on a number of observations that can inform tool designers interested in improving the usability of refactoring tools. for instance, we found a desire for developers to guide how a refactoring tool changes the code and a need for refactoring tools to describe changes made to developers. refactoring tools are currently expected to preserve program behavior. these observations indicate that it may be necessary to give developers more control over this property, including the ability to relax it, for the tools to be usable; that is, for the tools to be effective, efficient and satisfying for the developer to employ."
        },
        {
            "id": "R108350",
            "label": "Improving Usability of Software Refactoring Tools",
            "doi": "10.1109/aswec.2007.24",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R108355",
                    "label": "How can the usability of refactoring tools be improved?"
                }
            ],
            "abstract": "\"post-deployment maintenance and evolution can account for up to 75% of the cost of developing a software system. software refactoring can reduce the costs associated with evolution by improving system quality. although refactoring can yield benefits, the process includes potentially complex, error-prone, tedious and time-consuming tasks. it is these tasks that automated refactoring tools seek to address. however, although the refactoring process is well-defined, current refactoring tools do not support the full process. to develop better automated refactoring support, we have completed a usability study of software refactoring tools. in the study, we analysed the task of software refactoring using the iso 9241-11 usability standard and fitts' list of task allocation. expanding on this analysis, we reviewed 11 collections of usability guidelines and combined these into a single list of 38 guidelines. from this list, we developed 81 usability requirements for refactoring tools. using these requirements, the software refactoring tools eclipse 3.2, condenser 1.05, refactorit 2.5.1, and eclipse 3.2 with the simian ui 2.2.12 plugin were studied. based on the analysis, we have selected a subset of the requirements that can be incorporated into a prototype refactoring tool intended to address the full refactoring process.\""
        },
        {
            "id": "R135602",
            "label": "Model-Driven Architecture Based Software Development for Epidemiological Surveillance Systems",
            "doi": "10.3233/SHTI190279",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "epidemiological surveillance systems enable collection, analysis and dissemination of information on the monitored disease to different stakeholders. it may be done manually or using a software. given the poor performances of manual systems, the software approach is generally adopted. epidemiological surveillance systems are based on existing softwares, softwares developed from scratch given the specifications or softwares provided by a vendor. these solutions are not always suitable because epidemiological surveillance systems evolve quickly (new drugs, new treatment protocols, etc.), leading to software updates, which can take time (while waiting for a new version) and be expensive. in this article, we present the use of the model-driven architecture (mda) approach to model and generate epidemiological surveillance systems. the result is a complete mda based methodology and tool to develop epidemiological surveillance systems. the tool was used to model and generate softwares that are now used for epidemiological surveillance of tuberculosis in cameroon."
        },
        {
            "id": "R138070",
            "label": "Grand challenges in model-driven engineering: an analysis of the state of the research",
            "doi": "10.1007/s10270-019-00773-6",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R138074",
                    "label": "Automatic generation of source code"
                }
            ],
            "abstract": "abstract in 2017 and 2018, two events were held\u2014in marburg, germany, and san vigilio di marebbe, italy, respectively\u2014focusing on an analysis of the state of research, state of practice, and state of the art in model-driven engineering (mde). the events brought together experts from industry, academia, and the open-source community to assess what has changed in research in mde over the last 10\\xa0years, what challenges remain, and what new challenges have arisen. this article reports on the results of those meetings, and presents a set of grand challenges that emerged from discussions and synthesis. these challenges could lead to research initiatives for the community going forward.\\n"
        },
        {
            "id": "R175392",
            "label": "Automatically improve software architecture models for performance, reliability, and cost using evolutionary algorithms",
            "doi": "10.1145/1712605.1712624",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "R49485",
                    "label": "Automated design space exploration"
                },
                {
                    "id": "R49487",
                    "label": "Software architecture optimization"
                }
            ],
            "abstract": "quantitative prediction of quality properties (i.e. extra-functional properties such as performance, reliability, and cost) of software architectures during design supports a systematic software engineering approach. designing architectures that exhibit a good trade-off between multiple quality criteria is hard, because even after a functional design has been created, many remaining degrees of freedom in the software architecture span a large, discontinuous design space. in current practice, software architects try to find solutions manually, which is time-consuming, can be error-prone and can lead to suboptimal designs. we propose an automated approach to search the design space for good solutions. starting with a given initial architectural model, the approach iteratively modifies and evaluates architectural models. our approach applies a multi-criteria genetic algorithm to software architectures modelled with the palladio component model. it supports quantitative performance, reliability, and cost prediction and can be extended to other quantitative quality criteria of software architectures. we validate the applicability of our approach by applying it to an architecture model of a component-based business information system and analyse its quality criteria trade-offs by automatically investigating more than 1200 alternative design candidates."
        },
        {
            "id": "R193371",
            "label": "Automated recommendation of templates for legal requirements",
            "doi": "10.1109/RE48521.2020.00027",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "[context] in legal requirements elicitation, requirements analysts need to extract obligations from legal texts. however, legal texts often express obligations only indirectly, for example, by attributing a right to the counterpart. this phenomenon has already been described in the requirements engineering (re) literature [1]. [objectives] we investigate the use of requirements templates for the systematic elicitation of legal requirements. our work is motivated by two observations: (1) the existing literature does not provide a harmonized view on the requirements templates that are useful for legal re; (2) despite the promising recent advancements in natural language processing (nlp), automated support for legal re through the suggestion of requirements templates has not been achieved yet. our objective is to take steps toward addressing these limitations. [methods] we review and reconcile the legal requirement templates proposed in re. subsequently, we conduct a qualitative study to define nlp rules for template recommendation. [results and conclusions] our contributions consist of (a) a harmonized list of requirements templates pertinent to legal re, and (b) rules for the automatic recommendation of such templates. we evaluate our rules through a case study on 400 statements from two legal domains. the results indicate a recall and precision of 82,3% and 79,8%, respectively. we show that introducing some limited interaction with the analyst considerably improves accuracy. specifically, our human-feedback strategy increases recall by 12% and precision by 10,8%, thus yielding an overall recall of 94,3% and overall precision of 90,6%."
        },
        {
            "id": "R193385",
            "label": "The way it makes you feel predicting users\u2019 engagement during interviews with biofeedback and supervised learning",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "capturing users\u2019 engagement is crucial for gathering feedback about the features of a software product. in a market-driven context, current approaches to collect and analyze users\u2019 feedback are based on techniques leveraging information extracted from product reviews and social media. these approaches are hardly applicable in bespoke software development, or in contexts in which one needs to gather information from specific users. in such cases, companies need to resort to face-to-face interviews to get feedback on their products. in this paper, we propose to utilize biofeedback to complement interviews with information about the engagement of the user on the discussed features and topics. we evaluate our approach by interviewing users while gathering their biometric data using an empatica e4 wristband. our results show that we can predict users\u2019 engagement by training supervised machine learning algorithms on the biometric data. the results of our work can be used to facilitate the prioritization of product features and to guide the interview based on users\u2019 engagement."
        },
        {
            "id": "R193406",
            "label": "Theory as a source of software requirements",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "today, when undertaking requirements elicitation, engineers attend to the needs and wants of the user groups considered relevant for the software system. however, answers to some relevant question (e.g., how to improve adoption of the intended system) cannot always be addressed through direct need and want elicitation. using an example of energy demand-response systems, this paper demonstrates that use of grounded theory analysis can help address such questions. the theory emerging from such analysis produces a set of additional requirements which cannot be directly elicited from individuals/groups, and would otherwise be missed out. thus, we demonstrate that the theory generated through grounded theory analysis can serve as an additional valuable source of software system requirements."
        },
        {
            "id": "R193418",
            "label": "Voice of the users: A demographic study of software feedback behaviour",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "user feedback on mobile app stores, product forums, and on social media can contain product development insights. there has been a lot of recent research studying this feedback and developing methods to automatically extract requirement-related information. this feedback is generally considered to be the \u201cvoice of the users\u201d; however, only a subset of software users provide online feedback. if the demographics of the online feedback givers are not representative of the user base, this introduces the possibility of developing software that does not meet the needs of all users. it is, therefore, important to understand who provides online feedback to ensure the needs of underrepresented groups are not being missed.in this work, we directly survey 1040 software users about their feedback habits, software use, and demographic information. their responses indicate that there are statistically significant differences in who gives feedback on each online channel, with respect to traditional demographics (gender, age, etc). we also identify key differences in what motivates software users to engage with each of the three channels. our findings provide valuable context for requirements elicited from online feedback and show that considering information from all channels will provide a more comprehensive view of user needs."
        },
        {
            "id": "R193467",
            "label": "Cutting through the jungle: Disambiguating model-based traceability terminology",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "traceability, a classic requirements engineering topic, is increasingly used in the context of model-based engineering. however, researchers and practitioners lack a concise terminology to discuss aspects of requirements traceability in situations in which engineers heavily rely on models and model-based engineering. while others have previously surveyed the domain, no one has so far provided a clear, unambiguous set of terms that can be used to discuss traceability in such a context. we therefore set out to cut a path through the jungle of terminology for model-based traceability, ground it in established terminology from requirements engineering, and derive an unambiguous set of relevant terms. we also map the terminology used in existing primary and secondary studies to our taxonomy to show differences and commonalities. the contribution of this paper is thus a terminology for model-based traceability that allows requirements engineers and engineers working with models to unambiguously discuss their joint traceability efforts."
        },
        {
            "id": "R193473",
            "label": "Continual human value analysis in software development: A goal model based approach",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "software failures that demonstrate violations of human values can result in financial losses, reputation damages and social implications. therefore, integrating human values into software is vital to satisfy stakeholder needs. however, developing methodological approaches that allow systematic integration of human values throughout the software development life cycle is an open challenge. this paper proposes the continual value(s) assessment (cva) framework that uses extended goal and feature modeling techniques to support systematic integration, tracing and evaluation of human values in software systems. the cva framework prescribes (i) brainstorming of value implications of system features based on conventional system artefacts and (ii) the expansion of the existing set of system features to better serve stakeholder values expectations. in a pilot study, we use an emergency alarm system for the elderly to demonstrate the feasibility of the framework. we further discuss the challenges we faced while applying the framework and present the lessons learned from the pilot study."
        },
        {
            "id": "R193481",
            "label": "Extracting and classifying requirements from software engineering contracts",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper, we present our work on extracting and classifying requirements from large software engineering contracts. typically, the process of requirements elicitation begins after a contractual agreement is signed by all participants. our interactions with the legal compliance team in a large vendor organization reveal that business contracts can help in the identification of high-level requirements relevant to the success of software engineering projects. we posit that requirements engineering as a discipline has an even wider scope than software engineering of which it is traditionally considered to be a sub-discipline. this is because software engineering-specific requirements are but a part of the success story of any large project. the requirements that emerge from contracts are obligatory in nature, whether or not they pertain to core software development. therefore, it is important that these are extracted and classified for the benefit of software engineers and other stakeholders responsible for a project. we discuss the results of an exploratory study and a range of experiments from the use of regular expressions to bidirectional encoder representations from transformers for automating the extraction and classification of requirements from software engineering contracts. with bidirectional encoder representations from transformers, we obtained a high f-score of greater than eighty four percent for classification of requirements."
        },
        {
            "id": "R193490",
            "label": "Which app features are being used? Learning app feature usages from interaction data",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the dynamic and fast-growing app market, monitoring and understanding how past releases are actually being used is indispensable for successful app maintenance and evolution. current app usage analytics tools either log execution events, e.g., in stack traces, or general usage information such as the app activation time, location, and device. in this paper, we focus on analyzing the usages of the single app features as described in release notes and app pages. we suggest monitoring nine app-independent, privacy-friendly interaction events for training a machine learning model to learn app feature usages. we conducted a crowdsourcing study with 55 participants who labeled 5,815 feature usages of 170 unique apps for 18 days. our within-apps evaluation shows that we could achieve encouraging precision and recall values already with ten labeled feature usages. for certain popular features such as browse newsfeed or send an email, we achieved f1 values above 88%. betweenapps feature learning seems feasible with f1 values of up to 86%."
        },
        {
            "id": "R193898",
            "label": "A deep context-wise method for coreference detection in natural language requirements",
            "doi": "",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "requirements are usually written by different stakeholders with diverse backgrounds and skills and evolve continuously. therefore inconsistency caused by specialized jargons and different domains, is inevitable. in particular, entity coreference in requirement engineering (re) is that different linguistic expressions refer to the same real-world entity. it leads to misconception about technical terminologies, and impacts the readability and understandability of requirements negatively. manual detection entity coreference is labor-intensive and time-consuming. in this paper, we propose a deep context-wise semantic method named deepcoref to entity coreference detection. it consists of one fine-tuning bert model for context representation and a word2vec-based network for entity representation. we use a multi-layer perception in the end to fuse and make a trade-off between two representations for obtaining a better representation of entities. the input of the network is requirement contextual text and related entities, and the output is the predictive label to infer whether two entities are coreferent. the evaluation on industry data shows that our approach significantly outperforms three baselines with average precision and recall of 96.10% and 96.06% respectively. we also compare deepcoref with three variants to demonstrate the performance enhancement from different components."
        },
        {
            "id": "R193920",
            "label": "Same same but different: Finding similar user feedback across multiple platforms and languages",
            "doi": "10.1109/RE48521.2020.00017",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "users submit feedback about the software they use through application distributions platforms, i.e., app stores, and social media. previous research has found that this type of feedback contains valuable information for software evolution, such as bug reports, or feature requests. however, popular applications receive thousands of feedback entities per day, making their manual analysis unrealistic. in this work, we present an approach to automatically identify similar user feedback across different languages and platforms. at the core of the approach is a word aligner that aligns words based on their semantic similarity and the similarity of their local semantic contexts. additionally, we make use of machine translation, sentiment analysis, and text classification, to extract the sentiment polarity and content nature of user feedback written in different languages. we use the results of these components to compute a similarity score between user feedback pairs. we evaluated our approach on user feedback entities written in four different languages, and retrieved from five different mobile applications obtained from four different app stores and social networking sites. the obtained results are encouraging. compared to human assessment, the overall performance for monolingual user feedback pairs yielded a strong correlation of 0.79. for the crosslingual feedback pairs the correlation was also strong, with a value of 0.78."
        },
        {
            "id": "R193925",
            "label": "Trace link recovery using semantic relation graphs and spreading activation",
            "doi": "10.1109/RE48521.2020.00015",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "trace link recovery tries to identify and link related existing requirements with each other to support further engineering tasks. existing approaches are mainly based on algebraic information retrieval or machine-learning. machinelearning approaches usually demand reasonably large and labeled datasets to train. algebraic information retrieval approaches like distance between tf-idf scores also work on smaller datasets without training but are limited in providing explanations for trace links. in this work, we present a trace link recovery approach that is based on an explicit representation of the content of requirements as a semantic relation graph and uses spreading activation to answer trace queries over this graph. our approach is fully automated including an nlp pipeline to transform unrestricted natural language requirements into a graph. we evaluate our approach on five common datasets. depending on the selected configuration, the predictive power strongly varies. with the best tested configuration, the approach achieves a mean average precision of 40% and a lag of 50%. even though the predictive power of our approach does not outperform state-of-the-art approaches, we think that an explicit knowledge representation is an interesting artifact to explore in trace link recovery approaches to generate explanations and refine results."
        },
        {
            "id": "R39020",
            "label": "A data-driven assessment of early travel restrictions related to the spreading of the novel COVID-19 within mainland China",
            "doi": "10.1101/2020.03.05.20031740",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R39009",
                    "label": "Predicting the evolution of 2019-nCoV"
                }
            ],
            "abstract": "two months after it was firstly reported, the novel coronavirus disease covid-19 has already spread worldwide. however, the vast majority of reported infections have occurred in china. to assess the effect of early travel restrictions adopted by the health authorities in china, we have implemented an epidemic metapopulation model that is fed with mobility data corresponding to 2019 and 2020. this allows to compare two radically different scenarios, one with no travel restrictions and another in which mobility is reduced by a travel ban. our findings indicate that i) travel restrictions are an effective measure in the short term, however, ii) they are ineffective when it comes to completely eliminate the disease. the latter is due to the impossibility of removing the risk of seeding the disease to other regions. our study also highlights the importance of developing more realistic models of behavioral changes when a disease outbreak is unfolding."
        },
        {
            "id": "R41005",
            "label": "Mechanistic-statistical SIR modelling for early estimation of the actual number of cases and mortality rate from COVID-19",
            "doi": "10.1101/2020.03.22.20040915 ",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41001",
                    "label": "COVID-19 case fatality rate"
                }
            ],
            "abstract": "\"the first cases of covid-19 in france were detected on january 24, 2020. the number of screening tests carried out and the methodology used to target the patients tested do not allow for a direct computation of the real number of cases and the mortality this http url this report, we develop a 'mechanistic-statistical' approach coupling a sir ode model describing the unobserved epidemiological dynamics, a probabilistic model describing the data acquisition process and a statistical inference method. the objective of this model is not to make forecasts but to estimate the real number of people infected with covid-19 during the observation window in france and to deduce the mortality rate associated with the epidemic.main results. the actual number of infected cases in france is probably much higher than the observations: we find here a factor x 15 (95%-ci: 1.5-11.7), which leads to a 5.2/1000 mortality rate (95%-ci: 1.5 / 1000-11.7/ 1000) at the end of the observation period. we find a r0 of 4.8, a high value which may be linked to the long viral shedding period of 20 days.\""
        },
        {
            "id": "R41169",
            "label": "Statistics based predictions of coronavirus 2019-nCoV spreading in mainland China",
            "doi": "10.1101/2020.02.12.20021931",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41168",
                    "label": "assess the impact of COVID-19 by SEIR model predictions"
                }
            ],
            "abstract": "abstract background the epidemic outbreak cased by coronavirus 2019-ncov is of great interest to researches because of the high rate of spread of the infection and the significant number of fatalities. a detailed scientific analysis of the phenomenon is yet to come, but the public is already interested in the questions of the duration of the epidemic, the expected number of patients and deaths. for long time predictions, the complicated mathematical models are necessary which need many efforts for unknown parameters identification and calculations. in this article, some preliminary estimates will be presented. objective since the reliable long time data are available only for mainland china, we will try to predict the epidemic characteristics only in this area. we will estimate some of the epidemic characteristics and present the most reliable dependences for victim numbers, infected and removed persons versus time. methods in this study we use the known sir model for the dynamics of an epidemic, the known exact solution of the linear equations and statistical approach developed before for investigation of the children disease, which occurred in chernivtsi (ukraine) in 1988-1989. results the optimal values of the sir model parameters were identified with the use of statistical approach. the numbers of infected, susceptible and removed persons versus time were predicted. conclusions simple mathematical model was used to predict the characteristics of the epidemic caused by coronavirus 2019-ncov in mainland china. the further research should focus on updating the predictions with the use of fresh data and using more complicated mathematical models."
        },
        {
            "id": "R41250",
            "label": "The impact of social distancing and epicenter lockdown on the COVID-19 epidemic in mainland China: A data-driven SEIQR model study",
            "doi": "10.1101/2020.03.04.20031187",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R39009",
                    "label": "Predicting the evolution of 2019-nCoV"
                }
            ],
            "abstract": "abstract the outbreak of coronavirus disease 2019 (covid-19) which originated in wuhan, china, constitutes a public health emergency of international concern with a very high risk of spread and impact at the global level. we developed data-driven susceptible-exposed-infectious-quarantine-recovered (seiqr) models to simulate the epidemic with the interventions of social distancing and epicenter lockdown. population migration data combined with officially reported data were used to estimate model parameters, and then calculated the daily exported infected individuals by estimating the daily infected ratio and daily susceptible population size. as of jan 01, 2020, the estimated initial number of latently infected individuals was 380.1 (95%-ci: 379.8\u223c381.0). with 30 days of substantial social distancing, the reproductive number in wuhan and hubei was reduced from 2.2 (95%-ci: 1.4\u223c3.9) to 1.58 (95%-ci: 1.34\u223c2.07), and in other provinces from 2.56 (95%-ci: 2.43\u223c2.63) to 1.65 (95%-ci: 1.56\u223c1.76). we found that earlier intervention of social distancing could significantly limit the epidemic in mainland china. the number of infections could be reduced up to 98.9%, and the number of deaths could be reduced by up to 99.3% as of feb 23, 2020. however, earlier epicenter lockdown would partially neutralize this favorable effect. because it would cause in situ deteriorating, which overwhelms the improvement out of the epicenter. to minimize the epidemic size and death, stepwise implementation of social distancing in the epicenter city first, then in the province, and later the whole nation without the epicenter lockdown would be practical and cost-effective."
        },
        {
            "id": "R41252",
            "label": "Spread of SARS-CoV-2 in the Icelandic Population",
            "doi": "10.1056/nejmoa2006100",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41279",
                    "label": "Sequencing of the SARS-CoV-2 genome in Iceland"
                },
                {
                    "id": "R41280",
                    "label": "SARS-CoV-2 screening in Iceland"
                },
                {
                    "id": "R41637",
                    "label": "Sequencing of the SARS-CoV-2 genome"
                }
            ],
            "abstract": "abstract background during the current worldwide pandemic, coronavirus disease 2019 (covid-19) was first diagnosed in iceland at the end of february. however, data are limited on how sars-cov-2, the virus that causes covid-19, enters and spreads in a population. methods we targeted testing to persons living in iceland who were at high risk for infection (mainly those who were symptomatic, had recently traveled to high-risk countries, or had contact with infected persons). we also carried out population screening using two strategies: issuing an open invitation to 10,797 persons and sending random invitations to 2283 persons. we sequenced sars-cov-2 from 643 samples. results as of april 4, a total of 1221 of 9199 persons (13.3%) who were recruited for targeted testing had positive results for infection with sars-cov-2. of those tested in the general population, 87 (0.8%) in the open-invitation screening and 13 (0.6%) in the random-population screening tested positive for the virus. in total, 6% of the population was screened. most persons in the targeted-testing group who received positive tests early in the study had recently traveled internationally, in contrast to those who tested positive later in the study. children under 10 years of age were less likely to receive a positive result than were persons 10 years of age or older, with percentages of 6.7% and 13.7%, respectively, for targeted testing; in the population screening, no child under 10 years of age had a positive result, as compared with 0.8% of those 10 years of age or older. fewer females than males received positive results both in targeted testing (11.0% vs. 16.7%) and in population screening (0.6% vs. 0.9%). the haplotypes of the sequenced sars-cov-2 viruses were diverse and changed over time. the percentage of infected participants that was determined through population screening remained stable for the 20-day duration of screening. conclusions in a population-based study in iceland, children under 10 years of age and females had a lower incidence of sars-cov-2 infection than adolescents or adults and males. the proportion of infected persons identified through population screening did not change substantially during the screening period, which was consistent with a beneficial effect of containment efforts. (funded by decode genetics\u2013amgen.)"
        },
        {
            "id": "R41605",
            "label": "Serological and molecular findings during SARS-CoV-2 infection: the first case study in Finland, January to February 2020",
            "doi": "10.2807/1560-7917.es.2020.25.11.2000266",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41637",
                    "label": "Sequencing of the SARS-CoV-2 genome"
                }
            ],
            "abstract": "the first case of coronavirus disease (covid-19) in finland was confirmed on 29 january 2020. no secondary cases were detected. we describe the clinical picture and laboratory findings 3\u201323 days since the first symptoms. the sars-cov-2/finland/1/2020 virus strain was isolated, the genome showing a single nucleotide substitution to the reference strain from wuhan. neutralising antibody response appeared within 9 days along with specific igm and igg response, targeting particularly nucleocapsid and spike proteins."
        },
        {
            "id": "R42003",
            "label": "Virus Isolation from the First Patient with SARS-CoV-2 in Korea",
            "doi": "10.3346/jkms.2020.35.e84",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41637",
                    "label": "Sequencing of the SARS-CoV-2 genome"
                }
            ],
            "abstract": "novel coronavirus (sars-cov-2) is found to cause a large outbreak started from wuhan since december 2019 in china and sars-cov-2 infections have been reported with epidemiological linkage to china in 25 countries until now. we isolated sars-cov-2 from the oropharyngeal sample obtained from the patient with the first laboratory-confirmed sars-cov-2 infection in korea. cytopathic effects of sars-cov-2 in the vero cell cultures were confluent 3 days after the first blind passage of the sample. coronavirus was confirmed with spherical particle having a fringe reminiscent of crown on transmission electron microscopy. phylogenetic analyses of whole genome sequences showed that it clustered with other sars-cov-2 reported from wuhan."
        },
        {
            "id": "R44087",
            "label": "Modelling the Potential Health Impact of the COVID-19 Pandemic on a Hypothetical European Country",
            "doi": "10.1101/2020.03.20.20039776",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R39009",
                    "label": "Predicting the evolution of 2019-nCoV"
                },
                {
                    "id": "R44086",
                    "label": "determining the potential impact of control measures in mitigating 2019-nCoV"
                }
            ],
            "abstract": "abstract a seir simulation model for the covid-19 pandemic was developed ( http://covidsim.eu ) and applied to a hypothetical european country of 10 million population. our results show which interventions potentially push the epidemic peak into the subsequent year (when vaccinations may be available) or which fail. different levels of control (via contact reduction) resulted in 22% to 63% of the population sick, 0.2% to 0.6% hospitalised, and 0.07% to 0.28% dead (n=6,450 to 28,228)."
        },
        {
            "id": "R44137",
            "label": "Full-genome sequences of the first two SARS-CoV-2 viruses from India",
            "doi": "10.4103/ijmr.ijmr_663_20",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41637",
                    "label": "Sequencing of the SARS-CoV-2 genome"
                }
            ],
            "abstract": "background & objectives: since december 2019, severe acute respiratory syndrome coronavirus 2 (sars-cov-2) has globally affected 195 countries. in india, suspected cases were screened for sars-cov-2 as per the advisory of the ministry of health and family welfare. the objective of this study was to characterize sars-cov-2 sequences from three identified positive cases as on february 29, 2020. methods: throat swab/nasal swab specimens for a total of 881 suspected cases were screened by e gene and confirmed by rdrp (1), rdrp (2) and n gene real-time reverse transcription-polymerase chain reactions and next-generation sequencing. phylogenetic analysis, molecular characterization and prediction of b- and t-cell epitopes for indian sars-cov-2 sequences were undertaken. results: three cases with a travel history from wuhan, china, were confirmed positive for sars-cov-2. almost complete (29,851 nucleotides) genomes of case 1, case 3 and a fragmented genome for case 2 were obtained. the sequences of indian sars-cov-2 though not identical showed high (~99.98%) identity with wuhan seafood market pneumonia virus (accession number: nc 045512). phylogenetic analysis showed that the indian sequences belonged to different clusters. predicted linear b-cell epitopes were found to be concentrated in the s1 domain of spike protein, and a conformational epitope was identified in the receptor-binding domain. the predicted t-cell epitopes showed broad human leucocyte antigen allele coverage of a and b supertypes predominant in the indian population. interpretation & conclusions: the two sars-cov-2 sequences obtained from india represent two different introductions into the country. the genetic heterogeneity is as noted globally. the identified b- and t-cell epitopes may be considered suitable for future experiments towards the design of vaccines and diagnostics. continuous monitoring and analysis of the sequences of new cases from india and the other affected countries would be vital to understand the genetic evolution and rates of substitution of the sars-cov-2."
        },
        {
            "id": "R74055",
            "label": "Case fatality risk of the SARS-CoV-2 variant of concern B.1.1.7 in England",
            "doi": "10.1101/2021.03.04.21252528",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41001",
                    "label": "COVID-19 case fatality rate"
                }
            ],
            "abstract": "abstract the b.1.1.7 variant of concern (voc) is increasing in prevalence across europe. accurate estimation of disease severity associated with this voc is critical for pandemic planning. we found increased risk of death for voc compared with non-voc cases in england (hr: 1.67 (95% ci: 1.34 - 2.09; p&lt;.0001)). absolute risk of death by 28-days increased with age and comorbidities. voc has potential to spread faster with higher mortality than the pandemic to date."
        },
        {
            "id": "R74069",
            "label": "Increased mortality in community-tested cases of SARS-CoV-2 lineage B.1.1.7",
            "doi": "10.1038/s41586-021-03426-1",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41001",
                    "label": "COVID-19 case fatality rate"
                }
            ],
            "abstract": "sars-cov-2 lineage b.1.1.7, a variant first detected in the united kingdom in september 2020 1 , has spread to multiple countries worldwide. several studies have established that b.1.1.7 is more transmissible than preexisting variants, but have not identified whether it leads to any change in disease severity 2 . we analyse a dataset linking 2,245,263 positive sars-cov-2 community tests and 17,452 covid-19 deaths in england from 1 september 2020 to 14 february 2021. for 1,146,534 (51%) of these tests, the presence or absence of b.1.1.7 can be identified because of mutations in this lineage preventing pcr amplification of the spike gene target (s gene target failure, sgtf 1 ). based on 4,945 deaths with known sgtf status, we estimate that the hazard of death associated with sgtf is 55% (95% ci 39\u201372%) higher after adjustment for age, sex, ethnicity, deprivation, care home residence, local authority of residence and test date. this corresponds to the absolute risk of death for a 55\u201369-year-old male increasing from 0.6% to 0.9% (95% ci 0.8\u20131.0%) within 28 days after a positive test in the community. correcting for misclassification of sgtf and missingness in sgtf status, we estimate a 61% (42\u201382%) higher hazard of death associated with b.1.1.7. our analysis suggests that b.1.1.7 is not only more transmissible than preexisting sars-cov-2 variants, but may also cause more severe illness."
        },
        {
            "id": "R74102",
            "label": "Risk of mortality in patients infected with SARS-CoV-2 variant of concern 202012/1: matched cohort study",
            "doi": "10.1136/bmj.n579",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R41001",
                    "label": "COVID-19 case fatality rate"
                }
            ],
            "abstract": "abstract \\n \\n objective \\n to establish whether there is any change in mortality from infection with a new variant of sars-cov-2, designated a variant of concern (voc-202012/1) in december 2020, compared with circulating sars-cov-2 variants. \\n \\n \\n design \\n matched cohort study. \\n \\n \\n setting \\n community based (pillar 2) covid-19 testing centres in the uk using the taqpath assay (a proxy measure of voc-202012/1 infection). \\n \\n \\n participants \\n 54\\u2009906 matched pairs of participants who tested positive for sars-cov-2 in pillar 2 between 1 october 2020 and 29 january 2021, followed-up until 12 february 2021. participants were matched on age, sex, ethnicity, index of multiple deprivation, lower tier local authority region, and sample date of positive specimens, and differed only by detectability of the spike protein gene using the taqpath assay. \\n \\n \\n main outcome measure \\n death within 28 days of the first positive sars-cov-2 test result. \\n \\n \\n results \\n the mortality hazard ratio associated with infection with voc-202012/1 compared with infection with previously circulating variants was 1.64 (95% confidence interval 1.32 to 2.04) in patients who tested positive for covid-19 in the community. in this comparatively low risk group, this represents an increase in deaths from 2.5 to 4.1 per 1000 detected cases. \\n \\n \\n conclusions \\n the probability that the risk of mortality is increased by infection with voc-202012/01 is high. if this finding is generalisable to other populations, infection with voc-202012/1 has the potential to cause substantial additional mortality compared with previously circulating variants. healthcare capacity planning and national and international control policies are all impacted by this finding, with increased mortality lending weight to the argument that further coordinated and stringent measures are justified to reduce deaths from sars-cov-2. \\n"
        },
        {
            "id": "R110684",
            "label": "Enterovirus inhibiting activities of two lupane triterpenoids and anthraquinones from senna siamea stem bark against three serotypes of echovirus",
            "doi": "10.23893/1307-2080.aps.05720",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R110693",
                    "label": "Antiviral Compounds from Natural Sources"
                }
            ],
            "abstract": "echovirus 7, 13 and 19 are part of the diseases-causing enteroviruses identified in nigeria. presently, no treatment modality is clinically available against these enteric viruses. herein, we investigated the ability of two anthraquinones (physcion and chrysophanol) and two lupane triterpenoids (betulinic acid and lupeol), isolated from the stem bark of senna siamea, to reduce the viral-induced cytopathic effect on rhabdomyosarcoma cells using mtt (3-[4,5-dimethylthiazol\u20132-yl]-2,5diphenyltetrazolium bromide) colorimetric method. viral-induced cpe by e7 and e19 was inhibited in the presence of all tested compounds, e13 was resistant to all the compounds except betulinic acid. physcion was the most active with ic50 of 0.42 and 0.33 \u03bcg/ml on e7 and e19, respectively. we concluded that these compounds from senna siamea possess anti-enteroviral activities and betulinic acid may represent a potential therapeutic agent to control e7, e13, and e19 infections, especially due its ability to inhibit cpe caused by the impervious e13."
        },
        {
            "id": "R110711",
            "label": "Antiviral Chromones from the Stem of Cassia siamea",
            "doi": "10.1021/np300395m",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "R110710",
                    "label": "Antiviral Compounds from Natural Sources"
                }
            ],
            "abstract": "seven new chromones, siamchromones a-g (1-7), and 12 known chromones (8-19) were isolated from the stems of cassia siamea. compounds 1-19 were evaluated for their antitobacco mosaic virus (anti-tmv) and anti-hiv-1 activities. compound 6 showed antitobacco mosaic virus (anti-tmv) activity with an inhibition rate of 35.3% and ic50 value of 31.2 \u03bcm, which is higher than that of the positive control, ningnamycin. compounds 1, 10, 13, and 16 showed anti-tmv activities with inhibition rates above 10%. compounds 4, 6, 13, and 19 showed anti-hiv-1 activities with therapeutic index values above 50."
        },
        {
            "id": "R191315",
            "label": "Quantitative Detection and Viral Load Analysis of SARS-CoV-2 in Infected Patients",
            "doi": "10.1093/cid/ciaa345",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n \\n background \\n coronavirus disease 2019 (covid-19) has become a public health emergency. the widely used reverse transcription\u2013polymerase chain reaction (rt-pcr) method has limitations for clinical diagnosis and treatment. \\n \\n \\n methods \\n a total of 323 samples from 76 covid-19\u2013confirmed patients were analyzed by droplet digital pcr (ddpcr) and rt-pcr based 2 target genes (orf1ab and n). nasal swabs, throat swabs, sputum, blood, and urine were collected. clinical and imaging data were obtained for clinical staging. \\n \\n \\n results \\n in 95 samples that tested positive by both methods, the cycle threshold (ct) of rt-pcr was highly correlated with the copy number of ddpcr (orf1ab gene, r2\\u2005=\\u20050.83; n gene, r2\\u2005=\\u20050.87). four (4/161) negative and 41 (41/67) single-gene positive samples tested by rt-pcr were positive according to ddpcr with viral loads ranging from 11.1 to 123.2 copies/test. the viral load of respiratory samples was then compared and the average viral load in sputum (17\\u2005429\\u2005\u00b1\\u20056920 copies/test) was found to be significantly higher than in throat swabs (2552\\u2005\u00b1\\u20051965 copies/test, p\\u2005&amp;lt;\\u2005.001) and nasal swabs (651\\u2005\u00b1\\u2005501 copies/test, p\\u2005&amp;lt;\\u2005.001). furthermore, the viral loads in the early and progressive stages were significantly higher than that in the recovery stage (46\\u2005800\\u2005\u00b1\\u200517\\u2005272 vs 1252\\u2005\u00b1\\u20051027, p\\u2005&amp;lt;\\u2005.001) analyzed by sputum samples. \\n \\n \\n conclusions \\n quantitative monitoring of viral load in lower respiratory tract samples helps to evaluate disease progression, especially in cases of low viral load. \\n"
        },
        {
            "id": "R200003",
            "label": "Detection of Antibodies against Norovirus Genogroup GIV in Carnivores",
            "doi": "10.1128/cvi.00312-09",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n noroviruses (novs) resembling human nov genotype giv (alphatron-like) have recently been detected in carnivores. by using an enzyme-linked immunosorbent assay based on baculovirus-expressed capsid protein vp1 of lion strain ggiv.2/pistoia/387/06/ita, nov-specific antibodies were detected in cats (16.11%) and dogs (4.8%), demonstrating that these animals are exposed to infections caused by novs."
        },
        {
            "id": "R202083",
            "label": "Genetic Diversity and Histo-Blood Group Antigen Interactions of Rhesus Enteric Caliciviruses",
            "doi": "10.1128/jvi.00630-10",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract recently, we reported the discovery and characterization of tulane virus (tv), a novel rhesus calicivirus (cv) (t. farkas, k. sestak, c. wei, and x. jiang, j. virol. 82: 5408-5416, 2008). tv grows well in tissue culture, and it represents a new genus within caliciviridae , with the proposed name of recovirus . we also reported a high prevalence of cv antibodies in macaques of the tulane national primate research center (tnprc) colony, including anti-norovirus (nov), anti-sapovirus (sav), and anti-tv (t. farkas, j. dufour, x. jiang, and k. sestak, j. gen. virol. 91:734-738, 2010). to broaden our knowledge about cv infections in captive nonhuman primates (nhp), 500 rhesus macaque stool samples collected from breeding colony tnprc macaques were tested for cvs. fifty-seven (11%) samples contained recovirus isolates. in addition, one nov was detected. phylogenetic analysis classified the recovirus isolates into two genogroups and at least four genetic types. the rhesus nov isolate was closely related to gii human novs. tv-neutralizing antibodies were detected in 88% of serum samples obtained from primate caretakers. binding and plaque reduction assays revealed the involvement of type a and b histo-blood group antigens (hbga) in tv infection. taken together, these findings indicate the zoonotic potential of primate cvs. the discovery of a genetically diverse and prevalent group of primate cvs and remarkable similarities between rhesus enteric cvs and human novs opens new possibilities for research involving in vitro and in vivo models of human nov gastroenteritis."
        },
        {
            "id": "R210496",
            "label": "Hunting coronavirus by transmission electron microscopy\u00a0\u2013\u00a0a guide to SARS\u2010CoV\u20102\u2010associated ultrastructural pathology in COVID\u201019 tissues",
            "doi": "10.1111/his.14264",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "transmission electron microscopy has become a valuable tool to investigate tissues of covid\u201019 patients because it allows visualisation of sars\u2010cov\u20102, but the \u2018virus\u2010like particles\u2019 described in several organs have been highly contested. because most electron microscopists in pathology are not accustomed to analysing viral particles and subcellular structures, our review aims to discuss the ultrastructural changes associated with sars\u2010cov\u20102 infection and covid\u201019 with respect to pathology, virology and electron microscopy. using micrographs from infected cell cultures and autopsy tissues, we show how coronavirus replication affects ultrastructure and put the morphological findings in the context of viral replication, which induces extensive remodelling of the intracellular membrane systems. virions assemble by budding into the endoplasmic reticulum\u2013golgi intermediate complex and are characterised by electron\u2010dense dots of cross\u2010sections of the nucleocapsid inside the viral particles. physiological mimickers such as multivesicular bodies or coated vesicles serve as perfect decoys. compared to other in\u2010situ techniques, transmission electron microscopy is the only method to visualise assembled virions in tissues, and will be required to prove sars\u2010cov\u20102 replication outside the respiratory tract. in practice, documenting in tissues the characteristic features seen in infected cell cultures seems to be much more difficult than anticipated. in our view, the hunt for coronavirus by transmission electron microscopy is still on."
        },
        {
            "id": "R214011",
            "label": "Transmission of SARS-CoV-2 from Human to Domestic Ferret",
            "doi": "10.3201/eid2709.210774",
            "research_field": {
                "id": "R57",
                "label": "Virology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we report a case of natural infection with severe acute respiratory syndrome coronavirus 2 transmitted from an owner to a pet ferret in the same household in slovenia. the ferret had onset of gastroenteritis with severe dehydration. whole-genome sequencing of the viruses isolated from the owner and ferret revealed a 2-nt difference."
        },
        {
            "id": "R138607",
            "label": "A Novel Nanoparticle Formulation for Sustained Paclitaxel Delivery",
            "doi": "10.1208/s12249-008-9063-7",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R3070",
                    "label": "Breast cancer"
                },
                {
                    "id": "R110161",
                    "label": "Polymeric nanoparticles for cancer treatment"
                }
            ],
            "abstract": "purposeto develop a novel nanoparticle drug delivery system consisting of chitosan and glyceryl monooleate (gmo) for the delivery of a wide variety of therapeutics including paclitaxel.methodschitosan/gmo nanoparticles were prepared by multiple emulsion (o/w/o) solvent evaporation methods. particle size and surface charge were determined. the morphological characteristics and cellular adhesion were evaluated with surface or transmission electron microscopy methods. the drug loading, encapsulation efficiency, in vitro release and cellular uptake were determined using hplc methods. the safety and efficacy were evaluated by mtt cytotoxicity assay in human breast cancer cells (mda-mb-231).resultsthese studies provide conceptual proof that chitosan/gmo can form polycationic nano-sized particles (400 to 700\\xa0nm). the formulation demonstrates high yields (98 to 100%) and similar entrapment efficiencies. the lyophilized powder can be stored and easily be resuspended in an aqueous matrix. the nanoparticles have a hydrophobic inner-core with a hydrophilic coating that exhibits a significant positive charge and sustained release characteristics. this novel nanoparticle formulation shows evidence of mucoadhesive properties; a fourfold increased cellular uptake and a 1000-fold reduction in the ic50 of ptx.conclusionthese advantages allow lower doses of ptx to achieve a therapeutic effect, thus presumably minimizing the adverse side effects."
        },
        {
            "id": "R138611",
            "label": "Paclitaxel/Chitosan Nanosupensions Provide Enhanced Intravesical Bladder Cancer Therapy with Sustained and Prolonged Delivery of Paclitaxel",
            "doi": "10.1021/acsabm.8b00501",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R110161",
                    "label": "Polymeric nanoparticles for cancer treatment"
                }
            ],
            "abstract": "bladder cancer (bc) is a very common cancer. nonmuscle-invasive bladder cancer (nmibc) is the most common type of bladder cancer. after postoperative tumor resection, chemotherapy intravesical instillation is recommended as a standard treatment to significantly reduce recurrences. nanomedicine-mediated delivery of a chemotherapeutic agent targeting cancer could provide a solution to obtain longer residence time and high bioavailability of an anticancer drug. the approach described here provides a nanomedicine with sustained and prolonged delivery of paclitaxel and enhanced therapy of intravesical bladder cancer, which is paclitaxel/chitosan (ptx/cs) nanosupensions (nss). the positively charged ptx/cs nss exhibited a rod-shaped morphology with a mean diameter about 200 nm. they have good dispersivity in water without any protective agents, and the positively charged properties make them easy to be adsorbed on the inner mucosa of the bladder through electrostatic adsorption. ptx/cs nss also had a high drug loading capacity and can maintain sustained release of paclitaxel which could be prolonged over 10 days. cell experiments in vitro demonstrated that ptx/cs nss had good biocompatibility and effective bladder cancer cell proliferation inhibition. the significant anticancer efficacy against intravesical bladder cancer was verified by an in situ bladder cancer model. the paclitaxel/chitosan nanosupensions could provide sustained delivery of chemotherapeutic agents with significant anticancer efficacy against intravesical bladder cancer."
        },
        {
            "id": "R138909",
            "label": "Targeted Paclitaxel by Conjugation to Iron Oxide and Gold Nanoparticles",
            "doi": "10.1021/ja804947u",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R138892",
                    "label": "Inorganic nanoparticles for cancer treatment"
                }
            ],
            "abstract": "\"the fe(3)o(4) nanoparticles, tailored with maleimidyl 3-succinimidopropionate ligands, were conjugated with paclitaxel molecules that were attached with a poly(ethylene glycol) (peg) spacer through a phosphodiester moiety at the (c-2')-oh position. the average number of paclitaxel molecules/nanoparticles was determined as 83. these nanoparticles liberated paclitaxel molecules upon exposure to phosphodiesterase.\""
        },
        {
            "id": "R138920",
            "label": "Functionalization of Silver Nanoparticles Loaded with Paclitaxel-induced A549 Cells Apoptosis Through ROS-Mediated Signaling Pathways",
            "doi": "10.2174/1568026619666191019102219",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R138892",
                    "label": "Inorganic nanoparticles for cancer treatment"
                }
            ],
            "abstract": "\\n background: \\n paclitaxel (ptx) is one of the most important and effective anticancer drugs for\\nthe treatment of human cancer. however, its low solubility and severe adverse effects limited clinical\\nuse. to overcome this limitation, nanotechnology has been used to overcome tumors due to its excellent\\nantimicrobial activity. \\n \\n \\n objective: \\n this study was to demonstrate the anticancer properties of functionalization silver nanoparticles\\nloaded with paclitaxel (ag@ptx) induced a549 cells apoptosis through ros-mediated signaling\\npathways. \\n \\n \\n methods: \\n the ag@ptx nanoparticles were charged with a zeta potential of about -17 mv and characterized\\naround 2 nm with a narrow size distribution. \\n \\n \\n results: \\n ag@ptx significantly decreased the viability of a549 cells and possessed selectivity between\\ncancer and normal cells. ag@ptx induced a549 cells apoptosis was confirmed by nuclear condensation,\\ndna fragmentation, and activation of caspase-3. furthermore, ag@ptx enhanced the anti-cancer\\nactivity of a549 cells through ros-mediated p53 and akt signalling pathways. finally, in a xenograft\\nnude mice model, ag@ptx suppressed the growth of tumors. \\n \\n \\n conclusion: \\n our findings suggest that ag@ptx may be a candidate as a chemopreventive agent and\\ncould be a highly efficient way to achieve anticancer synergism for human cancers. \\n"
        },
        {
            "id": "R140238",
            "label": "Oral Drug Delivery Systems for Ulcerative Colitis Therapy: A Comparative Study with Microparticles and Nanoparticles",
            "doi": "10.2174/1568009618666181016152042",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R140235",
                    "label": "Nanoparticles for the management of inflammatory bowel disease (IBD)"
                }
            ],
            "abstract": "\\n background: \\n oral administrations of microparticles (mps) and nanoparticles (nps) have\\nbeen widely employed as therapeutic approaches for the treatment of ulcerative colitis (uc). however,\\nno previous study has comparatively investigated the therapeutic efficacies of mps and nps.\\n \\n \\n methods: \\n in this study, curcumin (cur)-loaded mps (cur-mps) and cur-loaded nps (cur-nps)\\nwere prepared using a single water-in-oil emulsion solvent evaporation technique. their therapeutic\\noutcomes against uc were further comparatively studied.\\n \\n \\n results: \\n the resultant spherical mps and nps exhibited slightly negative zeta-potential with average\\nparticle diameters of approximately 1.7 &amp;#181;m and 270 nm, respectively. it was found that nps exhibited\\na much higher cur release rate than mps within the same period of investigation. in vivo experiments\\ndemonstrated that oral administration of cur-mps and cur-nps reduced the symptoms\\nof inflammation in a uc mouse model induced by dextran sulfate sodium. importantly, cur-nps\\nshowed much better therapeutic outcomes in alleviating uc compared with cur-mps.\\n \\n \\n conclusion: \\n nps can improve the anti-inflammatory activity of cur by enhancing the drug release\\nand cellular uptake efficiency, in comparison with mps. thus, they could be exploited as a promising\\noral drug delivery system for effective uc treatment. \\n"
        },
        {
            "id": "R141102",
            "label": "Oral delivery of anti-TNF antibody shielded by natural polyphenol-mediated supramolecular assembly for inflammatory bowel disease therapy",
            "doi": "10.7150/thno.47601",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R140235",
                    "label": "Nanoparticles for the management of inflammatory bowel disease (IBD)"
                }
            ],
            "abstract": "rationale: anti-tumor necrosis factor (tnf) therapy is a very effective way to treat inflammatory bowel disease. however, systemic exposure to anti-tnf-\u03b1 antibodies through current clinical systemic administration can cause serious adverse effects in many patients. here, we report a facile prepared self-assembled supramolecular nanoparticle based on natural polyphenol tannic acid and poly(ethylene glycol) containing polymer for oral antibody delivery. method: this supramolecular nanoparticle was fabricated within minutes in aqueous solution and easily scaled up to gram level due to their ph-dependent reversible assembly. dss-induced colitis model was prepared to evaluate the ability of inflammatory colon targeting ability and therapeutic efficacy of this antibody-loaded nanoparticles. results: this polyphenol-based nanoparticle can be aqueous assembly without organic solvent and thus scaled up easily. the oral administration of antibody loaded nanoparticle achieved high accumulation in the inflamed colon and low systemic exposure. the novel formulation of anti-tnf-\u03b1 antibodies administrated orally achieved high efficacy in the treatment of colitis mice compared with free antibodies administered orally. the average weight, colon length, and inflammatory factors in colon and serum of colitis mice after the treatment of novel formulation of anti-tnf-\u03b1 antibodies even reached the similar level to healthy controls. conclusion: this polyphenol-based supramolecular nanoparticle is a promising platform for oral delivery of antibodies for the treatment of inflammatory bowel diseases, which may have promising clinical translation prospects."
        },
        {
            "id": "R141302",
            "label": "Engineered biomimetic nanovesicles show intrinsic anti-inflammatory properties for the treatment of inflammatory bowel diseases",
            "doi": "10.1039/c7nr04734g",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we debut for the first time specialized leukosomes (slks) for the treatment of inflammatory bowel disease."
        },
        {
            "id": "R144137",
            "label": "Low active loading of cargo into engineered extracellular vesicles results in inefficient miRNA mimic delivery",
            "doi": "10.1080/20013078.2017.1333882",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144143",
                    "label": "Extracellular vesicles as drug delivery systems"
                }
            ],
            "abstract": "abstract extracellular vesicles (evs) hold great potential as novel systems for nucleic acid delivery due to their natural composition. our goal was to load evs with microrna that are synthesized by the cells that produce the evs. hek293t cells were engineered to produce evs expressing a lysosomal associated membrane, lamp2a fusion protein. the gene encoding pre-mir-199a was inserted into an artificial intron of the lamp2a fusion protein. the tat peptide/hiv-1 transactivation response (tar) rna interacting peptide was exploited to enhance the ev loading of the pre-mir-199a containing a modified tar rna loop. computational modeling demonstrated a stable interaction between the modified pre-mir-199a loop and tat peptide. emsa gel shift, recombinant dicer processing and luciferase binding assays confirmed the binding, processing and functionality of the modified pre-mir-199a. the tat-tar interaction enhanced the loading of the mir-199a into evs by 65-fold. endogenously loaded evs were ineffective at delivering active mir-199a-3p therapeutic to recipient sk-hep1 cells. while the low degree of mirna loading into evs through this approach resulted in inefficient distribution of rna cargo into recipient cells, the tat tar strategy to load mirna into evs may be valuable in other drug delivery approaches involving mirna mimics or other hairpin containing rnas."
        },
        {
            "id": "R144256",
            "label": "Nanoemulsions: formation, properties and applications",
            "doi": "10.1039/c5sm02958a",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144262",
                    "label": "Nanoemulsions: formation, properties and applications"
                }
            ],
            "abstract": "nanoemulsions are kinetically stable liquid-in-liquid dispersions with droplet sizes on the order of 100 nm."
        },
        {
            "id": "R144268",
            "label": "PEG\u2013lipid micelles as drug carriers: physiochemical attributes, formulation principles and biological implication",
            "doi": "10.3109/1061186x.2014.997735",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144272",
                    "label": "Lipid micelles as drug carriers"
                }
            ],
            "abstract": "abstract peg\u2013lipid micelles, primarily conjugates of polyethylene glycol (peg) and distearyl phosphatidylethanolamine (dspe) or peg\u2013dspe, have emerged as promising drug-delivery carriers to address the shortcomings associated with new molecular entities with suboptimal biopharmaceutical attributes. the flexibility in peg\u2013dspe design coupled with the simplicity of physical drug entrapment have distinguished peg\u2013lipid micelles as versatile and effective drug carriers for cancer therapy. they were shown to overcome several limitations of poorly soluble drugs such as non-specific biodistribution and targeting, lack of water solubility and poor oral bioavailability. therefore, considerable efforts have been made to exploit the full potential of these delivery systems; to entrap poorly soluble drugs and target pathological sites both passively through the enhanced permeability and retention (epr) effect and actively by linking the terminal peg groups with targeting ligands, which were shown to increase delivery efficiency and tissue specificity. this article reviews the current state of peg\u2013lipid micelles as delivery carriers for poorly soluble drugs, their biological implications and recent developments in exploring their active targeting potential. in addition, this review sheds light on the physical properties of peg\u2013lipid micelles and their relevance to the inherent advantages and applications of peg\u2013lipid micelles for drug delivery."
        },
        {
            "id": "R144328",
            "label": "Preparation, Biodistribution and Neurotoxicity of Liposomal Cisplatin following Convection Enhanced Delivery in Normal and F98 Glioma Bearing Rats",
            "doi": "10.1371/journal.pone.0048752",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144332",
                    "label": "Liposomes as drug carriers"
                }
            ],
            "abstract": "the purpose of this study was to evaluate two novel liposomal formulations of cisplatin as potential therapeutic agents for treatment of the f98 rat glioma. the first was a commercially produced agent, lipoplatin\u2122, which currently is in a phase iii clinical trial for treatment of non-small cell lung cancer (nsclc). the second, produced in our laboratory, was based on the ability of cisplatin to form coordination complexes with lipid cholesteryl hemisuccinate (chems). the in vitro tumoricidal activity of the former previously has been described in detail by other investigators. the chems liposomal formulation had a pt loading efficiency of 25% and showed more potent in vitro cytotoxicity against f98 glioma cells than free cisplatin at 24 h. in vivo chems liposomes showed high retention at 24 h after intracerebral (i.c.) convection enhanced delivery (ced) to f98 glioma bearing rats. neurotoxicologic studies were carried out in non-tumor bearing fischer rats following i.c. ced of lipoplatin\u2122 or chems liposomes or their \u201chollow\u201d counterparts. unexpectedly, lipoplatin\u2122 was highly neurotoxic when given i.c. by ced and resulted in death immediately following or within a few days after administration. similarly \u201chollow\u201d lipoplatin\u2122 liposomes showed similar neurotoxicity indicating that this was due to the liposomes themselves rather than the cisplatin. this was particularly surprising since lipoplatin\u2122 has been well tolerated when administered intravenously. in contrast, chems liposomes and their \u201chollow\u201d counterparts were clinically well tolerated. however, a variety of dose dependent neuropathologic changes from none to severe were seen at either 10 or 14 d following their administration. these findings suggest that further refinements in the design and formulation of cisplatin containing liposomes will be required before they can be administered i.c. by ced for the treatment of brain tumors and that a formulation that may be safe when given systemically may be highly neurotoxic when administered directly into the brain."
        },
        {
            "id": "R144333",
            "label": "Development and Evaluation of Lipid Nanoparticles for Drug Delivery: Study of Toxicity In Vitro and In Vivo",
            "doi": "10.1166/jnn.2016.11667",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"lipid nanoparticles have received considerable attention in the field of drug delivery, due their ability to incorporate lipophilic drugs and to allow controlled drug release. solid lipid nanoparticles (sln), nanostructured lipid carriers (nlc), and nanoemulsion (ne) are three different lipid nanostructured systems presenting intrinsically physical properties, which have been widely studied in recent years. despite the extensive applicability of lipid nanoparticles, the toxicity of these systems has not been sufficiently investigated thus far. it is generally believed that lipids are biocompatible. however, it is known that materials structured in nanoscale might have their intrinsic physicochemical properties modified. thus, the aim of this study was to evaluate the cytotoxicity of these three nanoparticle systems. to this end, in vitro and in vivo toxicity studies were carried out. our results indicate that nanoparticles containing the solid lipid gms (sln and nlc) induced an important cytotoxicity in vitro, but showed minimal toxicity in vivo--evidenced by the body weight analysis. the ne did not induce in vitro toxicity and did not induce body weight alteration. on the contrary, the sln and nlc possibly induce an inflammatory process in vivo. all nanoparticle systems induced lipid peroxidation in the animals' livers, but only sln and nlc induced a decrease of antioxidant defences indicating that the main mechanism of toxicity is the induction of oxidative stress in liver. the higher toxicity induced by sln and nlc indicates that the solid lipid gms could be the responsible for this effect. nevertheless, this study provides important insights for toxicological studies of different lipid nanoparticles systems.\""
        },
        {
            "id": "R144336",
            "label": "Solid Lipid Nanoparticles: Emerging Colloidal Nano Drug Delivery Systems",
            "doi": "10.3390/pharmaceutics10040191",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144340",
                    "label": "Solid lipid nanoparticles as drug carriers"
                }
            ],
            "abstract": "solid lipid nanoparticles (slns) are nanocarriers developed as substitute colloidal drug delivery systems parallel to liposomes, lipid emulsions, polymeric nanoparticles, and so forth. owing to their unique size dependent properties and ability to incorporate drugs, slns present an opportunity to build up new therapeutic prototypes for drug delivery and targeting. slns hold great potential for attaining the goal of targeted and controlled drug delivery, which currently draws the interest of researchers worldwide. the present review sheds light on different aspects of slns including fabrication and characterization techniques, formulation variables, routes of administration, surface modifications, toxicity, and biomedical applications."
        },
        {
            "id": "R144353",
            "label": "Exosome-based nanocarriers as bio-inspired and versatile vehicles for drug delivery: recent advances and challenges",
            "doi": "10.1039/c9tb00170k",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144363",
                    "label": "Extracellular vesicles as drug carrier"
                }
            ],
            "abstract": "exosomes as drug vehicles have attracted increasing attention due to their ability of shuttling proteins, lipids and genes among cells and natural affinity to target cells."
        },
        {
            "id": "R144462",
            "label": "Surface Functionalization of PLGA Nanoparticles to Increase Transport across the BBB for Alzheimer\u2019s Disease",
            "doi": "10.3390/app11094305",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "alzheimer\u2019s disease (ad) is a chronic neurodegenerative disorder that accounts for about 60% of all diagnosed cases of dementia worldwide. although there are currently several drugs marketed for its treatment, none are capable of slowing down or stopping the progression of ad. the role of the blood-brain barrier (bbb) plays a key role in the design of a successful treatment for this neurodegenerative disease. nanosized particles have been proposed as suitable drug delivery systems to overcome bbb with the purpose of increasing bioavailability of drugs in the brain. biodegradable poly (lactic-co-glycolic acid) nanoparticles (plga-nps) have been particularly regarded as promising drug delivery systems as they can be surface-tailored with functionalized molecules for site-specific targeting. in this review, a thorough discussion about the most recent functionalization strategies based on plga-nps for ad and their mechanisms of action is provided, together with a description of ad pathogenesis and the role of the bbb in brain targeting."
        },
        {
            "id": "R147006",
            "label": "Exendin-4-Loaded PLGA Microspheres Relieve Cerebral Ischemia/Reperfusion Injury and Neurologic Deficits through Long-Lasting Bioactivity-Mediated Phosphorylated Akt/eNOS Signaling in Rats",
            "doi": "10.1038/jcbfm.2015.126",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R144394",
                    "label": "PLGA-based nanoparticles for drug delivery to the brain"
                },
                {
                    "id": "R147009",
                    "label": "Drug delivery across the blood brain barrier"
                }
            ],
            "abstract": "glucagon-like peptide-1 (glp-1) receptor activation in the brain provides neuroprotection. exendin-4 (ex-4), a glp-1 analog, has seen limited clinical usage because of its short half-life. we developed long-lasting ex-4-loaded poly(d,l-lactide-co-glycolide) microspheres (pex-4) and explored its neuroprotective potential against cerebral ischemia in diabetic rats. compared with ex-4, pex-4 in the gradually degraded microspheres sustained higher ex-4 levels in the plasma and cerebrospinal fluid for at least 2 weeks and improved diabetes-induced glycemia after a single subcutaneous administration (20 \u03bcg/day). ten minutes of bilateral carotid artery occlusion (cao) combined with hemorrhage-induced hypotension (around 30 mm hg) significantly decreased cerebral blood flow and microcirculation in male wistar rats subjected to streptozotocin-induced diabetes. cao increased cortical o 2 \u2013 levels by chemiluminescence amplification and prefrontal cortex edema by t2-weighted magnetic resonance imaging analysis. cao significantly increased aquaporin 4 and glial fibrillary acidic protein expression and led to cognition deficits. cao downregulated phosphorylated akt/endothelial nitric oxide synthase (p-akt/p-enos) signaling and enhanced nuclear factor (nf)-\u03babp65/ intercellular adhesion molecule-1 (icam-1) expression, endoplasmic reticulum (er) stress, and apoptosis in the cerebral cortex. pex-4 was more effective than ex-4 to improve cao-induced oxidative injury and cognitive deficits. the neuroprotection provided by pex-4 was through p-akt/p-enos pathways, which suppressed cao-enhanced nf- \u03bab/icam-1 signaling, er stress, and apoptosis."
        },
        {
            "id": "R147029",
            "label": "Synergistic Combination of Doxorubicin and Paclitaxel Delivered by Blood Brain Barrier and Glioma Cells Dual Targeting Liposomes for Chemotherapy of Brain Glioma",
            "doi": "10.2174/1389201017666160401144440",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "brain glioma has become a great threat to human health in decades. to maximize the therapeutic efficacy of brain glioma as well as minimize the side effects, drugs should be penetrated through the blood brain barrier (bbb) and then targeted to the brain carcinoma cells with effective concentration. a dual-ligand delivery strategy was employed to achieve both of these goals. herein, both specific targeting ligand transferrin and cell-penetrating peptide tat were conjugated onto liposomes (tf/tat-lp) to develop a brain glioma dual-ligand delivery system. synergistic combination of doxorubicin (dox) and paclitaxel (ptx), compared with using them separately, could more efficiently suppress tumor aggravation. in vitro studies including cellular uptake and three-dimensional (3d) tumor spheroid penetration assays proved that tf/tat-lp could target brain endothelial and carcinoma cells with deeply penetration through the endothelial monolayers and target to the core of the tumor spheroids. in vivo imaging proved that the tf/tat-lp possesses the highest tumor distribution, which was also confirmed by fluorescent images of the brain section. ultimately, the dox and ptx-loaded tf/tat-lp (tf/tat-ptx/dox-lp) shows the best anti-glioma effect with improvement of glioma bearing survival time. in conclusion, synergistic combination of doxorubicin and paclitaxel delivered by the tf/tat-lp could efficiently target to the brain glioma with satisfying treatment efficiency, which may be a promising formulation for glioma therapy."
        },
        {
            "id": "R147246",
            "label": "PEG-g-chitosan nanoparticles functionalized with the monoclonal antibody OX26 for brain drug targeting",
            "doi": "10.2217/nnm.15.29",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R147009",
                    "label": "Drug delivery across the blood brain barrier"
                }
            ],
            "abstract": "aim: drug targeting to the cns is challenging due to the presence of blood\u2013brain barrier. we investigated chitosan (cs) nanoparticles (nps) as drug transporter system across the blood\u2013brain barrier, based on mab ox26 modified cs. materials &amp; methods: cs nps functionalized with peg, modified and unmodified with ox26 (cs-peg-ox26) were prepared and chemico-physically characterized. these nps were administered (intraperitoneal) in mice to define their ability to reach the brain. results: brain uptake of ox26-conjugated nps is much higher than of unmodified nps, because: long-circulating abilities (conferred by peg), interaction between cationic cs and brain endothelium negative charges and ox26 tfr receptor affinity. conclusion: cs-peg-ox26 nps are promising drug delivery system to the cns."
        },
        {
            "id": "R148187",
            "label": "Dual-Peptide-Functionalized Albumin-Based Nanoparticles with pH-Dependent Self-Assembly Behavior for Drug Delivery",
            "doi": "10.1021/acsami.5b03866",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R147009",
                    "label": "Drug delivery across the blood brain barrier"
                }
            ],
            "abstract": "drug delivery has become an important strategy for improving the chemotherapy efficiency. here we developed a multifunctionalized nanosized albumin-based drug-delivery system with tumor-targeting, cell-penetrating, and endolysosomal ph-responsive properties. crgd-bsa/kala/dox nanoparticles were fabricated by self-assembly through electrostatic interaction between cell-penetrating peptide kala and crgd-bsa, with crgd as a tumor-targeting ligand. under endosomal/lysosomal acidic conditions, the changes in the electric charges of crgd-bsa and kala led to the disassembly of the nanoparticles to accelerate intracellular drug release. crgd-bsa/kala/dox nanoparticles showed an enhanced inhibitory effect in the growth of \u03b1v\u03b23-integrin-overexpressed tumor cells, indicating promising application in cancer treatments."
        },
        {
            "id": "R148330",
            "label": "Enhanced Intracellular Delivery and Chemotherapy for Glioma Rats by Transferrin-Conjugated Biodegradable Polymersomes Loaded with Doxorubicin",
            "doi": "10.1021/bc200062q",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R147009",
                    "label": "Drug delivery across the blood brain barrier"
                }
            ],
            "abstract": "a brain drug delivery system for glioma chemotherapy based on transferrin-conjugated biodegradable polymersomes, tf-po-dox, was made and evaluated with doxorubicin (dox) as a model drug. biodegradable polymersomes (po) loaded with doxorubicin (dox) were prepared by the nanoprecipitation method (po-dox) and then conjugated with transferrin (tf) to yield tf-po-dox with an average diameter of 107 nm and surface tf molecule number per polymersome of approximately 35. compared with po-dox and free dox, tf-po-dox demonstrated the strongest cytotoxicity against c6 glioma cells and the greatest intracellular delivery. it was shown in pharmacokinetic and brain distribution experiments that tf-po significantly enhanced brain delivery of dox, especially the delivery of dox into brain tumor cells. pharmacodynamics results revealed a significant reduction of tumor volume and a significant increase of median survival time in the group of tf-po-dox compared with those in saline control animals, animals treated with po-dox, and free dox solution. by terminal deoxynucleotidyl transferase-mediated dutp nick-end-labeling, tf-po-dox could extensively make tumor cell apoptosis. these results indicated that tf-po-dox could significantly enhance the intracellular delivery of dox in glioma and the chemotherapeutic effect of dox for glioma rats."
        },
        {
            "id": "R148337",
            "label": "The proton permeability of self-assembled polymersomes and their neuroprotection by enhancing a neuroprotective peptide across the blood\u2013brain barrier after modification with lactoferrin",
            "doi": "10.1039/c3nr05196j",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R147009",
                    "label": "Drug delivery across the blood brain barrier"
                }
            ],
            "abstract": "biotherapeutics such as peptides possess strong potential for the treatment of intractable neurological disorders. however, because of their low stability and the impermeability of the blood-brain barrier (bbb), biotherapeutics are difficult to transport into brain parenchyma via intravenous injection. herein, we present a novel poly(ethylene glycol)-poly(d,l-lactic-co-glycolic acid) polymersome-based nanomedicine with self-assembled bilayers, which was functionalized with lactoferrin (lf-pos) to facilitate the transport of a neuroprotective peptide into the brain. the apparent diffusion coefficient (d*) of h(+) through the polymersome membrane was 5.659 \u00d7 10(-26) cm(2) s(-1), while that of liposomes was 1.017 \u00d7 10(-24) cm(2) s(-1). the stability of the polymersome membrane was much higher than that of liposomes. the uptake of polymersomes by mouse brain capillary endothelial cells proved that the optimal density of lactoferrin was 101 molecules per polymersome. fluorescence imaging indicated that lf101-pos was effectively transferred into the brain. in pharmacokinetics, compared with transferrin-modified polymersomes and cationic bovine serum albumin-modified polymersomes, lf-pos obtained the greatest bbb permeability surface area and percentage of injected dose per gram (%id per g). furthermore, lf-pos holding s14g-humanin protected against learning and memory impairment induced by amyloid-\u03b225-35 in rats. western blotting revealed that the nanomedicine provided neuroprotection against over-expression of apoptotic proteins exhibiting neurofibrillary tangle pathology in neurons. the results indicated that polymersomes can be exploited as a promising non-invasive nanomedicine capable of mediating peptide therapeutic delivery and controlling the release of drugs to the central nervous system."
        },
        {
            "id": "R148414",
            "label": "Evaluation of psoralen ethosomes for topical delivery in rats by using in vivo microdialysis",
            "doi": "10.2147/ijn.s57314",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R148397",
                    "label": "Lipid vesicles for psoriasis therapy"
                }
            ],
            "abstract": "this study aimed to improve skin permeation and deposition of psoralen by using ethosomes and to investigate real-time drug release in the deep skin in rats. we used a uniform design method to evaluate the effects of different ethosome formulations on entrapment efficiency and drug skin deposition. using in vitro and in vivo methods, we investigated skin penetration and release from psoralen-loaded ethosomes in comparison with an ethanol tincture. in in vitro studies, the use of ethosomes was associated with a 6.56-fold greater skin deposition of psoralen than that achieved with the use of the tincture. in vivo skin microdialysis showed that the peak concentration and area under the curve of psoralen from ethosomes were approximately 3.37 and 2.34 times higher, respectively, than those of psoralen from the tincture. moreover, it revealed that the percutaneous permeability of ethosomes was greater when applied to the abdomen than when applied to the chest or scapulas. enhanced permeation and skin deposition of psoralen delivered by ethosomes may help reduce toxicity and improve the efficacy of long-term psoralen treatment."
        },
        {
            "id": "R149126",
            "label": "Superparamagnetic Iron Oxide\u2013enhanced MR Imaging of Head and Neck Lymph Nodes",
            "doi": "10.1148/radiol.2221010225",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R149134",
                    "label": "Super magnetic iron oxide nanoparticles"
                }
            ],
            "abstract": "purpose\\nto compare findings on superparamagnetic iron oxide (spio)-enhanced magnetic resonance (mr) images of the head and neck with those from resected lymph node specimens and to determine the effect of such imaging on surgical planning in patients with histopathologically proved squamous cell carcinoma of the head and neck.\\n\\n\\nmaterials and methods\\nthirty patients underwent mr imaging with nonenhanced and spio-enhanced (2.6 mg fe/kg intravenously) t1-weighted (500/15 [repetition time msec/echo time msec]) and t2-weighted (1,900/80) spin-echo and t2-weighted gradient-echo (gre) (500/15, 15 degrees flip angle) sequences. signal intensity decrease was measured, and visual analysis was performed. surgical plans were modified, if necessary, according to mr findings. histopathologic and mr findings were compared.\\n\\n\\nresults\\nhistopathologic evaluation of 1,029 lymph nodes revealed 69 were metastatic. mr imaging enabled detection of 59 metastases. regarding lymph node levels, mr diagnosis was correct in 26 of 27 patients who underwent surgery: only one metastasis was localized in level ii with mr imaging, whereas histopathologic evaluation placed it at level iii. extent of surgery was changed in seven patients. spio-enhanced t2-weighted gre was the best sequence for differentiating between benign and malignant lymph nodes.\\n\\n\\nconclusion\\nspio-enhanced mr imaging has an important effect on planning the extent of surgery. on a patient basis, spio-enhanced mr images compared well with resected specimens."
        },
        {
            "id": "R38466",
            "label": "Biotea-2-Bioschemas, facilitating structured markup for semantically annotated scholarly publications",
            "doi": "10.5808/gi.2019.17.2.e14",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R38476",
                    "label": "Structured data for scholarly publications"
                },
                {
                    "id": "R38477",
                    "label": "Semantic annotation for scholarly publications"
                }
            ],
            "abstract": "the total number of scholarly publications grows day by day, making it necessary to explore and use simple yet effective ways to expose their metadata. schema.org supports adding structured metadata to web pages via markup, making it easier for data providers but also for search engines to provide the right search results. bioschemas is based on the standards of schema.org, providing new types, properties and guidelines for metadata, i.e., providing metadata profiles tailored to the life sciences domain. here we present our proposed contribution to bioschemas (from the project \u201cbiotea\u201d), which supports metadata contributions for scholarly publications via profiles and web components. biotea comprises a semantic model to represent publications together with annotated elements recognized from the scientific text; our biotea model has been mapped to schema.org following bioschemas standards."
        },
        {
            "id": "R5107",
            "label": "Implementing LOINC \u2013 Current Status and Ongoing Work at a Medical University",
            "doi": "10.3233/SHTI190806",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R5120",
                    "label": "semantics of medical data"
                }
            ],
            "abstract": "the logical observation identifiers, names and codes (loinc) is a common terminology used for standardizing laboratory terms. within the consortium of the highmed project, loinc is one of the central terminologies used for health data sharing across all university sites. therefore, linking the loinc codes to the site-specific tests and measures is one crucial step to reach this goal. in this work we report our ongoing efforts in implementing loinc to our laboratory information system and research infrastructure, as well as our challenges and the lessons learned. 407 local terms could be mapped to 376 loinc codes of which 209 are already available to routine laboratory data. in our experience, mapping of local terms to loinc is a widely manual and time consuming process for reasons of language and expert knowledge of local laboratory procedures."
        },
        {
            "id": "R5129",
            "label": "PARAMO: A Pipeline for Reconstructing Ancestral Anatomies Using Ontologies and Stochastic Mapping",
            "doi": "10.1093/isd/ixz009",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R5137",
                    "label": "Comparative phylogenetics"
                }
            ],
            "abstract": "abstract \\n comparative phylogenetics has been largely lacking a method for reconstructing the evolution of phenotypic entities that consist of ensembles of multiple discrete traits\u2014entire organismal anatomies or organismal body regions. in this study, we provide a new approach named paramo (phylogeneticancestralreconstruction ofanatomy bymappingontologies) that appropriately models anatomical dependencies and uses ontology-informed amalgamation of stochastic maps to reconstruct phenotypic evolution at different levels of anatomical hierarchy including entire phenotypes. this approach provides new opportunities for tracking phenotypic radiations and evolution of organismal anatomies."
        },
        {
            "id": "R138698",
            "label": "Application of Autoencoder in Depression Diagnosis",
            "doi": "10.12783/dtcse/csma2017/17335",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "major depressive disorder (mdd) is a mental disorder characterized by at least two weeks of low mood which is present across most situations. diagnosis of mdd using rest-state functional magnetic resonance imaging (fmri) data faces many challenges due to the high dimensionality, small samples, noisy and individual variability. no method can automatically extract discriminative features from the origin time series in fmri images for mdd diagnosis. in this study, we proposed a new method for feature extraction and a workflow which can make an automatic feature extraction and classification without a prior knowledge. an autoencoder was used to learn pre-training parameters of a dimensionality reduction process using 3-d convolution network. through comparison with the other three feature extraction methods, our method achieved the best classification performance. this method can be used not only in mdd diagnosis, but also other similar disorders."
        },
        {
            "id": "R148043",
            "label": "MedPost: a part-of-speech tagger for bioMedical text",
            "doi": "10.1093/bioinformatics/bth227",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R116310",
                    "label": "Part-Of-Speech Tagging"
                }
            ],
            "abstract": "summary\\nwe present a part-of-speech tagger that achieves over 97% accuracy on medline citations.\\n\\n\\navailability\\nsoftware, documentation and a corpus of 5700 manually tagged sentences are available at ftp://ftp.ncbi.nlm.nih.gov/pub/lsmith/medpost/medpost.tar.gz"
        },
        {
            "id": "R148599",
            "label": "An approach to protein name extraction using heuristics and a dictionary",
            "doi": "10.1002/meet.1450400109",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R148595",
                    "label": "Protein tagging"
                }
            ],
            "abstract": "this paper proposes a method for protein name extraction from biological texts. our method exploits hand-crafted rules based on heuristics and a set of protein names (dictionary). in contrast to previously proposed methods, our approach avoids the use of natural language processing tools such as part-of-speech taggers and syntactic parsers so as to improve processing speed. we implemented a prototype system for protein name extraction based on our method and conducted evaluation experiments. the result showed that our system produces outcome comparable to the state-of-the-art protein name extraction system on multiple corpora."
        },
        {
            "id": "R150475",
            "label": "Biomedical named entity recognition and linking datasets: survey and our recent development",
            "doi": "10.1093/bib/bbaa054",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R147583",
                    "label": "Scientific concept annotation"
                },
                {
                    "id": "R76427",
                    "label": "Language resource"
                }
            ],
            "abstract": "abstract natural language processing (nlp) is widely applied in biological domains to retrieve information from publications. systems to address numerous applications exist, such as biomedical named entity recognition (bner), named entity normalization (nen) and protein\u2013protein interaction extraction (ppie). high-quality datasets can assist the development of robust and reliable systems; however, due to the endless applications and evolving techniques, the annotations of benchmark datasets may become outdated and inappropriate. in this study, we first review commonlyused bner datasets and their potential annotation problems such as inconsistency and low portability. then, we introduce a revised version of the jnlpba dataset that solves potential problems in the original and use state-of-the-art named entity recognition systems to evaluate its portability to different kinds of biomedical literature, including protein\u2013protein interaction and biology events. lastly, we introduce an ensembled biomedical entity dataset (ebed) by extending the revised jnlpba dataset with pubmed central full-text paragraphs, figure captions and patent abstracts. this ebed is a multi-task dataset that covers annotations including gene, disease and chemical entities. in total, it contains 85000 entity mentions, 25000 entity mentions with database identifiers and 5000 attribute tags. to demonstrate the usage of the ebed, we review the bner track from the ai cup biomedical paper analysis challenge. availability: the revised jnlpba dataset is available at https://iasl-btm.iis.sinica.edu.tw/bner/content/re vised_jnlpba.zip. the ebed dataset is available at https://iasl-btm.iis.sinica.edu.tw/bner/content/aicup _ebed_dataset.rar. contact: email: thtsai@g.ncu.edu.tw, tel. 886-3-4227151 ext. 35203, fax: 886-3-422-2681 email: hsu@iis.sinica.edu.tw, tel. 886-2-2788-3799 ext. 2211, fax: 886-2-2782-4814 supplementary information: supplementary data are available at briefings in bioinformatics online."
        },
        {
            "id": "R150537",
            "label": "LINNAEUS: A species name identification system for biomedical literature",
            "doi": "10.1186/1471-2105-11-85",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R150540",
                    "label": "Species name recognition and normalization"
                }
            ],
            "abstract": "abstract \\n \\n background \\n the task of recognizing and identifying species names in biomedical literature has recently been regarded as critical for a number of applications in text and data mining, including gene name recognition, species-specific document retrieval, and semantic enrichment of biomedical articles. \\n \\n \\n results \\n in this paper we describe an open-source species name recognition and normalization software system, linnaeus, and evaluate its performance relative to several automatically generated biomedical corpora, as well as a novel corpus of full-text documents manually annotated for species mentions. linnaeus uses a dictionary-based approach (implemented as an efficient deterministic finite-state automaton) to identify species names and a set of heuristics to resolve ambiguous mentions. when compared against our manually annotated corpus, linnaeus performs with 94% recall and 97% precision at the mention level, and 98% recall and 90% precision at the document level. our system successfully solves the problem of disambiguating uncertain species mentions, with 97% of all mentions in pubmed central full-text documents resolved to unambiguous ncbi taxonomy identifiers. \\n \\n \\n conclusions \\n linnaeus is an open source, stand-alone software system capable of recognizing and normalizing species name mentions with speed and accuracy, and can therefore be integrated into a range of bioinformatics and text-mining applications. the software and manually annotated corpus can be downloaded freely at http://linnaeus.sourceforge.net/ . \\n"
        },
        {
            "id": "R150549",
            "label": "Classifying semantic relations in bioscience texts",
            "doi": "10.3115/1218955.1219010",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R150562",
                    "label": "Identification of semantic relations"
                }
            ],
            "abstract": "a crucial step toward the goal of automatic extraction of propositional information from natural language text is the identification of semantic relations between constituents in sentences. we examine the problem of distinguishing among seven relation types that can occur between the entities \"treatment\" and \"disease\" in bioscience text, and the problem of identifying such entities. we compare five generative graphical models and a neural network, using lexical, syntactic, and semantic features, finding that the latter help achieve high classification accuracy."
        },
        {
            "id": "R164009",
            "label": "A Survey of Bioinformatics Database and Software Usage through Mining the Literature",
            "doi": "10.1371/journal.pone.0157989",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "computer-based resources are central to much, if not most, biological and medical research. however, while there is an ever expanding choice of bioinformatics resources to use, described within the biomedical literature, little work to date has provided an evaluation of the full range of availability or levels of usage of database and software resources. here we use text mining to process the pubmed central full-text corpus, identifying mentions of databases or software within the scientific literature. we provide an audit of the resources contained within the biomedical literature, and a comparison of their relative usage, both over time and between the sub-disciplines of bioinformatics, biology and medicine. we find that trends in resource usage differs between these domains. the bioinformatics literature emphasises novel resource development, while database and software usage within biology and medicine is more stable and conservative. many resources are only mentioned in the bioinformatics literature, with a relatively small number making it out into general biology, and fewer still into the medical literature. in addition, many resources are seeing a steady decline in their usage (e.g., blast, swiss-prot), though some are instead seeing rapid growth (e.g., the go, r). we find a striking imbalance in resource usage with the top 5% of resource names (133 names) accounting for 47% of total usage, and over 70% of resources extracted being only mentioned once each. while these results highlight the dynamic and creative nature of bioinformatics research they raise questions about software reuse, choice and the sharing of bioinformatics practice. is it acceptable that so many resources are apparently never reused? finally, our work is a step towards automated extraction of scientific method from text. we make the dataset generated by our study available under the cc0 license here: http://dx.doi.org/10.6084/m9.figshare.1281371."
        },
        {
            "id": "R168464",
            "label": "Microscopy Image Browser: A Platform for Segmentation and Analysis of Multidimensional Datasets",
            "doi": "10.1371/journal.pbio.1002340",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "understanding the structure\u2013function relationship of cells and organelles in their natural context requires multidimensional imaging. as techniques for multimodal 3-d imaging have become more accessible, effective processing, visualization, and analysis of large datasets are posing a bottleneck for the workflow. here, we present a new software package for high-performance segmentation and image processing of multidimensional datasets that improves and facilitates the full utilization and quantitative analysis of acquired data, which is freely available from a dedicated website. the open-source environment enables modification and insertion of new plug-ins to customize the program for specific needs. we provide practical examples of program features used for processing, segmentation and analysis of light and electron microscopy datasets, and detailed tutorials to enable users to rapidly and thoroughly learn how to use the program."
        },
        {
            "id": "R168467",
            "label": "CellProfiler 3.0: Next-generation image processing for biology",
            "doi": "10.1371/journal.pbio.2005970",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cellprofiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. here, we describe cellprofiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3d) image stacks, increasingly common in biomedical research. cellprofiler\u2019s infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. new plugins enable running pretrained deep learning models on images. designed by and for biologists, cellprofiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows."
        },
        {
            "id": "R168483",
            "label": "PhyloGibbs-MP: Module Prediction and Discriminative Motif-Finding by Gibbs Sampling",
            "doi": "10.1371/journal.pcbi.1000156",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"phylogibbs, our recent gibbs-sampling motif-finder, takes phylogeny into account in detecting binding sites for transcription factors in dna and assigns posterior probabilities to its predictions obtained by sampling the entire configuration space. here, in an extension called phylogibbs-mp, we widen the scope of the program, addressing two major problems in computational regulatory genomics. first, phylogibbs-mp can localise predictions to small, undetermined regions of a large input sequence, thus effectively predicting cis-regulatory modules (crms) ab initio while simultaneously predicting binding sites in those modules\u2014tasks that are usually done by two separate programs. phylogibbs-mp's performance at such ab initio crm prediction is comparable with or superior to dedicated module-prediction software that use prior knowledge of previously characterised transcription factors. second, phylogibbs-mp can predict motifs that differentiate between two (or more) different groups of regulatory regions, that is, motifs that occur preferentially in one group over the others. while other \u201cdiscriminative motif-finders\u201d have been published in the literature, phylogibbs-mp's implementation has some unique features and flexibility. benchmarks on synthetic and actual genomic data show that this algorithm is successful at enhancing predictions of differentiating sites and suppressing predictions of common sites and compares with or outperforms other discriminative motif-finders on actual genomic data. additional enhancements include significant performance and speed improvements, the ability to use \u201cinformative priors\u201d on known transcription factors, and the ability to output annotations in a format that can be visualised with the generic genome browser. in stand-alone motif-finding, phylogibbs-mp remains competitive, outperforming phylogibbs-1.0 and other programs on benchmark data.\""
        },
        {
            "id": "R168487",
            "label": "PSICIC: Noise and Asymmetry in Bacterial Division Revealed by Computational Image Analysis at Sub-Pixel Resolution",
            "doi": "10.1371/journal.pcbi.1000233",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "live-cell imaging by light microscopy has demonstrated that all cells are spatially and temporally organized. quantitative, computational image analysis is an important part of cellular imaging, providing both enriched information about individual cell properties and the ability to analyze large datasets. however, such studies are often limited by the small size and variable shape of objects of interest. here, we address two outstanding problems in bacterial cell division by developing a generally applicable, standardized, and modular software suite termed projected system of internal coordinates from interpolated contours (psicic) that solves common problems in image quantitation. psicic implements interpolated-contour analysis for accurate and precise determination of cell borders and automatically generates internal coordinate systems that are superimposable regardless of cell geometry. we have used psicic to establish that the cell-fate determinant, spoiie, is asymmetrically localized during bacillus subtilis sporulation, thereby demonstrating the ability of psicic to discern protein localization features at sub-pixel scales. we also used psicic to examine the accuracy of cell division in esherichia coli and found a new role for the min system in regulating division-site placement throughout the cell length, but only prior to the initiation of cell constriction. these results extend our understanding of the regulation of both asymmetry and accuracy in bacterial division while demonstrating the general applicability of psicic as a computational approach for quantitative, high-throughput analysis of cellular images."
        },
        {
            "id": "R168492",
            "label": "PoreWalker: A Novel Tool for the Identification and Characterization of Channels in Transmembrane Proteins from Their Three-Dimensional Structure",
            "doi": "10.1371/journal.pcbi.1000440",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "transmembrane channel proteins play pivotal roles in maintaining the homeostasis and responsiveness of cells and the cross-membrane electrochemical gradient by mediating the transport of ions and molecules through biological membranes. therefore, computational methods which, given a set of 3d coordinates, can automatically identify and describe channels in transmembrane proteins are key tools to provide insights into how they function. herein we present porewalker, a fully automated method, which detects and fully characterises channels in transmembrane proteins from their 3d structures. a stepwise procedure is followed in which the pore centre and pore axis are first identified and optimised using geometric criteria, and then the biggest and longest cavity through the channel is detected. finally, pore features, including diameter profiles, pore-lining residues, size, shape and regularity of the pore are calculated, providing a quantitative and visual characterization of the channel. to illustrate the use of this tool, the method was applied to several structures of transmembrane channel proteins and was able to identify shape/size/residue features representative of specific channel families. the software is available as a web-based resource at http://www.ebi.ac.uk/thornton-srv/software/porewalker/."
        },
        {
            "id": "R168498",
            "label": "Podbat: A Novel Genomic Tool Reveals Swr1-Independent H2A.Z Incorporation at Gene Coding Sequences through Epigenetic Meta-Analysis",
            "doi": "10.1371/journal.pcbi.1002163",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "epigenetic regulation consists of a multitude of different modifications that determine active and inactive states of chromatin. conditions such as cell differentiation or exposure to environmental stress require concerted changes in gene expression. to interpret epigenomics data, a spectrum of different interconnected datasets is needed, ranging from the genome sequence and positions of histones, together with their modifications and variants, to the transcriptional output of genomic regions. here we present a tool, podbat (positioning database and analysis tool), that incorporates data from various sources and allows detailed dissection of the entire range of chromatin modifications simultaneously. podbat can be used to analyze, visualize, store and share epigenomics data. among other functions, podbat allows data-driven determination of genome regions of differential protein occupancy or rna expression using hidden markov models. comparisons between datasets are facilitated to enable the study of the comprehensive chromatin modification system simultaneously, irrespective of data-generating technique. any organism with a sequenced genome can be accommodated. we exemplify the power of podbat by reanalyzing all to-date published genome-wide data for the histone variant h2a.z in fission yeast together with other histone marks and also phenotypic response data from several sources. this meta-analysis led to the unexpected finding of h2a.z incorporation in the coding regions of genes encoding proteins involved in the regulation of meiosis and genotoxic stress responses. this incorporation was partly independent of the h2a.z-incorporating remodeller swr1. we verified an swr1-independent role for h2a.z following genotoxic stress in vivo. podbat is open source software freely downloadable from www.podbat.org, distributed under the gnu lgpl license. user manuals, test data and instructions are available at the website, as well as a repository for third party\u2013developed plug-in modules. podbat requires java version 1.6 or higher."
        },
        {
            "id": "R168503",
            "label": "DOGS: Reaction-Driven de novo Design of Bioactive Compounds",
            "doi": "10.1371/journal.pcbi.1002380",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"we present a computational method for the reaction-based de novo design of drug-like molecules. the software dogs (design of genuine structures) features a ligand-based strategy for automated \u2018in silico\u2019 assembly of potentially novel bioactive compounds. the quality of the designed compounds is assessed by a graph kernel method measuring their similarity to known bioactive reference ligands in terms of structural and pharmacophoric features. we implemented a deterministic compound construction procedure that explicitly considers compound synthesizability, based on a compilation of 25'144 readily available synthetic building blocks and 58 established reaction principles. this enables the software to suggest a synthesis route for each designed compound. two prospective case studies are presented together with details on the algorithm and its implementation. de novo designed ligand candidates for the human histamine h4 receptor and \u03b3-secretase were synthesized as suggested by the software. the computational approach proved to be suitable for scaffold-hopping from known ligands to novel chemotypes, and for generating bioactive molecules with drug-like properties.\""
        },
        {
            "id": "R168508",
            "label": "ACME: Automated Cell Morphology Extractor for Comprehensive Reconstruction of Cell Membranes",
            "doi": "10.1371/journal.pcbi.1002780",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the quantification of cell shape, cell migration, and cell rearrangements is important for addressing classical questions in developmental biology such as patterning and tissue morphogenesis. time-lapse microscopic imaging of transgenic embryos expressing fluorescent reporters is the method of choice for tracking morphogenetic changes and establishing cell lineages and fate maps in vivo. however, the manual steps involved in curating thousands of putative cell segmentations have been a major bottleneck in the application of these technologies especially for cell membranes. segmentation of cell membranes while more difficult than nuclear segmentation is necessary for quantifying the relations between changes in cell morphology and morphogenesis. we present a novel and fully automated method to first reconstruct membrane signals and then segment out cells from 3d membrane images even in dense tissues. the approach has three stages: 1) detection of local membrane planes, 2) voting to fill structural gaps, and 3) region segmentation. we demonstrate the superior performance of the algorithms quantitatively on time-lapse confocal and two-photon images of zebrafish neuroectoderm and paraxial mesoderm by comparing its results with those derived from human inspection. we also compared with synthetic microscopic images generated by simulating the process of imaging with fluorescent reporters under varying conditions of noise. both the over-segmentation and under-segmentation percentages of our method are around 5%. the volume overlap of individual cells, compared to expert manual segmentation, is consistently over 84%. by using our software (acme) to study somite formation, we were able to segment touching cells with high accuracy and reliably quantify changes in morphogenetic parameters such as cell shape and size, and the arrangement of epithelial and mesenchymal cells. our software has been developed and tested on windows, mac, and linux platforms and is available publicly under an open source bsd license (https://github.com/krm15/acme)."
        },
        {
            "id": "R168516",
            "label": "Redirector: Designing Cell Factories by Reconstructing the Metabolic Objective",
            "doi": "10.1371/journal.pcbi.1002882",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "advances in computational metabolic optimization are required to realize the full potential of new in vivo metabolic engineering technologies by bridging the gap between computational design and strain development. we present redirector, a new flux balance analysis-based framework for identifying engineering targets to optimize metabolite production in complex pathways. previous optimization frameworks have modeled metabolic alterations as directly controlling fluxes by setting particular flux bounds. redirector develops a more biologically relevant approach, modeling metabolic alterations as changes in the balance of metabolic objectives in the system. this framework iteratively selects enzyme targets, adds the associated reaction fluxes to the metabolic objective, thereby incentivizing flux towards the production of a metabolite of interest. these adjustments to the objective act in competition with cellular growth and represent up-regulation and down-regulation of enzyme mediated reactions. using the iaf1260 e. coli metabolic network model for optimization of fatty acid production as a test case, redirector generates designs with as many as 39 simultaneous and 111 unique engineering targets. these designs discover proven in vivo targets, novel supporting pathways and relevant interdependencies, many of which cannot be predicted by other methods. redirector is available as open and free software, scalable to computational resources, and powerful enough to find all known enzyme targets for fatty acid production."
        },
        {
            "id": "R168521",
            "label": "Chaste: An Open Source C++ Library for Computational Physiology and Biology",
            "doi": "10.1371/journal.pcbi.1002970",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "chaste \u2014 cancer, heart and soft tissue environment \u2014 is an open source c++ library for the computational simulation of mathematical models developed for physiology and biology. code development has been driven by two initial applications: cardiac electrophysiology and cancer development. a large number of cardiac electrophysiology studies have been enabled and performed, including high-performance computational investigations of defibrillation on realistic human cardiac geometries. new models for the initiation and growth of tumours have been developed. in particular, cell-based simulations have provided novel insight into the role of stem cells in the colorectal crypt. chaste is constantly evolving and is now being applied to a far wider range of problems. the code provides modules for handling common scientific computing components, such as meshes and solvers for ordinary and partial differential equations (odes/pdes). re-use of these components avoids the need for researchers to \u2018re-invent the wheel\u2019 with each new project, accelerating the rate of progress in new applications. chaste is developed using industrially-derived techniques, in particular test-driven development, to ensure code quality, re-use and reliability. in this article we provide examples that illustrate the types of problems chaste can be used to solve, which can be run on a desktop computer. we highlight some scientific studies that have used or are using chaste, and the insights they have provided. the source code, both for specific releases and the development version, is available to download under an open source berkeley software distribution (bsd) licence at http://www.cs.ox.ac.uk/chaste, together with details of a mailing list and links to documentation and tutorials."
        },
        {
            "id": "R168527",
            "label": "GEMINI: Integrative Exploration of Genetic Variation and Genome Annotations",
            "doi": "10.1371/journal.pcbi.1003153",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"modern dna sequencing technologies enable geneticists to rapidly identify genetic variation among many human genomes. however, isolating the minority of variants underlying disease remains an important, yet formidable challenge for medical genetics. we have developed gemini (genome mining), a flexible software package for exploring all forms of human genetic variation. unlike existing tools, gemini integrates genetic variation with a diverse and adaptable set of genome annotations (e.g., dbsnp, encode, ucsc, clinvar, kegg) into a unified database to facilitate interpretation and data exploration. whereas other methods provide an inflexible set of variant filters or prioritization methods, gemini allows researchers to compose complex queries based on sample genotypes, inheritance patterns, and both pre-installed and custom genome annotations. gemini also provides methods for ad hoc queries and data exploration, a simple programming interface for custom analyses that leverage the underlying database, and both command line and graphical tools for common analyses. we demonstrate gemini's utility for exploring variation in personal genomes and family based genetic studies, and illustrate its ability to scale to studies involving thousands of human samples. gemini is designed for reproducibility and flexibility and our goal is to provide researchers with a standard framework for medical genomics.\""
        },
        {
            "id": "R168532",
            "label": "GINI: From ISH Images to Gene Interaction Networks",
            "doi": "10.1371/journal.pcbi.1003227",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "accurate inference of molecular and functional interactions among genes, especially in multicellular organisms such as drosophila, often requires statistical analysis of correlations not only between the magnitudes of gene expressions, but also between their temporal-spatial patterns. the ish (in-situ-hybridization)-based gene expression micro-imaging technology offers an effective approach to perform large-scale spatial-temporal profiling of whole-body mrna abundance. however, analytical tools for discovering gene interactions from such data remain an open challenge due to various reasons, including difficulties in extracting canonical representations of gene activities from images, and in inference of statistically meaningful networks from such representations. in this paper, we present gini, a machine learning system for inferring gene interaction networks from drosophila embryonic ish images. gini builds on a computer-vision-inspired vector-space representation of the spatial pattern of gene expression in ish images, enabled by our recently developed system; and a new multi-instance-kernel algorithm that learns a sparse markov network model, in which, every gene (i.e., node) in the network is represented by a vector-valued spatial pattern rather than a scalar-valued gene intensity as in conventional approaches such as a gaussian graphical model. by capturing the notion of spatial similarity of gene expression, and at the same time properly taking into account the presence of multiple images per gene via multi-instance kernels, gini is well-positioned to infer statistically sound, and biologically meaningful gene interaction networks from image data. using both synthetic data and a small manually curated data set, we demonstrate the effectiveness of our approach in network building. furthermore, we report results on a large publicly available collection of drosophila embryonic ish images from the berkeley drosophila genome project, where gini makes novel and interesting predictions of gene interactions. software for gini is available at http://sailing.cs.cmu.edu/drosophila_ish_images/"
        },
        {
            "id": "R151437",
            "label": "Fast-discharge excitation of hot capillary plasmas for soft-x-ray amplifiers",
            "doi": "10.1103/physreve.47.1299",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151465",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "high-temperature (${\\\\mathit{t}}_{\\\\mathit{e}}$g150 ev), small-diameter (\\\\ensuremath{\\\\sim}200 \\\\ensuremath{\\\\mu}m) plasma columns have been efficiently generated by very fast (13 ns rise time, 28 ns full width at half maximum) pulsed discharge excitation of capillary channels filled with preionized gas. discharges in argon-filled capillaries at currents between 20 and 60 ka produced plasmas with ar x--ar xiv line emission, in which the degree of ionization was controlled by the magnitude of the current pulse. the characteristics of these plasmas differ from those created by vacuum discharges in the same capillaries and approach those necessary for soft-x-ray amplification in low-z elements."
        },
        {
            "id": "R151466",
            "label": "Demonstration of a Discharge Pumped Table-Top Soft-X-Ray Laser",
            "doi": "10.1103/physrevlett.73.2192",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151465",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we report the first observation of large soft-x-ray amplification ([ital gl]=7.2) in a discharge created plasma. a fast, [similar to]40 ka current pulse from a compact discharge was used to excite plasma columns up to 12 cm in length in 4 mm channels, producing population inversion in the [ital j]=0[minus]1 line of ne-like ar and resulting in a gain of 0.6 cm[sup [minus]1] at 46.9 nm. the beam divergence was measured to be [lt]9 mrad."
        },
        {
            "id": "R151493",
            "label": "Energy Extraction and Achievement of the Saturation Limit in a Discharge-Pumped Table-Top Soft X-Ray Amplifier",
            "doi": "10.1103/physrevlett.77.1476",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151465",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "a major goal in ultrashort wavelength laser research is the development of practical laser sources that can impact applications. of particular interest is the demonstration of compact \u201ctable-top\u201d amplifiers capable of generating soft x-ray pulses of substantial energy. such development motivates the demonstration of gain media generated by compact devices that can be successfully scaled in length to reach gain saturation. at this condition, which occurs when the laser intensity reaches the saturation intensity, a large fraction of the energy stored in the laser upper level can be extracted. to date, gain saturation had only been achieved in a few soft x-ray laser transitions in plasmas generated by some of the world\u2019s largest laser facilities [1\u20134]. while gain in soft x-ray lines has been reported in several compact systems [5\u201313] only in three cases the gain-length product was measured to be greater than 5 [5\u20137]. these include the observation of amplification at 46.9 nm in ne-like ar by our group in a plasma column generated by a fast capillary discharge [5,14], and the demonstration of gain at 41.8 nm in pd-like xe and at 32.6 nm in ne-like ti in plasmas generated by relatively compact terawatt class femtosecond and picosecond laser facilities, respectively [6,7]. in all cases, however, the laser energy extraction from table-top amplifiers has been small and detection of the laser lines was performed with high sensitivity detectors such as microchannel plate (mcp) intensifiers. a next major step in the development of compact ultrashort wavelength lasers consists in advancing from gain observations to the demonstration of substantial laser output energies. depending on the specific amplifier characteristics, this amounts to overcoming barriers that are imposed by small gain volumes and short plasma lengths, by short duration of the gain, or by axial plasma inhomogeneities and limiting refraction effects. recent optimization of the capillary discharge scheme, which has the advantages of a relatively large gain volume and long gain duration, allowed amplification at 46.9 nm to reach 14 gain-length products [15], but no demonstration of substantial laser energy extraction was realized. in this letter we report the generation of laser pulse en-"
        },
        {
            "id": "R151644",
            "label": "Discharge\u2010pumped soft\u2010x\u2010ray laser in neon\u2010like argon",
            "doi": "10.1063/1.871216",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151667",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "starting with the discovery of x\u2010ray lasers in 1984, laser\u2010created plasmas remained for almost a decade, the only medium in which large amplification of soft\u2010x\u2010ray radiation could be obtained. in this paper the recent first demonstration of large soft\u2010x\u2010ray amplification in a discharge\u2010created plasma column, realized utilizing a fast capillary discharge to collisionally excite the 46.9 nm transition of ne\u2010like, ar is reviewed. results of the parametrization of the ar\\u2009ix discharge\u2010pumped amplifier, the study of the dynamics of its plasma column, and the measurement of the time history of the laser pulse are reported. prospects for laser operation at shorter wavelengths are also discussed."
        },
        {
            "id": "R151668",
            "label": "Lasing at 60.8 nm in Ne-like sulfur ions in ablated material excited by a capillary discharge",
            "doi": "10.1103/physreva.55.1437",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151690",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we report the observation of discharge-pumped extreme ultraviolet lasing in collisionally excited ions of a material ablated from a solid target. excitation of sulfur plasmas by a capillary discharge resulted in amplification of the j50\u20131 line of ne-like sulfur at 60.8 nm, with a gain coefficient of 0.45 cm and a gain-length product of 7.5. overheating of the electron temperature and transient population effects are computed to make a significant contribution to the measured gain. @s1050-2947~97!01702-2#"
        },
        {
            "id": "R151692",
            "label": "Demonstration of a desk-top size high repetition rate soft x-ray laser",
            "doi": "10.1364/opex.13.004050",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we have demonstrated a new type of high repetition rate 46.9 nm capillary discharge laser that fits on top of a small desk and that it does not require a marx generator for its excitation. the relatively low voltage required for its operation allows a reduction of nearly one order of magnitude in the size of the pulsed power unit relative to previous capillary discharge lasers. laser pulses with an energy of ~ 13 microj are generated at repetition rates up to 12 hz. about (2-3) x 10 4 laser shots can be generated with a single capillary. this new type of portable laser is an easily accessible source of intense short wavelength laser light for applications."
        },
        {
            "id": "R151716",
            "label": "Discharge-driven 46.9-nm amplifier with gain-length approaching saturation",
            "doi": "10.1109/2944.473682",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "gain length products up to gl/spl ap/14 for the j=0-1 line of ne-like ar at 46.9 nm have been achieved in 15-cm-long plasma columns generated by a fast capillary discharge. amplification in plasma columns up to 20 cm in length was investigated. the laser line intensity is observed to increase exponentially for plasma lengths of up to 15 cm, above which it is observed to saturate. the saturation behavior is discussed. >"
        },
        {
            "id": "R151763",
            "label": "Demonstration of a High Average Power Tabletop Soft X-Ray Laser",
            "doi": "10.1103/physrevlett.81.5804",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we report the first demonstration of a high average power tabletop soft x-ray laser. an average laser output power of o1 mw s.2 3 1014 photonsysd was generated at 46.9 nm in ne-like ar using a very compact tabletop discharge. the spatially coherent average power emitted by this 26.5 ev laser is comparable to that generated at this photon energy in a similar bandwidth sdlyl \\xad 1024d by a thirdgeneration synchrotron beam line. lasing was obtained at a repetition rate of 7 hz with an average output energy of 135 mjypulse by exciting a plasma column in a ceramic capillary with a fast current pulse. this very compact high-repetition-rate laser source makes intense short-wavelength coherent radiation accessible to a wide variety of new applications. [s0031-9007(98)08022-3]"
        },
        {
            "id": "R151786",
            "label": "Generation of millijoule-level soft-x-ray laser pulses at a 4-Hz repetition rate in a highly saturated tabletop capillary discharge amplifier",
            "doi": "10.1364/ol.24.001115",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "laser pulses with energies of as much as 1 mj were generated at a wavelength of 46.9 nm by single-pass amplification in a 34.5 cm-long ne-like ar capillary discharge plasma. the large gain\u2013length product of this plasma column allows for soft-x-ray amplification in a highly saturated regime, resulting in efficient energy extraction. average laser output pulse energy of 0.88 mj and peak power of 0.6 mw were obtained at a repetition rate of 4 hz. with an estimated peak spectral brightness of ?1\u00d71023 photons/(s mm2 mrad2 0.01% bandwidth) this tabletop laser is one of the brightest soft-x-ray sources to date."
        },
        {
            "id": "R152841",
            "label": "Short Pulse X-Ray Laser at 32.6 nm Based on Transient Gain in Ne-like Titanium",
            "doi": "10.1103/physrevlett.78.2748",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "a novel two-step excitation scheme for an efficient table-top x-ray laser has been realized for the first time. a nanosecond pulse creates a plasma of neonlike ions of titanium, followed by a subpicosecond pulse which excites a nonstationary population inversion. with only a few joules of pump energy, a compact x-ray laser at 32.6 nm with a very high gain coefficient of $g\\\\phantom{\\\\rule{0ex}{0ex}}=\\\\phantom{\\\\rule{0ex}{0ex}}19{\\\\mathrm{cm}}^{\\\\ensuremath{-}1}$ and a gain-length product of $gl\\\\phantom{\\\\rule{0ex}{0ex}}=\\\\phantom{\\\\rule{0ex}{0ex}}9.5$ was achieved."
        },
        {
            "id": "R153258",
            "label": "Demonstration of X-Ray Amplification in Transient Gain Nickel-like Palladium Scheme",
            "doi": "10.1103/physrevlett.80.2825",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we report experimental results of x-ray amplification of spontaneous emission in a ni-like transient collisional excitation scheme. the ni-like plasma formation, ionization, and collisional excitation requires irradiation of a slab target by two laser pulses: a formation beam with 5j energy of 800ps duration and a pump beam of 5j energy in 1.1ps. a gain of 35 cm{sup {minus}1} and a gl product of 12.5 are measured on the 4d{r_arrow}4p j=0{r_arrow}1 transition for ni-like pd at 147{angstrom} with an 8mm line focus. the high efficiency of this scheme at {open_quotes}table-top{close_quotes} laser energies is a direct consequence of the nonstationary population inversion produced by the high intensity picosecond pulse. {copyright} {ital 1998} {ital the american physical society}"
        },
        {
            "id": "R153969",
            "label": "Demonstration of transient gain x-ray lasers near 20??nm for nickellike yttrium, zirconium, niobium, and molybdenum",
            "doi": "10.1364/ol.24.000101",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we demonstrate strong lasing on the ni-like 4d(1)s(0)?4p(1)p(1) transition at 18.9, 20.3, 22.0, and 24.0 nm for mo, nb, zr, and y ions, respectively, using the transient collisional excitation scheme. approximately 5 j of laser energy in a combination of a 600-ps pulse and a 1-ps pulse from the compact multipulse terawatt (comet) tabletop laser system is used to irradiate slab targets of these materials. small-signal gains of 17-26cm (-1) are determined on the 4d?4p transition, with overall gain-length products gl of 11-12. lasing is observed and gain is measured on the 4f(1)p(1)?4d(1)p(1) transition, which is pumped by collisional excitation combined with self-photopumping, for what is to our knowledge the first time."
        },
        {
            "id": "R154021",
            "label": "Gain Saturation Regime for Laser-Driven Tabletop, Transient Ni-Like Ion X-Ray Lasers",
            "doi": "10.1103/physrevlett.84.4834",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we have demonstrated small signal gain saturation on several transient-gain ni-like ion x-ray lasers by using a high-power, chirped-pulse amplification, tabletop laser. these results have been achieved at wavelengths from 139-203 a using a total of 5-7 j energy in a traveling-wave excitation scheme. strong amplification is also observed for ni-like sn at 119 a. gain of 62 cm(-1) and gl product of 18 are determined on the 4d-->4p transition for ni-like pd at 147 a with an output energy of 12 &mgr;j. a systematic evaluation of the laser driver parameters yields optimum beam divergence and small deflection angles of 2-5 mrads, in good agreement with simulations."
        },
        {
            "id": "R154122",
            "label": "Efficient Excitation of Gain-Saturated Sub-9-nm-Wavelength Tabletop Soft-X-Ray Lasers and Lasing Down to 7.36\u00a0nm",
            "doi": "10.1103/physrevx.1.021023",
            "research_field": {
                "id": "R185",
                "label": "Plasma and Beam Physics"
            },
            "research_problems": [
                {
                    "id": "R151715",
                    "label": "X-ray laser physics"
                }
            ],
            "abstract": "we have demonstrated the efficient generation of sub-9-nm-wavelength picosecond laser pulses of microjoule energy at 1-hz repetition rate with a tabletop laser. gain-saturated lasing was obtained a ..."
        },
        {
            "id": "R139475",
            "label": "Artificial immune algorithm to function optimization problems",
            "doi": "10.1109/iccsn.2011.6014177",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"optimization problems abound in the scientific research and engineering applications in various fields, the optimization method has important theoretical and practical value. the existence of the traditional shortcomings of optimization methods, in today's mass production application is limited. multidisciplinary research to solve the optimization problem provides a new approach to biological intelligence or natural phenomena based on new intelligent optimization algorithms and applications in the study have shown excellent performance, the modern intelligent algorithms has become a new field of artificial intelligence research focus. artificial immune optimization algorithm is an imitation of biological function of the immune system an intelligent way, providing a similar immune system noise tolerance, non-teacher learning, self-organization, memory and other evolutionary learning mechanism to solve the complex problems of the new distributed program, compared to other intelligent optimization algorithm has a high success rate optimization, individual diversity and good.\""
        },
        {
            "id": "R139493",
            "label": "Technological Innovation in Biomass Energy for the Sustainable Growth of Textile Industry",
            "doi": "10.3390/su11020528",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the growing increase in world energy consumption favors the search for renewable energy sources. one of the existing options for the growth and sustainable development of such types of sources is through the use of biomass as an input. the employment of biomass as solid fuel is widely studied and is no longer a novelty nor presents any difficulty from the technical point of view. it presents, however, logistic obstacles, thus not allowing their direct dissemination in every organization that is willing to replace it as an energy source. use of biomass can be rewarding due to the fact that it can bring significant economic gains attained due to the steadiness of the biomass price in portugal. however, the price may rise as predicted in the coming years, although it will be a gradual rising. the main goal of this study was to analyze whether biomass in the case of the portuguese textile industry can be a viable alternative that separates the possibility of sustainable growth from the lack of competitiveness due to high energy costs. the study showed that biomass can be a reliable, sustainable and permanent energy alternative to more traditional energy sources such as propane gas, naphtha and natural gas for the textile industry. at the same time, it can bring savings of 35% in energy costs related to steam generation. also, with new technology systems related to the internet of things, a better on-time aware of needs, energy production and logistic chain information will be possible."
        },
        {
            "id": "R185255",
            "label": "Supply chain network design under the risk of uncertain disruptions",
            "doi": "10.1080/00207543.2019.1696999",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R185258",
                    "label": "Supply chain"
                }
            ],
            "abstract": "facility disruptions in the supply chain often lead to catastrophic consequences, although they occur rarely. the low frequency and non-repeatability of disruptive events also make it impossible to estimate the disruption probability accurately. therefore, we construct an uncertain programming model to design the three-echelon supply chain network with the disruption risk, in which disruptions are considered as uncertain events. under the constraint of satisfying customer demands, the model optimises the selection of retailers with uncertain disruptions and the assignment of customers and retailers, in order to minimise the expected total cost of network design. in addition, we simplify the proposed model by analysing its properties and further linearise the simplified model. a lagrangian relaxation algorithm for the linearised model and a genetic algorithm for the simplified model are developed to solve medium-scale problems and large-scale problems, respectively. finally, we illustrate the effectiveness of proposed models and algorithms through several numerical examples."
        },
        {
            "id": "R193951",
            "label": "Supplier Selection and Order Allocation under a Carbon Emission Trading Scheme: A Case Study from China",
            "doi": "10.3390/ijerph17010111",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R193977",
                    "label": "Supplier selection"
                }
            ],
            "abstract": "in implementing carbon emission trading schemes (etss), the cost of carbon embedded in raw materials further complicates supplier selection and order allocation. firms have to make decisions by comprehensively considering the cost and the important intangible performance of suppliers. this paper uses an analytic network process\u2013integer programming (anp\u2013ip) model based on a multiple-criteria decision-making (mcdm) approach to solve the above issues by first evaluating and then optimizing them. the carbon embedded in components, which can be used to reflect the carbon competitiveness of a supplier, is integrated into the anp\u2013ip model. in addition, an international large-scale electronic equipment manufacturer in china is used to validate the model. different scenarios involving different carbon prices are designed to analyze whether china\u2019s current ets drives firms to choose more low-carbon suppliers. the results show that current carbon constraints are not stringent enough to drive firms to select low-carbon suppliers. a more stringent ets with a higher carbon price could facilitate the creation of a low-carbon supply chain. the analysis of the firm\u2019s total cost and of the total cost composition indicates that the impact of a more stringent ets on the firm results mainly from indirect costs instead of direct costs. the indirect cost is caused by the suppliers\u2019 transfer of part of the low-carbon investment in the product, and arises from buying carbon permits with high carbon prices. implications revealed by the model analysis are discussed to provide guidance to suppliers regarding the balance between soft competitiveness and low-carbon production capability and to provide guidance to the firm on how to cooperate with suppliers to achieve a mutually beneficial situation."
        },
        {
            "id": "R193972",
            "label": "A two stage green supplier selection and order allocation using AHP and multi-objective genetic algorithm optimization",
            "doi": "10.1109/icmsao.2017.7934843",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R193977",
                    "label": "Supplier selection"
                }
            ],
            "abstract": "green supplier selection and order allocation problem involves multi-criteria decisions. in this paper, the available suppliers are ranked based on selected green criteria by decision makers in the purchasing department using analytic hierarchy process (ahp). then, genetic algorithm (ga), that uses real-coded representation chromosomes, is used to find the optimal solution for the multi-objective integer linear programming model. the model deals with three conflicting objectives which are: total purchasing cost (tcp), total green value of purchasing (tgvp) and total rejected item due to quality (tr). the model is illustrated by a numerical example."
        },
        {
            "id": "R203458",
            "label": "Combinatorial optimization analysis of the unary NP-complete disassembly line balancing problem",
            "doi": "10.1080/00207540701476281",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the growing amount of waste created by products reaching the end of their useful lives poses challenges for the environment, governments and manufacturers. processing alternatives include reuse, remanufacturing, recycling, storage and disposal. with disposal considered the least desirable, the first process required by the remaining alternatives is disassembly. just as the assembly line is considered the most efficient way to assemble a product, the disassembly line is the most efficient way to disassemble a product. finding the optimal balance for the multi-objective disassembly line balancing problem is computationally intensive due to exponential growth. with exhaustive search calculations quickly becoming prohibitively large, methodologies from the field of combinatorial optimization hold promise for providing solutions. the disassembly line balancing problem is described here, then defined mathematically and proven to belong to the class of unary np-complete problems. known optimal instances of the problem are developed, then disassembly line versions of exhaustive search, genetic algorithm and ant colony optimization metaheuristics, a greedy algorithm, and greedy/hill-climbing and greedy/2-optimal hybrid heuristics are presented and compared along with a novel uninformed general-purpose search heuristic."
        },
        {
            "id": "R203662",
            "label": "Reinforcement Learning based Truck-and-Drone Coordinated Delivery",
            "doi": "10.1109/tai.2021.3087666",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "coronavirus disease 2019 has brought a great challenge to the supply of daily necessities and medical items for home-quarantined people. considering the unmanned operation, agility and use of clean energy of drones, we propose a novel truck-and-drone coordinated delivery system that does not require direct human contact during the delivery process. all final deliveries are completed by the drone while the truck acts as a movable charging station and a carrier, so that the contagion risks are reduced. moreover, we spilt the whole delivery problem into the customer clustering problem and the routing problems of both the truck and the drone. an encoder-decoder framework combined with reinforcement learning is created to solve the routing problems without handcrafted designed heuristics. we design the different problem contexts specific to the truck routing problem and the drone routing problem. the experimental results show the proposed approach has good generality and can consequently be applied to problems of different scales with high time efficiency."
        },
        {
            "id": "R203671",
            "label": "Research at the Intersection of Entrepreneurship, Supply Chain Management, and Strategic Management: Opportunities Highlighted by COVID-19",
            "doi": "10.1177/0149206320945028",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "since the early 2000s, research at the intersection of entrepreneurship and strategic management has flourished, as has work at the intersection of strategic management and supply chain management. in contrast, little inquiry has occurred at the intersection of entrepreneurship and supply chain management. this presents a tremendous opportunity, as does the relative lack of work bringing together all three fields. we seek to set the stage for exploiting these opportunities by first describing how incorporating a series of key supply chain concepts\u2014omni-channel, last-mile delivery, supply chain agility, supply chain resiliency, and service recovery\u2014could enrich entrepreneurship research. we then explain how the boundaries of key entrepreneurship concepts\u2014opportunity, entrepreneurial orientation, optimal distinctiveness, bricolage, and fear of failure\u2014could be extended to the supply chain context. both of these moves bring strategic management concepts into play, as well. in accomplishing our tasks, we draw on examples from how firms attempted to navigate the covid-19 pandemic via moves spanning entrepreneurship, supply chain management, and strategic management."
        },
        {
            "id": "R203726",
            "label": "Prediction Analysis Sales for Corporate Services Telecommunications Company using Gradient Boost Algorithm",
            "doi": "10.1109/bcwsp50066.2020.9249397",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R203643",
                    "label": "Demand forecasting in supply chain "
                }
            ],
            "abstract": "sales prediction analysis requires smart data mining techniques with accurate prediction models and high reliability. essentially, most market segments rely on the knowhow base and the demand trend forecast for analysis of business to business (b2b) sales data. data are provided by sales on how telecommunication company should manage its sales team, its products and also its budgeting flows. precise estimates make it possible for telecommunication company to survive the market war and increase its market growth. in this research, the study and analysis of comprehensible predictive models use machine learning techniques to improve future sales predictions. traditional forecasting systems are difficult to deal with big data and the accuracy of sales forecasting. in this paper, a brief analysis of the reliability of b2b sales using machine learning techniques. the latter part of this research explains a range of sales prediction strategies and interventions. based on the performance assessment, a best-adapted predictive model for the b2b sales trend forecast is suggested. projection, estimation and analysis findings are summarized in terms of reliability and consistency of efficient prediction and forecasting techniques. the results of this analysis are expected to generate reliable, accurate and effective forecasting data, a valuable resource for sales predictions. research has shown that gradient boost algorithm shows good accuracy in forecasting and future b2b sales prediction with mse = 24,743,000,000.00, and mape: 0.18."
        },
        {
            "id": "R203734",
            "label": "Analysis on Machine Learning Algorithms and Neural Networks for Demand Forecasting of Anti-Aircraft Missile Spare Parts",
            "doi": "10.1109/icces45898.2019.9002411",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R203643",
                    "label": "Demand forecasting in supply chain "
                }
            ],
            "abstract": "now-a-days demand forecasting is used in many countries for military applications such as spare parts of aircraft and for improving budget efficiency. in supply chain management demand forecasting is a major issue. currently, time series technique is used to demand forecast but this technique resulted in lack of accuracy and improvement in accuracy is needed. so this paper focused on comparing the features which leads to improvement in the accuracy and propose a system for demand forecasting of spare parts of anti-aircraft missiles, which are based on machine learning and neural networks such that equipment's are properly utilized and alongwith that budget is also maintained. we have compared the existing features with the new features added and applied algorithms and looked upon at the accuracy. experimental results proves that the new features added gave higher accuracy. here, we also present an end-to-end boosting system called xgboost and multi-layer perceptron. these new techniques were compared with traditional machine learning techniques. this experiment is conducted on the vietnam war dataset."
        },
        {
            "id": "R203739",
            "label": "Hoeffding Tree Method with Feature Selection for Forecasting Daily Demand Orders",
            "doi": "10.1109/taai51410.2020.00048",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R203643",
                    "label": "Demand forecasting in supply chain "
                }
            ],
            "abstract": "in supply companies, the task of forecasting daily demand orders is essential in planning and provision processes to achieve the consumers\u2019 requests on time and reduce the costs. machine learning (ml) methods play an important role in developing effective tools for forecasting problems in many fields. previous works of forecasting daily demand orders have proposed to use a set of effective ml algorithms and methods. however, there is still room for improving the accuracy result using more effective computational methods. in this paper, an effective approach that uses a hoeffding tree method with an information gain ratio feature selection algorithm is proposed to predict the orders of daily demand products in an interval period of time. the approach is assessed on a real public dataset of the brazilian logistics company that is gathered through 60 days. after selecting the most important features, the hoeffding tree method is trained and tested on this dataset using a 10-fold cross-validation technique. the experimental results show that the proposed approach is able to predict the daily demand orders and achieves a competitive accuracy result with a small number of features compared to the recent related works."
        },
        {
            "id": "R203757",
            "label": "Corona virus, tariffs, trade wars and supply chain evolutionary design",
            "doi": "10.1108/ijopm-03-2020-0171",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R203781",
                    "label": "COVID-19 and supply chain management"
                }
            ],
            "abstract": "purpose using the constructal law of physics this study aims to provide guidance to future scholarship on global supply chain management. further, through two case studies the authors are developing, the authors report interview findings with two senior vps from two multi-national corporations being disrupted by covid-19. this study suggests how this and recent events will impact on the design of future global supply chains. design/methodology/approach the authors apply the constructal law to explain the recent disruptions to the global supply chain orthodoxy. two interviews are presented from case studies the authors are developing in the usa and uk \u2013 one a multi-national automobile parts supplier and the other is a earth-moving equipment manufacture. specifically, this is an exploratory pathway work trying to make sense of the covid-19 pandemic and its impact on supply chain scholarship. findings adopting the approach of bejan, the authors believe that what is happening today with covid-19 and other trade disruptions such as brexit and the usa imposing tariffs is creating new obstacles that will redirect the future flow of supply chains. research limitations/implications it is clear that the covid-19 response introduced a bullwhip effect in the manufacturing sector on a scale never-before seen. for scholars, the authors would suggest there are four pathway topics going forward. these topics include: the future state of global sourcing, the unique nature of a combined \u201cdemand\u201d and \u201csupply shortage\u201d bullwhip effect, the resurrection of lean and local production systems and the development of risk-recovery contingency strategies to deal with pandemics. practical implications supply chain managers tend to be iterative and focused on making small and subtle changes to their current system and way of thinking, very often seeking to optimize cost or negotiate better contracts with suppliers. in the current environment, however, such activities have proved to be of little consequence compared to the massive forces of economic disruption of the past three years. organizations that have more tightly compressed supply chains are enjoying a significant benefit during the covid-19 crisis and are no longer being held hostage to governments of another country. social implications an implicit assumption in the press is that covid-19 caught everyone by surprise, and that executives foolishly ignored the risks of outsourcing to china and are now paying the price. however, noted scholars and epidemiologists have been warning of the threats of pandemics since the severe acute respiratory syndrome (sars) virus. the pundits would further posit that in their pursuit of low-cost production, global corporations made naive assumptions that nothing could disrupt them. both the firms the authors have interviewed had to close plants to protect their workforce. it was indicated in the cases the authors are developing that it is going to take manufacturers on average one month to recover from 4\u20136 days of disruption. these companies employ many thousands of people, and direct and ancillary workers are now temporarily laid off and face an uncertain future as/when they will recover back to normal production. originality/value using the constructal law of physics, the authors seek to provide guidance to future scholarship on global supply chain management. further, through two case studies, the authors provide the first insight from two senior vps from two leading multi-national corporations in their respective sectors being disrupted by covid-19. this study is the first indication to how this and recent disruptive events will impact on the design of future global supply chains. unlike the generic work, which has recently appeared in hbr and forbes, it is grounded in real operational insight."
        },
        {
            "id": "R203761",
            "label": "Transform or Perish: Preparing the Business for a Postpandemic Future",
            "doi": "10.1109/emr.2020.3014693",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R203782",
                    "label": "COVID-19 and supply chain management"
                }
            ],
            "abstract": "the coronavirus outbreak presents a significant threat to public health and is profoundly distresses the global economy. there are no sectors left affected by the outbreak on a local, national, and global scale. some sectors have come to a complete standstill, whereas others have received high demands. all known business models came under question. the crisis served as a check-up, allowing executives to question existing systems, the company, and its management capacities. nonetheless, crises have enabled businesses to adopt innovative approaches such as new ways of working and the use of modern technology quickly. it will be challenging for businesses to adapt to these innovations that are coming very fast in the postcrisis uncertainty. this article aims to inform managers, decision-makers, and team leaders about the changes they will face in the post-covid-19 world, based on the example of the agriculture and food sector, and to provide them with a road map."
        },
        {
            "id": "R203776",
            "label": "Digital Inclusion for Resilient Post-COVID-19 Supply Chains: Smallholder Farmer Perspectives",
            "doi": "10.1109/emr.2020.3006259",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "R203786",
                    "label": "COVID-19 and supply chain management"
                }
            ],
            "abstract": "the coronavirus (covid-19) pandemic has and continues to have far-reaching global economic and environmental implications. in developing economies and regions, the pandemic's disruption of the agriculture commodity supply chain has made it difficult for smallholder farmers to exist. smallholder farmer's traditional struggles have worsened. however, technology may provide promise of improving conditions for vulnerable farmers even in a period of crises such as the covid-19 period. in this article, we draw on lessons learned in developed and developing countries to propose critical digital transformation for building a resilient and sustainable post-covid- 19 supply chains for developing countries, especially for smallholder farmers operating in global value chains. we discuss how digital technologies and specifically digital inclusion of smallholder farmers can prevent major disruptions from damaging the livelihoods of society's most vulnerable. we discuss feasibility and provide some caveats for a post-covid-19 digital inclusion in developing countries."
        },
        {
            "id": "R204263",
            "label": "Age of Information Aware Trajectory Planning of UAVs in Intelligent Transportation Systems: A Deep Learning Approach",
            "doi": "10.1109/tvt.2020.3023861",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "unmanned aerial vehicles (uavs) are envisioned to play a key role in intelligent transportation systems to complement the communication infrastructure in future smart cities. uav-assisted vehicular networking research typically adopts throughput and latency as the main performance metrics. these conventional metrics, however, are not adequate to reflect the freshness of the information, an attribute that has been recently identified as a critical requirement to enable services such as autonomous driving and accident prevention. in this paper, we consider a uav-assisted single-hop vehicular network, wherein sensors (e.g., lidars and cameras) on vehicles generate time sensitive data streams, and uavs are used to collect and process this data while maintaining a minimum age of information (aoi). we aim to jointly optimize the trajectories of uavs and find scheduling policies to keep the information fresh under minimum throughput constraints. the formulated optimization problem is shown to be mixed integer non-linear program (minlp) and generally hard to be solved. motivated by the success of machine learning (ml) techniques particularly deep learning in solving complex problems with low complexity, we reformulate the trajectories and scheduling policies problem as a markov decision process (mdp) where the system state space considers the vehicular network dynamics. then, we develop deep reinforcement learning (drl) to learn the vehicular environment and its dynamics in order to handle uavs\u2019 trajectory and scheduling policy. in particular, we leverage deep deterministic policy gradient (ddpg) for learning the trajectories of the deployed uavs to efficiently minimize the expected weighted sum aoi (ewsa). simulations results demonstrate the effectiveness of the proposed design and show the deployed uavs adapt their velocities during the data collection mission in order to minimize the aoi."
        },
        {
            "id": "R11022",
            "label": "Evaluating Architectural Choices for Deep Learning Approaches for Question Answering Over Knowledge Bases",
            "doi": "10.1109/icosc.2019.8665496",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R11025",
                    "label": "Knowledge Graph Embeddings"
                },
                {
                    "id": "R9143",
                    "label": "Question Answering "
                }
            ],
            "abstract": "the task of answering natural language questions over knowledge bases has received wide attention in recent years. various deep learning architectures have been proposed for this task. however, architectural design choices are typically not systematically compared nor evaluated under the same conditions. in this paper, we contribute to a better understanding of the impact of architectural design choices by evaluating four different architectures under the same conditions. we address the task of answering simple questions, consisting in predicting the subject and predicate of a triple given a question. in order to provide a fair comparison of different architectures, we evaluate them under the same strategy for inferring the subject, and compare different architectures for inferring the predicate. the architecture for inferring the subject is based on a standard lstm model trained to recognize the span of the subject in the question and on a linking component that links the subject span to an entity in the knowledge base. the architectures for predicate inference are based on i) a standard softmax classifier ranging over all predicates as output, ii) a model that predicts a low-dimensional encoding of the property and subject entity, iii) a model that learns to score a pair of subject and predicate given the question as well as iv) a model based on the well-known fasttext model. the comparison of architectures shows that fasttext provides better results than other architectures."
        },
        {
            "id": "R3076",
            "label": "An expert system based on texture features and decision tree classifier for diagnosis of tumor in brain MR images",
            "doi": "10.1109/ic3i.2014.7019690",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R3082",
                    "label": "Brain tumor"
                }
            ],
            "abstract": "in this paper a new tumor classification system has been designed and developed for mri systems. the mr imaging is a mostly used scheme for high excellence in medical imaging, it gives clear imageing capability especially in brain imaging where the soft-tissues contrast and non invasiveness is a clear advantage. the proposed method consists of three stages namely pre-processing, feature extraction and classification. in the first stage, gausian filter is applied for extracting the noise for experimental image. in the second stage, statistical texture features are extracted for the purpose of classification. finally, the decision tree classifier is used to classify the type of tumor image. in our proposed system classification has two divisions: i) training stage and ii) testing stage. in the training stage, various features are extracted from the tumor and non tumor images. in testing stage, based on the knowledge base, the classifier classify the image into tumor and non- tumor. thus, the proposed system has been evaluated on a dataset of 40 patients. the proposed system was found efficient in classification with a success of more than 95% of accuracy."
        },
        {
            "id": "R38180",
            "label": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures",
            "doi": "10.18653/v1/p16-1105",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R38192",
                    "label": "End-to-end Relation Extraction"
                },
                {
                    "id": "R38193",
                    "label": "Joint entity and relation extraction"
                },
                {
                    "id": "R116569",
                    "label": "Relation Extraction"
                },
                {
                    "id": "R116714",
                    "label": "Joint Entity and Relation Extraction"
                }
            ],
            "abstract": "we present a novel end-to-end neural model to extract entities and relations between them. our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured lstm-rnns on bidirectional sequential lstm-rnns. this allows our model to jointly represent both entities and relations with shared parameters in a single model. we further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in f1-score on ace2005 and ace2004, respectively. we also show that our lstm-rnn based model compares favorably to the state-of-the-art cnn based model (in f1-score) on nominal relation classification (semeval-2010 task 8). finally, we present an extensive ablation analysis of several model components."
        },
        {
            "id": "R38225",
            "label": "Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme",
            "doi": "10.18653/v1/p17-1113",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R38192",
                    "label": "End-to-end Relation Extraction"
                },
                {
                    "id": "R38193",
                    "label": "Joint entity and relation extraction"
                },
                {
                    "id": "R116569",
                    "label": "Relation Extraction"
                }
            ],
            "abstract": "\"joint extraction of entities and relations is an important task in information extraction. to tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem. then, based on our tagging scheme, we study different end-to-end models to extract entities and their relations directly, without identifying entities and relations separately. we conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. what's more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.\""
        },
        {
            "id": "R39210",
            "label": "A Survey of Recommender Systems Based on Deep Learning",
            "doi": "10.1109/access.2018.2880197",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in recent years, deep learning\u2019s revolutionary advances in speech recognition, image analysis, and natural language processing have gained significant attention. deep learning technology has become a hotspot research field in the artificial intelligence and has been applied into recommender system. in contrast to traditional recommendation models, deep learning is able to effectively capture the non-linear and non-trivial user-item relationships and enables the codification of more complex abstractions as data representations in the higher layers. in this paper, we provide a comprehensive review of the related research contents of deep learning-based recommender systems. first, we introduce the basic terminologies and the background concepts of recommender systems and deep learning technology. second, we describe the main current research on deep learning-based recommender systems. third, we provide the possible research directions of deep learning-based recommender systems in the future. finally, concludes this paper."
        },
        {
            "id": "R41079",
            "label": "Speech Recognition Using Deep Neural Networks: A Systematic Review",
            "doi": "10.1109/access.2019.2896880",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R41109",
                    "label": "This paper provided a thorough statistical analysis on the use of deep learning in speech related applications by extracting specific information from 174 papers published between the years 2006 and 2018."
                }
            ],
            "abstract": "over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. however, in the past few years, research has focused on utilizing deep learning for speech-related applications. this new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. this paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. a thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. the results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics."
        },
        {
            "id": "R4857",
            "label": "How are topics born? Understanding the research dynamics preceding the emergence of new areas",
            "doi": "10.7717/peerj-cs.119",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R4864",
                    "label": "forecasting research trends"
                }
            ],
            "abstract": "the ability to promptly recognise new research trends is strategic for many stakeholders, including universities, institutional funding bodies, academic publishers and companies. while the literature describes several approaches which aim to identify the emergence of new research topics early in their lifecycle, these rely on the assumption that the topic in question is already associated with a number of publications and consistently referred to by a community of researchers. hence, detecting the emergence of a new research area at an embryonic stage , i.e., before the topic has been consistently labelled by a community of researchers and associated with a number of publications, is still an open challenge. in this paper, we begin to address this challenge by performing a study of the dynamics preceding the creation of new topics. this study indicates that the emergence of a new topic is anticipated by a significant increase in the pace of collaboration between relevant research areas, which can be seen as the \u2018parents\u2019 of the new topic. these initial findings (i) confirm our hypothesis that it is possible in principle to detect the emergence of a new topic at the embryonic stage, (ii) provide new empirical evidence supporting relevant theories in philosophy of science, and also (iii) suggest that new topics tend to emerge in an environment in which weakly interconnected research areas begin to cross-fertilise."
        },
        {
            "id": "R49468",
            "label": "Retinal Blood Vessel Segmentation Using Hybrid Features and Multi-Layer Perceptron Neural Networks",
            "doi": "10.3390/sym12060894",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R49473",
                    "label": "Retinal Blood Vessel Segmentation"
                }
            ],
            "abstract": "segmentation of retinal blood vessels is the first step for several computer aided-diagnosis systems (cad), not only for ocular disease diagnosis such as diabetic retinopathy (dr) but also of non-ocular disease, such as hypertension, stroke and cardiovascular diseases. in this paper, a supervised learning-based method, using a multi-layer perceptron neural network and carefully selected vector of features, is proposed. in particular, for each pixel of a retinal fundus image, we construct a 24-d feature vector, encoding information on the local intensity, morphology transformation, principal moments of phase congruency, hessian, and difference of gaussian values. a post-processing technique depending on mathematical morphological operators is used to optimise the segmentation. moreover, the selected feature vector succeeded in outfitting the symmetric features that provided the final blood vessel probability as a binary map image. the proposed method is tested on three known datasets: digital retinal image for extraction (drive), structure analysis of the retina (stare), and chased_db1 datasets. the experimental results, both visual and quantitative, testify to the robustness of the proposed method. this proposed method achieved 0.9607, 0.7542, and 0.9843 in drive, 0.9632, 0.7806, and 0.9825 on stare, 0.9577, 0.7585 and 0.9846 in chase_db1, with respectable accuracy, sensitivity, and specificity performance metrics. furthermore, they testify that the method is superior to seven similar state-of-the-art methods."
        },
        {
            "id": "R5289",
            "label": "Controlling an autonomous agent using internal value based action selection",
            "doi": "10.1504/ijista.2007.012491",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R5294",
                    "label": "controlling robot actions"
                }
            ],
            "abstract": "in this paper we describe an approach of controlling an autonomous robot by means of a hierarchical control structure, with a learning action selection. since damasio\\'s \"descartes\\' error\" in 1994 the number of approaches to action selection that use internal values, derived from psychological models of emotions or drives has increased significantly. the approach realises a learning action selection mechanism in a hierarchy of sensory and actuatory layers. the sensory values yield the internal states, as a basis for action selection. in addition they are used to calculate the reinforcement signal that trains the action selection."
        },
        {
            "id": "R6286",
            "label": "Template-based question answering",
            "doi": "10.1145/2187836.2187923",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6228",
                    "label": "Question answering systems evaluation"
                }
            ],
            "abstract": "as an increasing amount of rdf data is published as linked data, intuitive ways of accessing this data become more and more important. question answering approaches have been proposed as a good compromise between intuitiveness and expressivity. most question answering systems translate questions into triples which are matched against the rdf data to retrieve an answer, typically relying on some similarity metric. however, in many cases, triples do not represent a faithful representation of the semantic structure of the natural language question, with the result that more expressive queries can not be answered. to circumvent this problem, we present a novel approach that relies on a parse of the question to produce a sparql template that directly mirrors the internal structure of the question. this template is then instantiated using statistical entity identification and predicate detection. we show that this approach is competitive and discuss cases of questions that can be answered with our approach but not with competing approaches."
        },
        {
            "id": "R6294",
            "label": "Natural language question answering over RDF",
            "doi": "10.1145/2588555.2610525",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6228",
                    "label": "Question answering systems evaluation"
                }
            ],
            "abstract": "rdf question/answering (q/a) allows users to ask questions in natural languages over a knowledge base represented by rdf. to answer a national language question, the existing work takes a two-stage approach: question understanding and query evaluation. their focus is on question understanding to deal with the disambiguation of the natural language phrases. the most common technique is the joint disambiguation, which has the exponential search space. in this paper, we propose a systematic framework to answer natural language questions over rdf repository (rdf q/a) from a graph data-driven perspective. we propose a semantic query graph to model the query intention in the natural language question in a structural way, based on which, rdf q/a is reduced to subgraph matching problem. more importantly, we resolve the ambiguity of natural language questions at the time when matches of query are found. the cost of disambiguation is saved if there are no matching found. we compare our method with some state-of-the-art rdf q/a systems in the benchmark dataset. extensive experiments confirm that our method not only improves the precision but also speeds up query performance greatly."
        },
        {
            "id": "R6657",
            "label": "MSBGA: A Multi-Document Summarization System Based on Genetic Algorithm",
            "doi": "10.1109/ICMLC.2006.258921",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6544",
                    "label": "Automatic text summarization"
                }
            ],
            "abstract": "the multi-document summarizer using genetic algorithm-based sentence extraction (msbga) regards summarization process as an optimization problem where the optimal summary is chosen among a set of summaries formed by the conjunction of the original articles sentences. to solve the np hard optimization problem, msbga adopts genetic algorithm, which can choose the optimal summary on global aspect. the evaluation function employs four features according to the criteria of a good summary: satisfied length, high coverage, high informativeness and low redundancy. to improve the accuracy of term frequency, msbga employs a novel method tfs, which takes word sense into account while calculating term frequency. the experiments on duc04 data show that our strategy is effective and the rouge-1 score is only 0.55% lower than the best participant in duc04"
        },
        {
            "id": "R6685",
            "label": "Personalized PageRank Based Multi-document Summarization",
            "doi": "10.1109/WSCS.2008.32",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6544",
                    "label": "Automatic text summarization"
                }
            ],
            "abstract": "this paper presents a novel multi-document summarization approach based on personalized pagerank (pprsum). in this algorithm, we uniformly integrate various kinds of information in the corpus. at first, we train a salience model of sentence global features based on naive bayes model. secondly, we generate a relevance model for each corpus utilizing the query of it. then, we compute the personalized prior probability for each sentence in the corpus utilizing the salience model and the relevance model both. with the help of personalized prior probability, a personalized pagerank ranking process is performed depending on the relationships among all sentences in the corpus. additionally, the redundancy penalty is imposed on each sentence. the summary is produced by choosing the sentences with both high query-focused information richness and high information novelty. experiments on duc2007 are performed and the rouge evaluation results show that pprsum ranks between the 1st and the 2nd systems on duc2007 main task."
        },
        {
            "id": "R6689",
            "label": "AdaSum: an adaptive model for summarization",
            "doi": "10.1145/1458082.1458201",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6544",
                    "label": "Automatic text summarization"
                }
            ],
            "abstract": "topic representation mismatch is a key problem in topic-oriented summarization for the specified topic is usually too short to understand/interpret. this paper proposes a novel adaptive model for summarization, adasum, under the assumption that the summary and the topic representation can be mutually boosted. adasum aims to simultaneously optimize the topic representation and extract effective summaries. this model employs a mutual boosting process to minimize the topic representation mismatch for base summarizers. furthermore, a linear combination of base summarizers is proposed to further reduce the topic representation mismatch from the diversity of base summarizers with a general learning framework. we prove that the training process of adasum can enhance the performance measure used. experimental results on duc 2007 dataset show that adasum significantly outperforms the baseline methods for summarization (e.g. mrp, lexrank, and gsps)."
        },
        {
            "id": "R69387",
            "label": "Sarcasm Detection Using Soft Attention-Based Bidirectional Long Short-Term Memory Model With Convolution Network",
            "doi": "10.1109/access.2019.2899260",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a large community of research has been developed in recent years to analyze social media and social networks, with the aim of understanding, discovering insights, and exploiting the available information. the focus has shifted from conventional polarity classification to contemporary application-oriented fine-grained aspects such as, emotions, sarcasm, stance, rumor, and hate speech detection in the user-generated content. detecting a sarcastic tone in natural language hinders the performance of sentiment analysis tasks. the majority of the studies on automatic sarcasm detection emphasize on the use of lexical, syntactic, or pragmatic features that are often unequivocally expressed through figurative literary devices such as words, emoticons, and exclamation marks. in this paper, we propose a deep learning model called satt-blstm convnet that is based on the hybrid of soft attention-based bidirectional long short-term memory (satt-blstm) and convolution neural network (convnet) applying global vectors for word representation (glove) for building semantic word embeddings. in addition to the feature maps generated by the satt-blstm, punctuation-based auxiliary features are also merged into the convnet. the robustness of the proposed model is investigated using balanced (tweets from benchmark semeval 2015 task 11) and unbalanced (approximately 40000 random tweets using the sarcasm detector tool with 15000 sarcastic and 25000 non-sarcastic messages) datasets. an experimental study using the training- and test-set accuracy metrics is performed to compare the proposed deep neural model with convnet, lstm, and bidirectional lstm with/without attention and it is observed that the novel satt-blstm convnet model outperforms others with a superior sarcasm-classification accuracy of 97.87% for the twitter dataset and 93.71% for the random-tweet dataset."
        },
        {
            "id": "R8222",
            "label": "Crowd evacuation planning using Cartesian Genetic Programming and agent-based crowd modeling",
            "doi": "10.1109/wsc.2015.7408158",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R8224",
                    "label": "Crowd simulation and evacuation"
                },
                {
                    "id": "R8225",
                    "label": "finding optimal evacuation strategy"
                }
            ],
            "abstract": "\"this paper proposes a new evolutionary algorithm-based methodology for optimal crowd evacuation planning. in the proposed methodology, a heuristic-based evacuation scheme is firstly introduced. the key idea is to divide the region into a set of sub-regions and use a heuristic rule to dynamically recommend an exit to agents in each sub-region. then, an evolutionary framework based on the cartesian genetic programming algorithm and an agent-based crowd simulation model is developed to search for the optimal heuristic rule. by considering dynamic environment features to construct the heuristic rule and using multiple scenarios for training, the proposed methodology aims to find generic and efficient heuristic rules that perform well on different scenarios. the proposed methodology is applied to guide people's evacuation behaviors in six different scenarios. the simulation results demonstrate that the heuristic rule offered by the proposed method is effective to reduce the crowd evacuation time on different scenarios.\""
        },
        {
            "id": "R9567",
            "label": "A Neural Approach for Text Extraction from Scholarly Figures",
            "doi": "10.1109/icdar.2019.00231",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R10011",
                    "label": "text extraction from images "
                },
                {
                    "id": "R10012",
                    "label": "scene text detection"
                },
                {
                    "id": "R9570",
                    "label": "Scholarly Figure Text Extraction"
                }
            ],
            "abstract": "\"in recent years, the problem of scene text extraction from images has received extensive attention and significant progress. however, text extraction from scholarly figures such as plots and charts remains an open problem, in part due to the difficulty of locating irregularly placed text lines. to the best of our knowledge, literature has not described the implementation of a text extraction system for scholarly figures that adapts deep convolutional neural networks used for scene text detection. in this paper, we propose a text extraction approach for scholarly figures that forgoes preprocessing in favor of using a deep convolutional neural network for text line localization. our system uses a publicly available scene text detection approach whose network architecture is well suited to text extraction from scholarly figures. training data are derived from charts in arxiv papers which are extracted using allen institute's pdffigures tool. since this tool analyzes pdf data as a container format in order to extract text location through the mechanisms which render it, we were able to gather a large set of labeled training samples. we show significant improvement from methods in the literature, and discuss the structural changes of the text extraction pipeline.\""
        },
        {
            "id": "R138459",
            "label": "Transforming XML documents to OWL ontologies: A survey",
            "doi": "10.1177/0165551514565972",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "the aims of xml data conversion to ontologies are the indexing, integration and enrichment of existing ontologies with knowledge acquired from these sources. the contribution of this paper consists in providing a classification of the approaches used for the conversion of xml documents into owl ontologies. this classification underlines the usage profile of each conversion method, providing a clear description of the advantages and drawbacks belonging to each method. hence, this paper focuses on two main processes, which are ontology enrichment and ontology population using xml data. ontology enrichment is related to the schema of the ontology (tbox), and ontology population is related to an individual (abox). in addition, the ontologies described in these methods are based on formal languages of the semantic web such as owl (ontology web language) or rdf (resource description framework). these languages are formal because the semantics are formally defined and take advantage of the description logics. in contrast, xml data sources are without formal semantics. the xml language is used to store, export and share data between processes able to process the specific data structure. however, even if the semantics is not explicitly expressed, data structure contains the universe of discourse by using a qualified vocabulary regarding a consensual agreement. in order to formalize this semantics, the owl language provides rich logical constraints. therefore, these logical constraints are evolved in the transformation of xml documents into owl documents, allowing the enrichment and the population of the target ontology. to design such a transformation, the current research field establishes connections between owl constructs (classes, predicates, simple or complex data types, etc.) and xml constructs (elements, attributes, element lists, etc.). two different approaches for the transformation process are exposed. the instance approaches are based on xml documents without any schema associated. the validation approaches are based on the xml schema and document validated by the associated schema. the second approaches benefit from the schema definition to provide automated transformations with logic constraints. both approaches are discussed in the text."
        },
        {
            "id": "R139415",
            "label": "A GRAPH-BASED TOOL FOR THE TRANSLATION OF XML DATA TO OWL-DL ONTOLOGIES: ",
            "doi": "10.5220/0003629603610364",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "\"today most of the data exchanged between information systems is done with the help of the xml syntax. unfortunately when these data have to be integrated, the integration becomes difficult because of the semantics' heterogeneity. consequently, leading researches in the domain of database systems are moving to semantic model in order to store data and its semantics definition. to benefit from these new systems and technologies, and to integrate different data sources, a flexible method consists in populating an existing owl ontology from xml data. in paper we present such a method based on the definition of a graph which represents rules that drive the populating process. the graph of rules facilitates the mapping definition that consists in mapping elements from an xsd schema to the elements of the owl schema.\""
        },
        {
            "id": "R139421",
            "label": "DTD2OWL: automatic transforming XML documents into OWL ontology",
            "doi": "10.1145/1655925.1655949",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "dtd and its instance have been considered the standard for data representation and information exchange format on the current web. however, when coming to the next generation of web, the semantic web, the drawbacks of xml and its schema are appeared. they mainly focus on the structure level and lack support for data representation. meanwhile, some semantic web applications such as intelligent information services and semantic search engines require not only the syntactic format of the data, but also the semantic content. these requirements are supported by the web ontology language (owl), which is one of the recent w3c recommendation. but nowadays the amount of data presented in owl is small in compare with xml data. therefore, finding a way to utilize the available xml documents for the semantic web is a current challenge research. in this work we present an effective solution for transforming xml document into owl domain knowledge. while keeping the original structure, our work also adds more semantics for the xml document. moreover, whole of the transformation processes are done automatically without any outside intervention. further, unlike previous approaches which focus on the schema level, we also extend our methodology for the data level by transforming specific xml instances into owl individuals. the results in existing owl syntaxes help them to be loaded immediately by the semantic web applications."
        },
        {
            "id": "R139451",
            "label": "Mapping XML to OWL Ontologies",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "by now, xml has reached a wide acceptance as data exchange format in e-business. an efficient collaboration between different participants in e-business thus, is only possible, when business partners agree on a common syntax and have a common understanding of the basic concepts in the domain. xml covers the syntactic level, but lacks support for efficient sharing of conceptualizations. the web ontology language (owl [bec04]) in turn supports the representation of domain knowledge using classes, properties and instances for the use in a distributed environment as the worldwideweb. we present in this paper a mapping between the data model elements of xml and owl. we give account about its implementation within a ready-to-use xslt framework, as well as its evaluation for common use cases."
        },
        {
            "id": "R139897",
            "label": "Ontology enrichment and automatic population from XML data",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "this paper presents a flexible method to enrich and populate an existing owl ontology from xml data. basic mapping rules are defined in order to specify the conversion rules on properties. advanced mapping rules are defined on xml schemas a nd owl xml schema elements in order to define rules for th e population process. in addition, this flexible method allows u sers to reuse rules for other conversions and populations."
        },
        {
            "id": "R139899",
            "label": "Building ontologies from XML data sources",
            "doi": "10.1109/DEXA.2009.68",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "in this paper, we present a tool called x2owl that aims at building an owl ontology from an xml datasource. this method is based on xml schema to automatically generate the ontology structure, as well as, a set of mapping bridges. the presented method also includes a refinement step that allows to clean the mapping bridges and possibly to restructure the generated ontology."
        },
        {
            "id": "R139901",
            "label": "Transforming XML schema to OWL using patterns",
            "doi": "10.1109/ICSC.2011.77",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "one of the promises of the semantic web is to support applications that easily and seamlessly deal with heterogeneous data. most data on the web, however, is in the extensible markup language (xml) format, but using xml requires applications to understand the format of each data source that they access. to achieve the benefits of the semantic web involves transforming xml into the semantic web language, owl (ontology web language), a process that generally has manual or only semi-automatic components. in this paper we present a set of patterns that enable the direct, automatic transformation from xml schema into owl allowing the integration of much xml data in the semantic web. we focus on an advanced logical representation of xml schema components and present an implementation, including a comparison with related work."
        },
        {
            "id": "R139903",
            "label": "An efficient XML to OWL converter",
            "doi": "https://doi.org/10.1145/1953355.1953376",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "xml has become the de-facto standard of data exchange format in e-businesses. although xml can support syntactic inter-operability, problems arise when data sources represented as xml documents are needed to be integrated. the reason is that xml lacks support for efficient sharing of conceptualization. the web ontology language (owl) can play an important role here as it can enable semantic inter-operability, and it supports the representation of domain knowledge using classes, properties and instances for applications. in many applications it is required to convert huge xml documents automatically to owl ontologies, which is receiving a lot of attention. there are some existing converters for this job. unfortunately they have serious shortcomings, e. g., they do not address the handling of characteristics like internal references, (transitive) import(s), include etc. which are commonly used in xml schemas. to alleviate these drawbacks, we propose a new framework for mapping xml to owl automatically. we illustrate our technique on examples to show the efficacy of our approach. we also provide the performance measures of our approach on some standard datasets. we also check the correctness of the conversion process."
        },
        {
            "id": "R139905",
            "label": "Automatic generation of OWL ontology from XML data source",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "the extensible markup language (xml) can be used as data exchange format in different domains. it allows different parties to exchange data by providing common understanding of the basic concepts in the domain. xml covers the syntactic level, but lacks support for reasoning. ontology can provide a semantic representation of domain knowledge which supports efficient reasoning and expressive power. one of the most popular ontology languages is the web ontology language (owl). it can represent domain knowledge using classes, properties, axioms and instances for the use in a distributed environment such as the world wide web. this paper presents a new method for automatic generation of owl ontology from xml data sources."
        },
        {
            "id": "R139907",
            "label": "Automatic transforming XML documents into OWL Ontology",
            "doi": "10.1145/1655925.1655949",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138463",
                    "label": "Ontology learning from XML documents"
                }
            ],
            "abstract": "dtd and its instance have been considered the standard for data representation and information exchange format on the current web. however, when coming to the next generation of web, the semantic web, the drawbacks of xml and its schema are appeared. they mainly focus on the structure level and lack support for data representation. meanwhile, some semantic web applications such as intelligent information services and semantic search engines require not only the syntactic format of the data, but also the semantic content. these requirements are supported by the web ontology language (owl), which is one of the recent w3c recommendation. but nowadays the amount of data presented in owl is small in compare with xml data. therefore, finding a way to utilize the available xml documents for the semantic web is a current challenge research. in this work we present an effective solution for transforming xml document into owl domain knowledge. while keeping the original structure, our work also adds more semantics for the xml document. moreover, whole of the transformation processes are done automatically without any outside intervention. further, unlike previous approaches which focus on the schema level, we also extend our methodology for the data level by transforming specific xml instances into owl individuals. the results in existing owl syntaxes help them to be loaded immediately by the semantic web applications."
        },
        {
            "id": "R140371",
            "label": "An Approach For Transforming of Relational Databases to OWL Ontology",
            "doi": "10.5121/ijwest.2015.6102",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138541",
                    "label": "Ontology learning from databases"
                }
            ],
            "abstract": "rapid growth of documents, web pages, and other types of text content is a huge challenge for the modern content management systems. one of the problems in the areas of information storage and retrieval is the lacking of semantic data. ontologies can present knowledge in sharable and repeatedly usable manner and provide an effective way to reduce the data volume overhead by encoding the structure of a particular domain. metadata in relational databases can be used to extract ontology from database in a special domain. according to solve the problem of sharing and reusing of data, approaches based on transforming relational database to ontology are proposed. in this paper we propose a method for automatic ontology construction based on relational database. mining and obtaining further components from relational database leads to obtain knowledge with high semantic power and more expressiveness. triggers are one of the database components which could be transformed to the ontology model and increase the amount of power and expressiveness of knowledge by presenting part of the knowledge dynamically"
        },
        {
            "id": "R140383",
            "label": "Automatic Constructing OWL Ontology from Relational Database Schema: ",
            "doi": "10.5220/0004603100740081",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138541",
                    "label": "Ontology learning from databases"
                }
            ],
            "abstract": "in this paper we present a new tool, called db_doowl, for creating domain ontology from relational database schema (rdbs). in contrast with existing transformation approaches, we propose a generic solution based on automatic instantiation of a specified meta-ontology. this later is an owl ontology which describes any database structure. a prototype of our proposed tool is implemented based on jena in java in order to demonstrate its feasibility."
        },
        {
            "id": "R140398",
            "label": "Learning ontology from relational database",
            "doi": "10.1109/icmlc.2005.1527531",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R138541",
                    "label": "Ontology learning from databases"
                }
            ],
            "abstract": "ontology provides a shared and reusable piece of knowledge about a specific domain, and has been applied in many fields, such as semantic web, e-commerce and information retrieval, etc. however, building ontology by hand is a very hard and error-prone task. learning ontology from existing resources is a good solution. because relational database is widely used for storing data and owl is the latest standard recommended by w3c, this paper proposes an approach of learning owl ontology from data in relational database. compared with existing methods, the approach can acquire ontology from relational database automatically by using a group of learning rules instead of using a middle model. in addition, it can obtain owl ontology, including the classes, properties, properties characteristics, cardinality and instances, while none of existing methods can acquire all of them. the proposed learning rules have been proven to be correct by practice."
        },
        {
            "id": "R140830",
            "label": "SemEval 2014 Task 5 - L2 Writing Assistant",
            "doi": "10.3115/v1/s14-2005",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140833",
                    "label": "L2 Writing Assistant"
                }
            ],
            "abstract": "we present a new cross-lingual task for semeval concerning the translation of l1 fragments in an l2 context. the task is at the boundary of cross-lingual word sense disambiguation and machine translation. it finds its application in the field of computer-assisted translation, particularly in the context of second language learning. translating l1 fragments in an l2 context allows language learners when writing in a target language (l2) to fall back to their native language (l1) whenever they are uncertain of the right word or phrase."
        },
        {
            "id": "R140838",
            "label": "SemEval-2014 Task 7: Analysis of Clinical Text",
            "doi": "10.3115/v1/s14-2007",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                },
                {
                    "id": "R120611",
                    "label": "Word Sense Disambiguation"
                }
            ],
            "abstract": "this paper describes the semeval-2014, task 7 on the analysis of clinical text and presents the evaluation results. it focused on two subtasks: (i) identification (task a) and (ii) normalization (task b) of diseases and disorders in clinical reports as annotated in the shared annotated resources (share) 1 corpus. this task was a follow-up to the share/clef ehealth 2013 shared task, subtasks 1a and 1b, 2 but using a larger test set. a total of 21 teams competed in task a, and 18 of those also participated in task b. for task a, the best system had a strict f1-score of 81.3, with a precision of 84.3 and recall of 78.6. for task b, the same group had the best strict accuracy of 74.1. the organizers have made the text corpora, annotations, and evaluation tools available for future research and development at the shared task website. 3"
        },
        {
            "id": "R140841",
            "label": "SemEval-2015 Task 5: QA TempEval - Evaluating Temporal Information Understanding with Question Answering",
            "doi": "10.18653/v1/s15-2134",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140844",
                    "label": "Evaluating Temporal Information Understanding"
                },
                {
                    "id": "R140845",
                    "label": "QA TempEval"
                }
            ],
            "abstract": "qa tempeval shifts the goal of previous tempevals away from an intrinsic evaluation methodology toward a more extrinsic goal of question answering. this evaluation requires systems to capture temporal information relevant to perform an end-user task, as opposed to corpus-based evaluation where all temporal information is equally important. evaluation results show that the best automated timeml annotations reach over 30% recall on questions with \u2018yes\u2019 answer and about 50% on easier questions with \u2018no\u2019 answers. features that helped achieve better results are event coreference and a time expression reasoner."
        },
        {
            "id": "R140846",
            "label": "SemEval-2015 Task 9: CLIPEval Implicit Polarity of Events",
            "doi": "10.18653/v1/s15-2077",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140849",
                    "label": "Identification of implicit polarity"
                }
            ],
            "abstract": "sentiment analysis tends to focus on the polarity of words, combining their values to detect which portion of a text is opinionated. clipeval wants to promote a more holistic approach, looking at psychological researches that frame the connotations of words as the emotional values activated by them. the implicit polarity of events is just one aspect of connotative meaning and we address it with a task that is based on a dataset of sentences annotated as instantiations of pleasant and unpleasant events previously collected in psychological research as the ones on which human judgments converge."
        },
        {
            "id": "R140850",
            "label": "SemEval-2016 Task 7: Determining Sentiment Intensity of English and Arabic Phrases",
            "doi": "10.18653/v1/s16-1004",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140853",
                    "label": "Determining Sentiment Intensity"
                }
            ],
            "abstract": "we present a shared task on automatically determining sentiment intensity of a word or a phrase. the words and phrases are taken from three domains: general english, english twitter, and arabic twitter. the phrases include those composed of negators, modals, and degree adverbs as well as phrases formed by words with opposing polarities. for each of the three domains, we assembled the datasets that include multi-word phrases and their constituent words, both manually annotated for real-valued sentiment intensity scores. the three datasets were presented as the test sets for three separate tasks (each focusing on a specific domain). five teams submitted nine system outputs for the three tasks. all datasets created for this shared task are freely available to the research community."
        },
        {
            "id": "R140855",
            "label": "SemEval-2016 Task 10: Detecting Minimal Semantic Units and their Meanings (DiMSUM)",
            "doi": "10.18653/v1/s16-1084",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140858",
                    "label": "Detecting Minimal Semantic Units and their Meanings"
                }
            ],
            "abstract": "this task combines the labeling of multiword expressions and supersenses (coarse-grained classes) in an explicit, yet broad-coverage paradigm for lexical semantics. nine systems participated; the best scored 57.7% f 1 in a multi-domain evaluation setting, indicating that the task remains largely unresolved. an error analysis reveals that a large number of instances in the data set are either hard cases, which no systems get right, or easy cases, which all systems correctly solve."
        },
        {
            "id": "R140859",
            "label": "SemEval-2017 Task 8: RumourEval: Determining rumour veracity and\n            support for rumours",
            "doi": "10.18653/v1/s17-2006",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140862",
                    "label": "Determining rumor veracity"
                }
            ],
            "abstract": "media is full of false claims. even oxford dictionaries named \u201cpost-truth\u201d as the word of 2016. this makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. rumoureval is a semeval shared task that aims to identify and handle rumours and reactions to them, in text. we present an annotation scheme, a large dataset covering multiple topics \u2013 each having their own families of claims and replies \u2013 and use these to pose two concrete challenges as well as the results achieved by participants on these challenges."
        },
        {
            "id": "R140863",
            "label": "SemEval-2018 Task 1: Affect in Tweets",
            "doi": "10.18653/v1/s18-1001",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140866",
                    "label": "Infer the affectual state of a person from their tweet"
                }
            ],
            "abstract": "we present the semeval-2018 task 1: affect in tweets, which includes an array of subtasks on inferring the affectual state of a person from their tweet. for each task, we created labeled data from english, arabic, and spanish tweets. the individual tasks are: 1. emotion intensity regression, 2. emotion intensity ordinal classification, 3. valence (sentiment) regression, 4. valence ordinal classification, and 5. emotion classification. seventy-five teams (about 200 team members) participated in the shared task. we summarize the methods, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful. we also analyze systems for consistent bias towards a particular race or gender. the data is made freely available to further improve our understanding of how people convey emotions through language."
        },
        {
            "id": "R140867",
            "label": "SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA",
            "doi": "10.18653/v1/s19-2001",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140870",
                    "label": "Cross-lingual Semantic Parsing"
                }
            ],
            "abstract": "we present the semeval 2019 shared task on universal conceptual cognitive annotation (ucca) parsing in english, german and french, and discuss the participating systems and results. ucca is a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. ucca poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in dag structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. the shared task has yielded improvements over the state-of-the-art baseline in all languages and settings. full results can be found in the task\u2019s website https://competitions.codalab.org/competitions/19160."
        },
        {
            "id": "R140882",
            "label": "SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological Inflection",
            "doi": "10.18653/v1/2020.sigmorphon-1.1",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140885",
                    "label": "Typologically Diverse Morphological Inflection"
                }
            ],
            "abstract": "a broad goal in natural language processing (nlp) is to develop a system that has the capacity to process any natural language. most systems, however, are developed using data from just one language such as english. the sigmorphon 2020 shared task on morphological reinflection aims to investigate systems\u2019 ability to generalize across typologically distinct languages, many of which are low resource. systems were developed using data from 45 languages and just 5 language families, fine-tuned with data from an additional 45 languages and 10 language families (13 in total), and evaluated on all 90 languages. a total of 22 systems (19 neural) from 10 teams were submitted to the task. all four winning systems were neural (two monolingual transformers and two massively multilingual rnn-based models with gated attention). most teams demonstrate utility of data hallucination and augmentation, ensembles, and multilingual training for low-resource languages. non-neural learners and manually designed grammars showed competitive and even superior performance on some languages (such as ingrian, tajik, tagalog, zarma, lingala), especially with very limited data. some language families (afro-asiatic, niger-congo, turkic) were relatively easy for most systems and achieved over 90% mean accuracy while others were more challenging."
        },
        {
            "id": "R140948",
            "label": "Findings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas",
            "doi": "10.18653/v1/2021.americasnlp-1.23",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140954",
                    "label": " Open Machine Translation"
                }
            ],
            "abstract": "this paper presents the results of the 2021 shared task on open machine translation for indigenous languages of the americas. the shared task featured two independent tracks, and participants submitted machine translation systems for up to 10 indigenous languages. overall, 8 teams participated with a total of 214 submissions. we provided training sets consisting of data collected from various sources, as well as manually translated sentences for the development and test sets. an official baseline trained on this data was also provided. team submissions featured a variety of architectures, including both statistical and neural models, and for the majority of languages, many teams were able to considerably improve over the baseline. the best performing systems achieved 12.97 chrf higher than baseline, when averaged across languages."
        },
        {
            "id": "R140992",
            "label": "Overview of the MEDIQA 2021 Shared Task on Summarization in the Medical Domain",
            "doi": "10.18653/v1/2021.bionlp-1.8",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140995",
                    "label": "Summarization"
                }
            ],
            "abstract": "the mediqa 2021 shared tasks at the bionlp 2021 workshop addressed three tasks on summarization for medical text: (i) a question summarization task aimed at exploring new approaches to understanding complex real-world consumer health queries, (ii) a multi-answer summarization task that targeted aggregation of multiple relevant answers to a biomedical question into one concise and relevant answer, and (iii) a radiology report summarization task addressing the development of clinically relevant impressions from radiology report findings. thirty-five teams participated in these shared tasks with sixteen working notes submitted (fifteen accepted) describing a wide variety of models developed and tested on the shared and external datasets. in this paper, we describe the tasks, the datasets, the models and techniques developed by various teams, the results of the evaluation, and a study of correlations among various summarization evaluation measures. we hope that these shared tasks will bring new research and insights in biomedical text summarization and evaluation."
        },
        {
            "id": "R76548",
            "label": "Employee psychological well\u2010being during the\n            COVID\n            \u201019 pandemic in Germany: A longitudinal study of demands, resources, and exhaustion",
            "doi": "10.1002/ijop.12743",
            "research_field": {
                "id": "R351",
                "label": "Industrial and Organizational Psychology"
            },
            "research_problems": [
                {
                    "id": "R76572",
                    "label": "Effect of the COVID-19 pandemic on well-being"
                }
            ],
            "abstract": "\"many governments react to the current coronavirus/covid\u201019 pandemic by restricting daily (work) life. on the basis of theories from occupational health, we propose that the duration of the pandemic, its demands (e.g., having to work from home, closing of childcare facilities, job insecurity, work\u2010privacy conflicts, privacy\u2010work conflicts) and personal\u2010 and job\u2010related resources (co\u2010worker social support, job autonomy, partner support and corona self\u2010efficacy) interact in their effect on employee exhaustion. we test the hypotheses with a three\u2010wave sample of german employees during the pandemic from april to june 2020 (n w1 = 2900, n w12 = 1237, n w123 = 789). our findings show a curvilinear effect of pandemic duration on working women's exhaustion. the data also show that the introduction and the easing of lockdown measures affect exhaustion, and that women with children who work from home while childcare is unavailable are especially exhausted. job autonomy and partner support mitigated some of these effects. in sum, women's psychological health was more strongly affected by the pandemic than men's. we discuss implications for occupational health theories and that interventions targeted at mitigating the psychological consequences of the covid\u201019 pandemic should target women specifically.\""
        },
        {
            "id": "R75828",
            "label": "Decision-making at the sharp end: a survey of literature related to decision-making in humanitarian contexts",
            "doi": "10.1186/s41018-020-00068-2",
            "research_field": {
                "id": "R353",
                "label": "Social Psychology"
            },
            "research_problems": [
                {
                    "id": "R75831",
                    "label": "Describing the characteristics of humanitarian decision-making"
                }
            ],
            "abstract": "abstract in a humanitarian response, leaders are often tasked with making large numbers of decisions, many of which have significant consequences, in situations of urgency and uncertainty. these conditions have an impact on the decision-maker (causing stress, for example) and subsequently on how decisions get made. evaluations of humanitarian action suggest that decision-making is an area of weakness in many operations. there are examples of important decisions being missed and of decision-making processes that are slow and ad hoc. as part of a research process to address these challenges, this article considers literature from the humanitarian and emergency management sectors that relates to decision-making. it outlines what the literature tells us about the nature of the decisions that leaders at the country level are taking during humanitarian operations, and the circumstances under which these decisions are taken. it then considers the potential application of two different types of decision-making process in these contexts: rational/analytical decision-making and naturalistic decision-making. the article concludes with broad hypotheses that can be drawn from the literature and with the recommendation that these be further tested by academics with an interest in the topic."
        },
        {
            "id": "R166784",
            "label": "Automation and New Tasks: How Technology Displaces and Reinstates Labor",
            "doi": "10.1257/jep.33.2.3",
            "research_field": {
                "id": "R310",
                "label": "Labor Economics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present a framework for understanding the effects of automation and other types of technological changes on labor demand, and use it to interpret changes in us employment over the recent past. at the center of our framework is the allocation of tasks to capital and labor\u2014the task content of production. automation, which enables capital to replace labor in tasks it was previously engaged in, shifts the task content of production against labor because of a displacement effect. as a result, automation always reduces the labor share in value added and may reduce labor demand even as it raises productivity. the effects of automation are counterbalanced by the creation of new tasks in which labor has a comparative advantage. the introduction of new tasks changes the task content of production in favor of labor because of a reinstatement effect, and always raises the labor share and labor demand. we show how the role of changes in the task content of production\u2014due to automation and new tasks\u2014can be inferred from industry-level data. our empirical decomposition suggests that the slower growth of employment over the last three decades is accounted for by an acceleration in the displacement effect, especially in manufacturing, a weaker reinstatement effect, and slower growth of productivity than in previous decades."
        },
        {
            "id": "R42000",
            "label": "Micro-doppler effect in radar: phenomenon, model, and simulation study",
            "doi": "10.1109/taes.2006.1603402",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "when, in addition to the constant doppler frequency shift induced by the bulk motion of a radar target, the target or any structure on the target undergoes micro-motion dynamics, such as mechanical vibrations or rotations, the micro-motion dynamics induce doppler modulations on the returned signal, referred to as the micro-doppler effect. we introduce the micro-doppler phenomenon in radar, develop a model of doppler modulations, derive formulas of micro-doppler induced by targets with vibration, rotation, tumbling and coning motions, and verify them by simulation studies, analyze time-varying micro-doppler features using high-resolution time-frequency transforms, and demonstrate the micro-doppler effect observed in real radar data."
        },
        {
            "id": "R49301",
            "label": "Interactions between the perception of light and temperature",
            "doi": "10.1111/ina.12500",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R43007",
                    "label": "Indoor environmental perception and behaviour"
                }
            ],
            "abstract": "expanding the acceptable range of indoor temperatures allows to reduce building energy consumption and may be beneficial for health. therefore, we explored whether light conditions can be used to influence thermal perception under various ambient temperatures. in two laboratory experiments, we tested the effect of the correlated color temperature of light (2700\\xa0k and 5800\\xa0k) and its intensity (5 and 1200 lux) on thermal perception. the light exposures were provided during cool, neutral, and warm thermal conditions. cold-induced perceived shivering was higher for the 5800 k light exposure. all other parameters related to thermal perception did not significantly differ between the light exposures. interestingly, the other way around, an increasing ambient temperature resulted in a warmer perception of the light color. in every light condition, it appeared that the perceived light intensity was closest to neutral under the thermoneutral condition. between different light sessions, the change in visual comfort and the change in thermal comfort were positively related. the main conclusion therefore is that thermal discomfort can be partly compensated by lighting that results in a higher perceived visual comfort. field studies are required to demonstrate whether lighting can enable new strategies to improve indoor environmental workplace satisfaction."
        },
        {
            "id": "R139273",
            "label": "A Highly Sensitive Nonenzymatic Glucose Biosensor Based on the Regulatory Effect of Glucose on Electrochemical Behaviors of Colloidal Silver Nanoparticles on MoS2",
            "doi": "10.3390/s17081807",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R139272",
                    "label": "Improving the sensitivity of glucose biosensor"
                }
            ],
            "abstract": "a novel and highly sensitive nonenzymatic glucose biosensor was developed by nucleating colloidal silver nanoparticles (agnps) on mos2. the facile fabrication method, high reproducibility (97.5%) and stability indicates a promising capability for large-scale manufacturing. additionally, the excellent sensitivity (9044.6 \u03bca\u00b7mm\u22121\u00b7cm\u22122), low detection limit (0.03 \u03bcm), appropriate linear range of 0.1\u20131000 \u03bcm, and high selectivity suggests that this biosensor has a great potential to be applied for noninvasive glucose detection in human body fluids, such as sweat and saliva."
        },
        {
            "id": "R139283",
            "label": "Glucose Biosensor Based on Disposable Activated Carbon Electrodes Modified with Platinum Nanoparticles Electrodeposited on Poly(Azure A)",
            "doi": "10.3390/s20164489",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R139272",
                    "label": "Improving the sensitivity of glucose biosensor"
                }
            ],
            "abstract": "herein, a novel electrochemical glucose biosensor based on glucose oxidase (gox) immobilized on a surface containing platinum nanoparticles (ptnps) electrodeposited on poly(azure a) (paa) previously electropolymerized on activated screen-printed carbon electrodes (gox-ptnps-paa-aspces) is reported. the resulting electrochemical biosensor was validated towards glucose oxidation in real samples and further electrochemical measurement associated with the generated h2o2. the electrochemical biosensor showed an excellent sensitivity (42.7 \u03bca mm\u22121 cm\u22122), limit of detection (7.6 \u03bcm), linear range (20 \u03bcm\u20132.3 mm), and good selectivity towards glucose determination. furthermore, and most importantly, the detection of glucose was performed at a low potential (0.2 v vs. ag). the high performance of the electrochemical biosensor was explained through surface exploration using field emission sem, xps, and impedance measurements. the electrochemical biosensor was successfully applied to glucose quantification in several real samples (commercial juices and a plant cell culture medium), exhibiting a high accuracy when compared with a classical spectrophotometric method. this electrochemical biosensor can be easily prepared and opens up a good alternative in the development of new sensitive glucose sensors."
        },
        {
            "id": "R139290",
            "label": "Engineered Hierarchical CuO Nanoleaves Based Electrochemical Nonenzymatic Biosensor for Glucose Detection",
            "doi": "10.1149/1945-7111/abd515",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R139272",
                    "label": "Improving the sensitivity of glucose biosensor"
                }
            ],
            "abstract": "in this study, we synthesized hierarchical cuo nanoleaves in large-quantity via the hydrothermal method. we employed different techniques to characterize the morphological, structural, optical properties of the as-prepared hierarchical cuo nanoleaves sample. an electrochemical based nonenzymatic glucose biosensor was fabricated using engineered hierarchical cuo nanoleaves. the electrochemical behavior of fabricated biosensor towards glucose was analyzed with cyclic voltammetry (cv) and amperometry (i\u2013t) techniques. owing to the high electroactive surface area, hierarchical cuo nanoleaves based nonenzymatic biosensor electrode shows enhanced electrochemical catalytic behavior for glucose electro-oxidation in 100 mm sodium hydroxide (naoh) electrolyte. the nonenzymatic biosensor displays a high sensitivity (1467.32 \u03bc a/(mm cm 2 )), linear range (0.005\u20135.89 mm), and detection limit of 12 nm (s/n = 3). moreover, biosensor displayed good selectivity, reproducibility, repeatability, and stability at room temperature over three-week storage period. further, as-fabricated nonenzymatic glucose biosensors were employed for practical applications in human serum sample measurements. the obtained data were compared to the commercial biosensor, which demonstrates the practical usability of nonenzymatic glucose biosensors in real sample analysis."
        },
        {
            "id": "R141869",
            "label": "Integration of piezoelectric aluminum nitride and ultrananocrystalline diamond films for implantable biomedical microelectromechanical devices",
            "doi": "10.1063/1.4792238",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R141872",
                    "label": "Exploring the piezoelectric properties of AlN films for device applications"
                }
            ],
            "abstract": "the physics for integration of piezoelectric aluminum nitride (aln) films with underlying insulating ultrananocrystalline diamond (uncd), and electrically conductive grain boundary nitrogen-incorporated uncd (n-uncd) and boron-doped uncd (b-uncd) layers, as membranes for microelectromechanical system implantable drug delivery devices, has been investigated. aln films deposited on platinum layers on as grown uncd or n-uncd layer (5\u201310\\u2009nm rms roughness) required thickness of \u223c400 nm to induce (002) aln orientation with piezoelectric d33 coefficient \u223c1.91\\u2009pm/v at \u223c10\\u2009v. chemical mechanical polished b-uncd films (0.2\\u2009nm rms roughness) substrates enabled (002) aln film 200\\u2009nm thick, yielding d33\\u2009=\\u20095.3\\u2009pm/v."
        },
        {
            "id": "R141873",
            "label": "Preparation of highly c-axis oriented AlN thin films on Hastelloy tapes with Y2O3 buffer layer for flexible SAW sensor applications",
            "doi": "10.1142/s1793604716500235",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R141872",
                    "label": "Exploring the piezoelectric properties of AlN films for device applications"
                }
            ],
            "abstract": "highly c-axis oriented aluminum nitrade (aln) films were successfully deposited on flexible hastelloy tapes by middle-frequency magnetron sputtering. the microstructure and piezoelectric properties of the aln films were investigated. the results show that the aln films deposited directly on the bare hastelloy substrate have rough surface with root mean square (rms) roughness of 32.43[formula: see text]nm and its full width at half maximum (fwhm) of the aln (0002) peak is [formula: see text]. however, the aln films deposited on the hastelloy substrate with y 2 o 3 buffer layer show smooth surface with rms roughness of 5.46[formula: see text]nm and its fwhm of the aln (0002) peak is only [formula: see text]. the piezoelectric coefficient d[formula: see text] of the aln films deposited on the y 2 o 3 /hastelloy substrate is larger than three times that of the aln films deposited on the bare hastelloy substrate. the prepared highly c-axis oriented aln films can be used to develop high-temperature flexible saw sensors."
        },
        {
            "id": "R141877",
            "label": "Low temperature aluminum nitride thin films for sensory applications",
            "doi": "10.1063/1.4959895",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R141872",
                    "label": "Exploring the piezoelectric properties of AlN films for device applications"
                }
            ],
            "abstract": "a low-temperature sputter deposition process for the synthesis of aluminum nitride (aln) thin films that is attractive for applications with a limited temperature budget is presented. influence of the reactive gas concentration, plasma treatment of the nucleation surface and film thickness on the microstructural, piezoelectric and dielectric properties of aln is investigated. an improved crystal quality with respect to the increased film thickness was observed; where full width at half maximum (fwhm) of the aln films decreased from 2.88 \u00b1 0.16\u00b0 down to 1.25 \u00b1 0.07\u00b0 and the effective longitudinal piezoelectric coefficient (d33,f) increased from 2.30 \u00b1 0.32 pm/v up to 5.57 \u00b1 0.34 pm/v for film thicknesses in the range of 30 nm to 2 \u03bcm. dielectric loss angle (tan \u03b4) decreased from 0.626% \u00b1 0.005% to 0.025% \u00b1 0.011% for the same thickness range. the average relative permittivity (er) was calculated as 10.4 \u00b1 0.05. an almost constant transversal piezoelectric coefficient (|e31,f|) of 1.39 \u00b1 0.01 c/m2 was measured for samples in the range of 0.5 \u03bcm to 2 \u03bcm. transmission electron microscopy (tem) investigations performed on thin (100 nm) and thick (1.6 \u03bcm) films revealed an (002) oriented aln nucleation and growth starting directly from the aln-pt interface independent of the film thickness and exhibit comparable quality with the state-of-the-art aln thin films sputtered at much higher substrate temperatures."
        },
        {
            "id": "R141880",
            "label": "Integration of AlN piezoelectric thin films on ultralow fatigue TiNiCu shape memory alloys",
            "doi": "10.1557/jmr.2020.106",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R141872",
                    "label": "Exploring the piezoelectric properties of AlN films for device applications"
                }
            ],
            "abstract": "abstract"
        },
        {
            "id": "R141884",
            "label": "Enhancement of c-Axis Oriented Aluminum Nitride Films via Low Temperature DC Sputtering",
            "doi": "10.1109/jsen.2021.3077274",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R141872",
                    "label": "Exploring the piezoelectric properties of AlN films for device applications"
                }
            ],
            "abstract": "in this study, we successfully deposit c-axis oriented aluminum nitride (aln) piezoelectric films at low temperature (100 \u00b0c) via the dc sputtering method with tilt gun. the x-ray diffraction (xrd) observations prove that the deposited films have a c-axis preferred orientation. effective d33 value of the proposed films is 5.92 pm/v, which is better than most of the reported data using dc sputtering or other processing methods. it is found that the gun placed at 25\u00b0 helped the films to rearrange at low temperature and c-axis orientation aln films were successfully grown at 100 \u00b0c. this temperature is much lower than the reported growing temperature. it means the piezoelectric films can be deposited at flexible substrate and the photoresist can be stable at this temperature. the cantilever beam type microelectromechanical systems (mems) piezoelectric accelerometers are then fabricated based on the proposed aln films with a lift-off process. the results show that the responsivity of the proposed devices is 8.12 mv/g, and the resonance frequency is 460 hz, which indicates they can be used for machine tools."
        },
        {
            "id": "R141891",
            "label": "Microstructure and Electrical Properties of Novel piezo-optrodes Based on Thin-Film Piezoelectric Aluminium Nitride for Sensing",
            "doi": "10.1109/tnano.2020.3042234",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R141872",
                    "label": "Exploring the piezoelectric properties of AlN films for device applications"
                }
            ],
            "abstract": "thin-film piezoelectric materials are currently employed in micro- and nanodevices for energy harvesting and mechanical sensing. the deposition of these functional layers, however, is quite challenging onto non-rigid/non-flat substrates, such as optical fibers (ofs). besides the recent novel applications of ofs as probes for biosensing and bioactuation, the possibility to combine them with piezoelectric thin films and metallic electrodes can pave the way for the employment of novel opto-electro-mechanical sensors (e.g., waveguides, optical phase modulators, tunable filters, energy harvesters or biosensors). in this work the deposition of a thin-film piezoelectric wurtzite-phase aluminium nitride (aln), sandwiched between molybdenum (mo) electrodes, on the curved lateral surface of an optical fiber with polymeric cladding, is reported for the first time, without the need of an orientation-promoting interlayer. the material surface properties and morphology are characterized by microscopy techniques. high orientation is demonstrated by sem, pfm and x-ray diffraction analysis on a flat polymeric control, with a resulting piezoelectric coefficient (d33) of \u223c5.4 pm/v, while the surface roughness rms measured by afm is 9 \u00f7 16 nm. the output mechanical sensing capability of the resulting aln-based piezo-optrode is investigated through mechanical buckling tests: the peak-to-peak voltage for weakly impulsive loads increases with increasing relative displacements (up to 30%), in the range of 20 \u00f7 35 mv. impedance spectroscopy frequency sweeps (10 khz-1 mhz, 1 v) demonstrate a sensor capacitance of \u223c8 pf, with an electrical q factor as high as 150. the electrical response in the long-term period (two months) revealed good reliability and durability."
        },
        {
            "id": "R143687",
            "label": "Design and Development of a Flexible Strain Sensor for Textile Structures Based on a Conductive Polymer Composite",
            "doi": "10.3390/s7040473",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R143691",
                    "label": "Improving the performance of flexible strain sensors based on carbon nanomaterials"
                }
            ],
            "abstract": "\"the aim of this work is to develop a smart flexible sensor adapted to textile structures, able to measure their strain deformations. the sensors are \u201csmart\u201d because of their capacity to adapt to the specific mechanical properties of textile structures that are lightweight, highly flexible, stretchable, elastic, etc. because of these properties, textile structures are continuously in movement and easily deformed, even under very low stresses. it is therefore important that the integration of a sensor does not modify their general behavior. the material used for the sensor is based on a thermoplastic elastomer (evoprene)/carbon black nanoparticle composite, and presents general mechanical properties strongly compatible with the textile substrate. two preparation techniques are investigated: the conventional melt-mixing process, and the solvent process which is found to be more adapted for this particular application. the preparation procedure is fully described, namely the optimization of the process in terms of filler concentration in which the percolation theory aspects have to be considered. the sensor is then integrated on a thin, lightweight nylon fabric, and the electromechanical characterization is performed to demonstrate the adaptability and the correct functioning of the sensor as a strain gauge on the fabric. a normalized relative resistance is defined in order to characterize the electrical response of the sensor. finally, the influence of environmental factors, such as temperature and atmospheric humidity, on the sensor performance is investigated. the results show that the sensor's electrical resistance is particularly affected by humidity. this behavior is discussed in terms of the sensitivity of the carbon black filler particles to the presence of water.\""
        },
        {
            "id": "R144780",
            "label": "Solar Blind Photodetectors Enabled by Nanotextured \u03b2-Ga2O3 Films Grown via Oxidation of GaAs Substrates",
            "doi": "10.1109/jphot.2017.2688463",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R144785",
                    "label": " Application of Gallium Oxide Films in Photodetectors"
                }
            ],
            "abstract": "a simple and inexpensive method for growing ga 2 o 3 using gaas wafers is demonstrated. si-doped gaas wafers are heated to 1050\\xa0\u00b0c in a horizontal tube furnace in both argon and air ambients in order to convert their surfaces to \u03b2-ga 2 o 3 . the \u03b2-ga 2 o 3 films are characterized using scanning electron micrograph, energy-dispersive x-ray spectroscopy, and x-ray diffraction. they are also used to fabricate solar blind photodetectors. the devices, which had nanotextured surfaces, exhibited a high sensitivity to ultraviolet (uv) illumination due in part to large surface areas. furthermore, the films have coherent interfaces with the substrate, which leads to a robust device with high resistance to thermo-mechanical stress. the photoconductance of the \u03b2-ga 2 o 3 films is found to increase by more than three orders of magnitude under 270\\xa0nm ultraviolet illumination with respect to the dark current. the fabricated device shows a responsivity of \u223c292\\xa0ma/w at this wavelength."
        },
        {
            "id": "R144792",
            "label": "Thermal annealing effect on \u03b2-Ga2O3 thin film solar blind photodetector heteroepitaxially grown on sapphire substrate",
            "doi": "10.1002/pssa.201700063",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R144785",
                    "label": " Application of Gallium Oxide Films in Photodetectors"
                }
            ],
            "abstract": "this paper presents the effect of thermal annealing on \u03b2\u2010ga2o3 thin film solar\u2010blind (sb) photodetector (pd) synthesized on c\u2010plane sapphire substrates by a low pressure chemical vapor deposition (lpcvd). the thin films were synthesized using high purity gallium (ga) and oxygen (o2) as source precursors. the annealing was performed ex situ the under the oxygen atmosphere, which helped to reduce oxygen or oxygen\u2010related vacancies in the thin film. metal/semiconductor/metal (msm) type photodetectors were fabricated using both the as\u2010grown and annealed films. the pds fabricated on the annealed films had lower dark current, higher photoresponse and improved rejection ratio (r250/r370 and r250/r405) compared to the ones fabricated on the as\u2010grown films. these improved pd performances are due to the significant reduction of the photo\u2010generated carriers trapped by oxygen or oxygen\u2010related vacancies."
        },
        {
            "id": "R139736",
            "label": "Public History and Contested Heritage: Archival Memories of the Bombing of Italy",
            "doi": "10.5130/phrj.v27i0.7088",
            "research_field": {
                "id": "R417",
                "label": "Cultural History"
            },
            "research_problems": [
                {
                    "id": "R139751",
                    "label": "How to present contested heritage in a digital archive?"
                }
            ],
            "abstract": "this article presents a case study of a collaborative public history project between participants in two countries, the united kingdom and italy. its subject matter is the bombing war in europe, 1939-1945, which is remembered and commemorated in very different ways in these two countries: the sensitivities involved thus constitute not only a case of public history conducted at the national level but also one involving contested heritage. an account of the ways in which public history has developed in the uk and italy is presented. this is followed by an explanation of how the bombing war has been remembered in each country. in the uk, veterans of raf bomber command have long felt a sense of neglect, largely because the deliberate targeting of civilians has not fitted comfortably into the dominant victor narrative. in italy, recollections of being bombed have remained profoundly dissonant within the received liberation discourse. the international bomber command centre digital archive (or archive) is then described as a case study that employs a public history approach, focusing on various aspects of its inclusive ethos, intended to preserve multiple perspectives. the italian component of the project is highlighted, problematising the digitisation of contested heritage within the broader context of twentieth-century history. reflections on the use of digital archiving practices and working in partnership are offered, as well as a brief account of user analytics of the archive through its first eighteen months online."
        },
        {
            "id": "R139761",
            "label": "The Story of the Markham Car Collection: A Cross-Platform Panoramic Tour of Contested Heritage",
            "doi": "10.1177/1550190619832381",
            "research_field": {
                "id": "R417",
                "label": "Cultural History"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this article, we share our experiences of using digital technologies and various media to present historical narratives of a museum object collection aiming to provide an engaging experience on multiple platforms. based on p. joseph\u2019s article, dawson presented multiple interpretations and historical views of the markham car collection across various platforms using multimedia resources. through her creative production, she explored how to use cylindrical panoramas and rich media to offer new ways of telling the controversial story of the contested heritage of a museum\u2019s veteran and vintage car collection. the production\u2019s usability was investigated involving five experts before it was published online and the general users\u2019 experience was investigated. in this article, we present an important component of findings which indicates that virtual panorama tours featuring multimedia elements could be successful in attracting new audiences and that using this type of storytelling technique can be effective in the museum sector. the storyteller panorama tour presented here may stimulate glam (galleries, libraries, archives, and museums) professionals to think of new approaches, implement new strategies or services to engage their audiences more effectively. the research may ameliorate the education of future professionals as well."
        },
        {
            "id": "R139784",
            "label": "The Management Of Heritage In Contested Cross-Border Contexts: Emerging Research On The Island Of Ireland",
            "doi": "10.5281/ZENODO.1469765",
            "research_field": {
                "id": "R417",
                "label": "Cultural History"
            },
            "research_problems": [
                {
                    "id": "R139787",
                    "label": "How to integrate participatory approaches in hertage diplomacy?"
                }
            ],
            "abstract": "this paper introduces the recently begun reinvent research project focused on the management of heritage in the cross-border cultural landscape of derry/londonderry. the importance of facilitating dialogue over cultural heritage to the maintenance of \u2018thin\u2019 borders in contested cross-border contexts is underlined in the paper, as is the relatively favourable strategic policy context for progressing \u2018heritage diplomacy\u2019 on the island of ireland. however, it is argued that more inclusive and participatory approaches to the management \\nof heritage are required to assist in the mediation of contestation, particularly accommodating a greater diversity of \u2018non-expert\u2019 opinion, in addition to \\nhelping identify value conflicts and dissonance. the application of digital technologies in the form of public participation geographic information systems (ppgis) is proposed, and this is briefly discussed in relation to some of \\nthe expected benefits and methodological challenges that must be addressed \\nin the reinvent project. the paper concludes by emphasising the importance \\nof dialogue and knowledge exchange between academia and heritage \\npolicymakers/practitioners."
        },
        {
            "id": "R1020",
            "label": "Open Research Knowledge Graph: Towards Machine Actionability in Scholarly Communication",
            "doi": "",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R1032",
                    "label": "Structured descriptions of research contributions"
                },
                {
                    "id": "R1033",
                    "label": "Scholarly communications representation"
                }
            ],
            "abstract": "despite improved findability of and access to scientific knowledge in recent decades, scholarly communication continues to be document-based. scientific knowledge remains locked in representations that are inadequate for machine processing. in this article, we present initial steps towards next generation digital libraries and infrastructures that acquire, curate, publish and process scholarly knowledge semantically, in machine readable form leveraging knowledge graphs. the primary contribution of this work is to present and discuss early developments of a system designed to crowdsource machine readable descriptions of research contributions published in scholarly articles and a knowledge graph infrastructure for description storage and access. we report on the results of a first experimental evaluation of the concept and its implementation with the participants of a recent international conference. the results suggest that users find such a system useful, and the possibilities it could enable intriguing."
        },
        {
            "id": "R2022",
            "label": "Why Reinvent the Wheel",
            "doi": "10.1145/3178876.3186023",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R2039",
                    "label": "Collaborative question answering"
                }
            ],
            "abstract": "modern question answering (qa) systems need to flexibly integrate a number of components specialised to fulfil specific tasks in a qa pipeline. key qa tasks include named entity recognition and disambiguation, relation extraction, and query building. since a number of different software components exist that implement different strategies for each of these tasks, it is a major challenge to select and combine the most suitable components into a qa system, given the characteristics of a question. we study this optimisation problem and train classifiers, which take features of a question as input and have the goal of optimising the selection of qa components based on those features. we then devise a greedy algorithm to identify the pipelines that include the suitable components and can effectively answer the given question. we implement this model within frankenstein, a qa framework able to select qa components and compose qa pipelines. we evaluate the effectiveness of the pipelines generated by frankenstein using the qald and lc-quad benchmarks. these results not only suggest that frankenstein precisely solves the qa optimisation problem but also enables the automatic composition of optimised qa pipelines, which outperform the static baseline qa pipeline. thanks to this flexible and fully automated pipeline generation process, new qa components can be easily included in frankenstein, thus improving the performance of the generated pipelines."
        },
        {
            "id": "R2047",
            "label": "Capturing Knowledge in Semantically-typed Relational Patterns to Enhance Relation Linking",
            "doi": "10.1145/3148011.3148031",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R2059",
                    "label": "Relation linking"
                },
                {
                    "id": "R2061",
                    "label": "Question Answering"
                }
            ],
            "abstract": "transforming natural language questions into formal queries is an integral task in question answering (qa) systems. qa systems built on knowledge graphs like dbpedia, require a step after natural language processing for linking words, specifically including named entities and relations, to their corresponding entities in a knowledge graph. to achieve this task, several approaches rely on background knowledge bases containing semantically-typed relations, e.g., patty, for an extra disambiguation step. two major factors may affect the performance of relation linking approaches whenever background knowledge bases are accessed: a) limited availability of such semantic knowledge sources, and b) lack of a systematic approach on how to maximize the benefits of the collected knowledge. we tackle this problem and devise sibkb, a semantic-based index able to capture knowledge encoded on background knowledge bases like patty. sibkb represents a background knowledge base as a bi-partite and a dynamic index over the relation patterns included in the knowledge base. moreover, we develop a relation linking component able to exploit sibkb features. the benefits of sibkb are empirically studied on existing qa benchmarks and observed results suggest that sibkb is able to enhance the accuracy of relation linking by up to three times."
        },
        {
            "id": "R140043",
            "label": "Unleashing innovation through internal hackathons",
            "doi": "10.1109/innotek.2014.6877369",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "hackathons have become an increasingly popular approach for organizations to both test their new products and services as well as to generate new ideas. most events either focus on attracting external developers or requesting employees of the organization to focus on a specific problem. in this paper we describe extensions to this paradigm that open up the event to internal employees and preserve the open-ended nature of the hackathon itself. in this paper we describe our initial motivation and objectives for conducting an internal hackathon, our experience in pioneering an internal hackathon at at&t including specific things we did to make the internal hackathon successful. we conclude with the benefits (both expected and unexpected) we achieved from the internal hackathon approach, and recommendations for continuing the use of this valuable tool within at&t."
        },
        {
            "id": "R140059",
            "label": "Open data hackathons: an innovative strategy to enhance entrepreneurial intention",
            "doi": "10.1108/ijis-06-2017-0055",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R140068",
                    "label": "aims to suggest a model that incorporates factors that affect the decision of establishing a startup by developers who have participated in open data hackathons"
                }
            ],
            "abstract": "\\n purpose \\n in terms of entrepreneurship, open data benefits include economic growth, innovation, empowerment and new or improved products and services. hackathons encourage the development of new applications using open data and the creation of startups based on these applications. researchers focus on factors that affect nascent entrepreneurs\u2019 decision to create a startup but researches in the field of open data hackathons have not been fully investigated yet. this paper aims to suggest a model that incorporates factors that affect the decision of establishing a startup by developers who have participated in open data hackathons. \\n \\n \\n design/methodology/approach \\n in total, 70 papers were examined and analyzed using a three-phased literature review methodology, which was suggested by webster and watson (2002). these surveys investigated several factors that affect a nascent entrepreneur to create a startup. \\n \\n \\n findings \\n eventually, by identifying the motivations for developers to participate in a hackathon, and understanding the benefits of the use of open data, researchers will be able to elaborate the proposed model and evaluate if the contest has contributed to the decision of establish a startup and what factors affect the decision to establish a startup apply to open data developers, and if the participants of the contest agree with these factors. \\n \\n \\n originality/value \\n the paper expands the scope of open data research on entrepreneurship field, stating the need for more research to be conducted regarding the open data in entrepreneurship through hackathons. \\n"
        },
        {
            "id": "R140070",
            "label": "Hackathons as Co-optation Ritual: Socializing Workers and Institutionalizing Innovation in the \u201cNew\u201d Economy",
            "doi": "10.1108/s0277-283320170000031005",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\nhackathons, time-bounded events where participants write computer code and build apps, have become a popular means of socializing tech students and workers to produce \u201cinnovation\u201d despite little promise of material reward. although they offer participants opportunities for learning new skills and face-to-face networking and set up interaction rituals that create an emotional \u201chigh,\u201d potential advantage is even greater for the events\u2019 corporate sponsors, who use them to outsource work, crowdsource innovation, and enhance their reputation. ethnographic observations and informal interviews at seven hackathons held in new york during the course of a single school year show how the format of the event and sponsors\u2019 discursive tropes, within a dominant cultural frame reflecting the appeal of silicon valley, reshape unpaid and precarious work as an extraordinary opportunity, a ritual of ecstatic labor, and a collective imaginary for fictional expectations of innovation that benefits all, a powerful strategy for manufacturing workers\u2019 consent in the \u201cnew\u201d economy."
        },
        {
            "id": "R140080",
            "label": "Interdisciplinary Online Hackathons as an Approach to Combat the COVID-19 Pandemic: Case Study",
            "doi": "10.2196/25283",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\\n background \\n the covid-19 outbreak has affected the lives of millions of people by causing a dramatic impact on many health care systems and the global economy. this devastating pandemic has brought together communities across the globe to work on this issue in an unprecedented manner. \\n \\n \\n objective \\n this case study describes the steps and methods employed in the conduction of a remote online health hackathon centered on challenges posed by the covid-19 pandemic. it aims to deliver a clear implementation road map for other organizations to follow. \\n \\n \\n methods \\n this 4-day hackathon was conducted in april 2020, based on six covid-19\u2013related challenges defined by frontline clinicians and researchers from various disciplines. an online survey was structured to assess: (1) individual experience satisfaction, (2) level of interprofessional skills exchange, (3) maturity of the projects realized, and (4) overall quality of the event. at the end of the event, participants were invited to take part in an online survey with 17 (+5 optional) items, including multiple-choice and open-ended questions that assessed their experience regarding the remote nature of the event and their individual project, interprofessional skills exchange, and their confidence in working on a digital health project before and after the hackathon. mentors, who guided the participants through the event, also provided feedback to the organizers through an online survey. \\n \\n \\n results \\n a total of 48 participants and 52 mentors based in 8 different countries participated and developed 14 projects. a total of 75 mentorship video sessions were held. participants reported increased confidence in starting a digital health venture or a research project after successfully participating in the hackathon, and stated that they were likely to continue working on their projects. of the participants who provided feedback, 60% (n=18) would not have started their project without this particular hackathon and indicated that the hackathon encouraged and enabled them to progress faster, for example, by building interdisciplinary teams, gaining new insights and feedback provided by their mentors, and creating a functional prototype. \\n \\n \\n conclusions \\n this study provides insights into how online hackathons can contribute to solving the challenges and effects of a pandemic in several regions of the world. the online format fosters team diversity, increases cross-regional collaboration, and can be executed much faster and at lower costs compared to in-person events. results on preparation, organization, and evaluation of this online hackathon are useful for other institutions and initiatives that are willing to introduce similar event formats in the fight against covid-19. \\n"
        },
        {
            "id": "R148013",
            "label": "Google Dataset Search: Building a search engine for datasets in an open Web ecosystem",
            "doi": "",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R148016",
                    "label": "A search engine for datasets in an open Web ecosystem"
                }
            ],
            "abstract": "\"there are thousands of data repositories on the web, providing access to millions of datasets. national and regional governments, scientific publishers and consortia, commercial data providers, and others publish data for fields ranging from social science to life science to high-energy physics to climate science and more. access to this data is critical to facilitating reproducibility of research results, enabling scientists to build on others' work, and providing data journalists easier access to information and its provenance. in this paper, we discuss google dataset search, a dataset-discovery tool that provides search capabilities over potentially all datasets published on the web. the approach relies on an open ecosystem, where dataset owners and providers publish semantically enhanced metadata on their own sites. we then aggregate, normalize, and reconcile this metadata, providing a search engine that lets users find datasets in the \u201clong tail\u201d of the web. in this paper, we discuss both social and technical challenges in building this type of tool, and the lessons that we learned from this experience.\""
        },
        {
            "id": "R156129",
            "label": "DIGITAL MANUFACTURING: REQUIREMENTS AND CHALLENGES FOR IMPLEMENTING DIGITAL SURROGATES",
            "doi": "10.1109/wsc.2018.8632242",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R5007",
                    "label": "digital twin"
                }
            ],
            "abstract": "a key challenge for manufacturers today is efficiently producing and delivering products on time. issues include demand for customized products, changes in orders, and equipment status change, complicating the decision-making process. a real-time digital representation of the manufacturing operation would help address these challenges. recent technology advancements of smart sensors, iot, and cloud computing make it possible to realize a \"digital twin\" of a manufacturing system or process. digital twins or surrogates are data-driven virtual representations that replicate, connect, and synchronize the operation of a manufacturing system or process. they utilize dynamically collected data to track system behaviors, analyze performance, and help make decisions without interrupting production. in this paper, we define digital surrogate, explore their relationships to simulation, digital thread, artificial intelligence, and iot. we identify the technology and standard requirements and challenges for implementing digital surrogates. a production planning case is used to exemplify the digital surrogate concept."
        },
        {
            "id": "R161681",
            "label": "Link Prediction of Weighted Triples for Knowledge Graph Completion Within the Scholarly Domain",
            "doi": "10.1109/access.2021.3105183",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "knowledge graphs (kgs) are widely used for modeling scholarly communication, performing scientometric analyses, and supporting a variety of intelligent services to explore the literature and predict research dynamics. however, they often suffer from incompleteness (e.g., missing affiliations, references, research topics), leading to a reduced scope and quality of the resulting analyses. this issue is usually tackled by computing knowledge graph embeddings (kges) and applying link prediction techniques. however, only a few kge models are capable of taking weights of facts in the knowledge graph into account. such weights can have different meanings, e.g. describe the degree of association or the degree of truth of a certain triple. in this paper, we propose the weighted triple loss, a new loss function for kge models that takes full advantage of the additional numerical weights on facts and it is even tolerant to incorrect weights. we also extend the rule loss, a loss function that is able to exploit a set of logical rules, in order to work with weighted triples. the evaluation of our solutions on several knowledge graphs indicates significant performance improvements with respect to the state of the art. our main use case is the large-scale aida knowledge graph, which describes 21 million research articles. our approach enables to complete information about affiliation types, countries, and research topics, greatly improving the scope of the resulting scientometrics analyses and providing better support to systems for monitoring and predicting research dynamics."
        },
        {
            "id": "R163875",
            "label": "The role of software in science: a knowledge graph-based analysis of software mentions in PubMed Central",
            "doi": "10.7717/peerj-cs.835",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R166480",
                    "label": "Software named entity recognition"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "science across all disciplines has become increasingly data-driven, leading to additional needs with respect to software for collecting, processing and analysing data. thus, transparency about software used as part of the scientific process is crucial to understand provenance of individual research data and insights, is a prerequisite for reproducibility and can enable macro-analysis of the evolution of scientific methods over time. however, missing rigor in software citation practices renders the automated detection and disambiguation of software mentions a challenging problem. in this work, we provide a large-scale analysis of software usage and citation practices facilitated through an unprecedented knowledge graph of software mentions and affiliated metadata generated through supervised information extraction models trained on a unique gold standard corpus and applied to more than 3 million scientific articles. our information extraction approach distinguishes different types of software and mentions, disambiguates mentions and outperforms the state-of-the-art significantly, leading to the most comprehensive corpus of 11.8 m software mentions that are described through a knowledge graph consisting of more than 300 m triples. our analysis provides insights into the evolution of software usage and citation patterns across various fields, ranks of journals, and impact of publications. whereas, to the best of our knowledge, this is the most comprehensive analysis of software use and citation at the time, all data and models are shared publicly to facilitate further research into scientific use and citation of software."
        },
        {
            "id": "R164003",
            "label": "SoMeSci- A 5 Star Open Data Gold Standard Knowledge Graph of Software Mentions in Scientific Articles",
            "doi": "10.1145/3459637.3482017",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R147583",
                    "label": "Scientific concept annotation"
                },
                {
                    "id": "R166480",
                    "label": "Software named entity recognition"
                },
                {
                    "id": "R76427",
                    "label": "Language resource"
                }
            ],
            "abstract": "knowledge about software used in scientific investigations is important for several reasons, for instance, to enable an understanding of provenance and methods involved in data handling. however, software is usually not formally cited, but rather mentioned informally within the scholarly description of the investigation, raising the need for automatic information extraction and disambiguation. given the lack of reliable ground truth data, we present somesci-software mentions in science-a gold standard knowledge graph of software mentions in scientific articles. it contains high quality annotations (irr: k=.82) of 3756 software mentions in 1367 pubmed central articles. besides the plain mention of the software, we also provide relation labels for additional information, such as the version, the developer, a url or citations. moreover, we distinguish between different types, such as application, plugin or programming environment, as well as different types of mentions, such as usage or creation. to the best of our knowledge, somesci is the most comprehensive corpus about software mentions in scientific articles, providing training samples for named entity recognition, relation extraction, entity disambiguation, and entity linking. finally, we sketch potential use cases and provide baseline results."
        },
        {
            "id": "R164557",
            "label": "SaL-Lightning Dataset: Search and Eye Gaze Behavior, Resource Interactions and Knowledge Gain during Web Search",
            "doi": "10.1145/3498366.3505835",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R161722",
                    "label": "Dataset creation"
                }
            ],
            "abstract": "the emerging research field search as learning (sal) investigates how the web facilitates learning through modern information retrieval systems. sal research requires significant amounts of data that capture both search behavior of users and their acquired knowledge in order to obtain conclusive insights or train supervised machine learning models. however, the creation of such datasets is costly and requires interdisciplinary efforts in order to design studies and capture a wide range of features. in this paper, we address this issue and introduce an extensive dataset based on a user study, in which 114 participants were asked to learn about the formation of lightning and thunder. participants\u2019 knowledge states were measured before and after web search through multiple-choice questionnaires and essay-based free recall tasks. to enable future research in sal-related tasks we recorded a plethora of features and person-related attributes. besides the screen recordings, visited web pages, and detailed browsing histories, a large number of behavioral features and resource features were monitored. we underline the usefulness of the dataset by describing three, already published, use cases."
        },
        {
            "id": "R165783",
            "label": "ROBOKOP: an abstraction layer and user interface for knowledge graphs to support question answering",
            "doi": "10.1093/bioinformatics/btz604",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R165792",
                    "label": "question answering for knowledge graphs"
                }
            ],
            "abstract": "abstract \\n \\n summary \\n knowledge graphs (kgs) are quickly becoming a common-place tool for storing relationships between entities from which higher-level reasoning can be conducted. kgs are typically stored in a graph-database format, and graph-database queries can be used to answer questions of interest that have been posed by users such as biomedical researchers. for simple queries, the inclusion of direct connections in the kg and the storage and analysis of query results are straightforward; however, for complex queries, these capabilities become exponentially more challenging with each increase in complexity of the query. for instance, one relatively complex query can yield a kg with hundreds of thousands of query results. thus, the ability to efficiently query, store, rank and explore sub-graphs of a complex kg represents a major challenge to any effort designed to exploit the use of kgs for applications in biomedical research and other domains. we present reasoning over biomedical objects linked in knowledge oriented pathways as an abstraction layer and user interface to more easily query kgs and store, rank and explore query results. \\n \\n \\n availability and implementation \\n an instance of the robokop ui for exploration of the robokop knowledge graph can be found at http://robokop.renci.org. the robokop knowledge graph can be accessed at http://robokopkg.renci.org. code and instructions for building and deploying robokop are available under the mit open software license from https://github.com/ncats-gamma/robokop. \\n \\n \\n supplementary information \\n supplementary data are available at bioinformatics online. \\n"
        },
        {
            "id": "R166497",
            "label": "Softcite dataset: A dataset of software mentions in biomedical and economic research publications",
            "doi": "10.1002/asi.24454",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R166480",
                    "label": "Software named entity recognition"
                }
            ],
            "abstract": "software contributions to academic research are relatively invisible, especially to the formalized scholarly reputation system based on bibliometrics. in this article, we introduce a gold\u2010standard dataset of software mentions from the manual annotation of 4,971 academic pdfs in biomedicine and economics. the dataset is intended to be used for automatic extraction of software mentions from pdf format research publications by supervised learning at scale. we provide a description of the dataset and an extended discussion of its creation process, including improved text conversion of academic pdfs. finally, we reflect on our challenges and lessons learned during the dataset creation, in hope of encouraging more discussion about creating datasets for machine learning use."
        },
        {
            "id": "R166504",
            "label": "bioNerDS: exploring bioinformatics\u2019 database and software use through literature mining",
            "doi": "10.1186/1471-2105-14-194",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R166527",
                    "label": "Bioinformatics databases and software named entity recognition"
                }
            ],
            "abstract": "abstract \\n \\n background \\n biology-focused databases and software define bioinformatics and their use is central to computational biology. in such a complex and dynamic field, it is of interest to understand what resources are available, which are used, how much they are used, and for what they are used. while scholarly literature surveys can provide some insights, large-scale computer-based approaches to identify mentions of bioinformatics databases and software from primary literature would automate systematic cataloguing, facilitate the monitoring of usage, and provide the foundations for the recovery of computational methods for analysing biological data, with the long-term aim of identifying best/common practice in different areas of biology. \\n \\n \\n results \\n we have developed bionerds, a named entity recogniser for the recovery of bioinformatics databases and software from primary literature. we identify such entities with an f-measure ranging from 63% to 91% at the mention level and 63-78% at the document level, depending on corpus. not attaining a higher f-measure is mostly due to high ambiguity in resource naming, which is compounded by the on-going introduction of new resources. to demonstrate the software, we applied bionerds to full-text articles from bmc bioinformatics and genome biology. general mention patterns reflect the remit of these journals, highlighting bmc bioinformatics\u2019s emphasis on new tools and genome biology\u2019s greater emphasis on data analysis. the data also illustrates some shifts in resource usage: for example, the past decade has seen r and the gene ontology join blast and genbank as the main components in bioinformatics processing. \\n \\n \\n conclusions \\n we demonstrate the feasibility of automatically identifying resource names on a large-scale from the scientific literature and show that the generated data can be used for exploration of bioinformatics database and software usage. for example, our results help to investigate the rate of change in resource usage and corroborate the suspicion that a vast majority of resources are created, but rarely (if ever) used thereafter. bionerds is available at http://bionerds.sourceforge.net/ . \\n"
        },
        {
            "id": "R175410",
            "label": "The FAIR Data Maturity Model: An Approach to Harmonise FAIR Assessments",
            "doi": "10.5334/dsj-2020-041",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R175413",
                    "label": "assess the FAIRness of research data"
                }
            ],
            "abstract": "in the past years, many methodologies and tools have been developed to assess the fairness of research data. these different methodologies and tools have been based on various interpretations of the fair principles, which makes comparison of the results of the assessments difficult. the work in the rda fair data maturity model working group reported here has delivered a set of indicators with priorities and guidelines that provide a \u2018lingua franca\u2019 that can be used to make the results of the assessment using those methodologies and tools comparable. the model can act as a tool that can be used by various stakeholders, including researchers, data stewards, policy makers and funding agencies, to gain insight into the current fairness of data as well as into the aspects that can be improved to increase the potential for reuse of research data. through increased efficiency and effectiveness, it helps research activities to solve societal challenges and to support evidence-based decisions. the maturity model is publicly available and the working group is encouraging application of the model in practice. experience with the model will be taken into account in the further development of the model."
        },
        {
            "id": "R175113",
            "label": "Toward Altmetric-Driven Research-Paper Recommender System Framework",
            "doi": "10.1109/sitis.2017.21",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the volume of literature and more particularly research-oriented publications is growing at an exponential rate, and better tools and methodologies are required to efficiently and effectively retrieve desired documents. the development of academic search engines, digital libraries and archives has led to better information filtering mechanisms that has resulted to improved search results. however, the state-of-the art research-paper recommender systems are still retrieving research articles without explicitly defining the domain of interest of the researchers. also, a rich set of research output (research objects) and their associated metrics are also not being utilized in the process of searching, querying, retrieving and recommending articles. consequently, a lot of irrelevant and unrelated information is being presented to the user. then again, the use of citation counts to rank and recommend research-paper to users is still disputed. recommendation metrics like citation counts, ratings in collaborative filtering, and keyword analysis' cannot be fully relied on as the only techniques through which similarity between documents can be computed, and this is because recommendations based on such metrics are not accurate and have lots of biasness. henceforth, altmetric-based techniques and methodologies are expected to give better recommendations of research papers since the circumstances surrounding a research papers are taken into consideration. this paper proposes a research paper recommender system framework that utilizes paper ontology and altmetric from research papers, to enhance the performance of research paper recommender systems.\""
        },
        {
            "id": "R178149",
            "label": "A Similarity-Inclusive Link Prediction Based Recommender System Approach",
            "doi": "10.5755/j01.eie.25.6.24828",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R109082",
                    "label": "Knowledge Graph-based Recommendation"
                }
            ],
            "abstract": "despite being a challenging research field with many unresolved problems, recommender systems are getting more popular in recent years. these systems rely on the personal preferences of users on items given in the form of ratings and return the preferable items based on choices of like-minded users. in this study, a graph-based recommender system using link prediction techniques incorporating similarity metrics is proposed. a graph-based recommender system that has ratings of users on items can be represented as a bipartite graph, where vertices correspond to users and items and edges to ratings. recommendation generation in a bipartite graph is a link prediction problem. in current literature, modified link prediction approaches are used to distinguish between fundamental relational dualities of like vs. dislike and similar vs. dissimilar. however, the similarity relationship between users/items is mostly disregarded in the complex domain. the proposed model utilizes user-user and item-item cosine similarity value with the relational dualities in order to improve coverage and hits rate of the system by carefully incorporating similarities. on the standard movielens hetrec and movielens datasets, the proposed similarity-inclusive link prediction method performed empirically well compared to other methods operating in the complex domain. the experimental results show that the proposed recommender system can be a plausible alternative to overcome the deficiencies in recommender systems."
        },
        {
            "id": "R178155",
            "label": "A link prediction approach for item recommendation with complex number",
            "doi": "10.1016/j.knosys.2015.02.013",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R109082",
                    "label": "Knowledge Graph-based Recommendation"
                }
            ],
            "abstract": "recommendation can be reduced to a sub-problem of link prediction, with specific nodes (users and items) and links (similar relations among users/items, and interactions between users and items). however, the previous link prediction algorithms need to be modified to suit the recommendation cases since they do not consider the separation of these two fundamental relations: similar or dissimilar and like or dislike. in this paper, we propose a novel and unified way to solve this problem, which models the relation duality using complex number. under this representation, the previous works can directly reuse. in experiments with the movie lens dataset and the android software website appchina.com, the presented approach achieves significant performance improvement comparing with other popular recommendation algorithms both in accuracy and coverage. besides, our results revealed some new findings. first, it is observed that the performance is improved when the user and item popularities are taken into account. second, the item popularity plays a more important role than the user popularity does in final recommendation. since its notable performance, we are working to apply it in a commercial setting, appchina.com website, for application recommendation."
        },
        {
            "id": "R186108",
            "label": "Asset management maturity in public infrastructure: the case of Rijkswaterstaat",
            "doi": "",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in times of restructuring governmental policies and resources, the need for strategic asset management is growing. maturity models offer organisations a structure to assist them in improving their asset management performance. we present the results of a repeated maturity measurement based on the infrastructure management maturity matrix (im3) in rijkswaterstaat, a dutch public infrastructure organisation. the im3 distinguishes five maturity levels from ad hoc to optimised, and seven asset management dimensions: information management, internal coordination, external coordination, market approach, risk management, processes and roles, and culture and leadership. the results show significant progress on all dimensions, and continued learning and widespread awareness of asset management in the organisation. in the discussion, we reflect on the findings and possible future developments for the organisation. we also discuss the potential impact of infrastructure maturity models for the professionalisation of other asset intensive organisations"
        },
        {
            "id": "R187161",
            "label": "An Ontology for Smart Contracts",
            "doi": "",
            "research_field": {
                "id": "R137681",
                "label": "Information Systems, Process and Knowledge Management"
            },
            "research_problems": [
                {
                    "id": "R187163",
                    "label": "ontology for smart contracts"
                }
            ],
            "abstract": "this paper introduces a basic ontology that attempts to capture the essential features of many smart contracts, in order to aid in formal reasoning about their behavior. section ii gives a general overview of the proposed ontology, and section iii gives analyses of a number of interesting smart contracts from the literature, through the lens of this ontology. the proposals here are not intended to be the one true ontology, but rather a useful ontology. a well-designed blockchain should be able to support arbitrary such ontologies."
        },
        {
            "id": "R139591",
            "label": "Understanding Brand Consistency from Web Content",
            "doi": "10.1145/3292522.3326048",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R139594",
                    "label": "Brand Personality Detection"
                },
                {
                    "id": "R139595",
                    "label": "Brand Consistency Computation"
                }
            ],
            "abstract": "\"brands produce content to engage with the audience continually and tend to maintain a set of human characteristics in their marketing campaigns. in this era of digital marketing, they need to create a lot of content to keep up the engagement with their audiences. however, such kind of content authoring at scale introduces challenges in maintaining consistency in a brand's messaging tone, which is very important from a brand's perspective to ensure a persistent impression for its customers and audiences. in this work, we quantify brand personality and formulate its linguistic features. we score text articles extracted from brand communications on five personality dimensions: sincerity, excitement, competence, ruggedness and sophistication, and show that a linear svm model achieves a decent f1 score of $0.822$. the linear svm allows us to annotate a large set of data points free of any annotation error. we utilize this huge annotated dataset to characterize the notion of brand consistency, which is maintaining a company's targeted brand personality across time and over different content categories; we make certain interesting observations. as per our knowledge, this is the first study which investigates brand personality from the company's official websites, and that formulates and analyzes the notion of brand consistency on such a large scale.\""
        },
        {
            "id": "R139596",
            "label": "An Integrated Approach for Improving Brand Consistency of Web Content: Modeling, Analysis, and Recommendation",
            "doi": "10.1145/3450445",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R139594",
                    "label": "Brand Personality Detection"
                },
                {
                    "id": "R139595",
                    "label": "Brand Consistency Computation"
                },
                {
                    "id": "R139600",
                    "label": "Sentence Ranking"
                }
            ],
            "abstract": "\\n a consumer-dependent (business-to-consumer) organization tends to present itself as possessing a set of human qualities, which is termed the\\n brand personality \\n of the company. the perception is impressed upon the consumer through the content, be it in the form of advertisement, blogs, or magazines, produced by the organization. a consistent brand will generate trust and retain customers over time as they develop an affinity toward regularity and common patterns. however, maintaining a consistent messaging tone for a brand has become more challenging with the virtual explosion in the amount of content that needs to be authored and pushed to the internet to maintain an edge in the era of digital marketing. to understand the depth of the problem, we collect around 300k web page content from around 650 companies. we develop trait-specific classification models by considering the linguistic features of the content. the classifier automatically identifies the web articles that are not consistent with the mission and vision of a company and further helps us to discover the conditions under which the consistency cannot be maintained. to address the brand inconsistency issue, we then develop a sentence ranking system that outputs the top three sentences that need to be changed for making a web article more consistent with the company\u2019s brand personality.\\n"
        },
        {
            "id": "R140161",
            "label": "Semantic similarity and machine learning with ontologies",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n ontologies have long been employed in the life sciences to formally represent and reason over domain knowledge and they are employed in almost every major biological database. recently, ontologies are increasingly being used to provide background knowledge in similarity-based analysis and machine learning models. the methods employed to combine ontologies and machine learning are still novel and actively being developed. we provide an overview over the methods that use ontologies to compute similarity and incorporate them in machine learning methods; in particular, we outline how semantic similarity measures and ontology embeddings can exploit the background knowledge in ontologies and how ontologies can provide constraints that improve machine learning models. the methods and experiments we describe are available as a set of executable notebooks, and we also provide a set of slides and additional resources at https://github.com/bio-ontology-research-group/machine-learning-with-ontologies."
        },
        {
            "id": "R144816",
            "label": "NLTK: The Natural Language Toolkit",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R144852",
                    "label": "ready-to-use computational linguistics courseware"
                }
            ],
            "abstract": "nltk, the natural language toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware. nltk covers symbolic and statistical natural language processing, and is interfaced to annotated corpora. students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset."
        },
        {
            "id": "R144923",
            "label": "A Fast and Accurate Dependency Parser using Neural Networks",
            "doi": "10.3115/v1/d14-1082",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R122279",
                    "label": "Dependency Parsing"
                }
            ],
            "abstract": "almost all current dependency parsers classify based on millions of sparse indicator features. not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly. in this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser. because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both english and chinese datasets. concretely, our parser is able to parse more than 1000 sentences per second at 92.2% unlabeled attachment score on the english penn treebank."
        },
        {
            "id": "R144933",
            "label": "Generating Typed Dependency Parses from Phrase Structure Parses",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R122279",
                    "label": "Dependency Parsing"
                }
            ],
            "abstract": "this paper describes a system for extracting typed dependency parses of english sentences from phrase structure parses. in order to capture inherent relations occurring in corpus texts that can be critical in real-world applications, many np relations are included in the set of grammatical relations used. we provide a comparison of our system with minipar and the link parser. the typed dependency extraction facility described here is integrated in the stanford parser, available for download."
        },
        {
            "id": "R144951",
            "label": "Accurate unlexicalized parsing",
            "doi": "10.3115/1075096.1075150",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R144956",
                    "label": "Parsing"
                }
            ],
            "abstract": "we demonstrate that an unlexicalized pcfg can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. indeed, its performance of 86.36% (lp/lr f1) is better than that of early lexicalized pcfg models, and surprisingly close to the current state-of-the-art. this result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized pcfg is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize."
        },
        {
            "id": "R145794",
            "label": "Neural Architectures for Named Entity Recognition",
            "doi": "10.18653/v1/n16-1030",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R145797",
                    "label": "Neural Architectures for Named Entity Recognition"
                }
            ],
            "abstract": "comunicacio presentada a la 2016 conference of the north american chapter of the association for computational linguistics, celebrada a san diego (ca, eua) els dies 12 a 17 de juny 2016."
        },
        {
            "id": "R147894",
            "label": "Active Learning Yields Better Training Data for Scientific Named Entity Recognition",
            "doi": "10.1109/escience.2019.00021",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R147897",
                    "label": "Crowdsourcing"
                },
                {
                    "id": "R114168",
                    "label": "Active Learning"
                }
            ],
            "abstract": "despite significant progress in natural language processing, machine learning models require substantial expertannotated training data to perform well in tasks such as named entity recognition (ner) and entity relations extraction. furthermore, ner is often more complicated when working with scientific text. for example, in polymer science, chemical structure may be encoded using nonstandard naming conventions, the same concept can be expressed using many different terms (synonymy), and authors may refer to polymers with ad-hoc labels. these challenges, which are not unique to polymer science, make it difficult to generate training data, as specialized skills are needed to label text correctly. we have previously designed polyner, a semi-automated system for efficient identification of scientific entities in text. polyner applies word embedding models to generate entity-rich corpora for productive expert labeling, and then uses the resulting labeled data to bootstrap a context-based classifier. polyner facilitates a labeling process that is otherwise tedious and expensive. here, we use active learning to efficiently obtain more annotations from experts and improve performance. our approach requires just five hours of expert time to achieve discrimination capacity comparable to that of a state-of-the-art chemical ner toolkit."
        },
        {
            "id": "R151036",
            "label": "A hybrid AI approach for supporting clinical diagnosis of attention deficit hyperactivity disorder (ADHD) in adults",
            "doi": "10.1007/s13755-020-00123-7",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R70420",
                    "label": "Biomedical research in  Psychiatric Disorders"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract attention deficit hyperactivity disorder (adhd) is a neurodevelopmental disorder that includes symptoms such as inattentiveness, hyperactivity and impulsiveness. it is considered as an important public health issue and prevalence of, as well as demand for diagnosis, has increased as awareness of the disease grew over the past years. supply of specialist medical experts has not kept pace with the increasing demand for assessment, both due to financial pressures on health systems and the difficulty to train new experts, resulting in growing waiting lists. patients are not being treated quickly enough causing problems in other areas of health systems (e.g. increased gp visits, increased risk of self-harm and accidents) and more broadly (e.g. time off work, relationship problems). advances in ai make it possible to support the clinical diagnosis of adhd based on the analysis of relevant data. this paper reports on findings related to the mental health services of a specialist trust within the uk\u2019s national health service (nhs). the analysis studied data of adult patients who underwent diagnosis over the past few years, and developed a hybrid approach, consisting of two different models: a machine learning model obtained by training on data of past cases; and a knowledge model capturing the expertise of medical experts through knowledge engineering. the resulting algorithm has an accuracy of 95% on data currently available, and is currently being tested in a clinical environment."
        },
        {
            "id": "R151328",
            "label": "Neuro-Symbolic Architectures for Context Understanding",
            "doi": "10.3233/SSW200016",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R157109",
                    "label": "Commonsense Question answering"
                },
                {
                    "id": "R115365",
                    "label": "Autonomous Driving"
                }
            ],
            "abstract": "\"computational context understanding refers to an agent's ability to fuse disparate sources of information for decision-making and is, therefore, generally regarded as a prerequisite for sophisticated machine reasoning capabilities, such as in artificial intelligence (ai). data-driven and knowledge-driven methods are two classical techniques in the pursuit of such machine sense-making capability. however, while data-driven methods seek to model the statistical regularities of events by making observations in the real-world, they remain difficult to interpret and they lack mechanisms for naturally incorporating external knowledge. conversely, knowledge-driven methods, combine structured knowledge bases, perform symbolic reasoning based on axiomatic principles, and are more interpretable in their inferential processing; however, they often lack the ability to estimate the statistical salience of an inference. to combat these issues, we propose the use of hybrid ai methodology as a general framework for combining the strengths of both approaches. specifically, we inherit the concept of neuro-symbolism as a way of using knowledge-bases to guide the learning progress of deep neural networks. we further ground our discussion in two applications of neuro-symbolism and, in both cases, show that our systems maintain interpretability while achieving comparable performance, relative to the state-of-the-art.\""
        },
        {
            "id": "R157417",
            "label": "Autoformer: Searching transformers for visual recognition",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R157430",
                    "label": "Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification."
                }
            ],
            "abstract": "recently, pure transformer-based models have shown great potentials for vision tasks such as image classification and detection. however, the design of transformer networks is challenging. it has been observed that the depth, embedding dimension, and number of heads can largely affect the performance of vision transformers. previous models configure these dimensions based upon manual crafting. in this work, we propose a new one-shot architecture search framework, namely autoformer, dedicated to vision transformer search. autoformer entangles the weights of different blocks in the same layers during supernet training. benefiting from the strategy, the trained supernet allows thousands of subnets to be very well-trained. specifically, the performance of these subnets with weights inherited from the supernet is comparable to those retrained from scratch. besides, the searched models, which we refer to autoformers, surpass the recent state-of-the-arts such as vit and deit. in particular, autoformer-tiny/small/base achieve 74.7%/81.7%/82.4% top-1 accuracy on imagenet with 5.7m/22.9m/53.7m parameters, respectively. lastly, we verify the transferability of autoformer by providing the performance on downstream benchmarks and distillation experiments. code and models are available at https://github.com/microsoft/cream."
        },
        {
            "id": "R161808",
            "label": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R41156",
                    "label": "transfer learning"
                }
            ],
            "abstract": "transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (nlp). the effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. in this paper, we explore the landscape of transfer learning techniques for nlp by introducing a unified framework that converts every language problem into a text-to-text format. our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. by combining the insights from our exploration with scale and our new \"colossal clean crawled corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. to facilitate future work on transfer learning for nlp, we release our dataset, pre-trained models, and code."
        },
        {
            "id": "R162333",
            "label": "Sample-Efficient Automated Deep Reinforcement Learning",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R162336",
                    "label": "Automated Reinforcement Learning (AutoRL)"
                }
            ],
            "abstract": "despite significant progress in challenging problems across various domains, applying state-of-the-art deep reinforcement learning (rl) algorithms remains challenging due to their sensitivity to the choice of hyperparameters. this sensitivity can partly be attributed to the non-stationarity of the rl problem, potentially requiring different hyperparameter settings at various stages of the learning process. additionally, in the rl setting, hyperparameter optimization (hpo) requires a large number of environment interactions, hindering the transfer of the successes in rl to real-world applications. in this work, we tackle the issues of sample-efficient and dynamic hpo in rl. we propose a population-based automated rl (autorl) framework to meta-optimize arbitrary off-policy rl algorithms. in this framework, we optimize the hyperparameters and also the neural architecture while simultaneously training the agent. by sharing the collected experience across the population, we substantially increase the sample efficiency of the meta-optimization. we demonstrate the capabilities of our sample-efficient autorl approach in a case study with the popular td3 algorithm in the mujoco benchmark suite, where we reduce the number of environment interactions needed for meta-optimization by up to an order of magnitude compared to population-based training."
        },
        {
            "id": "R176039",
            "label": "Attention is All you Need",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. the best performing models also connect the encoder and decoder through an attention mechanism. we propose a new simple network architecture, the transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. our model achieves 28.4 bleu on the wmt 2014 english-to-german translation task, improving over the existing best results, including ensembles by over 2 bleu. on the wmt 2014 english-to-french translation task, our model establishes a new single-model state-of-the-art bleu score of 41.8 after training for 3.5 days on eight gpus, a small fraction of the training costs of the best models from the literature. we show that the transformer generalizes well to other tasks by applying it successfully to english constituency parsing both with large and limited training data."
        },
        {
            "id": "R176050",
            "label": "Probabilistic Logic Graph Attention Networks for Reasoning",
            "doi": "10.1145/3366424.3391265",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "knowledge base completion, which involves the prediction of missing relations between entities in a knowledge graph, has been an active area of research. markov logic networks, which combine probabilistic graphical models and first order logic, have proven to be effective on knowledge graph tasks like link prediction and question answering. however, their intractable inference limits their scalability and wider applicability across various tasks. in recent times, graph attention neural networks, which capture features of neighbouring entities, have achieved superior results on highly complex graph problems like node classification and link prediction. combining the best of both worlds, we propose probabilistic logic graph attention network (pgat) for reasoning. in the proposed model, the joint distribution of all possible triplets defined by a markov logic network is optimized with a variational em algorithm. this helps us to efficiently combine first-order logic and graph attention networks. with the goal of establishing strong baselines for future research on link prediction, we evaluate our model on various standard link prediction benchmarks, and obtain competitive results."
        },
        {
            "id": "R139328",
            "label": "High-Performance Sensors Based on Molybdenum Disulfide Thin Films",
            "doi": "10.1002/adma.201303230",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "high-performance sensors based on molybdenum disulfide (mos2 ) grown by sulfurization of sputtered molybdenum layers are presented. using a simple integration scheme, it is found that the electrical conductivity of mos2 films is highly sensitive to nh3 adsorption, consistent with n-type semiconducting behavior. a sensitivity of 300 ppb at room temperature is achieved, showing the high potential of 2d transition metal-dichalcogenides for sensing."
        },
        {
            "id": "R139336",
            "label": "Single-layer MoSe2 based NH3 gas sensor",
            "doi": "10.1063/1.4903358",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "high performance chemical sensor is highly desirable to detect traces of toxic gas molecules. two dimensional (2d) transition metal dichalcogenides (tmdc) semiconducting materials has attracted as high performance gas sensor device applications due to unique properties such as high surface to volume ratio. here, we describe the utilization of single-layer mose2 as high-performance room temperature nh3 gas sensors. our single-layer mose2 based gas sensor device shows comprehensible detection of nh3 gas down to 50 ppm. we also confirmed gas sensing measurement by recording the raman spectra before and after exposing the device to nh3 gas, which subsequently shows the shift due to charger transfer and analyte gas molecule adsorption on surface of single-layer mose2 nanosheet. our investigations show the potential use of single-layer and few layer thick mose2 and other tmdc as high-performance gas sensors."
        },
        {
            "id": "R139340",
            "label": "Cu2O nanorods modified by reduced graphene oxide for NH3 sensing at room temperature",
            "doi": "10.1039/c4ta06024e",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "in this work, cu 2 o nanorods modified by reduced graphene oxide (rgo) were produced via a two-step synthesis method."
        },
        {
            "id": "R139346",
            "label": "Layer-by-Layer Assembled Conductive Metal-Organic Framework Nanofilms for Room-Temperature Chemiresistive Sensing",
            "doi": "10.1002/anie.201709558",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "the utility of electronically conductive metal-organic frameworks (ec-mofs) in high-performance devices has been limited to date by a lack of high-quality thin film. the controllable thin-film fabrication of an ec-mof, cu3 (hhtp)2 , (hhtp=2,3,6,7,10,11-hexahydroxytriphenylene), by a spray layer-by-layer liquid-phase epitaxial method is reported. the cu3 (hhtp)2 thin film can not only be precisely prepared with thickness increment of about 2\\u2005nm per growing cycle, but also shows a smooth surface, good crystallinity, and high orientation. the chemiresistor gas sensor based on this high-quality thin film is one of the best room-temperature sensors for nh3 among all reported sensors based on various materials."
        },
        {
            "id": "R139374",
            "label": "CuO Nanosheets for Sensitive and Selective Determination of H2S with High Recovery Ability",
            "doi": "10.1021/jp106098z",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "in this article, cupric oxide (cuo) leafletlike nanosheets have been synthesized by a facile, low-cost, and surfactant-free method, and they have further been successfully developed for sensitive and selective determination of hydrogen sulfide (h2s) with high recovery ability. the experimental results have revealed that the sensitivity and recovery time of the present h2s gas sensor are strongly dependent on the working temperature. the best h2s sensing performance has been achieved with a low detection limit of 2 ppb and broad linear range from 30 ppb to 1.2 ppm. the gas sensor is reversible, with a quick response time of 4 s and a short recovery time of 9 s. in addition, negligible responses can be observed exposed to 100-fold concentrations of other gases which may exist in the atmosphere such as nitrogen (n2), oxygen (o2), nitric oxide (no), cabon monoxide (co), nitrogen dioxide (no2), hydrogen (h2), and so on, indicating relatively high selectivity of the present h2s sensor. the h2s sensor based on t..."
        },
        {
            "id": "R141429",
            "label": "VUV Spectral Irradiance Measurements in H_2/He/Ar Microwave Plasmas and Comparison with Solar Data",
            "doi": "10.3847/1538-4365/aaf0a1",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "microwave plasmas with h2 and h2/rare gas mixtures are convenient sources of vuv radiation for laboratory simulations of astrophysical media. we recently undertook an extensive study to characterize microwave plasmas in an h2/he gas mixture in order to optimize a vuv solar simulator over the 115\u2013170 nm spectral range. in this paper, we extend our investigation to the effect of the addition of ar into h2/he plasma on the vuv spectral irradiance. our study combines various optical diagnostics such as a vuv spectrometer and optical emission spectroscopy. quantitative measurements of the spectral irradiance and photons flux in different mixtures are accomplished using a combination of vuv spectrometry and chemical actinometry. results show that the ar addition into h2/he plasma largely affects the predominant emissions of the hydrogen ly\u03b1 line (121.6 nm) and h2 (b\u03c3u\u2013x \u03c3g) band (150\u2013170 nm). while a microwave plasma with 1.4% h2/he is required to mimic the entire vuv solar spectrum in the 115\u2013170 nm range, the combination with 1.28% h2/35% ar/he is the best alternative to obtain a quasi-monochromatic spectrum with emission dominated by the ly\u03b1 line. the maximum of the spectral irradiance is significantly higher in the ternary mixtures compared to the binary mixture of 1.4% h2/he. further ar increase yielded lower spectral irradiance and absolute photon fluxes. our measured spectral irradiances are compared to vuv solar data in the 115\u2013170 nm range, emphasizing the use of microwave plasmas in astrophysical studies and laboratory simulations of planetary atmospheres."
        },
        {
            "id": "R141432",
            "label": "In situmeasurement of VUV/UV radiation from low-pressure microwave-produced plasma in Ar/O_2 gas mixtures",
            "doi": "10.1088/1361-6501/aa7816",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "ultraviolet (uv) and vacuum ultraviolet (vuv) spectral irradiance is determined in low-pressure microwave-produced plasma, which is regularly used for polymer surface treatment. the re-emitted fluorescence in the uv/vis spectral range from a sodium salicylate layer is measured. this fluorescence is related to vuv/uv radiation in different spectral bands based on cut-off filters. the background produced by direct emitted radiation in the fluorescence spectral region is quantified using a specific background filter, thus enabling the use of the whole fluorescence spectral range. a novel procedure is applied to determine the absolute value of the vuv/uv irradiance on a substrate. for that, an independent measurement of the absolute spectral emissivity of the plasma in the uv is performed. the measured irradiances on a substrate from a 25 pa ar/o2-produced plasma are in the range of 1015\u20131016 (photon s\u22121cm\u22122). these values include the contribution from impurities present in the discharge."
        },
        {
            "id": "R141435",
            "label": "Multifold study of volume plasma chemistry in Ar/CF_4and Ar/CHF_3  CCP discharges",
            "doi": "10.1088/1361-6595/aa72c9",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "low-pressure rf plasma in fluorohydrocarbon gas mixtures is widely used in modern microelectronics, e.g. in the etching of materials with a low dielectric constant (low-k) materials). the multifold experimental and theoretical study of a radio frequency capacitively coupled plasma at 81 mhz in ar/cf4/chf3 has been carried out at 50 mtorr and 150 mtorr gas pressures. a wide set of experimental diagnostics together with hybrid pic mc model calculations were applied to a detailed study of the plasmas. measurements of the f atoms, hf molecules and cfx radicals, electron density, electronegativity and positive ion composition were performed. absolutely calibrated vuv spectrometry was carried out to measure the vuv photon fluence towards the electrode. this combined experimental and model approach allowed us to establish the fundamental mechanisms of the charged and neutral species elementary reactions. dissociative charge transfer reactions and fluoride transfer reactions influence the main ion (cf 3 + , chf 2 + ) composition in ar/cf4/chf3 plasma a lot. the mechanisms of heavy ion formation in ar/chf3 are also discussed. the important role of additional attachment mechanisms (besides dissociative attachment to the feedstock gases, cf4, chf3) was analyzed. the catalytic chain mechanism, including the hf molecules, which defines the cfx kinetics in ar/chf3 plasma, was validated. this multifold approach enabled us to determine the complicated plasma chemical composition of the active species as well as the fluxes of vuv photons at the surface of the processed material, and is a result that is important for understanding low-k damage."
        },
        {
            "id": "R141439",
            "label": "Comparison of vacuum ultra-violet emission of Ar/CF_4 and Ar/CF_3I capacitively coupled plasmas",
            "doi": "10.1088/0963-0252/25/5/055001",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "spectra in the vacuum-ultra violet range (vuv, 30 nm\u2013200\\u2009nm) as well as in the ultra-violet(uv) and visible ranges (uv+vis, 200 nm\u2013800\\u2009nm) were measured from ar/cf3i and ar/cf4 discharges. the discharges were generated in an industrial 300\\u2009mm capacitively coupled plasma source with 27 mhz radio-frequency power. it was seen that the measured spectra were strongly modified. this is mainly due to absorption, especially by cf3i, and ar self-trapping along the line of sight, towards the detector and in the plasma itself. the estimated unabsorbed vuv spectra were revealed from the spectra of mixtures with low fluorocarbon gas content by means of normalization with unabsorbed i* emission, at 206\\u2009nm, and cf2\u2217 band (1b1(0,v\u2032,0)\u21921a1(0,v\u2032\u2032,0)) emission between 230\\u2009nm and 430\\u2009nm. absolute fluences of uv cf2\u2217 emission were derived using hybrid 1-dimensional (1d) particle-in-cell (pic) monte-carlo (mc) model calculations. absolute calibration of the vuv emission was performed using these calculated values from the model, which has never been done previously for real etch conditions in an industrial chamber. it was seen that the argon resonant lines play a significant role in the vuv spectra. these lines are dominant in the case of etching recipes close to the standard ones. the restored unabsorbed spectra confirm that replacement of conventional cf4 etchant gas with cf3i in low-k etching recipes leads to an increase in the overall vuv emission intensity. however, emission from ar exhibited the most intense peaks. damage to low-k sicoh glasses by the estimated vuv was calculated for blanket samples with pristine k-value of 2.2. the calculations were then compared with fourier transform infrared (ftir) data for samples exposed to the similar experimental conditions in the same reactor. it was shown that ar emission plays the most significant role in vuv-induced damage."
        },
        {
            "id": "R141441",
            "label": "Optimization of a Solar Simulator for Planetary-Photochemical Studies",
            "doi": "10.1088/0067-0049/218/2/19",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "low-temperature microwave-powered plasma based on hydrogen and hydrogen with noble gas mixtures are widely used as a continuous vacuum ultraviolet (vuv) source in laboratory experiments carried out to mimic the photochemistry in astrophysical environments. in this work, we present a study dedicated to optimizing such sources in terms of mono-chromaticity at ly\u03b1 (h(ly\u03b1) line at 121.6 nm \u223c 10.2 ev) and high spectral irradiance. we report the influence on the emission spectrum of a wide range of experimental conditions including gas composition (pure h2, pure he, and h2/he mixture), gas pressure, flow rates, and microwave power. the absolute spectral irradiance delivered by this vuv light source has been measured. with a microwave input power of 100 w, the best conditions for producing a quasi-monochromatic source are a 1% h2/he gas mixture at a total pressure of 5 mbar and a flow rate of 2 sccm. by changing the microwave input power from 30 to 120 w, h(ly\u03b1) increases by more than one order of magnitude. a comparison between the current measurements and the solar vuv spectral irradiance is reported over 115\u2013170 nm."
        },
        {
            "id": "R141450",
            "label": "The effect of VUV radiation from Ar/O_2 plasmas on low-kSiOCH films",
            "doi": "10.1088/0022-3727/44/32/325203",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the degradation of porous low-k materials, like sioch, under plasma processing continues to be a problem in the next generation of integrated-circuit fabrication. due to the exposure of the film to many species during plasma treatment, such as photons, ions, radicals, etc, it is difficult to identify the mechanisms responsible for plasma-induced damage. using a vacuum beam apparatus with a calibrated xe vacuum ultraviolet (vuv) lamp, we show that 147\\u2009nm vuv photons and molecular o2 alone can damage these low-k materials. using fourier-transform infrared (ftir) spectroscopy, we show that vuv/o2 exposure causes a loss of methylated species, resulting in a hydrophilic, siox-like layer that is susceptible to h2o absorption, leading to an increased dielectric constant. the effect of vuv radiation on chemical modification of porous sioch films in the vacuum beam apparatus and in ar and o2 plasma exposure was found to be a significant contributor to dielectric damage. measurements of dielectric constant change using a mercury probe are consistent with chemical modification inferred from ftir analysis. furthermore, the extent of chemical modification appears to be limited by the penetration depth of the vuv photons, which is dependent on wavelength of radiation. the creation of a siox-like layer near the surface of the material, which grows deeper as more methyl is extracted, introduces a dynamic change of vuv absorption throughout the material over time. as a result, the rate of methyl loss is continuously changing during the exposure. we present a model that attempts to capture this dynamic behaviour and compare the model predictions to experimental data through a fitting parameter that represents the effective photo-induced methyl removal. while this model accurately simulates the methyl loss through vuv exposure by the xe lamp and ar plasma, the methyl loss from vuv photons in o2 plasma are only accurately depicted at longer exposure times. we conclude that other species, such as oxygen radicals or ions, may play a major role in chemical modification at short times near the surface of the material, while vuv photons contribute to the majority of the damage in the bulk."
        },
        {
            "id": "R144287",
            "label": "Stark-broadening measurements of 3d\u2192nftransitions in lithiumlike and heliumlike ions",
            "doi": "10.1103/PhysRevA.47.374",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R144273",
                    "label": "Line broadening in plasmas"
                },
                {
                    "id": "R145287",
                    "label": "Spectral lines broadening in plasmas"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we report here on high-resolution spectral measurements of stark-broadened 3[ital d]-5[ital f] lines from lithiumlike ions and 3[ital d]-4[ital f] lines from heliumlike ions. the spectra were emitted from high-density laser-produced plasmas. plasmas were produced by irradiating thin- and thick-foil targets made of magnesium, aluminum, phosphorus, and chlorine with the omega laser in a line-focus geometry. line profiles were compared to a stark-broadening calculation that uses the static-ion approximation and an impact approximation for the electrons. the dependence of stark broadening on atomic number is discussed. for the aluminum plasmas [similar to]10% narrowing was observed in the width of the 3[ital d]-5[ital f] line as the length of the plasma was increased from 3 to 6 mm."
        },
        {
            "id": "R144290",
            "label": "Stark broadening of spectral lines along the isoelectronic sequence of B",
            "doi": "10.1088/0953-4075/27/3/008",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R144273",
                    "label": "Line broadening in plasmas"
                }
            ],
            "abstract": "a systematic study of experimental stark widths of 3s-3p and 3p-3d transitions in n iii-ne vi measured in a plasma produced by the gas-liner pinch device is reported. the scaling of measured stark widths with the spectroscopic charge number z (z=3 for n iii, etc.) shows appreciable deviations from that predicted by some theoretical calculations in the electron-impact approximation. a strong indication is found that proton collisions influence the linewidth of the 2s2p3s4p0-2s2p3p4d transition in ne vi in a significant way."
        },
        {
            "id": "R144293",
            "label": "Plasma broadening and shifting of spectral lines along the isoelectronic sequence of boron",
            "doi": "10.1103/PhysRevE.54.743",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R144273",
                    "label": "Line broadening in plasmas"
                }
            ],
            "abstract": "temperature dependence of the stark widths ~n iii and f v! and shifts ~n iii and o iv! of the 3s 2 s-3p( 1 s) 2 p 0 and 3p 2 p 0 -3d( 1 s) 2 d transitions have been studied theoretically using the impact semiclassical method and experimentally observed in the plasma of a low pressure pulsed arc. plasma electron densities were determined from the width of the he ii pa line while electron temperatures were measured from the relative line intensities. to estimate the influence of different ions on the width and shift of lines, evaluations of the plasma composition data were performed and, in conjunction with our theoretical results, the contribution of ion broadening was estimated. within the estimated uncertainties experimental stark widths agree well with the results of our semiclassical electron impact widths in the studied electron temperature range. for the conditions of the present experiment, estimated contribution of the ion broadening has never exceeded five percent of the total width. so within the precision of this experiment it was not possible to detect its presence with certainty. along the boron isoelectronic sequence the experimental widths and shifts agree with semiclassical electron impact data predictions. in the case of o iv lines the inclusion of the energy levels with different parent terms in our semiclassical calculations of the stark widths and shifts improved the agreement between theory and experiment considerably. comparisons of the experimental widths with simple theoretical formulas for estimation of plasma broadened linewidths show an agreement within estimated uncertainties. @s1063-651x~96!00307-8# pacs number~s!: 52.70.kz, 32.70.jz"
        },
        {
            "id": "R144613",
            "label": "Stark-broadening measurements of 3d \u2192 nf transitions in lithiumlike and heliumlike ions,",
            "doi": "10.1103/PhysRevA.47.374",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R144273",
                    "label": "Line broadening in plasmas"
                }
            ],
            "abstract": "we report here on high-resolution spectral measurements of stark-broadened 3[ital d]-5[ital f] lines from lithiumlike ions and 3[ital d]-4[ital f] lines from heliumlike ions. the spectra were emitted from high-density laser-produced plasmas. plasmas were produced by irradiating thin- and thick-foil targets made of magnesium, aluminum, phosphorus, and chlorine with the omega laser in a line-focus geometry. line profiles were compared to a stark-broadening calculation that uses the static-ion approximation and an impact approximation for the electrons. the dependence of stark broadening on atomic number is discussed. for the aluminum plasmas [similar to]10% narrowing was observed in the width of the 3[ital d]-5[ital f] line as the length of the plasma was increased from 3 to 6 mm."
        },
        {
            "id": "R145572",
            "label": "Stark broadening of C iv and N v lines in the vacuum-uv spectral range",
            "doi": "10.1103/physreva.36.2265",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R145287",
                    "label": "Spectral lines broadening in plasmas"
                }
            ],
            "abstract": "spectral line shapes of 3p-4d, 3d-4f, 4d-5f, and 4f-5g transitions in the lithiumlike ions c iv and n v have been measured in a gas-liner pinch discharge at a density of 7.7\\\\ifmmode\\\\times\\\\else\\\\texttimes\\\\fi{}${10}^{23}$ ${\\\\mathrm{m}}^{\\\\mathrm{\\\\ensuremath{-}}3}$. the full widths at half maximum are larger than theoretical values obtained by the impact approximation by factors between 3 and 4 and smaller than theoretical full widths at half maximum calculated in the quasistatic, linear stark effect approximation by factors between 1.2 and 3."
        },
        {
            "id": "R74330",
            "label": "Impact of SARS-CoV-2 on the mobility behaviour in Germany",
            "doi": "10.1186/s12544-021-00469-3",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R135221",
                    "label": "Impact of Covid-19 on mobility behaviour"
                }
            ],
            "abstract": "abstract \\n background \\n the covid-19 pandemic and the measures taken to combat it led to severe constraints for various areas of life, including mobility. to study the effects of\\xa0this disruptive situation on the mobility behaviour of entire subgroups, and how they shape their mobility in reaction to the special circumstances, can help\\xa0to better understand, how people react to external changes. \\n \\n methodology \\n aim of the study presented in this article was to investigate to what extent, how and in what areas mobility behaviour has changed during the outbreak of\\xa0sars-cov-2 in germany. in addition, a focus was put on the comparison of federal states with and without lockdown in order to investigate a possible\\xa0contribution of this measure to changes in mobility. we asked respondents via an online survey about their trip purposes and trip frequency, their choice of\\xa0transport mode and the reasons for choosing it in the context of the covid-19 crisis. for the analyses presented in this paper, we used the data of 4157survey participants (2512 without lockdown, 1645 with lockdown). \\n \\n results \\n the data confirmed a profound impact on the mobility behaviour with a shift away from public transport and increases in car usage, walking and cycling.\\xa0comparisons of federal states with and without lockdown revealed only isolated differences. it seems that, even if the lockdown had some minor effects, its\\xa0role in the observed behavioural changes was minimal. \\n"
        },
        {
            "id": "R139875",
            "label": "Framework for Smart City Applications Based on Participatory Sensing",
            "doi": "",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139590",
                    "label": "Smart City framework"
                },
                {
                    "id": "R139887",
                    "label": "Participatory Sensing"
                }
            ],
            "abstract": "smart cities offer services to their inhabitants which make everyday life easier beyond providing a feedback channel to the city administration. for instance, a live timetable service for public transportation or real-time traffic jam notification can increase the efficiency of travel planning substantially. traditionally, the implementation of these smart city services require the deployment of some costly sensing and tracking infrastructure. as an alternative, the crowd of inhabitants can be involved in data collection via their mobile devices. this emerging paradigm is called mobile crowd-sensing or participatory sensing. in this paper, we present our generic framework built upon xmpp (extensible messaging and presence protocol) for mobile participatory sensing based smart city applications. after giving a short description of this framework we show three use-case smart city application scenarios, namely a live transit feed service, a soccer intelligence agency service and a smart campus application, which are currently under development on top of our framework."
        },
        {
            "id": "R139878",
            "label": "A Conceptual Enterprise Architecture Framework for Smart Cities - A Survey Based Approach: ",
            "doi": "10.5220/0005021400470054",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139590",
                    "label": "Smart City framework"
                },
                {
                    "id": "R139888",
                    "label": "Enterprise architecture"
                }
            ],
            "abstract": "\"enterprise architecture for smart cities is the focus of the research project \u201ceadic - (developing an enterprise architecture for digital cities)\u201d which is the context of the reported results in this work. we report in detail the results of a survey we contacted. using these results we identify important quality and functional requirements for smart cities. important quality properties include interoperability, usability, security, availability, recoverability and maintainability. we also observe business-related issues such as an apparent uncertainty on who is selling services, the lack of business plan in most cases and uncertainty in commercialization of services. at the software architecture domain we present a conceptual architectural framework based on architectural patterns which address the identified quality requirements. the conceptual framework can be used as a starting point for actual smart cities' projects.\""
        },
        {
            "id": "R139881",
            "label": "An Information Framework for Creating a Smart City Through Internet of Things",
            "doi": "10.1109/jiot.2013.2296516",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139590",
                    "label": "Smart City framework"
                },
                {
                    "id": "R139889",
                    "label": "Internet of Things"
                }
            ],
            "abstract": "increasing population density in urban centers demands adequate provision of services and infrastructure to meet the needs of city inhabitants, encompassing residents, workers, and visitors. the utilization of information and communications technologies to achieve this objective presents an opportunity for the development of smart cities, where city management and citizens are given access to a wealth of real-time information about the urban environment upon which to base decisions, actions, and future planning. this paper presents a framework for the realization of smart cities through the internet of things (iot). the framework encompasses the complete urban information system, from the sensory level and networking support structure through to data management and cloud-based integration of respective systems and services, and forms a transformational part of the existing cyber-physical system. this iot vision for a smart city is applied to a noise mapping case study to illustrate a new method for existing operations that can be adapted for the enhancement and delivery of important city services."
        },
        {
            "id": "R141931",
            "label": "A blueprint for strategic urban research: the urban piazza",
            "doi": "10.3828/tpr.2014.7",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "\"urban research in many countries has failed to keep up with the pace of rapidly and constantly evolving urban change. the growth of cities, the increasing complexity of their functions and the complex intra- and inter-urban linkages in this 'urban century' demand new approaches to urban analysis, which, from a systemic perspective, supersede the existing fragmentation in urban studies. in this paper we propose the concept of the urban piazza as a framework in order to address some of the inefficiencies associated with current urban analysis. by combining wealth-creating potential with smart urban mobility, ecological resilience and social buzz in this integrated and systemic framework, the aim is to set the basis for a 'new urban world' research blueprint, which lays the foundation for a broader and more integrated research programme for strategic urban issues.\""
        },
        {
            "id": "R141934",
            "label": "Smart Cities: Definitions, Dimensions, Performance, and Initiatives",
            "doi": "10.1080/10630732.2014.942092",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "abstract as the term \u201csmart city\u201d gains wider and wider currency, there is still confusion about what a smart city is, especially since several similar terms are often used interchangeably. this paper aims to clarify the meaning of the word \u201csmart\u201d in the context of cities through an approach based on an in-depth literature review of relevant studies as well as official documents of international institutions. it also identifies the main dimensions and elements characterizing a smart city. the different metrics of urban smartness are reviewed to show the need for a shared definition of what constitutes a smart city, what are its features, and how it performs in comparison to traditional cities. furthermore, performance measures and initiatives in a few smart cities are identified."
        },
        {
            "id": "R141937",
            "label": "Mapping Dimensions of Governance in Smart Cities: Practitioners versus Prior Research",
            "doi": "10.1145/2912160.2912176",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "many of the challenges to be faced by smart cities surpass the capacities, capabilities, and reaches of their traditional institutions and their classical processes of governing, and therefore new and innovative forms of governance are needed to meet these challenges. according to the network governance literature, governance models in public administrations can be categorized through the identification and analysis of some main dimensions that govern in the way of managing the city by governments. based on prior research and on the perception of city practitioners in european smart cities, this paper seeks to analyze the relevance of main dimensions of governance models in smart cities. results could shed some light regarding new future research on efficient patterns of governance models within smart cities."
        },
        {
            "id": "R141940",
            "label": "Smart city or smart citizens? The Barcelona case",
            "doi": "10.1108/jsma-03-2015-0030",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "purpose \u2013 in recent years, the term \u201csmart city\u201d has attracted a lot of attention from policy makers, business leaders and citizenship in general. although there is not a unique definition of what a smart city is, it is generally accepted that \u201csmart\u201d urban policies refer to local governments\u2019 initiatives that use information and communication technologies in order to increase the quality of life of their inhabitants while contributing to a sustainable development. so far, \u201csmart city\u201d approaches have generally been related to top-down processes of technology diffusion. the purpose of this paper is to present a broader view on \u201csmart\u201d initiatives to analyze both top-down and bottom-up dynamics in a smart city. the authors argue that these two perspectives are complementary and its combination can reinforce the collaboration between different city stakeholders. top-down and bottom-up initiatives are not opposed forces but, on the contrary, can have a synergistic effect on the innovation capacity of the city. both perspectives are illustrated by providing examples of different \u201csmart\u201d aspects in the city of barcelona: smart districts, open collaborative spaces, infrastructures and open data. design/methodology/approach \u2013 to illustrate the arguments, the authors analyze the case of the city of barcelona providing examples of top-down and bottom-up initiatives in four different smart city aspects: smart districts, open collaborative spaces, infrastructures and open data. the research method is based on a case study (yin, 1984). the primary data consisted on interviews to city council representatives as well as managers of local public institutions, like economic development offices, and local organizations like for instance coworking spaces. the authors interviewed also specialists on the innovation history of the city in order to validate the data. in addition, the authors used secondary data such as reports on the 22@, and documentation on the barcelona innovation policies, as well as doing a compilation of press articles and the online content of the institutional webpages. all together, the authors have followed a data triangulation strategy to seek data validation based on the cross-verification of the analyzed data sources. findings \u2013 the analysis suggests that the top-down and bottom-up perspectives are complementary and their combination can reinforce the collaboration between different city stakeholders. top-down and bottom-up initiatives are not opposed forces but, on the contrary, can have a synergistic effect on the innovation capacity of the city. both perspectives are illustrated by providing examples of different \u201csmart\u201d aspects in the city of barcelona: smart districts, open collaborative spaces, infrastructures and open data. research limitations/implications \u2013 nevertheless, the analysis has its limitations. even if the authors have emphasized the importance of the bottom-up initiatives, citizens do not have often the resources to act without governmental intervention. this is the case of services that require high-cost infrastructures or regulatory changes. also, as it usually happens in the case of disruptive technology, it is hard for citizens to understand the possibilities of its use. in these cases, firms and institutions must play an important role in the first phases of the diffusion of innovations, by informing and incentivizing its use. it is also important to note that some of the emerging usages of technology are confronted to legal or regulatory issues. for instance, distributed and shared wi-fi networks might be in opposition to economic interests of internet providers, that often difficult its expansion. it is also the case of services of the sharing economy that represent a menace to established institutions (like the tensions between uber and taxi companies, or airbnb and hotels). in these cases, city halls like it is the case in barcelona, tend to respond to these emergent uses of technology by regulating to ensure protection to existing corporate services. practical implications \u2013 in conclusion, the transformational process that leads a city to become a smart city has to take in consideration the complexity and the plurality of the urban reality. beyond considering citizens as being users, testers or consumers of technology, local administrations that are able to identify, nourish and integrate the emerging citizens\u2019 initiatives would contribute to the reinforcement of a smart city reality. originality/value \u2013 the contribution of the paper is to go beyond the generalized technologic discourse around smart cities by adding the layer of the citizens\u2019 initiatives."
        },
        {
            "id": "R141943",
            "label": "Smart city intellectual capital: an emerging view of territorial systems innovation management",
            "doi": "10.1108/jic-02-2015-0018",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "purpose \u2013 the purpose of this paper is to explore whether and how the intellectual capital (ic) approach and concepts could be fruitfully adapted to study the smart city phenomenon from a managerial point of view. design/methodology/approach \u2013 this study is based on a long-term, in-depth ethnographic exploration of the vast global community, which is created around the smart city movement. findings \u2013 the analysis suggests that, in order to effectively analyse a smart city context through the ic lens, the traditional ic framework needs to be extended for: expected outcomes, which should also include sustainability, resilience and quality of life; categories of key resources, which should also include institutional capital and environmental capital; units of analysis, which should also include territorial systems, such as transportation or waste; and key managerial challenges implied. as a final result, a smart city intellectual capital (sc-ic) framework is proposed. research limitations/implications \u2013 most of the cases analysed in this study are european; further studies are advisable to better investigate non-european smart city contexts. practical implications \u2013 the paper suggests that the knowledge management, project portfolio management and network management approaches are crucial to better support managerial practices in smart city organizations. originality/value \u2013 the sc-ic framework allows for a clear definition of the smart city organization, as a new knowledge-based, project-oriented, network-shaped type of organization. therefore, the sc-ic framework provides smart city research with a consistent rooting in management studies. further, this paper contributes to the fourth stage of ic research."
        },
        {
            "id": "R141946",
            "label": "What makes a city smart? Identifying core components and proposing an integrative and comprehensive conceptualization",
            "doi": "10.3233/IP-150354",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "this study represents two critical steps forward in the area of smart city research and practice. the first is in the form of the development of a comprehensive conceptualization of smart city as a resource for researchers and government practition- ers; the second is in the form of the creation of a bridge between smart cities research and practice expertise. city governments increasingly need innovative arrangements to solve a variety of technical, physical, and social problems. \"smart city\" could be used to represent efforts that in many ways describe a vision of a city, but there is little clarity about this new concept. this paper proposes a comprehensive conceptualization of smart city, including its main components and several specific elements. academic literature is used to create a robust framework, while a review of practical tools is used to identify specific elements or aspects not treated in the academic studies, but essential to create an integrative and comprehensive conceptualization of smart city. the paper also provides policy implications and suggests areas for future research in this topic."
        },
        {
            "id": "R141949",
            "label": "Making smart cities work in the face of conflicts: lessons from practitioners of South Korea\u2019s U-City projects",
            "doi": "10.3828/tpr.2015.33",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "a common concern in relation to smart cities is how to turn the concept into reality. the aim of this research is to investigate the implementation process of smart cities based upon the experience of south korea\u2019s u-city projects. the research shows that poorly-managed conflicts during implementation can diminish the potential of smart cities and discourage future improvements. the nature of smart cities is based on the concept of governance, while the planning practice is still in the notion of government. in order to facilitate the collaborative practice, the research has shown that collaborative institutional arrangements and joint fact-finding processes might secure an integrated service delivery for smart cities by overcoming operational difficulties in real-life contexts."
        },
        {
            "id": "R141955",
            "label": "The economic value of smart city technology",
            "doi": "",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "1. introductioneconomy is the main determinant of smart city proposals, and a city with a significant level of economic competitiveness (popescu, 2015a, b, c, d, e) has one of the features of a smart city. the economic consequences of the smart city proposals are business production, job generation, personnel development, and enhancement in the productivity. the enforcement of an ict infrastructure is essential to a smart city\\'s advancement and is contingent on several elements associated with its attainability and operation. (chourabi et al., 2012) smart city involvements are the end results of, and uncomfortably incorporated into, present social and spatial configurations of urban governa nce (br a tu, 2015) a nd the built setting: the s ma rt city is put together gradually, integrated awkwardly into current arrangements of city administration and the reinforced environment. smart cities are intrinsically distinguished, being geographically asymmetrical at a diversity of scales. not all places of the city will be similarly smart: smart cities will favor some spaces, individuals, and undertakings over others. an essential component of the smart city is its capacity to further economic growth. (shelton et al., 2015)2. the assemblage of participants, tenets and technologies related to smart city interventionsthe \"smart city\" notion has arisen from long-persisting opinions regarding urban technological idealistic schemes (lazaroiu, 2013) and the absolutely competitive city. smart cities are where novel technologies may be produced and the receptacles for technology, i.e. the goal of its utilizations. the contest to join this movement and become a smart city has stimulated city policymakers to endogenize the performance of technology-led growth (lazaroiu, 2014a, b, c), leading municipal budgets toward financings that present smart city standing. the boundaries of the smart city are generated both by the lack of data utilizations that can handle shared and not separate solutions and by the incapacity to aim at indefinit e features of cities that both enhance and blemish from the standard of urban existence for city inhabitants. smart city technology fina ncings are chiefly composed of a meliorations inst ea d of genuine innovations, on the cit izen consumer side. (glasmeier and christopherson, 2015) the notion of smart city as a method to improve the life standard of individuals has been achieving rising relevance in the calendars of policymakers. the amount of \"smart\" proposals initiated by a municipality can lead to an intermediate final product that indicates the endeavors made to augment the quality of existence of the citizens. the probabilities of a city raising its degree of smartness are contingent on several country-specific variables that outweigh its economic, technological and green advancement rate. public administrations dema nd backing to organize the notion of the smartness of a city (nica, 2015a, b, c, d), to encapsulate its ramifications, to establish standards at the global level, and to observe enhancement chances. (neir otti et a l., 2014) t he gr owth of smart cit ies is assisting the rise of government employment of itcs to enhance political involvement, enforce public schemes or supply public spher e ser vices. ther e is no one wa y to becoming smart, and diverse cities ha ve embraced distinct adva nces that indicate their specific circumstances. the administration of smart cities is dependent on elaborate arrangements of interdependent entities. (rodriguez bolivar, 2015)the association of smart (technology-enabled) solutions to satisfy the leading societal difficult tasks and the concentration on the city as the chief determinant of alteration bring about the notion of the \"smart city.\" the rise of novel technologies to assess and interlink various facets of ordinary exis- tence (\"the internet of things\") is relevant in the progression towards a smart city. the latter is attempt ing to encourage a nd adjust innovations to the demands of their citizens (pera, 2015a, b) by urging synergetic advancement of inventions with various stakeholders. \u2026"
        },
        {
            "id": "R141958",
            "label": "The \u2018actually existing smart city\u2019",
            "doi": "10.1093/cjres/rsu026",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "this paper grounds the critique of the \u2018smart city\u2019 in its historical and geographical context. adapting brenner and theodore\u2019s notion of \u2018actually existing neoliberalism\u2019, we suggest a greater attention be paid to the \u2018actually existing smart city\u2019, rather than the exceptional or paradigmatic smart cities of songdo, masdar and living planit valley. through a closer analysis of cases in louisville and philadelphia, we demonstrate the utility of understanding the material effects of these policies in actual cities around the world, with a particular focus on how and from where these policies have arisen, and how they have unevenly impacted the places that have adopted them."
        },
        {
            "id": "R141961",
            "label": "Smart Cities at the Crossroads: New Tensions in City Transformation",
            "doi": "10.1177/0008125616683949",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "the smart cities movement has produced a large number of projects and experiments around the world. to understand the primary ones, as well as their underlying tensions and the insights emerging from them, the editors of this special issue of the california management review enlisted a panel of experts, academics, and practitioners from different nationalities, backgrounds, experiences, and perspectives. the panel focused its discussion on three main areas: new governance models for smart cities, how to spur growth and renewal, and the sharing economy\u2014both commons and market based."
        },
        {
            "id": "R141967",
            "label": "Unveiling smart city implementation challenges: The case of Ghent",
            "doi": "10.3233/IP-150370",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "\"the 'smart city' label is internationally used by cities, researchers and technology providers with different meanings. as a popular concept it is widely used by city administrators and politicians to promote their efforts to prepare their cities for the future. there are decent definitions for what a smart city is, but it is much harder to find a trustworthy description of what it takes to become a smart city and how a city administration is impacted by that effort. this paper sets out to investigate how a city, aspiring to become a 'smart city', can manage its internal organization to realize that ambition. specifically, it describes the case of the city of ghent, belgium, and the key challenges it has been facing in its ongoing efforts to be a smart city. based on in depth interviews with city representatives six key challenges for smart city realization were identified and tested with a panel of representatives from five european cities that are in the process of becoming a smart city. the study contributes to a more professional pursuit of the smart city concept and elaborates the academic body of knowledge on smart city development, as an instance of it-enabled transformation in public services.\""
        },
        {
            "id": "R141970",
            "label": "ICT and sustainability in smart cities management",
            "doi": "10.1108/ijpsm-07-2015-0132",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "\\n purpose \\n \u2013 contemporary debate is increasingly focused on ict and sustainability, especially in relation to the modern configuration of urban and metropolitan areas in the so-called smartization process. the purpose of this paper is to observe the connections between smart city features as conceptualized in the framework proposed by giffinger et al. (2007) and new technologies as tools, and sustainability as the goal. \\n \\n \\n design/methodology/approach \\n \u2013 the connections are identified through a content analysis performed using nvivo on official reports issued by organizations, known as industry players within smart city projects, listed in the navigant research report 2013. \\n \\n \\n findings \\n \u2013 the results frame ict and sustainability as \u201cacross-the-board elements\u201d because they connect with all of the services provided to communities in a smart city and play a key role in smart city planning. specifically, sustainability and ict can be seen as tools to enable the smartization process. \\n \\n \\n research limitations/implications \\n \u2013 an all-in-one perspective emerges by embedding sustainability and ict in smart interventions; further research could be conduct through direct interviews to city managers and industry players in order to understand their attitude towards the development of smart city projects. \\n \\n \\n practical implications \\n \u2013 potential approaches emerging from this research are useful to city managers or large corporations partnering with local agencies in order to increase the opportunities for the long-term success of smart projects. \\n \\n \\n originality/value \\n \u2013 the results of this paper delineate a new research path looking at the development of new models that integrate drivers, ict, and sustainability in an all-in-one perspective and new indicators for the evaluation of the interventions. \\n"
        },
        {
            "id": "R141974",
            "label": "Smart Governance: Using a Literature Review and Empirical Analysis to Build a Research Model",
            "doi": "10.1177/0894439315611088",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "the attention for smart governance, a key aspect of smart cities, is growing, but our conceptual understanding of it is still limited. this article fills this gap in our understanding by exploring the concept of smart governance both theoretically and empirically and developing a research model of smart governance. on the basis of a systematic review of the literature defining elements, aspired outcomes and implementation strategies are identified as key dimensions of smart governance. inductively, we identify various categories within these variables. the key dimensions were presented to a sample of representatives of european local governments to investigate the dominant perceptions of practitioners and to refine the categories. our study results in a model for research into the implementation strategies, smart governance arrangements, and outcomes of smart governance."
        },
        {
            "id": "R141977",
            "label": "Smart citizens for smart cities: participating in the future",
            "doi": "10.1680/jener.15.00030",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "this paper discusses smart cities and raises critical questions about the faith being placed in technology to reduce carbon dioxide emissions. given increasingly challenging carbon reduction targets, the role of information and communication technology and the digital economy are increasingly championed as offering potential to contribute to meeting these targets within cities and buildings. this paper questions the faith being placed in smart or intelligent solutions through asking, what role then for the ordinary citizen? the smart approach often appears to have a narrow view of how technology and user-engagement can sit together, viewing the behaviour of users as a hurdle to overcome rather than a resource to be utilised. this paper suggests lessons can be learnt from other disciplines and wider sustainable development policy that champions the role of citizens and user-engagement to harness the co-creation of knowledge, collaboration and empowerment. specifically, empirical findings and observations are presented from a case study of citizen engagement around an energy-from-waste infrastructure development. recommendations are provided for engineers, planners and decision makers in order to help plan more effective engagement strategies for citizens, building users and stakeholders."
        },
        {
            "id": "R141980",
            "label": "Smart Cities Governance: The Need for a Holistic Approach to Assessing Urban Participatory Policy Making",
            "doi": "10.1177/0894439315611103",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "most of the definitions of a \u201csmart city\u201d make a direct or indirect reference to improving performance as one of the main objectives of initiatives to make cities \u201csmarter\u201d. several evaluation approaches and models have been put forward in literature and practice to measure smart cities. however, they are often normative or limited to certain aspects of cities\u2019 \u201csmartness\u201d, and a more comprehensive and holistic approach seems to be lacking. thus, building on a review of the literature and practice in the field, this paper aims to discuss the importance of adopting a holistic approach to the assessment of smart city governance and policy decision making. it also proposes a performance assessment framework that overcomes the limitations of existing approaches and contributes to filling the current gap in the knowledge base in this domain. one of the innovative elements of the proposed framework is its holistic approach to policy evaluation. it is designed to address a smart city\u2019s specificities and can benefit from the active participation of citizens in assessing the public value of policy decisions and their sustainability over time. we focus our attention on the performance measurement of codesign and coproduction by stakeholders and social innovation processes related to public value generation. more specifically, we are interested in the assessment of both the citizen centricity of smart city decision making and the processes by which public decisions are implemented, monitored, and evaluated as regards their capability to develop truly \u201cblended\u201d value services\u2014that is, simultaneously socially inclusive, environmentally friendly, and economically sustainable."
        },
        {
            "id": "R141983",
            "label": "Smart City Implementation Through Shared Vision of Social Innovation for Environmental Sustainability: A Case Study of Kitakyushu, Japan",
            "doi": "10.1177/0894439315611085",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "environmental sustainability is a critical global issue that requires comprehensive intervention policies. viewed as localized intervention policy implementations, smart cities leverage information infrastructures and distributed renewable energy smart micro-grids, smart meters, and home/building energy management systems to reduce city-wide carbon emissions. however, theory-driven smart city implementation research is critically lacking. this theory-building case study identifies antecedent conditions necessary for implementing smart cities. we integrated resource dependence, social embeddedness, and citizen-centric e-governance theories to develop a citizen-centric social governance framework. we apply the framework to a field-based case study of japan\u2019s kitakyushu smart community project to examine the validity and utility of the framework\u2019s antecedent conditions: resource-dependent leadership network, cross-sector collaboration based on social ties, and citizen-centric e-governance. we conclude that complex smart community implementation processes require shared vision of social innovation owned by diverse stakeholders with conflicting values and adaptive use of informal social governance mechanisms for effective smart city implementation."
        },
        {
            "id": "R141986",
            "label": "How smart is smart? Theoretical and empirical considerations on implementing smart city objectives \u2013 a case study of Dutch railway station areas",
            "doi": "10.1080/13511610.2016.1201758",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "the current widespread attention on the concept of smart city in both policy and practice has stimulated academic discussion regarding the scope and applicability of this concept. an important question is whether cities and regions are truly advanced in implementing the concept in their policies and practices relative to its conceptual elaborations in academia. the aim of this paper is to analyse this congruence between theory and practice in the context of the ongoing transformations of railway station areas in european urban regions. based on in-depth interviewing using aspects of q-methodology, this paper investigates whether and how smart city concepts are implemented by stakeholders in three station redevelopment projects in the netherlands. the results show that the current implementation of smart city concepts in practice is varied but modest and not (yet) very advanced. knowledge exchange and innovations are currently hampered by a lack of acceptance and know-how among stakeholders, as well as by institutional and competitive constraints. for instance, stakeholders stress that data privacy regulations should be well organized before further implementation can occur. transparency about how and what data are used may create more willingness among users to assist in developing and accepting new data technologies. however, the technologies are not yet completely developed, and concerns about the \u201closs\u201d of personal privacy are holding back the widespread and advanced use of data supplied technologies. although stakeholders seem to be aware of the opportunities the smart city concept offers, for now, the widespread implementation of innovative and advanced smart city concepts remains in the future."
        },
        {
            "id": "R141989",
            "label": "Governing Smart Cities: An Empirical Analysis",
            "doi": "10.1177/0894439315611093",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "smart cities (scs) are a recent but emerging phenomenon, aiming at using high technology and especially information and communications technology (ict) to implement better living conditions in large metropolises, to involve citizens in city government, and to support sustainable economic development and city attractiveness. the final goal is to improve the quality of city life for all stakeholders. until now, scs have been developing as bottom-up projects, bringing together smart initiatives driven by public bodies, enterprises, citizens, and not-for-profit organizations. however, to build a long-term smart strategy capable of producing better returns from investments and deciding priorities regarding each city, a comprehensive sc governance framework is needed. the aim of this paper is to collect empirical evidences regarding government structures implemented in scs and to outline a framework for the roles of local governments, nongovernmental agencies, and administrative officials. the survey shows that no consolidated standards or best practices for governing scs are implemented in the examined cities; however, each city applies its own governance framework. moreover, the study reveals some interesting experiences that may be useful for involving citizens and civil society in sc governance."
        },
        {
            "id": "R141995",
            "label": "Incorporating a Systemic and Foresight Approach into Smart City Initiatives: The Case of Spanish Cities",
            "doi": "10.1080/10630732.2016.1164441",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "abstract at the dawn of the twenty-first century, cities face serious societal, economic, environmental, and governance challenges. under the term \u201csmart city,\u201d numerous technology-based initiatives are emerging to help cities face contemporary challenges while the concept itself is evolving towards a more holistic approach. nevertheless, the capability of smart initiatives to provide an integrated vision of our cities is still very limited. eventually, many of these initiatives do not fulfill satisfactorily their initial objectives because they fail to understand the complexity, diversity, and uncertainty that characterize contemporary cities. the purpose of this paper is twofold: to display an urban functional system, capable of interpreting the city in a more holistic way, and to incorporate foresight tools so as to formulate smart city visions in a more participatory way with the involvement of local stakeholders."
        },
        {
            "id": "R141998",
            "label": "How are citizens involved in smart cities? Analysing citizen participation in Japanese ``Smart Communities''",
            "doi": "10.3233/IP-150367",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "\"in recent years, ``smart cities'' have rapidly increased in discourses as well as in their real number, and raise various issues. while citizen engagement is a key element of most definitions of smart cities, information and communication technologies (icts) would also have great potential for facilitating public participation. however, scholars have highlighted that little research has focused on actual practices of citizen involvement in smart cities so far. in this respect, the authors analyse public participation in japanese ``smart communities'', paying attention to both official discourses and actual practices. smart communities were selected in 2010 by the japanese government which defines them as ``smart city'' projects and imposed criteria such as focus on energy issues, participation and lifestyle innovation. drawing on analysis of official documents as well as on interviews with each of the four smart communities' stakeholders, the paper explains that very little input is expected from japanese citizens. instead, icts are used by municipalities and electric utilities to steer project participants and to change their behaviour. the objective of smart communities would not be to involve citizens in city governance, but rather to make them participate in the co-production of public services, mainly energy production and distribution.\""
        },
        {
            "id": "R142001",
            "label": "The ethics of smart cities and urban science",
            "doi": "10.1098/rsta.2016.0115",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "software-enabled technologies and urban big data have become essential to the functioning of cities. consequently, urban operational governance and city services are becoming highly responsive to a form of data-driven urbanism that is the key mode of production for smart cities. at the heart of data-driven urbanism is a computational understanding of city systems that reduces urban life to logic and calculative rules and procedures, which is underpinned by an instrumental rationality and realist epistemology. this rationality and epistemology are informed by and sustains urban science and urban informatics, which seek to make cities more knowable and controllable. this paper examines the forms, practices and ethics of smart cities and urban science, paying particular attention to: instrumental rationality and realist epistemology; privacy, datafication, dataveillance and geosurveillance; and data uses, such as social sorting and anticipatory governance. it argues that smart city initiatives and urban science need to be re-cast in three ways: a re-orientation in how cities are conceived; a reconfiguring of the underlying epistemology to openly recognize the contingent and relational nature of urban systems, processes and science; and the adoption of ethical principles designed to realize benefits of smart cities and urban science while reducing pernicious effects. this article is part of the themed issue \u2018the ethical impact of data science\u2019."
        },
        {
            "id": "R142005",
            "label": "Human limitations to introduction of smart cities: Comparative analysis from two CEE cities",
            "doi": "",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "abstract smart cities are a modern administrative/ developmental concept that tries to combine the development of urban areas with a higher level of citizens\u2019 participation. however, there is a lack of understanding of the concept\u2019s potential, due possibly to an unwillingness to accept a new form of relationship with the citizens. in this article, the willingness to introduce the elements of smart cities into two central and eastern european cities is tested. the results show that people are reluctant to use technology above the level of their needs and show little interest in participating in matters of governance, which prevents smart cities from developing in reality."
        },
        {
            "id": "R142008",
            "label": "Speculative futures: Cities, data, and governance beyond smart urbanism",
            "doi": "10.1177/0308518x16651445",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "in this paper, i examine the convergence of big data and urban governance beyond the discursive and material contexts of the smart city. i argue that in addition to understanding the intensifying relationship between data, cities, and governance in terms of regimes of automated management and coordination in \u2018actually existing\u2019 smart cities, we should further engage with urban algorithmic governance and governmentality as material-discursive projects of future-ing, i.e., of anticipating particular kinds of cities-to-come. as urban big data looks to the future, it does so through the lens of an anticipatory security calculus fixated on identifying and diverting risks of urban anarchy and personal harm against which life in cities must be securitized. i suggest that such modes of algorithmic speculation are discernible at two scales of urban big data praxis: the scale of the body, and that of the city itself. at the level of the urbanite body, i use the selective example of mobile neighborhood safety apps to demonstrate how algorithmic governmentality enacts digital mediations of individual mobilities by routing individuals around \u2018unsafe\u2019 parts of the city in the interests of technologically ameliorating the risks of urban encounter. at the scale of the city, amongst other empirical examples, sentiment analytics approaches prefigure ephemeral spatialities of civic strife by aggregating and mapping individual emotions distilled from unstructured real-time content flows (such as tweets). in both of these instances, the urban futures anticipated by the urban \u2018big data security assemblage\u2019 are highly uneven, as data and algorithms cannot divest themselves of urban inequalities and the persistence of their geographies."
        },
        {
            "id": "R142017",
            "label": "Governing the smart city: a review of the literature on smart urban governance",
            "doi": "10.1177/0020852314564308",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "academic attention to smart cities and their governance is growing rapidly, but the fragmentation in approaches makes for a confusing debate. this article brings some structure to the debate by analyzing a corpus of 51 publications and mapping their variation. the analysis shows that publications differ in their emphasis on (1) smart technology, smart people or smart collaboration as the defining features of smart cities, (2) a transformative or incremental perspective on changes in urban governance, (3) better outcomes or a more open process as the legitimacy claim for smart city governance. we argue for a comprehensive perspective: smart city governance is about crafting new forms of human collaboration through the use of icts to obtain better outcomes and more open governance processes. research into smart city governance could benefit from previous studies into success and failure factors for e-government and build upon sophisticated theories of socio-technical change. this article highlights that smart city governance is not a technological issue: we should study smart city governance as a complex process of institutional change and acknowledge the political nature of appealing visions of socio-technical governance. points for practitioners the study provides practitioners with an in-depth understanding of current debates about smart city governance. the article highlights that governing a smart city is about crafting new forms of human collaboration through the use of information and communication technologies. city managers should realize that technology by itself will not make a city smarter: building a smart city requires a political understanding of technology, a process approach to manage the emerging smart city and a focus on both economic gains and other public values."
        },
        {
            "id": "R142020",
            "label": "Smart City Research: Contextual Conditions, Governance Models, and Public Value Assessment",
            "doi": "10.1177/0894439315618890",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "there are three issues that are crucial to advancing our academic understanding of smart cities: (1) contextual conditions, (2) governance models, and (3) the assessment of public value. a brief review of recent literature and the analysis of the included papers provide support for the assumption that cities cannot simply copy good practices but must develop approaches that fit their own situation ( contingency) and concord with their own organization in terms of broader strategies, human resource policies, information policies, and so on ( configuration). a variety of insights into the mechanisms and building blocks of smart city practices are presented, and issues for further research are identified."
        },
        {
            "id": "R142026",
            "label": "Creating Smart Governance: The key to radical ICT overhaul at the City of Munich",
            "doi": "10.3233/IP-150369",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "\"around the end of the first decade in the 21 st century, quite a few city governments in municipalities of various sizes began conducting so-called smart-city initiatives. while many of these initiatives have successfully reached for low- hanging fruits and easy wins when responding to the growing demand of smart online services, others have identified the need for fundamental change and overhaul with regard to organizational integration and alignment as well as interorganizational information system interoperability as a pre-requisite for creating smart operations and providing smart services. sweepingly changing the governance over citywide information and communication technologies (icts) turned out to be at the core of creating an environment conducive to smart operations and smart services, and ultimately, smart city government. the city of munich in germany embarked on a fundamental overhaul of its ict structures. the article describes the case and the challenges, insights, and workarounds in this multiyear change program, which ultimately led to the successful overhaul of the ict governance model. in principle, munich's approach might be transferable to other cases. at the very least, the case holds valuable lessons learned when engaging in smart government initiatives in practice. when microsoft ended the support for windows nt 4.0 in late 2003, with its some 18,000 desktop workstations the city of munich made a dramatic decision in disfavor of migrating to the then next version of the proprietary windows platform (windows xp). despite a dramatic personal onsite en- gagement of microsoft's then ceo steve balmer who attempted to make the city cancel its decision with a blend of cajoling and coercing, munich's elected officials were unimpressed and stayed course in their decision to walk away from proprietary platforms and rather migrate to an open source-based (linux) platform for their servers and desktops. the city of munich's move made headlines around the world, since such an attempt to escape the proprietary path dependencyand vendor lock-in had been un- heard of before, since the inevitable switching cost were (and still are by many) considered prohibitive. while for the vast majority of the city's systems the migration ultimately took exactly a decade to com- plete at overall cost by and large as projected, the city government's elected officials, senior appointed officials along with the city's ict leadership had entered an uncharted territory, in which they felt capa- ble of building the city's future ict landscape. however, when the migration to linux began in 2006, it quickly became obviousthat an even deeperand more fundamentaloverhaulof organizationalstructures\""
        },
        {
            "id": "R142029",
            "label": "Smart governance as key to multi-jurisdictional smart city initiatives: The case of the eCityGov Alliance",
            "doi": "10.1177/0539018416629230",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "quite a number of smart-city initiatives from around the world have been analyzed and documented, and a growing body of academic knowledge is evolving around the phenomenon of the smart city. smart-city government is seen as an important driver for developing a smart urban environment. the ecitygov alliance in the pacific northwest of the usa represents a special case of a successful smart-city collaboration between nine neighboring municipalities, which combined forces to provide smart services to citizens and businesses that no single municipality could have provided alone. developing and maintaining a collaborative governance model appears as the most important key success factor in such multi-jurisdictional smart-city undertakings. this study investigates the governance model of the ecitygov alliance and its opportunities, and potential pitfalls. it concludes that the ecitygov alliance can serve as a role model for such multi-jurisdictional smart-city initiatives."
        },
        {
            "id": "R142032",
            "label": "The empty rhetoric of the smart city: from digital inclusion to economic promotion in Philadelphia",
            "doi": "10.1080/02723638.2015.1065686",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "smart city initiatives have been adopted by cities worldwide, proposing forward-looking, technological solutions to urban problems big and small. these policies are indicative of a digitized urban condition, where social and economic exchange rely on globalized telecommunications networks, and governance strategies follow suit. propelled through events such as ibm\u2019s smarter cities challenge, the smart city acts as a data-driven logic urban change where widespread benefit to a city and its residents is proposed, masking the utility of these policies to further entrepreneurial economic development strategies. in this article, i present a case study of the digital on-ramps initiative that emerged from ibm\u2019s policy-consultation in philadelphia. the initiative proposed a social media-style workforce education application (app) to train up to 500,000 low-literacy residents for jobs in the information and knowledge economy, but even as the city\u2019s mayor declared the project a success, it did not meet expectations. this essay argues that the rhetoric of intelligent, transformative digital change works much more to \u201csell\u201d a city in the global economy than to actually address urban inequalities."
        },
        {
            "id": "R142035",
            "label": "Co-Governing Smart Cities Through Living Labs. Top Evidences From EU",
            "doi": "10.24193/tras.2017.0002",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "our purpose is to identify the relevance of participative governance in urban areas characterized by smart cities projects, especially those implementing living labs initiatives as real-life settings to develop services innovation and enhance engagement of all urban stakeholders. a research on the three top smart cities in europe \u2013 i.e. amsterdam, barcelona and helsinki \u2013 is proposed through a content analysis with nvivo on the offi cial documents issued by the project partners (2012-2015) to investigate their living lab initiatives. the results show the increasing usefulness of living labs for the development of more inclusive smart cities projects in which public and private actors, and people, collaborate in innovation processes and governance for the co-creation of new services, underlining the importance of the open and ecosystem-oriented approach for smart cities."
        },
        {
            "id": "R142050",
            "label": "Competitive urbanism and the limits to smart city innovation: The UK Future Cities initiative",
            "doi": "10.1177/0042098015597162",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R139925",
                    "label": "Smart cities"
                }
            ],
            "abstract": "the technological vision of smart urbanism has been promoted as a silver bullet for urban problems and a major market opportunity. the search is on for firms and governments to find effective and transferable demonstrations of advanced urban technology. this paper examines initiatives by the uk national government to facilitate urban technological innovation through a range of strategies, particularly the tsb future cities demonstrator competition. this case study is used to explore opportunities and tensions in the practical realisation of the smart city imaginary. tensions are shown to be partly about the conjectural nature of the smart city debate. attention is also drawn to weakened capacity of urban governments to control their infrastructural destiny and also constraints on the ability of the public and private sectors to innovate. the paper contributes to smart city debates by providing further evidence of the difficulties in substantiating the smart city imaginary."
        },
        {
            "id": "R146416",
            "label": "Collaborating Filtering Community Image Recommendation System Based on Scene",
            "doi": "10.1051/itmconf/20171204010",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R138291",
                    "label": "Recommender systems for Smart city"
                }
            ],
            "abstract": "\"with the advancement of smart city, the development of intelligent mobile terminal and wireless network, the traditional text information service no longer meet the needs of the community residents, community image service appeared as a new media service. \u201cthere are pictures of the truth\u201d has become a community residents to understand and master the new dynamic community, image information service has become a new information service. however, there are two major problems in image information service. firstly, the underlying eigenvalues extracted by current image feature extraction techniques are difficult for users to understand, and there is a semantic gap between the image content itself and the user\u2019s understanding; secondly, in community life of the image data increasing quickly, it is difficult to find their own interested image data. aiming at the two problems, this paper proposes a unified image semantic scene model to express the image content. on this basis, a collaborative filtering recommendation model of fusion scene semantics is proposed. in the recommendation model, a comprehensiveness and accuracy user interest model is proposed to improve the recommendation quality. the results of the present study have achieved good results in the pilot cities of wenzhou and yan'an, and it is applied normally.\""
        },
        {
            "id": "R146434",
            "label": "Skunkworks finder: unlocking the diversity advantage of urban innovation ecosystems",
            "doi": "10.1145/3292147.3292169",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "R138291",
                    "label": "Recommender systems for Smart city"
                }
            ],
            "abstract": "entrepreneurs and start-up founders using innovation spaces and hubs often find themselves inside a filter bubble or echo chamber, where like-minded people tend to come up with similar ideas and recommend similar approaches to innovation. this trend towards homophily and a polarisation of like-mindedness is aggravated by algorithmic filtering and recommender systems embedded in mobile technology and social media platforms. yet, genuine innovation thrives on social inclusion fostering a diversity of ideas. to escape these echo chambers, we designed and tested the skunkworks finder - an exploratory tool that employs social network analysis to help users discover spaces of difference and otherness in their local urban innovation ecosystem."
        },
        {
            "id": "R166573",
            "label": "Intranets: A New Dimension for Library Services",
            "doi": "10.14429/dbit.24.1.3617",
            "research_field": {
                "id": "R136187",
                "label": "Social Sciences"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this article is based on some practical experiences of indian rubber manufacturing research association (irmra). it gives a brief introduction about the intranet, controversies of an intranet, and its library applications. it also gives information about accessing management information, improving internal communications, e-mail, intra mail, collaborative working, communities of interests, discussion groups, electronic forms, internal newsletters, search facilities, training materials, and library applications/access. the use of intranet in providing library services like sdi, cas and other information management is explained with a schematic diagram."
        },
        {
            "id": "R142138",
            "label": "Mapping Intracellular Temperature Using Green Fluorescent Protein",
            "doi": "10.1021/nl300389y",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R142135",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "heat is of fundamental importance in many cellular processes such as cell metabolism, cell division and gene expression. (1-3) accurate and noninvasive monitoring of temperature changes in individual cells could thus help clarify intricate cellular processes and develop new applications in biology and medicine. here we report the use of green fluorescent proteins (gfp) as thermal nanoprobes suited for intracellular temperature mapping. temperature probing is achieved by monitoring the fluorescence polarization anisotropy of gfp. the method is tested on gfp-transfected hela and u-87 mg cancer cell lines where we monitored the heat delivery by photothermal heating of gold nanorods surrounding the cells. a spatial resolution of 300 nm and a temperature accuracy of about 0.4 \u00b0c are achieved. benefiting from its full compatibility with widely used gfp-transfected cells, this approach provides a noninvasive tool for fundamental and applied research in areas ranging from molecular biology to therapeutic and diagnostic studies."
        },
        {
            "id": "R142147",
            "label": "2D surface thermal imaging using rise-time analysis from laser-induced luminescence phosphor thermometry",
            "doi": "10.1088/0957-0233/20/2/025305",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R142135",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "\"the purpose of this paper is to demonstrate a novel technique for imaging 2d temperature distributions using rise-time analysis from luminescence exhibited from a y2o3:eu thermographic phosphor. in phosphor thermometry, it is usually the lifetime-decay temporal response that is used to determine temperature; the rise component is usually ignored. we claim to be the first to obtain 2d thermal imaging using the rise-time response. this was demonstrated using flame impingement experiments. a 1 mfps state-of-the-art high-speed shiamadzu hypervision camera was used to capture the phosphors' temporal response, and was later processed in matlab. the resulting thermal map clearly indicated a variation in temperature and showed an uncertainty of 20% at 400 \u00b0c. this is relatively high, and suggestions to improve this are proposed. a calibration of rise time versus temperature is taken between 200 and 700 \u00b0c. this paper builds on previous work in the field, and the results presented in this paper confirm the extended temperature sensing capability of y2o3:eu using rise-time characteristics.\""
        },
        {
            "id": "R142153",
            "label": "CdSe Quantum Dots for Two-Photon Fluorescence Thermal Imaging",
            "doi": "10.1021/nl1036098",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R142135",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "the technological development of quantum dots has ushered in a new era in fluorescence bioimaging, which was propelled with the advent of novel multiphoton fluorescence microscopes. here, the potential use of cdse quantum dots has been evaluated as fluorescent nanothermometers for two-photon fluorescence microscopy. in addition to the enhancement in spatial resolution inherent to any multiphoton excitation processes, two-photon (near-infrared) excitation leads to a temperature sensitivity of the emission intensity much higher than that achieved under one-photon (visible) excitation. the peak emission wavelength is also temperature sensitive, providing an additional approach for thermal imaging, which is particularly interesting for systems where nanoparticles are not homogeneously dispersed. on the basis of these superior thermal sensitivity properties of the two-photon excited fluorescence, we have demonstrated the ability of cdse quantum dots to image a temperature gradient artificially created in a biocompatible fluid (phosphate-buffered saline) and also their ability to measure an intracellular temperature increase externally induced in a single living cell."
        },
        {
            "id": "R142171",
            "label": "Temperature dependence of luminescent spectra and dynamics in nanocrystalline Y2O3:Eu3+",
            "doi": "10.1063/1.1538181",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R142135",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "a temperature dependence for emission of eu3+ in cubic nanocrystalline y2o3:eu3+ was studied in contrast with the polycrystalline powders. the emission intensity of eu3+ decreased solely with elevated temperature under the excitation of a 580 nm light, while it had a maximum at a certain temperature under a 488 nm light. the experimental data were well fitted based on a theory considering both the thermal activated distribution of electrons among 7fj and the thermal quenching effect. the results indicated that the thermal quenching rate in nanocrystals (ncs) was faster than that in the polycrystals. the nonradiative decay rate, wnr, the radiative transition rate, w0r, and the luminescent quantum efficiency (qe) were obtained according to the temperature dependence of fluorescence lifetime. it can be concluded that wnr and w0r both increase in ncs, and that qe decreases."
        },
        {
            "id": "R142305",
            "label": "Mapping ER Schemas to OWL Ontologies",
            "doi": "10.1109/icsc.2009.61",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142303",
                    "label": "Ontology Learning from Entity Relation Model"
                }
            ],
            "abstract": "as the semantic web initiative gains momentum, a fundamental problem of integrating existing data-intensive www applications into the semantic web emerges. in order for today\u2019s relational database supported web applications to transparently participate in the semantic web, their associated database schemas need to be converted into semantically equivalent ontologies. in this paper we present a solution to an important special case of the automatic mapping problem with wide applicability: mapping well-formed entity-relationship (er) schemas to semantically equivalent owl lite ontologies. we present a set of mapping rules that fully capture the er schema semantics, along with an overview of an implementation of the complete mapping algorithm integrated into the current sfsu er design tools software."
        },
        {
            "id": "R142311",
            "label": "ERONTO: a tool for extracting ontologies from extended E/R diagrams",
            "doi": "10.1145/1066677.1066828",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142303",
                    "label": "Ontology Learning from Entity Relation Model"
                }
            ],
            "abstract": "realization of semantic web requires structuring of web data using domain ontologies. most data intensive websites are powered by relational databases whose design process involves developing conceptual model using e/r or extended e/r diagrams. this paper discusses the implementation details of a tool that builds domain ontologies in owl (ontology web language) from extended e/r diagrams. ontology development being a knowledge intensive task, our tool would be helpful in reducing the developmental efforts by automating the process. we bring out the differences and the similarities between the expressive capabilities of the two conceptual modeling methods, namely owl and extended e/r diagrams."
        },
        {
            "id": "R142319",
            "label": "An Innovative Statistical Tool for Automatic OWL-ERD Alignment",
            "doi": "10.1109/icsc.2016.22",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142303",
                    "label": "Ontology Learning from Entity Relation Model"
                }
            ],
            "abstract": "aligning two representations of the same domain with different expressiveness is a crucial topic in nowadays semantic web and big data research. owl ontologies and entity relation diagrams are the most widespread representations whose alignment allows for semantic data access via ontology interface, and ontology storing techniques. the term \"\"alignment\" encompasses three different processes: owl-to-erd and erd-to-owl transformation, and owl-erd mapping. in this paper an innovative statistical tool is presented to accomplish all the three aspects of the alignment. the main idea relies on the use of a hmm to estimate the most likely erd sentence that is stated in a suitable grammar, and corresponds to the observed owl axiom. the system and its theoretical background are presented, and some experiments are reported."
        },
        {
            "id": "R142349",
            "label": "Mapping between Relational Database Schema and OWL Ontology for Deep Annotation",
            "doi": "10.1109/wi.2006.114",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142303",
                    "label": "Ontology Learning from Entity Relation Model"
                }
            ],
            "abstract": "creating mappings between database schema and web ontology is a preconditioning process in the generation of ontological annotations for dynamic web page contents extracted from the database. in this paper, a practical approach to creating mappings between a relational database schema and an owl ontology is presented. the approach can automatically construct the mappings by following a set of predefined heuristic rules based on the conceptual correspondences between the schema and the ontology. this automatic mapping is implemented as the core functionality in a prototype tool d2omapper that has some assistant functions to help the user manually create and maintain the mappings. case studies show that the proposed approach is effective and the produced mappings can be applied to semantic annotation of database-based, dynamic web pages"
        },
        {
            "id": "R142352",
            "label": "Schema ",
            "doi": "10.1109/cbms.2006.7",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142303",
                    "label": "Ontology Learning from Entity Relation Model"
                }
            ],
            "abstract": "ontologies are one of the key technologies for data integration and meta-databases, by connecting databases on a semantical level. still, everything fails when one of the database schemas changes: specific parts of the ontology have to be reconstructed by hand. we propose an approach that allows the database schema and the ontology to change and evolve, without ever losing their connection to each other. we call that \"coevolution\". coevolution cannot be completely automated, as data definition languages do not define the change of semantical concepts, but only technical schema changes. in this paper we present our mapping of database schemas to ontologies, describe how these ontologies can be enriched by semantical information and show our approach to transfer schema changes to the ontology"
        },
        {
            "id": "R142380",
            "label": "A Method for Building Domain Ontologies based on the Transformation of UML Models",
            "doi": "10.1109/sera.2006.4",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142387",
                    "label": "Ontology learning from Unified Modeling Language"
                }
            ],
            "abstract": "ontologies are used in the integration of information resources by describing the semantics of the information sources with machine understandable terms and definitions. but, creating an ontology is a difficult and time-consuming process, especially in the early stage of extracting key concepts and relations. this paper proposes a method for domain ontology building by extracting ontological knowledge from uml models of existing systems. we compare the uml model elements with the owl ones and derive transformation rules between the corresponding model elements. based on these rules, we define an xslt document which implements the transformation processes. we expect that the proposed method reduce the cost and time for building domain ontologies with the reuse of existing uml models"
        },
        {
            "id": "R142422",
            "label": "UML and the Semantic Web",
            "doi": "",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142392",
                    "label": "Ontology learning from Unified Modeling Language"
                }
            ],
            "abstract": "\"this paper discusses technology to support the use of uml for representing ontologies and domain knowledge in the semantic web. two mappings have been defined and implemented using xslt to produce java classes and an rdf schema from an ontology represented as a uml class diagram and encoded using xmi. a java application can encode domain knowledge as an object diagram realised as a network of instances of the generated classes. support is provided for marshalling and unmarshalling this object-oriented knowledge to and from an rdf/xml serialisation. the paper also proposes an extension to rdf allowing the identification of property-- resource pairs in a model for which 'closed world' reasoning cannot be used due to incomplete knowledge.\""
        },
        {
            "id": "R142433",
            "label": "REUSING UML CLASS MODELS TO GENERATE OWL ONTOLOGIES - A Use Case in the Pharmacotherapeutic Domain: ",
            "doi": "10.5220/0002307802810286",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper presents a method for the reuse of existing knowledge in uml software models. our purpose is being able to adapt fragments of existing uml class diagrams in order to build domain ontologies, represented in owl-dl, reducing the required amount of time and resources to create one from scratch. our method is supported by a case tool, visualwade, and a developed plug-in, used for the management of ontologies and the generation of semantically tagged web applications. in order to analyse the designed transformations between knowledge representation formalisms, uml and owl, we have chosen a use case in the pharmacotherapeutic domain. then, we discuss some of the most relevant aspects of the proposal and, finally, conclusions are obtained and future work briefly described."
        },
        {
            "id": "R12208",
            "label": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "doi": "10.18653/v1/n19-1423",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R125059",
                    "label": "Word Embeddings"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we introduce a new language representation model called bert, which stands for bidirectional encoder representations from transformers. unlike recent language representation models (peters et al., 2018a; radford et al., 2018), bert is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. as a result, the pre-trained bert model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. bert is conceptually simple and empirically powerful. it obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the glue score to 80.5 (7.7 point absolute improvement), multinli accuracy to 86.7% (4.6% absolute improvement), squad v1.1 question answering test f1 to 93.2 (1.5 point absolute improvement) and squad v2.0 test f1 to 83.1 (5.1 point absolute improvement)."
        },
        {
            "id": "R141003",
            "label": "SemEval-2021 Task 5: Toxic Spans Detection",
            "doi": "10.18653/v1/2021.semeval-1.6",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R141006",
                    "label": "Toxic Spans Detection"
                }
            ],
            "abstract": "the toxic spans detection task of semeval-2021 required participants to predict the spans of toxic posts that were responsible for the toxic label of the posts. the task could be addressed as supervised sequence labeling, using training data with gold toxic spans provided by the organisers. it could also be treated as rationale extraction, using classifiers trained on potentially larger external datasets of posts manually annotated as toxic or not, without toxic span annotations. for the supervised sequence labeling approach and evaluation purposes, posts previously labeled as toxic were crowd-annotated for toxic spans. participants submitted their predicted spans for a held-out test set and were scored using character-based f1. this overview summarises the work of the 36 teams that provided system descriptions."
        },
        {
            "id": "R141010",
            "label": "UnImplicit Shared Task Report: Detecting Clarification Requirements in Instructional Text",
            "doi": "10.18653/v1/2021.unimplicit-1.4",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R141013",
                    "label": "Detecting Clarification Requirements"
                }
            ],
            "abstract": "this paper describes the data, task setup, and results of the shared task at the first workshop on understanding implicit and underspecified language (unimplicit). the task requires computational models to predict whether a sentence contains aspects of meaning that are contextually unspecified and thus require clarification. two teams participated and the best scoring system achieved an accuracy of 68%."
        },
        {
            "id": "R141066",
            "label": "CLPsych 2018 Shared Task: Predicting Current and Future\n            Psychological Health from Childhood Essays",
            "doi": "10.18653/v1/w18-0604",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R141069",
                    "label": "Predicting Current and Future Psychological Health"
                }
            ],
            "abstract": "we describe the shared task for the clpsych 2018 workshop, which focused on predicting current and future psychological health from an essay authored in childhood. language-based predictions of a person\u2019s current health have the potential to supplement traditional psychological assessment such as questionnaires, improving intake risk measurement and monitoring. predictions of future psychological health can aid with both early detection and the development of preventative care. research into the mental health trajectory of people, beginning from their childhood, has thus far been an area of little work within the nlp community. this shared task represents one of the first attempts to evaluate the use of early language to predict future health; this has the potential to support a wide variety of clinical health care tasks, from early assessment of lifetime risk for mental health problems, to optimal timing for targeted interventions aimed at both prevention and treatment."
        },
        {
            "id": "R141070",
            "label": "Named Entity Recognition on Code-Switched Data: Overview of the CALCS 2018 Shared Task",
            "doi": "10.18653/v1/w18-3219",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "in the third shared task of the computational approaches to linguistic code-switching (calcs) workshop, we focus on named entity recognition (ner) on code-switched social-media data. we divide the shared task into two competitions based on the english-spanish (eng-spa) and modern standard arabic-egyptian (msa-egy) language pairs. we use twitter data and 9 entity types to establish a new dataset for code-switched ner benchmarks. in addition to the cs phenomenon, the diversity of the entities and the social media challenges make the task considerably hard to process. as a result, the best scores of the competitions are 63.76% and 71.61% for eng-spa and msa-egy, respectively. we present the scores of 9 participants and discuss the most common challenges among submissions."
        },
        {
            "id": "R141092",
            "label": "DSTC7 Task 1: Noetic End-to-End Response Selection",
            "doi": "10.18653/v1/w19-4107",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R116510",
                    "label": "Goal-Oriented Dialogue Systems"
                }
            ],
            "abstract": "goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. this task provided two new resources that presented different challenges: one was focused but small, while the other was large but diverse. we also considered several new variations on the next utterance selection problem: (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. both datasets have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems."
        },
        {
            "id": "R142108",
            "label": "SemEval-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R140632",
                    "label": "Recognizing Textual Entailment"
                },
                {
                    "id": "R140633",
                    "label": " Joint Student Response Analysis"
                }
            ],
            "abstract": "we present the results of the joint student response analysis and 8th recognizing textual entailment challenge, aiming to bring together researchers in educational nlp technology and textual entailment. the task of giving feedback on student answers requires semantic inference and therefore is related to recognizing textual entailment. thus, we offered to the community a 5-way student response labeling task, as well as 3-way and 2way rte-style tasks on educational data. in addition, a partial entailment task was piloted. we present and compare results from 9 participating teams, and discuss future directions."
        },
        {
            "id": "R145803",
            "label": "End-to-end Neural Coreference Resolution",
            "doi": "10.18653/v1/d17-1018",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R145806",
                    "label": "End-to-end coreference resolution"
                }
            ],
            "abstract": "we introduce the first end-to-end coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or hand-engineered mention detector. the key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each. the model computes span embeddings that combine context-dependent boundary representations with a head-finding attention mechanism. it is trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions. experiments demonstrate state-of-the-art performance, with a gain of 1.5 f1 on the ontonotes benchmark and by 3.1 f1 using a 5-model ensemble, despite the fact that this is the first approach to be successfully trained with no external resources."
        },
        {
            "id": "R146670",
            "label": "ParsCit: an Open-source CRF Reference String Parsing Package",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R146673",
                    "label": "Reference string parsing"
                },
                {
                    "id": "R146674",
                    "label": "Open-source implementation"
                }
            ],
            "abstract": "we describe parscit, a freely available, open-source implementation of a reference string parsing package. at the core of parscit is a trained conditional random field (crf) model used to label the token sequences in the reference string. a heuristic model wraps this core with added functionality to identify reference strings from a plain text file, and to retrieve the citation contexts. the package comes with utilities to run it as a web service or as a standalone utility. we compare parscit on three distinct reference string datasets and show that it compares well with other previously published work."
        },
        {
            "id": "R146741",
            "label": "The Stanford CoreNLP Natural Language Processing Toolkit",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R146744",
                    "label": "natural language processing toolkit"
                },
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "we describe the design and use of the stanford corenlp toolkit, an extensible pipeline that provides core natural language analysis. this toolkit is quite widely used, both in the research nlp community and also among commercial and government users of open source nlp technology. we suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
        },
        {
            "id": "R146915",
            "label": "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. however, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. we introduce a new reading comprehension benchmark, drop, which requires discrete reasoning over the content of paragraphs. in this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). these operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. we apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this dataset and show that the best systems only achieve 38.4% f1 on our generalized accuracy metric, while expert human performance is 96%. we additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 51% f1."
        },
        {
            "id": "R147523",
            "label": "The ACL Anthology Reference Corpus: A Reference Dataset for Bibliographic Research in Computational Linguistics",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R147526",
                    "label": "Reference Dataset for Bibliographic Research"
                }
            ],
            "abstract": "this is a post-print of a paper from sixth international conference on language resources and evaluation 2008 http://www.lrec-conf.org/lrec2008/"
        },
        {
            "id": "R147989",
            "label": "Semantic Parsing Freebase: Towards Open-domain Semantic Parsing",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "existing semantic parsing research has steadily improved accuracy on a few domains and their corresponding databases. this paper introduces freeparser, a system that trains on one domain and one set of predicate and constant symbols, and then can parse sentences for any new domain, including sentences that refer to symbols never seen during training. freeparser uses a domain-independent architecture to automatically identify sentences relevant to each new database symbol, which it uses to supplement its manually-annotated training data from the training domain. in cross-domain experiments involving 23 domains, freeparser can parse sentences for which it has seen comparable unannotated sentences with an f1 of 0.71."
        },
        {
            "id": "R150009",
            "label": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R150027",
                    "label": "Compositional Semantics"
                },
                {
                    "id": "R150028",
                    "label": "Comprehensive Dataset"
                },
                {
                    "id": "R150029",
                    "label": "Recursive Neural Networks"
                },
                {
                    "id": "R122620",
                    "label": "Sentiment Analysis"
                }
            ],
            "abstract": "semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. to remedy this, we introduce a sentiment treebank. it includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. to address them, we introduce the recursive neural tensor network. when trained on the new treebank, this model outperforms all previous methods on several metrics. it pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. the accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases."
        },
        {
            "id": "R151315",
            "label": "CitationIE: Leveraging the Citation Graph for Scientific Information Extraction",
            "doi": "10.18653/v1/2021.acl-long.59",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R146875",
                    "label": "Automatic leaderboard construction"
                },
                {
                    "id": "R123009",
                    "label": "Scientific Concept Extraction"
                }
            ],
            "abstract": "automatically extracting key information from scientific documents has the potential to help scientists work more efficiently and accelerate the pace of scientific progress. prior work has considered extracting document-level entity clusters and relations end-to-end from raw scientific text, which can improve literature search and help identify methods and materials for a given problem. despite the importance of this task, most existing works on scientific information extraction (sciie) consider extraction solely based on the content of an individual paper, without considering the paper\u2019s place in the broader literature. in contrast to prior work, we augment our text representations by leveraging a complementary source of document context: the citation graph of referential links between citing and cited papers. on a test set of english-language scientific documents, we show that simple ways of utilizing the structure and content of the citation graph can each lead to significant gains in different scientific information extraction tasks. when these tasks are combined, we observe a sizable improvement in end-to-end information extraction over the state-of-the-art, suggesting the potential for future work along this direction. we release software tools to facilitate citation-aware sciie development."
        },
        {
            "id": "R154294",
            "label": "The Value of Semantic Parse Labeling for Knowledge Base Question Answering",
            "doi": "10.18653/v1/p16-2033",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R9143",
                    "label": "Question Answering "
                }
            ],
            "abstract": "we demonstrate the value of collecting semantic parse labels for knowledge base question answering. in particular, (1) unlike previous studies on small-scale datasets, we show that learning from labeled semantic parses significantly improves overall performance, resulting in absolute 5 point gain compared to learning from answers, (2) we show that with an appropriate user interface, one can obtain semantic parses with high accuracy and at a cost comparable or lower than obtaining just answers, and (3) we have created and shared the largest semantic-parse labeled dataset to date in order to advance research in question answering."
        },
        {
            "id": "R156121",
            "label": "The Web as a Knowledge-Base for Answering Complex Questions",
            "doi": "10.18653/v1/n18-1059",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R9143",
                    "label": "Question Answering "
                }
            ],
            "abstract": "answering complex questions is a time-consuming activity for humans that requires reasoning and integration of information. recent work on reading comprehension made headway in answering simple questions, but tackling complex questions is still an ongoing research challenge. conversely, semantic parsers have been successful at handling compositionality, but only when the information resides in a target knowledge-base. in this paper, we present a novel framework for answering broad and complex questions, assuming answering simple questions is possible using a search engine and a reading comprehension model. we propose to decompose complex questions into a sequence of simple questions, and compute the final answer from the sequence of answers. to illustrate the viability of our approach, we create a new dataset of complex questions, complexwebquestions, and present a model that decomposes questions and interacts with the web to compute an answer. we empirically demonstrate that question decomposition improves performance from 20.8 precision@1 to 27.5 precision@1 on this new dataset."
        },
        {
            "id": "R161707",
            "label": "Just Add Functions: A Neural-Symbolic Language Model",
            "doi": "10.1609/aaai.v34i05.6264",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R172402",
                    "label": " Prediction Geographic Location Word Classes."
                },
                {
                    "id": "R172401",
                    "label": "Prediction Number Word Classes"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\" neural network language models (nnlms) have achieved ever-improving accuracy due to more sophisticated architectures and increasing amounts of training data. however, the inductive bias of these models (formed by the distributional hypothesis of language), while ideally suited to modeling most running text, results in key limitations for today's models. in particular, the models often struggle to learn certain spatial, temporal, or quantitative relationships, which are commonplace in text and are second-nature for human readers. yet, in many cases, these relationships can be encoded with simple mathematical or logical expressions. how can we augment today's neural models with such encodings?in this paper, we propose a general methodology to enhance the inductive bias of nnlms by incorporating simple functions into a neural architecture to form a hierarchical neural-symbolic language model (nslm). these functions explicitly encode symbolic deterministic relationships to form probability distributions over words. we explore the effectiveness of this approach on numbers and geographic locations, and show that nslms significantly reduce perplexity in small-corpus language modeling, and that the performance improvement persists for rare tokens even on much larger corpora. the approach is simple and general, and we discuss how it can be applied to other word classes beyond numbers and geography. \""
        },
        {
            "id": "R161742",
            "label": "Relationship extraction for knowledge graph creation from biomedical literature",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R161745",
                    "label": "Relationship extraction"
                }
            ],
            "abstract": "biomedical research is growing at such an exponential pace that scientists, researchers, and practitioners are no more able to cope with the amount of published literature in the domain. the knowledge presented in the literature needs to be systematized in such a way that claims and hypotheses can be easily found, accessed, and validated. knowledge graphs can provide such a framework for semantic knowledge representation from literature. however, in order to build a knowledge graph, it is necessary to extract knowledge as relationships between biomedical entities and normalize both entities and relationship types. in this paper, we present and compare a few rule-based and machine learning-based (naive bayes, random forests as examples of traditional machine learning methods and distilbert and t5-based models as examples of modern deep learning transformers) methods for scalable relationship extraction from biomedical literature, and for the integration into the knowledge graphs. we examine how resilient are these various methods to unbalanced and fairly small datasets, showing that transformer-based models handle well both small datasets, due to pre-training on large c4 dataset, as well as unbalanced data. the best performing model was the distilbert-based model \ufb01ne-tuned on balanced data, with a reported f1-score of 0.89."
        },
        {
            "id": "R162342",
            "label": "Overview of BioCreAtIvE: critical assessment of information extraction for biology",
            "doi": "10.1186/1471-2105-6-s1-s1",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R162345",
                    "label": "Extraction of gene or protein names"
                },
                {
                    "id": "R162346",
                    "label": "Gene or protein name normalization"
                },
                {
                    "id": "R162348",
                    "label": "gene name finding and normalization"
                },
                {
                    "id": "R74030",
                    "label": "Information Extraction"
                }
            ],
            "abstract": "abstract \\n \\n background \\n the goal of the first biocreative challenge (critical assessment of information extraction in biology) was to provide a set of common evaluation tasks to assess the state of the art for text mining applied to biological problems. the results were presented in a workshop held in granada, spain march 28\u201331, 2004. the articles collected in this bmc bioinformatics supplement entitled \"a critical assessment of text mining methods in molecular biology\" describe the biocreative tasks, systems, results and their independent evaluation. \\n \\n \\n results \\n biocreative focused on two tasks. the first dealt with extraction of gene or protein names from text, and their mapping into standardized gene identifiers for three model organism databases (fly, mouse, yeast). the second task addressed issues of functional annotation, requiring systems to identify specific text passages that supported gene ontology annotations for specific proteins, given full text articles. \\n \\n \\n conclusion \\n the first biocreative assessment achieved a high level of international participation (27 groups from 10 countries). the assessment provided state-of-the-art performance results for a basic task (gene name finding and normalization), where the best systems achieved a balanced 80% precision / recall or better, which potentially makes them suitable for real applications in biology. the results for the advanced task (functional annotation from free text) were significantly lower, demonstrating the current limitations of text-mining approaches where knowledge extrapolation and interpretation are required. in addition, an important contribution of biocreative has been the creation and release of training and test data sets for both tasks. there are 22 articles in this special issue, including six that provide analyses of results or data quality for the data sets, including a novel inter-annotator consistency assessment for the test set used in task 2. \\n"
        },
        {
            "id": "R162920",
            "label": "GATE: an architecture for development of robust HLT applications",
            "doi": "10.3115/1073083.1073112",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R162965",
                    "label": "develop and deploy language engineering components"
                }
            ],
            "abstract": "in this paper we present gate, a framework and graphical development environment which enables users to develop and deploy language engineering components and resources in a robust fashion. the gate architecture has enabled us not only to develop a number of successful applications for various language processing tasks (such as information extraction), but also to build and annotate corpora and carry out evaluations on the applications generated. the framework can be used to develop applications and resources in multiple languages, based on its thorough unicode support."
        },
        {
            "id": "R162973",
            "label": "Shared Tasks of the 2015 Workshop on Noisy User-generated Text: Twitter Lexical Normalization and Named Entity Recognition",
            "doi": "10.18653/v1/w15-4319",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R162976",
                    "label": "Named Entity Recognition in Twitter"
                }
            ],
            "abstract": "this paper presents the results of the two shared tasks associated with w-nut 2015: (1) a text normalization task with 10 participants; and (2) a named entity tagging task with 8 participants. we outline the task, annotation process and dataset statistics, and provide a high-level overview of the participating systems for each shared task."
        },
        {
            "id": "R163028",
            "label": "Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition",
            "doi": "10.18653/v1/w17-4418",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R163031",
                    "label": "Novel and Emerging Entity Recognition in Twitter"
                }
            ],
            "abstract": "this shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions. named entities form the basis of many modern approaches to other tasks (like event clustering and summarization), but recall on them is a real problem in noisy text - even among annotators. this drop tends to be due to novel entities and surface forms. take for example the tweet \u201cso.. kktny in 30 mins?!\u201d \u2013 even human experts find the entity \u2018kktny\u2019 hard to detect and resolve. the goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these entities. the task as described in this paper evaluated the ability of participating entries to detect and classify novel and emerging named entities in noisy text."
        },
        {
            "id": "R163043",
            "label": "NLTK: the natural language toolkit",
            "doi": "10.3115/1225403.1225421",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "nltk, the natural language toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware. nltk covers symbolic and statistical natural language processing, and is interfaced to annotated corpora. students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset."
        },
        {
            "id": "R163221",
            "label": "Extraction of Information from the Text of Chemical Patents. 1. Identification of Specific Chemical Names",
            "doi": "10.1021/ci980324v",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R163240",
                    "label": "Chemical named entity recognition"
                }
            ],
            "abstract": "much attention has been paid to translating isolated chemical names into forms such as connection tables, but less effort has been expended in identifying substance names in running text to make them available for processing. the requirement for automatic name identification becomes a more urgent priority today, not the least in light of the inherent importance of patents and the increasing complexity of newly synthesized substances and, with these, the need for error-free processing of information from patent and other documents. the elaboration of a methodology for isolating substance names in the text of english-language patents is described here, using, in part, the sgml (standard generalized markup language) of the patent text as an aid to this process. evaluation of the procedures, which are still at an early stage of development, demonstrates that even simple methods can achieve very high degrees of success."
        },
        {
            "id": "R163747",
            "label": "CrossNER: Evaluating Cross-Domain Named Entity Recognition",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                },
                {
                    "id": "R123004",
                    "label": "Cross-Domain Named Entity Recognition"
                }
            ],
            "abstract": "cross-domain named entity recognition (ner) models are able to cope with the scarcity issue of ner samples in target domains. however, most of the existing ner benchmarks lack domain-specialized entity types or do not focus on a certain domain, leading to a less effective cross-domain evaluation. to address these obstacles, we introduce a cross-domain ner dataset (crossner), a fully-labeled collection of ner data spanning over five diverse domains with specialized entity categories for different domains. additionally, we also provide a domain-related corpus since using it to continue pre-training language models (domain-adaptive pre-training) is effective for the domain adaptation. we then conduct comprehensive experiments to explore the effectiveness of leveraging different levels of the domain corpus and pre-training strategies to do domain-adaptive pre-training for the cross-domain task. results show that focusing on the fractional corpus containing domain-specialized entities and utilizing a more challenging pre-training strategy in domain-adaptive pre-training are beneficial for the ner domain adaptation, and our proposed method can consistently outperform existing cross-domain ner baselines. nevertheless, experiments also illustrate the challenge of this cross-domain ner task. we hope that our dataset and baselines will catalyze research in the ner domain adaptation area. the code and data are available at this https url."
        },
        {
            "id": "R164240",
            "label": "Towards Exhaustive Protein Modification Event Extraction",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R164243",
                    "label": "Protein post-translational modification event extraction"
                }
            ],
            "abstract": "protein modifications, in particular post-translational modifications, have a central role in bringing about the full repertoire of protein functions, and the identification of specific protein modifications is important for understanding biological systems. this task presents a number of opportunities for the automatic support of manual curation efforts. however, the sheer number of different types of protein modifications is a daunting challenge for automatic extraction that has so far not been met in full, with most studies focusing on single modifications or a few prominent ones. in this work, aim to meet this challenge: we analyse protein modification types through ontologies, databases, and literature and introduce a corpus of 360 abstracts manually annotated in the bionlp shared task event representation for over 4500 mentions of proteins and 1000 statements of modification events of nearly 40 different types. we argue that together with existing resources, this corpus provides sufficient coverage of modification types to make effectively exhaustive extraction of protein modifications from text feasible."
        },
        {
            "id": "R164274",
            "label": "From Pathways to Biomolecular Events: Opportunities and Challenges",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R164277",
                    "label": "Pathway to Biomolecular event conversion"
                }
            ],
            "abstract": "the construction of pathways is a major focus of present-day biology. typical pathways involve large numbers of entities of various types whose associations are represented as reactions involving arbitrary numbers of reactants, outputs and modifiers. until recently, few information extraction approaches were capable of resolving the level of detail in text required to support the annotation of such pathway representations. we argue that event representations of the type popularized by the bionlp shared task are potentially applicable for pathway annotation support. as a step toward realizing this possibility, we study the mapping from a formal pathway representation to the event representation in order to identify remaining challenges in event extraction for pathway annotation support. following initial analysis, we present a detailed study of protein association and dissociation reactions, proposing a new event class and representation for the latter and, as a step toward its automatic extraction, introduce a manually annotated resource incorporating the type among a total of nearly 1300 annotated event instances. as a further practical contribution, we introduce the first pathway-to-event conversion software for sbml/celldesigner pathways and discuss the opportunities arising from the ability to convert the substantial existing pathway resources to events."
        },
        {
            "id": "R164289",
            "label": "Towards Event Extraction from Full Texts on Infectious Diseases",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R164292",
                    "label": "Event Extraction on Infectious Diseases"
                }
            ],
            "abstract": "event extraction approaches based on expressive structured representations of extracted information have been a significant focus of research in recent biomedical natural language processing studies. however, event extraction efforts have so far been limited to publication abstracts, with most studies further considering only the specific transcription factor-related subdo-main of molecular biology of the genia corpus. to establish the broader relevance of the event extraction approach and proposed methods, it is necessary to expand on these constraints. in this study, we propose an adaptation of the event extraction approach to a subdomain related to infectious diseases and present analysis and initial experiments on the feasibility of event extraction from domain full text publications."
        },
        {
            "id": "R164317",
            "label": "Named Entity Recognition for Bacterial Type IV Secretion Systems",
            "doi": "10.1371/journal.pone.0014780",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "research on specialized biological systems is often hampered by a lack of consistent terminology, especially across species. in bacterial type iv secretion systems genes within one set of orthologs may have over a dozen different names. classifying research publications based on biological processes, cellular components, molecular functions, and microorganism species should improve the precision and recall of literature searches allowing researchers to keep up with the exponentially growing literature, through resources such as the pathosystems resource integration center (patric, patricbrc.org). we developed named entity recognition (ner) tools for four entities related to type iv secretion systems: 1) bacteria names, 2) biological processes, 3) molecular functions, and 4) cellular components. these four entities are important to pathogenesis and virulence research but have received less attention than other entities, e.g., genes and proteins. based on an annotated corpus, large domain terminological resources, and machine learning techniques, we developed recognizers for these entities. high accuracy rates (>80%) are achieved for bacteria, biological processes, and molecular function. contrastive experiments highlighted the effectiveness of alternate recognition strategies; results of term extraction on contrasting document sets demonstrated the utility of these classes for identifying t4ss-related documents."
        },
        {
            "id": "R165975",
            "label": "Named Entity Recognition for Astronomy Literature",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "we present a system for named entity recognition (ner) in astronomy journal articles. we have developed this system on a ne corpus comprising approximately 200,000 words of text from astronomy articles. these have been manually annotated with \u223c40 entity types of interest to astronomers. we report on the challenges involved in extracting the corpus, defining entity classes and annotating scientific text. we investigate which features of an existing state-of-the-art maximum entropy approach perform well on astronomy text. our system achieves an f-score of 87.8%."
        },
        {
            "id": "R166335",
            "label": "Overview of BioCreAtIvE task 1B: normalized gene lists",
            "doi": "10.1186/1471-2105-6-s1-s11",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R162355",
                    "label": "gene name normalization"
                }
            ],
            "abstract": "abstract \\n \\n background \\n our goal in biocreative has been to assess the state of the art in text mining, with emphasis on applications that reflect real biological applications, e.g., the curation process for model organism databases. this paper summarizes the biocreative task 1b, the \"normalized gene list\" task, which was inspired by the gene list supplied for each curated paper in a model organism database. the task was to produce the correct list of unique gene identifiers for the genes and gene products mentioned in sets of abstracts from three model organisms (yeast, fly, and mouse). \\n \\n \\n results \\n eight groups fielded systems for three data sets (yeast, fly, and mouse). for yeast, the top scoring system (out of 15) achieved 0.92 f-measure (harmonic mean of precision and recall); for mouse and fly, the task was more difficult, due to larger numbers of genes, more ambiguity in the gene naming conventions (particularly for fly), and complex gene names (for mouse). for fly, the top f-measure was 0.82 out of 11 systems and for mouse, it was 0.79 out of 16 systems. \\n \\n \\n conclusion \\n this assessment demonstrates that multiple groups were able to perform a real biological task across a range of organisms. the performance was dependent on the organism, and specifically on the naming conventions associated with each organism. these results hold out promise that the technology can provide partial automation of the curation process in the near future. \\n"
        },
        {
            "id": "R172653",
            "label": "Character-aware neural language models",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R172656",
                    "label": "Neural language modeling"
                }
            ],
            "abstract": "\\n \\n we describe a simple neural language model that relies only on character-level inputs. predictions are still made at the word-level. our model employs a convolutional neural network (cnn) and a highway net work over characters, whose output is given to a long short-term memory (lstm) recurrent neural network language model (rnn-lm). on the english penn treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. on languages with rich morphology (arabic, czech, french, german, spanish, russian), the model outperforms word-level/morpheme-level lstm baselines, again with fewer parameters. the results suggest that on many languages, character inputs are sufficient for language modeling. analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\\n \\n"
        },
        {
            "id": "R213454",
            "label": "Named Entity Recognition for Hindi-English Code-Mixed Social Media Text",
            "doi": "10.18653/v1/w18-2405",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "named entity recognition (ner) is a major task in the field of natural language processing (nlp), and also is a sub-task of information extraction. the challenge of ner for tweets lie in the insufficient information available in a tweet. there has been a significant amount of work done related to entity extraction, but only for resource rich languages and domains such as newswire. entity extraction is, in general, a challenging task for such an informal text, and code-mixed text further complicates the process with it\u2019s unstructured and incomplete information. we propose experiments with different machine learning classification algorithms with word, character and lexical features. the algorithms we experimented with are decision tree, long short-term memory (lstm), and conditional random field (crf). in this paper, we present a corpus for ner in hindi-english code-mixed along with extensive experiments on our machine learning models which achieved the best f1-score of 0.95 with both crf and lstm."
        },
        {
            "id": "R76157",
            "label": "SemEval-2020 Task 3: Graded Word Similarity in Context",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R76161",
                    "label": "Graded Word Similarity in Context"
                },
                {
                    "id": "R76227",
                    "label": "Predicting change of human similarity ratings for pairs of words in two different contexts"
                },
                {
                    "id": "R76228",
                    "label": "Predicting change of human similarity ratings for words"
                },
                {
                    "id": "R76302",
                    "label": "Predict contextual human perception of similarity"
                }
            ],
            "abstract": "this paper presents the graded word similarity in context (gwsc) task which asked participants to predict the effects of context on human perception of similarity in english, croatian, slovene and finnish. we received 15 submissions and 11 system description papers. a new dataset (cosimlex) was created for evaluation in this task: it contains pairs of words, each annotated within two different contexts. systems beat the baselines by significant margins, but few did well in more than one language or subtask. almost every system employed a transformer model, but with many variations in the details: wordnet sense embeddings, translation of contexts, tf-idf weightings, and the automatic creation of datasets for fine-tuning were all used to good effect."
        },
        {
            "id": "R147977",
            "label": "The ACL Anthology Network",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R147976",
                    "label": "A Reference Dataset"
                }
            ],
            "abstract": "we introduce the acl anthology network (aan), a manually curated networked database of citations, collaborations, and summaries in the field of computational linguistics. we also present a number of statistics about the network including the most cited authors, the most central collaborators, as well as network statistics about the paper citation, author citation, and author collaboration networks."
        },
        {
            "id": "R150967",
            "label": "Annotation of Chemical Named Entities",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R147583",
                    "label": "Scientific concept annotation"
                },
                {
                    "id": "R150601",
                    "label": "Chemical named entity annotation"
                },
                {
                    "id": "R76427",
                    "label": "Language resource"
                }
            ],
            "abstract": "we describe the annotation of chemical named entities in scientific text. a set of annotation guidelines defines 5 types of named entities, and provides instructions for the resolution of special cases. a corpus of fulltext chemistry papers was annotated, with an inter-annotator agreement f score of 93%. an investigation of named entity recognition using lingpipe suggests that f scores of 63% are possible without customisation, and scores of 74% are possible with the addition of custom tokenisation and the use of dictionaries."
        },
        {
            "id": "R155259",
            "label": "Leveraging Abstract Meaning Representation for Knowledge Base Question Answering",
            "doi": "10.18653/v1/2021.findings-acl.339",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R129144",
                    "label": "Natural Language Understanding"
                },
                {
                    "id": "R129215",
                    "label": "Multi-hop Question Answering"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "knowledge base question answering (kbqa) is an important task in natural language processing. existing approaches face significant challenges including complex question understanding, necessity for reasoning, and lack of large end-to-end training datasets. in this work, we propose neuro-symbolic question answering (nsqa), a modular kbqa system, that leverages (1) abstract meaning representation (amr) parses for task-independent question understanding; (2) a simple yet effective graph transformation approach to convert amr parses into candidate logical queries that are aligned to the kb; (3) a pipeline-based approach which integrates multiple, reusable modules that are trained specifically for their individual tasks (semantic parser, entity and relationship linkers, and neuro-symbolic reasoner) and do not require end-to-end training data. nsqa achieves state-of-the-art performance on two prominent kbqa datasets based on dbpedia (qald-9 and lc-quad 1.0). furthermore, our analysis emphasizes that amr is a powerful tool for kbqa systems."
        },
        {
            "id": "R171931",
            "label": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: atomic (sap et al., 2019) and conceptnet (speer et al., 2017). contrary to many conventional kbs that store knowledge with canonical templates, commonsense kbs only store loosely structured open-text descriptions of knowledge. we posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose commonsense transformers (comet) that learn to generate rich and diverse commonsense descriptions in natural language. despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. empirical results demonstrate that comet is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (atomic) and 91.7% (conceptnet) precision at top 1, which approaches human performance for these resources. our findings suggest that using generative commonsense models for automatic commonsense kb completion could soon be a plausible alternative to extractive methods."
        },
        {
            "id": "R171970",
            "label": "Social IQa: Commonsense Reasoning about Social Interactions",
            "doi": "10.18653/v1/D19-1454",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we introduce social iqa, the first large-scale benchmark for commonsense reasoning about social situations. social iqa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., q: \u201cjordan wanted to tell tracy a secret, so jordan leaned towards tracy. why did jordan do this?\u201d a: \u201cmake sure no one else could hear\u201d). through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance (>20% gap). notably, we further establish social iqa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (winograd schemas, copa)."
        },
        {
            "id": "R110733",
            "label": "Extractive Summarization of Meeting Recordings",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "several approaches to automatic speech summarization are discussed below, using the icsi meetings corpus. we contrast feature-based approaches using prosodic and lexical features with maximal marginal relevance and latent semantic analysis approaches to summarization. while the latter two techniques are borrowed directly from the field of text summarization, feature-based approaches using prosodic information are able to utilize characteristics unique to speech data. we also investigate how the summarization results might deteriorate when carried out on asr output as opposed to manual transcripts. all of the summaries are of an extractive variety, and are compared using the software rouge."
        },
        {
            "id": "R187826",
            "label": "Discovering Implicit Entity Relation with the Gene-Citation-Gene Network",
            "doi": "10.1371/journal.pone.0084639",
            "research_field": {
                "id": "R136138",
                "label": "Medical Informatics and Medical Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper, we apply the entitymetrics model to our constructed gene-citation-gene (gcg) network. based on the premise there is a hidden, but plausible, relationship between an entity in one article and an entity in its citing article, we constructed a gcg network of gene pairs implicitly connected through citation. we compare the performance of this gcg network to a gene-gene (gg) network constructed over the same corpus but which uses gene pairs explicitly connected through traditional co-occurrence. using 331,411 medline abstracts collected from 18,323 seed articles and their references, we identify 25 gene pairs. a comparison of these pairs with interactions found in biogrid reveal that 96% of the gene pairs in the gcg network have known interactions. we measure network performance using degree, weighted degree, closeness, betweenness centrality and pagerank. combining all measures, we find the gcg network has more gene pairs, but a lower matching rate than the gg network. however, combining top ranked genes in both networks produces a matching rate of 35.53%. by visualizing both the gg and gcg networks, we find that cancer is the most dominant disease associated with the genes in both networks. overall, the study indicates that the gcg network can be useful for detecting gene interaction in an implicit manner."
        },
        {
            "id": "R143695",
            "label": "Electrically conductive thermoplastic elastomer nanocomposites at ultralow graphene loading levels for strain sensor applications",
            "doi": "10.1039/c5tc02751a",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R143691",
                    "label": "Improving the performance of flexible strain sensors based on carbon nanomaterials"
                }
            ],
            "abstract": "strain sensors with high sensitivity are reported in the thermoplastic polyurethane nanocomposites with ultralow graphene loading."
        },
        {
            "id": "R143705",
            "label": "A highly stretchable and sensitive strain sensor based on graphene\u2013elastomer composites with a novel double-interconnected network",
            "doi": "10.1039/c6tc01925k",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R143691",
                    "label": "Improving the performance of flexible strain sensors based on carbon nanomaterials"
                }
            ],
            "abstract": "a facile assembly approach was firstly reported to fabricate a highly stretchable and sensitive strain sensor based on graphene\u2013rubber composites with a novel double-interconnected network."
        },
        {
            "id": "R143712",
            "label": "Highly Stretchable Core\u2013Sheath Fibers via Wet-Spinning for Wearable Strain Sensors",
            "doi": "10.1021/acsami.7b18677",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R143691",
                    "label": "Improving the performance of flexible strain sensors based on carbon nanomaterials"
                }
            ],
            "abstract": "lightweight, stretchable, and wearable strain sensors have recently been widely studied for the development of health monitoring systems, human-machine interfaces, and wearable devices. herein, highly stretchable polymer elastomer-wrapped carbon nanocomposite piezoresistive core-sheath fibers are successfully prepared using a facile and scalable one-step coaxial wet-spinning assembly approach. the carbon nanotube-polymeric composite core of the stretchable fiber is surrounded by an insulating sheath, similar to conventional cables, and shows excellent electrical conductivity with a low percolation threshold (0.74 vol %). the core-sheath elastic fibers are used as wearable strain sensors, exhibiting ultra-high stretchability (above 300%), excellent stability (>10\\u2009000 cycles), fast response, low hysteresis, and good washability. furthermore, the piezoresistive core-sheath fiber possesses bending-insensitiveness and negligible torsion-sensitive properties, and the strain sensing performance of piezoresistive fibers maintains a high degree of stability under harsh conditions. on the basis of this high level of performance, the fiber-shaped strain sensor can accurately detect both subtle and large-scale human movements by embedding it in gloves and garments or by directly attaching it to the skin. the current results indicate that the proposed stretchable strain sensor has many potential applications in health monitoring, human-machine interfaces, soft robotics, and wearable electronics."
        },
        {
            "id": "R78237",
            "label": "Comparative Assessment of Iodine Content of Commercial Table Salt Brands Available in Nigerian Market",
            "doi": "",
            "research_field": {
                "id": "R93",
                "label": "Human and Clinical Nutrition"
            },
            "research_problems": [
                {
                    "id": "R78244",
                    "label": "Iodine deficiency disorders (IDD) has been a major global public health problem threatening more than 2 billion people worldwide."
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "iodine deficiency disorders (idd) has been a major global public health problem threatening more than 2 billion people worldwide. considering various human health implications associated with iodine deficiency, universal salt iodization programme has been recognized as one of the best methods of preventing iodine deficiency disorder and iodizing table salt is currently done in many countries. in this study, comparative assessment of iodine content of commercially available table salt brands in nigerian market were investigated and iodine content were measured in ten table salt brands samples using iodometric titration. the iodine content ranged from 14.80 mg/kg \u2013 16.90 mg/kg with mean value of 15.90 mg/kg for sea salt; 24.30 mg/kg \u2013 25.40 mg/kg with mean value of 24.60 mg/kg for dangote salt (blue sachet); 22.10 mg/kg \u2013 23.10 mg/kg with mean value of 22.40 mg/kg for dangote salt (red sachet); 23.30 mg/kg \u2013 24.30 mg/kg with mean value of 23.60 mg/kg for mr chef salt; 23.30 mg/kg \u2013 24.30 mg/kg with mean value of 23.60 mg/kg for annapurna; 26.80 mg/kg \u2013 27.50 mg/kg with mean value of 27.20mg/kg for uncle palm salt; 23.30 mg/kg \u2013 29.60 mg/kg with mean content of 26.40 mg/kg for dangote (bag); 25.40 mg/kg \u2013 26.50 mg/kg with mean value of 26.50 mg/kg for royal salt; 36.80 mg/kg \u2013 37.20 mg/kg with mean iodine content of 37.0 mg/kg for abakaliki refined salt, and 30.07 mg/kg \u2013 31.20 mg/kg with mean value of 31.00 mg/kg for ikom refined salt. the mean iodine content measured in the sea salt brand (15.70 mg/kg) was significantly p < 0.01 lower compared to those measured in other table salt brands. although the iodine content of abakaliki and ikom refined salt exceed the recommended value, it is clear that only sea salt brand falls below the world health organization (who) recommended value (20 \u2013 30 mg/kg), while the remaining table salt samples are just within the range. the results obtained have revealed that 70 % of the table salt brands were adequately iodized while 30 % of the table salt brands were not adequately iodized and provided baseline data that can be used for potential identification of human health risks associated with inadequate and/or excess iodine content in table salt brands consumed in households in nigeria."
        },
        {
            "id": "R108772",
            "label": "Dietary Reference Intakes for Water, Potassium, Sodium, Chloride, and Sulfate",
            "doi": "10.17226/10925",
            "research_field": {
                "id": "R93",
                "label": "Human and Clinical Nutrition"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "dietary reference intakes for water, potassium, sodium, chloride, and sulfate the dietary reference intakes (dris) are quantitative estimates of nutrient intakes to be used for planning and assessing diets for healthy people. this new report, the sixth in a series of reports presenting dietary reference values for the intakes of nutrients by americans and canadians, establishes nutrient recommendations on water, potassium, and salt for health maintenance and the reduction of chronic disease risk. dietary reference intakes for water, potassium, sodium, chloride, and sulfate discusses in detail the role of water, potassium, salt, chloride, and sulfate in human physiology and health. the major findings in this book include the establishment of adequate intakes for total water (drinking water, beverages, and food), potassium, sodium, and chloride and the establishment of tolerable upper intake levels for sodium and chloride. the book makes research recommendations for information needed to advance the understanding of human requirements for water and electrolytes, as well as adverse effects associated with the intake of excessive amounts of water, sodium, chloride, potassium, and sulfate. this book will be an invaluable reference for nutritionists, nutrition researchers, and food manufacturers."
        },
        {
            "id": "R182166",
            "label": "Nutrition education, farm production diversity, and commercialization on household and individual dietary diversity in Zimbabwe",
            "doi": "10.29219/fnr.v62.1276",
            "research_field": {
                "id": "R93",
                "label": "Human and Clinical Nutrition"
            },
            "research_problems": [
                {
                    "id": "R182132",
                    "label": "Correlation between crop diversity and dietary diversity"
                }
            ],
            "abstract": "background nutrition education is crucial for improved nutrition outcomes. however, there are no studies to the best of our knowledge that have jointly analysed the roles of nutrition education, farm production diversity and commercialization on household, women and child dietary diversity. objective this article jointly analyses the role of nutrition education, farm production diversity and commercialization on household, women and children dietary diversity in zimbabwe. in addition, we analyze separately the roles of crop and livestock diversity and individual agricultural practices on dietary diversity. design data were collected from 2,815 households randomly selected in eight districts. negative binomial regression was used for model estimations. results nutrition education increased household, women, and child dietary diversity by 3, 9 and 24%, respectively. farm production diversity had a strong and positive association with household and women dietary diversity. crop diversification led to a 4 and 5% increase in household and women dietary diversity, respectively. furthermore, livestock diversification and market participation were positively associated with household, women, and children dietary diversity. the cultivation of pulses and fruits increased household, women, and children dietary diversity. vegetable production and goat rearing increased household and women dietary diversity. conclusions nutrition education and improving access to markets are promising strategies to improve dietary diversity at both household and individual level. results demonstrate the value of promoting nutrition education; farm production diversity; small livestock; pulses, vegetables and fruits; crop-livestock integration; and market access for improved nutrition."
        },
        {
            "id": "R182384",
            "label": "Production diversity and dietary diversity in smallholder farm households",
            "doi": "10.1073/pnas.1510982112",
            "research_field": {
                "id": "R93",
                "label": "Human and Clinical Nutrition"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "significance \\n given that hunger and malnutrition are still widespread problems in many developing countries, the question of how to make agriculture and food systems more nutrition-sensitive is of high relevance for research and policy. many of the undernourished people in africa and asia are small-scale subsistence farmers. diversifying production on these farms is often perceived as a promising strategy to improve dietary quality and diversity. this hypothesis is tested with data from smallholder farm households in indonesia, kenya, ethiopia, and malawi. higher farm production diversity significantly contributes to dietary diversity in some situations, but not in all. improving small farmers\u2019 access to markets seems to be a more effective strategy to improve nutrition than promoting production diversity on subsistence farms."
        },
        {
            "id": "R142089",
            "label": "Iranian Registry of Crohn\u2019s and Colitis: study profile of first nation-wide inflammatory bowel disease registry in Middle East",
            "doi": "10.5217/ir.2018.00157",
            "research_field": {
                "id": "R33",
                "label": "Epidemiology"
            },
            "research_problems": [
                {
                    "id": "R142088",
                    "label": "Disease Registration System"
                }
            ],
            "abstract": "background/aims a recent study revealed increasing incidence and prevalence of inflammatory bowel disease (ibd) in iran. the iranian registry of crohn\u2019s and colitis (ircc) was designed recently to answer the needs. we reported the design, methods of data collection, and aims of ircc in this paper. methods ircc is a multicenter prospective registry, which is established with collaboration of more than 100 gastroenterologists from different provinces of iran. minimum data set for ircc was defined according to an international consensus on standard set of outcomes for ibd. a pilot feasibility study was performed on 553 ibd patients with a web-based questionnaire. the reliability of questionnaire evaluated by cronbach\u2019s \u03b1. results all sections of questionnaire had cronbach\u2019s \u03b1 of more than 0.6. in pilot study, 312 of participants (56.4%) were male and mean age was 38 years (standard deviation=12.8) and 378 patients (68.35%) had ulcerative colitis, 303 subjects (54,7%) had college education and 358 patients (64.74%) were of fars ethnicity. we found that 68 (12.3%), 44 (7.9%), and 13 (2.3%) of participants were smokers, hookah and opium users, respectively. history of appendectomy was reported in 58 of patients (10.48%). the most common medication was 5-aminosalicylate (94.39%). conclusions to the best of our knowledge, ircc is the first national ibd registry in the middle east and could become a reliable infrastructure for national and international research on ibd. ircc will improve the quality of care of ibd patients and provide national information for policy makers to better plan for controlling ibd in iran."
        },
        {
            "id": "R142094",
            "label": "A National Iranian Cochlear Implant Registry (ICIR): cochlear implanted recipient\n            observational study",
            "doi": "10.5935/0946-5448.20190013",
            "research_field": {
                "id": "R33",
                "label": "Epidemiology"
            },
            "research_problems": [
                {
                    "id": "R142088",
                    "label": "Disease Registration System"
                }
            ],
            "abstract": "\"background and objective\\npatients who receive cochlear implants (cis) constitutes a significant population in iran. this population needs regular monitor on long-term outcomes, educational placement and quality of life. currently, there is no national or regional registry on the long term outcomes of ci users in iran. the present study aims to introduce the design and implementation of a national patient-outcomes registry on ci recipients for iran. this iranian ci registry (icir) provides an integrated framework for data collection and sharing, scientific communication and collaboration inci research.\\n\\n\\nmethods\\nthe national icir is a prospective patient-outcomes registry for patients who are implanted in one of iranian centers. the registry is based on an integrated database that utilizes a secure web-based platform to collect response data from clinicians and patient's proxy via electronic case report forms (e-crfs) at predefined intervals. the ci candidates are evaluated with a set of standardized and non-standardized questionnaires prior to initial device activation(as baseline variables) and at three-monthly interval follow-up intervals up to 24 months and annually thereafter.\\n\\n\\nresults\\nthe software application of the icir registry is designed in a user-friendly graphical interface with different entry fields. the collected data are categorized into four subsets including personal information, clinical data, surgery data and commission results. the main parameters include audiometric performance of patient, device use, patient comorbidities, device use, quality of life and health-related utilities, across different types of ci devices from different manufacturers.\\n\\n\\nconclusion\\nthe icir database could be used by the increasingly growing network of ci centers in iran. clinicians, academic and industrial researchers as well as healthcare policy makers could use this database to develop more effective ci devices and better management of the recipients as well as to develop national guidelines.\""
        },
        {
            "id": "R38662",
            "label": "Physical chemistry of the groups IVA (Ti, Zr), VA (V, Nb, Ta) and rare earth elements in steel",
            "doi": "10.2355/isijinternational1966.15.145",
            "research_field": {
                "id": "R254",
                "label": "Materials Science and Engineering"
            },
            "research_problems": [
                {
                    "id": "R38654",
                    "label": "Solubility parameters"
                }
            ],
            "abstract": "\"vanadium, niobium and tantalum that belong to the grouj) va in the j)eriodic table have strong affinity .lor nitrogen and carbon in steel. besides, these elements differ from aluminium, and titanium and zirconium in the group iva in deoxidizing power, and are not oxidized remarkably in liquid steel . these, therefore, are vely interesting as allqying-elemen/s in steelmaking process. on the other hand, the rare earths are very' important elements as a good scavenger 0.1 oxygen and sulphur in liqu id steelfrom their chemical activities. in this paper, (1) chemical reactions between each 0.1 the iva elements, the va elements, the rare earths and aluminium and each 0.1 oxygen, nitrogen, carbon and sulphur, respectively, both in liquid and solid steels, and (2) roles and influences 0.1 these elements on steelmaking process and on the quality and property ~r steel, are discussed from a viewpoint 0.1 physical chemistly\u00b7\""
        },
        {
            "id": "R38668",
            "label": "Effect of Distribution of TiN Precipitate Particles on the Austenite Grain Size of Low Carbon Low Alloy Steels",
            "doi": "10.2355/isijinternational1966.18.198",
            "research_field": {
                "id": "R254",
                "label": "Materials Science and Engineering"
            },
            "research_problems": [
                {
                    "id": "R38654",
                    "label": "Solubility parameters"
                }
            ],
            "abstract": "i t is wcl l known that the toughness of steel is improved by the a ustenite grain r efinement. there a re many ways to obtain a fin e grain size . a typical example is to use fine aln or nb(cn) precipitate.1 ,2) gladman3 ) h as developed a genera l theory on the mechanism controlling the austenite grain size in which he correlated the critical stage of grain coarsening with the size a nd the vo lume frac tion of precipitates . there are many expel\"imenta l evidences concerning the austenite grain refin ement using carbides and nitrid es. george and ira ni ) determined grain coarsening temperature of th e ti bearing steels as about i 200\u00b0c, which is higher by loo\u00b0c tha n th at of the cases of other precipitate particles. sim il a r experimental resu lts on ti containing steels were obtained by bashford and george. 5 ) i t has been suggested from these works that the size and the volume fraction of tin a re the major factors which control the austenite grain coarsening at high tempel\"atu res , but no observation has been offered. the present work is to study the dissolution , coalescence a nd precipita tion of tin in the austenite temperature range with special reference to the austenite grain size. a simple model is proposed on the m echa nism of controlling the austenite g rain size by precipitate pa rti cles."
        },
        {
            "id": "R213410",
            "label": "Ultrastrong Fibers Assembled from Giant Graphene Oxide Sheets",
            "doi": "10.1002/adma.201203448",
            "research_field": {
                "id": "R254",
                "label": "Materials Science and Engineering"
            },
            "research_problems": [
                {
                    "id": "R189413",
                    "label": "Mechanical properties of nacre-inspired materials"
                }
            ],
            "abstract": "continuous, ultrastrong graphene fibers are achieved by wet-spinning of giant graphene oxide liquid crystals, followed by wet-drawing and ion-cross-linking. the giant size and regular alignment of graphene sheets render the fibers with high mechanical strength and good conductivity. such graphene fibers promise wide applications in functional textiles, flexible and wearable sensors, and supercapacitor devices."
        },
        {
            "id": "R211059",
            "label": "Scalable One-Step Wet-Spinning of Graphene Fibers and Yarns from Liquid Crystalline Dispersions of Graphene Oxide: Towards Multifunctional Textiles",
            "doi": "10.1002/adfm.201300765",
            "research_field": {
                "id": "R254",
                "label": "Materials Science and Engineering"
            },
            "research_problems": [
                {
                    "id": "R189413",
                    "label": "Mechanical properties of nacre-inspired materials"
                }
            ],
            "abstract": "key points in the formation of liquid crystalline (lc) dispersions of graphene oxide (go) and their processability via wet\u2010spinning to produce long lengths of micrometer\u2010dimensional fibers and yarns are addressed. based on rheological and polarized optical microscopy investigations, a rational relation between go sheet size and polydispersity, concentration, liquid crystallinity, and spinnability is proposed, leading to an understanding of lyotropic lc behavior and fiber spinnability. the knowledge gained from the straightforward formulation of lc go \u201cinks\u201d in a range of processable concentrations enables the spinning of continuous conducting, strong, and robust fibers at concentrations as low as 0.075 wt%, eliminating the need for relatively concentrated spinning dope dispersions. the dilute lc go dispersion is proven to be suitable for fiber spinning using a number of coagulation strategies, including non\u2010solvent precipitation, dispersion destabilization, ionic cross\u2010linking, and polyelectrolyte complexation. one\u2010step continuous spinning of graphene fibers and yarns is introduced for the first time by in situ spinning of lc go in basic coagulation baths (i.e., naoh or koh), eliminating the need for post\u2010treatment processes. the thermal conductivity of these graphene fibers is found to be much higher than polycrystalline graphite and other types of 3d carbon based materials."
        },
        {
            "id": "R186112",
            "label": "Detecting ADS-B Spoofing Attacks Using Deep Neural Networks",
            "doi": "10.1109/CNS.2019.8802732",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "R119122",
                    "label": "Group Anomaly Detection"
                }
            ],
            "abstract": "the automatic dependent surveillance-broadcast (ads-b) system is a key component of the next generation air transportation system (nextgen) that manages the increasingly congested airspace. it provides accurate aircraft localization and efficient air traffic management and also improves the safety of billions of current and future passengers. while the benefits of ads-b are well known, the lack of basic security measures like encryption and authentication introduces various exploitable security vulnerabilities. one practical threat is the ads-b spoofing attack that targets the ads-b ground station, in which the ground-based or aircraft-based attacker manipulates the international civil aviation organization (icao) address (a unique identifier for each aircraft)in the ads-b messages to fake the appearance of non-existent aircraft or masquerade as a trusted aircraft. as a result, this attack can confuse the pilots or the air traffic control personnel and cause dangerous maneuvers. in this paper, we introduce soda - a two-stage deep neural network (dnn)-based spoofing detector for ads-b that consists of a message classifier and an aircraft classifier. it allows a ground station to examine each incoming message based on the phy-layer features (e.g., iq samples and phases) and flag suspicious messages. our experimental results show that soda detects ground-based spoofing attacks with a probability of 99.34%, while having a very small false alarm rate (i.e., 0.43%). it outperforms other machine learning techniques such as xgboost, logistic regression, and support vector machine. it further identifies individual aircraft with an average f-score of 96.68 % and an accuracy of 96.66%, with a significant improvement over the state-of-the-art detector."
        },
        {
            "id": "R188861",
            "label": "in-vehicle network intrusion",
            "doi": "10.1109/pst.2017.00017",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "controller area network (can) is a bus communication protocol which defines a standard for reliable and efficient transmission between in-vehicle nodes in real-time. since can message is broadcast from a transmitter to the other nodes on a bus, it does not contain information about the source and destination address for validation. therefore, an attacker can easily inject any message to lead system malfunctions. in this paper, we propose an intrusion detection method based on the analysis of the offset ratio and time interval between request and response messages in can. if a remote frame having a particular identifier is transmitted, a receiver node should respond to the remote frame immediately. in attack-free state, each node has a fixed response offset ratio and time interval while these values vary in attack state. using this property, we can measure the response performance of the existing nodes based on the offset ratio and time interval between request and response messages. as a result, our methodology can detect intrusions by monitoring offset ratio and time interval, and it allows quick intrusion detection with high accuracy."
        },
        {
            "id": "R188891",
            "label": "Evaluation Framework for Network Intrusion Detection Systems for In-Vehicle CAN",
            "doi": "10.1109/ICCVE45908.2019.8965028",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "modern vehicles are complex safety critical cyber physical systems, that are connected to the outside world, with all security implications it brings. different network intrusion detection systems (nidss) proposed for the can bus, the predominant type of in-vehicle network, to improve security are hard to compare due to disparate evaluation methods adopted. in this paper we provide the means to compare can nidss on equal footing and evaluate the ones detailed in the literature. based on this we observe some limitation of existing approaches and why in the can setting it is intrinsically difficult to distinguish benign from malicious payload. we argue that \u201cmeaning-aware\u201d detection (a concept we define) which is challenging (but perhaps not impossible) to create for this setting."
        },
        {
            "id": "R194155",
            "label": "Car2X Communication: Securing the Last Meter - A Cost-Effective Approach for Ensuring Trust in Car2X Applications Using In-Vehicle Symmetric Cryptography",
            "doi": "10.1109/vetecf.2011.6093081",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the effectiveness of car2x communication strongly relies on trust in received data. securing in-vehicle communication is an essential yet so far overlooked step to achieve this objective. we present an approach based on the use of symmetric key material protected with inexpensive hardware. we modeled the involved cryptographic and network protocols, showed their applicability to automotive bus systems and conclude about their soundness with analytical and simulation methods. a prototype realization in real vehicles is envisaged as part of an ongoing project."
        },
        {
            "id": "R194161",
            "label": "Cyber-Security for the Controller Area Network (CAN) Communication Protocol",
            "doi": "10.1109/cybersecurity.2012.7",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we propose a security mechanism to help prevent cyber-attacks (masquerade and replay) in vehicles with architecture based on controller area network (can). we focus on can as it will likely continue being used in upcoming in-vehicle architectures. the can protocol contains no direct support for secure communications. retrofitting the protocol with security mechanisms poses several challenges given the very limited data rates available (e.g., 500kbps) since bus utilization may significantly increase. in this paper, we focus on a security mechanism which keeps the bus utilization as low as possible. through our experimental results, we show that our security mechanism can achieve high security levels while keeping communication overheads (e.g., bus load and message latency) at reasonable levels."
        },
        {
            "id": "R194166",
            "label": "VeCure: A practical security framework to protect the CAN bus of vehicles",
            "doi": "10.1109/IOT.2014.7030108",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"vehicles are being revolutionized by integrating modern computing and communication technologies in order to improve both user experience and driving safety. as a result, vehicular systems that used to be closed systems are opening up various interfaces, such as bluetooth, 3g/4g, gps, etc., to the outside world, thus introducing new opportunities for cyber attacks. it has been recently demonstrated that modern vehicles are vulnerable to several remote attacks launched through bluetooth and cellular interfaces, allowing the attacker to take full control of the vehicle. the common root cause of these attacks is the lack of message authentication for the vehicle's internal bus system, called controller area network (can). in this work, we propose vecure - a practical security framework for vehicular systems, which can fundamentally solve the message authentication issue of the can bus. vecure is designed to be compatible with existing vehicle system architectures, and employs a trust group structure and a novel message authentication scheme with offline computation capability to minimize online message processing delay and deployment cost. we built a proof-of-concept prototype on a testbed using freescale's automotive development boards. the experimental results show that vecure only introduces 50us additional delay to process a message, which is at least 20-fold faster than any existing solution.\""
        },
        {
            "id": "R194169",
            "label": "A Practical Wireless Attack on the Connected Car and Security Protocol for In-Vehicle CAN",
            "doi": "10.1109/TITS.2014.2351612",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "vehicle-it convergence technology is a rapidly rising paradigm of modern vehicles, in which an electronic control unit (ecu) is used to control the vehicle electrical systems, and the controller area network (can), an in-vehicle network, is commonly used to construct an efficient network of ecus. unfortunately, security issues have not been treated properly in can, although can control messages could be life-critical. with the appearance of the connected car environment, in-vehicle networks (e.g., can) are now connected to external networks (e.g., 3g/4g mobile networks), enabling an adversary to perform a long-range wireless attack using can vulnerabilities. in this paper we show that a long-range wireless attack is physically possible using a real vehicle and malicious smartphone application in a connected car environment. we also propose a security protocol for can as a countermeasure designed in accordance with current can specifications. we evaluate the feasibility of the proposed security protocol using canoe software and a dsp-f28335 microcontroller. our results show that the proposed security protocol is more efficient than existing security protocols with respect to authentication delay and communication load."
        },
        {
            "id": "R204210",
            "label": "Accelerating PUF-based UAV Authentication Protocols Using Programmable Switch",
            "doi": "10.1109/comsnets53615.2022.9668481",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "many uav technology use cases (e.g., traffic management) has ultra-low latency and strong security requirements. but achieving both simultaneously is challenging. in this work, we consider uav device authentication as a use case and develop a fast and secure uav device authentication system. our key idea is to leverage highly secure physically unclonable functions (pufs) and high-speed programmable packet-processing data planes, and develop a practically deployable puf-based authentication protocol for uavs that is (a) robust to various security attacks, and (b) enables uav authentication at network speed. in this work, we demonstrate the feasibility of our idea by offloading the authentication protocol to a tofino-based highspeed programmable switch. our preliminary experiments show that protocol offloading would reduce authentication latency significantly (approx. 100 %)."
        },
        {
            "id": "R206145",
            "label": "The Effect of Online Privacy Information on Purchasing Behavior: An Experimental Study",
            "doi": "10.1287/isre.1090.0260",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "R206151",
                    "label": "privacy behavior"
                }
            ],
            "abstract": "although online retailers detail their privacy practices in online privacy policies, this information often remains invisible to consumers, who seldom make the effort to read and understand those policies. this paper reports on research undertaken to determine whether a more prominent display of privacy information will cause consumers to incorporate privacy considerations into their online purchasing decisions. we designed an experiment in which a shopping search engine interface clearly and compactly displays privacy policy information. when such information is made available, consumers tend to purchase from online retailers who better protect their privacy. in fact, our study indicates that when privacy information is made more salient and accessible, some consumers are willing to pay a premium to purchase from privacy protective websites. this result suggests that businesses may be able to leverage privacy protection as a selling point."
        },
        {
            "id": "R214006",
            "label": "Continuous authentication of UAV flight command data using behaviometrics",
            "doi": "10.1109/vlsi-soc.2017.8203494",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the authentication of flight data in unmanned aerial vehicles (uavs) is highly critical because processing fake commands by the on-board flight controller can cause fatal consequences. depending on the criticality level of the uav mission, multi-layer authentication techniques can be useful to assure higher security levels. this paper proposes a technique for continuous authentication of flight data based on the behavior of the uav operator, who flies the vehicle in a manual mode. in contrast to one-time authentication, this technique allows for an on-the-fly identification of malicious commands aiming at manipulating, hijacking, or crashing the uav. the operator behavior is defined by the sequence of flight commands sent to the drone using a standard radio control transmitter. this is based on our assumption that every uav operator has a distinctive pattern when it comes to controlling a uav using transmitter's levers or joysticks. to verify this assumption, we captured 22,402 commands from five different operators, who flew a small multicopter uav using a standard flight transmitter. machine learning was applied to train a random forest classifier. the results show that the uav operators can be identified with accuracies between 76% and 88% in a 10-tree configuration. these promising results pave the way for a comprehensive study towards implementing a real-time classifier on the uav embedded system."
        },
        {
            "id": "R194153",
            "label": "CANAuth - A Simple, Backward Compatible Broadcast Authentication Protocol for CAN bus",
            "doi": "",
            "research_field": {
                "id": "R112117",
                "label": "Cryptography and Security"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the controller-area network (can) bus protocol [1] is a bus protocol invented in 1986 by robert bosch gmbh, originally intended for automotive use. by now, the bus can be found in devices ranging from cars and trucks, over lightning setups to industrial looms. due to its nature, it is a system very much focused on safety, i.e., reliability. unfortunately, there is no build-in way to enforce security, such as encryption or authentication. in this paper, we investigate the problems associated with implementing a backward compatible message authentication protocol on the can bus. we show which constraints such a protocol has to meet and why this eliminates, to the best of our knowledge, all the authentication protocols published so far. furthermore, we present a message authentication protocol, canauth, that meets all of the requirements set forth and does not violate any constraint of the can bus. keywords\u2014can bus, embedded networks, broadcast authentication, symmetric cryptography"
        },
        {
            "id": "R176009",
            "label": "Situational Awareness: Detecting Critical Dependencies and Devices in a Network",
            "doi": "10.1007/978-3-319-60774-0_17",
            "research_field": {
                "id": "R137678",
                "label": "Security and Dependability"
            },
            "research_problems": [
                {
                    "id": "R176016",
                    "label": "Detection of critical equipments"
                }
            ],
            "abstract": "abstract large-scale networks consisting of thousands of connected devices are like a living organism, constantly changing and evolving. it is very difficult for a human administrator to orient in such environment and to react to emerging security threats. with such motivation, this phd proposal aims to find new methods for automatic identification of devices, the services they provide, their dependencies and importance. the main focus of the proposal is to find novel approaches to building cyber situational awareness in an unknown network for the purpose of computer security incident response. our research is at the initial phase and will contribute to a phd thesis in four years."
        },
        {
            "id": "R178436",
            "label": "SAIDuCANT: Specification-Based Automotive Intrusion Detection Using Controller Area Network (CAN) Timing",
            "doi": "10.1109/tvt.2019.2961344",
            "research_field": {
                "id": "R137678",
                "label": "Security and Dependability"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the proliferation of embedded devices in modern vehicles has opened the traditionally-closed vehicular system to the risk of cybersecurity attacks through physical and remote access to the in-vehicle network such as the controller area network (can). the can bus does not implement a security protocol that can protect the vehicle against the increasing cyber and physical attacks. to address this risk, we introduce a novel algorithm to extract the real-time model parameters of the can bus and develop saiducant, a specification-based intrusion detection system (ids) using anomaly-based supervised learning with the real-time model as input. we evaluate the effectiveness of saiducant with real can logs collected from two passenger cars and on an open-source can dataset collected from real-world scenarios. experimental results show that saiducant can effectively detect data injection attacks with low false positive rates. over four real attack scenarios from the open-source dataset, saiducant observes at most one false positive before detecting an attack whereas other detection approaches using can timing features detect on average more than a hundred false positives before a real attack occurs."
        },
        {
            "id": "R25003",
            "label": "Predatory Open-Access Journals in India: A Study",
            "doi": "10.5958/0975-6922.2016.00012.7",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper analyses the list of predatory journals published by jeffrey beall. the study found that india is publishing the highest number of predatory journals. the state-wise analysis shows that the contribution of madhya pradesh is the highest in india. a trend reveals that majority of these journals are published after the year 2010."
        },
        {
            "id": "R5207",
            "label": "Warum brauchen wir eine (neue) Bibliothekswissenschaft?",
            "doi": "10.1515/bfp-2018-0046",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R5212",
                    "label": "Digital transformation requires an New Library and Information Science"
                }
            ],
            "abstract": "zusammenfassung \\n die medienschwelle, an der wir uns befinden, stellt viele institutionen infrage. nicht aber die bibliothek, wie viele \u00e4u\u00dferst erfolgreiche neue bibliotheksprojekte (\u00f6b und wb) belegen. der themenschwerpunkt l\u00e4sst (auch anl\u00e4sslich der next library conference in berlin im september 2018) unterschiedliche wissenschaftler zu wort kommen, die daf\u00fcr pl\u00e4dieren, sich auch wissenschaftlich mit dem ph\u00e4nomen bibliothek (wieder) zu befassen, um besser zu verstehen, wie ihre potentiale den digitalen wandel positiv begleiten k\u00f6nnen."
        },
        {
            "id": "R5223",
            "label": "Self-citation is the hallmark of productive authors, of any gender",
            "doi": "10.1371/journal.pone.0195773",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R1033",
                    "label": "Scholarly communications representation"
                },
                {
                    "id": "R5231",
                    "label": "gender bias"
                },
                {
                    "id": "R5232",
                    "label": "self-citation"
                }
            ],
            "abstract": "it was recently reported that men self-cite >50% more often than women across a wide variety of disciplines in the bibliographic database jstor. here, we replicate this finding in a sample of 1.6 million papers from author-ity, a version of pubmed with computationally disambiguated author names. more importantly, we show that the gender effect largely disappears when accounting for prior publication count in a multidimensional statistical model. gender has the weakest effect on the probability of self-citation among an extensive set of features tested, including byline position, affiliation, ethnicity, collaboration size, time lag, subject-matter novelty, reference/citation counts, publication type, language, and venue. we find that self-citation is the hallmark of productive authors, of any gender, who cite their novel journal publications early and in similar venues, and more often cross citation-barriers such as language and indexing. as a result, papers by authors with short, disrupted, or diverse careers miss out on the initial boost in visibility gained from self-citations. our data further suggest that this disproportionately affects women because of attrition and not because of disciplinary under-specialization."
        },
        {
            "id": "R191625",
            "label": "Deep Contextualized Word Embedding for Text-based Online User Profiling to Detect Social Bots on Twitter",
            "doi": "10.1109/icdmw51313.2020.00071",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                },
                {
                    "id": "R191525",
                    "label": "Fake Account Detection"
                }
            ],
            "abstract": "\"social media platforms can expose influential trends in many aspects of everyday life. however, the trends they represent can be contaminated by disinformation. social bots are one of the significant sources of disinformation in social media. social bots can pose serious cyber threats to society and public opinion. this research aims to develop machine learning models to detect bots based on the extracted user's profile from a tweet's text. online user profiles show the user's personal information, such as age, gender, education, and personality. in this work, the user's profile is constructed based on the user's online posts. this work's main contribution is three-fold: first, we aim to improve bot detection through machine learning models based on the user's personal information generated by the user's online comments. the similarity of personal information when comparing two online posts makes it difficult to differentiate a bot from a human user. however, in this research, we leverage personal information similarity among two online posts as an advantage for the new bot detection model. the new proposed model for bot detection creates user profiles based on personal information such as age, personality, gender, education from user's online posts, and introduces a machine learning model to detect social bots with high prediction accuracy based on personal information. second, we create a new public data set that shows the user's profile for more than 6900 twitter accounts in the cresci 2017 [1] data set. all user's profiles are extracted from the online user's posts on twitter. third, for the first time, this paper uses a deep contextualized word embedding model, elmo [2], for a social media bot detection task.\""
        },
        {
            "id": "R191648",
            "label": "Fake Accounts Detection on Twitter Using Blacklist",
            "doi": "10.1109/icis.2018.8466499",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                },
                {
                    "id": "R191525",
                    "label": "Fake Account Detection"
                }
            ],
            "abstract": "social networking sites such as twitter, facebook, weibo etc. are extremely mainstream today. also, the greater part of the malicious users utilize these sites to persuade legitimate users for different purposes, for example, to promote their products item, to enter their spam links, to stigmatize other persons and so forth. an ever increasing number of users are utilized these social networking sites and fake accounts on these destinations are turned into a major issue. in this paper, fake accounts are detected using blacklist instead of traditional spam words list. blacklist is created by using topic modeling approach and keyword extraction approach. we conduct an evaluation experiment with not only 1ks - 10kn dataset but also social honeypot dataset. the accuracy of the traditional spam words list based approach and our blacklist based approach are compared. decorate, a meta-learner classifier is applied for classifying fake accounts on twitter from legitimate accounts. our approach achieves 95.4% accuracy and true positive rate is 0.95."
        },
        {
            "id": "R191651",
            "label": "A Feature Based Approach to Detect Fake Profiles in Twitter",
            "doi": "10.1145/3361758.3361784",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                },
                {
                    "id": "R191525",
                    "label": "Fake Account Detection"
                }
            ],
            "abstract": "social networking platforms, particularly sites like twitter and facebook have grown tremendously in the past decade and has solicited the interest of millions of users. they have become a preferred means of communication, due to which it has also attracted the interest of various malicious entities such as spammers. the growing number of users on social media has also created the problem of fake accounts. these false and fake identities are intensively involved in malicious activities such as spreading abuse, misinformation, spamming and artificially inflating the number of users in an application to promote and sway public opinion. detecting these fake identities, thus becomes important to protect genuine users from malicious intents. to address this issue, we aim to use a feature-based approach to identify these fake profiles on social media platforms. we have used twenty-four features to identify fake accounts efficiently. to verify the classification results three classification algorithms are used. experimental results show that our model was able to reach 97.9% accuracy using the random forest algorithm. hence, the proposed approach is efficient in detecting fake profiles."
        },
        {
            "id": "R193190",
            "label": "Twitter fake account detection",
            "doi": "10.1109/UBMK.2017.8093420",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                },
                {
                    "id": "R191525",
                    "label": "Fake Account Detection"
                }
            ],
            "abstract": "social networking sites such as twitter and facebook attracts millions of users across the world and their interaction with social networking has affected their life. this popularity in social networking has led to different problems including the possibility of exposing incorrect information to their users through fake accounts which results to the spread of malicious content. this situation can result to a huge damage in the real world to the society. in our study, we present a classification method for detecting the fake accounts on twitter. we have preprocessed our dataset using a supervised discretization technique named entropy minimization discretization (emd) on numerical features and analyzed the results of the na\u00efve bayes algorithm."
        },
        {
            "id": "R209051",
            "label": "Bangla Fake News Detection Based On Multichannel Combined CNN-LSTM",
            "doi": "10.1109/icccnt51525.2021.9580035",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                },
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                }
            ],
            "abstract": "there have recently been many cases of unverified or misleading information circulating quickly over bogus web networks and news portals. this false news creates big damage to society and misleads people. for example, in 2019 there was a rumor that the padma bridge of bangladesh needed 100,000 human heads for sacrifice. this rumor turns into a deadly position and this misleading information takes the lives of innocent people. there is a lot of work in english but a few works in bangla. in this study, we are going to identify the fake news from the unconsidered news source to provide the newsreader with natural news or real news. the paper is based on the combination of convolutional neural network (cnn) and long short term memory (lstm) where cnn is used for deep feature extraction and lstm is used for detection using the extracted feature. the first thing we did to deploy this piece of work was data collection. we compiled a data set from websites and attempted to deploy it using the methodology of deep learning which contains about 50k of news. with the proposed model of multichannel combined cnn-lstm architecture, our model gained an accuracy of 75.05% which is a good sign for detecting fake news in bangla."
        },
        {
            "id": "R209074",
            "label": "Fake News Stance Detection Using Deep Learning Architecture (CNN-LSTM)",
            "doi": "10.1109/access.2020.3019735",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                },
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                }
            ],
            "abstract": "society and individuals are negatively influenced both politically and socially by the widespread increase of fake news either way generated by humans or machines. in the era of social networks, the quick rotation of news makes it challenging to evaluate its reliability promptly. therefore, automated fake news detection tools have become a crucial requirement. to address the aforementioned issue, a hybrid neural network architecture, that combines the capabilities of cnn and lstm, is used with two different dimensionality reduction approaches, principle component analysis (pca) and chi-square. this work proposed to employ the dimensionality reduction techniques to reduce the dimensionality of the feature vectors before passing them to the classifier. to develop the reasoning, this work acquired a dataset from the fake news challenges (fnc) website which has four types of stances: agree, disagree, discuss, and unrelated. the nonlinear features are fed to pca and chi-square which provides more contextual features for fake news detection. the motivation of this research is to determine the relative stance of a news article towards its headline. the proposed model improves results by ~4% and ~20% in terms of $accuracy$ and $f1-score$ . the experimental results show that pca outperforms than chi-square and state-of-the-art methods with 97.8% accuracy."
        },
        {
            "id": "R209105",
            "label": "Bidirectional LSTM Based on POS tags and CNN Architecture for Fake News Detection",
            "doi": "10.1109/icccnt45670.2019.8944460",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                },
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                }
            ],
            "abstract": "fake news generally on social media spreads very quickly and this brings many serious consequences. traditional lexico-syntactic based features have limited success to detect fake news. majority of fake news detection techniques are tested on small dataset containing limited training examples. in this work, we evaluate our architecture on liar-liar dataset which contain 12836 short news from different sources including social media. the proposed architecture incorporates pos (part of speech) tags information of news article through bidirectional lstm and speaker profile information through convolutional neural network. the results show that the resulting hybrid architecture significantly improves detection performance of fake news on liar dataset."
        },
        {
            "id": "R209121",
            "label": "Fake News Identification on Twitter with Hybrid CNN and RNN Models",
            "doi": "10.1145/3217804.3217917",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                },
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                }
            ],
            "abstract": "the problem associated with the propagation of fake news continues to grow at an alarming scale. this trend has generated much interest from politics to academia and industry alike. we propose a framework that detects and classifies fake news messages from twitter posts using hybrid of convolutional neural networks and long-short term recurrent neural network models. the proposed work using this deep learning approach achieves 82% accuracy. our approach intuitively identifies relevant features associated with fake news stories without previous knowledge of the domain."
        },
        {
            "id": "R212800",
            "label": "Language-Independent Fake News Detection: English, Portuguese, and Spanish Mutual Features",
            "doi": "10.3390/fi12050087",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                }
            ],
            "abstract": "online social media (osm) have been substantially transforming the process of spreading news, improving its speed, and reducing barriers toward reaching out to a broad audience. however, osm are very limited in providing mechanisms to check the credibility of news propagated through their structure. the majority of studies on automatic fake news detection are restricted to english documents, with few works evaluating other languages, and none comparing language-independent characteristics. moreover, the spreading of deceptive news tends to be a worldwide problem; therefore, this work evaluates textual features that are not tied to a specific language when describing textual data for detecting news. corpora of news written in american english, brazilian portuguese, and spanish were explored to study complexity, stylometric, and psychological text features. the extracted features support the detection of fake, legitimate, and satirical news. we compared four machine learning algorithms (k-nearest neighbors (k-nn), support vector machine (svm), random forest (rf), and extreme gradient boosting (xgb)) to induce the detection model. results show our proposed language-independent features are successful in describing fake, satirical, and legitimate news across three different languages, with an average detection accuracy of 85.3% with rf."
        },
        {
            "id": "R212917",
            "label": "Comparative analysis of machine learning methods to detect fake news in an Urdu language <i>corpus</i>",
            "doi": "10.7717/peerj-cs.1004",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                }
            ],
            "abstract": "wide availability and large use of social media enable easy and rapid dissemination of news. the extensive spread of engineered news with intentionally false information has been observed over the past few years. consequently, fake news detection has emerged as an important research area. fake news detection in the urdu language spoken by more than 230 million people has not been investigated very well. this study analyzes the use and efficacy of various machine learning classifiers along with a deep learning model to detect fake news in the urdu language. logistic regression, support vector machine, random forest (rf), naive bayes, gradient boosting, and passive aggression have been utilized to this end. the influence of term frequency-inverse document frequency and bow features has also been investigated. for experiments, a manually collected dataset that contains 900 news articles was used. results suggest that rf performs better and achieves the highest accuracy of 0.92 for urdu fake news with bow features. in comparison with machine learning models, neural networks models long short term memory, and multi-layer perceptron are used. machine learning models tend to show better performance than deep learning models."
        },
        {
            "id": "R213175",
            "label": "Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks",
            "doi": "10.1609/AAAI.V34I01.5393",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                }
            ],
            "abstract": "social media has been developing rapidly in public due to its nature of spreading new information, which leads to rumors being circulated. meanwhile, detecting rumors from such massive information in social media is becoming an arduous challenge. therefore, some deep learning methods are applied to discover rumors through the way they spread, such as recursive neural network (rvnn) and so on. however, these deep learning methods only take into account the patterns of deep propagation but ignore the structures of wide dispersion in rumor detection. actually, propagation and dispersion are two crucial characteristics of rumors. in this paper, we propose a novel bi-directional graph model, named bi-directional graph convolutional networks (bi-gcn), to explore both characteristics by operating on both top-down and bottom-up propagation of rumors. it leverages a gcn with a top-down directed graph of rumor spreading to learn the patterns of rumor propagation; and a gcn with an opposite directed graph of rumor diffusion to capture the structures of rumor dispersion. moreover, the information from source post is involved in each layer of gcn to enhance the influences from the roots of rumors. encouraging empirical results on several benchmarks confirm the superiority of the proposed method over the state-of-the-art approaches."
        },
        {
            "id": "R209138",
            "label": "TI-CNN: Convolutional Neural Networks for Fake News Detection",
            "doi": "",
            "research_field": {
                "id": "R373",
                "label": "Science and Technology Studies"
            },
            "research_problems": [
                {
                    "id": "R191103",
                    "label": "Misinformation & Fake News"
                },
                {
                    "id": "R191524",
                    "label": "Social Netwrok Security and Privacy"
                }
            ],
            "abstract": "with the development of social networks, fake news for various commercial and political purposes has been appearing in large numbers and gotten widespread in the online world. with deceptive words, people can get infected by the fake news very easily and will share them without any fact-checking. for instance, during the 2016 us president election, various kinds of fake news about the candidates widely spread through both official news media and the online social networks. these fake news is usually released to either smear the opponents or support the candidate on their side. the erroneous information in the fake news is usually written to motivate the voters' irrational emotion and enthusiasm. such kinds of fake news sometimes can bring about devastating effects, and an important goal in improving the credibility of online social networks is to identify the fake news timely. in this paper, we propose to study the fake news detection problem. automatic fake news identification is extremely hard, since pure model based fact-checking for news is still an open problem, and few existing models can be applied to solve the problem. with a thorough investigation of a fake news data, lots of useful explicit features are identified from both the text words and images used in the fake news. besides the explicit features, there also exist some hidden patterns in the words and images used in fake news, which can be captured with a set of latent features extracted via the multiple convolutional layers in our model. a model named as ti-cnn (text and image information based convolutinal neural network) is proposed in this paper. by projecting the explicit and latent features into a unified feature space, ti-cnn is trained with both the text and image information simultaneously. extensive experiments carried on the real-world fake news datasets have demonstrate the effectiveness of ti-cnn."
        },
        {
            "id": "R176011",
            "label": "A Stochastic Approach of Dependency Evaluation for IoT Devices",
            "doi": "10.1049/cje.2016.03.003",
            "research_field": {
                "id": "R112130",
                "label": "Networking and Internet Architecture"
            },
            "research_problems": [
                {
                    "id": "R176016",
                    "label": "Detection of critical equipments"
                }
            ],
            "abstract": "internet of things (iot) is an emerging technique that offers advanced connectivity of devices, systems, services, and human beings. with the rapid development of hardware and network technologies, the iot can refer to a wide variety and large number of devices, resulting in complex relationships among iot devices. the dependencies among iot devices, which reflect their relationships, are with reference value for the design, development and management of iot devices. this paper proposes a stochastic model based approach for evaluating the dependencies of iot devices. a random walk model is proposed to describe the relationships of iot devices, and its corresponding markov chain is obtained for dependency analysis. a framework as well as schemes and algorithms for dependency evaluation in real-world iot are designed based on traffic measurement. simulation experiments based on real-life data extracted from smart home environments are conducted to illustrate the efficacy of the approach."
        },
        {
            "id": "R186224",
            "label": "Building an AS-topology model that captures route diversity",
            "doi": "10.1145/1151659.1159937",
            "research_field": {
                "id": "R112130",
                "label": "Networking and Internet Architecture"
            },
            "research_problems": [
                {
                    "id": "R186227",
                    "label": "Inference of interdomain routing paths "
                }
            ],
            "abstract": "an understanding of the topological structure of the internet is needed for quite a number of networking tasks, e. g., making decisions about peering relationships, choice of upstream providers, inter-domain traffic engineering. one essential component of these tasks is the ability to predict routes in the internet. however, the internet is composed of a large number of independent autonomous systems (ases) resulting in complex interactions, and until now no model of the internet has succeeded in producing predictions of acceptable accuracy.we demonstrate that there are two limitations of prior models: (i) they have all assumed that an autonomous system (as) is an atomic structure - it is not, and (ii) models have tended to oversimplify the relationships between ases. our approach uses multiple quasi-routers to capture route diversity within the ases, and is deliberately agnostic regarding the types of relationships between ases. the resulting model ensures that its routing is consistent with the observed routes. exploiting a large number of observation points, we show that our model provides accurate predictions for unobserved routes, a first step towards developing structural mod-els of the internet that enable real applications."
        },
        {
            "id": "R186234",
            "label": "PredictRoute: A Network Path Prediction Toolkit",
            "doi": "10.1145/3460090",
            "research_field": {
                "id": "R112130",
                "label": "Networking and Internet Architecture"
            },
            "research_problems": [
                {
                    "id": "R186227",
                    "label": "Inference of interdomain routing paths "
                }
            ],
            "abstract": "\" accurate prediction of network paths between arbitrary hosts on the internet is of vital importance for network operators, cloud providers, and academic researchers. we present predictroute, a system that predicts network paths between hosts on the internet using historical knowledge of the data and control plane. in addition to feeding on freely available traceroutes and bgp routing tables, predictroute optimally explores network paths towards chosen bgp prefixes. predictroute's strategy for exploring network paths discovers 4x more autonomous system (as) hops than other well-known strategies used in practice today. using a corpus of traceroutes, predictroute trains probabilistic models of routing towards prefixes on the internet to predict network paths and their likelihood. predictroute's as-path predictions differ from the measured path by at most 1 hop, 75% of the time. we expose predictroute's path prediction capability via a rest api to facilitate its inclusion in other applications and studies. we additionally demonstrate the utility of predictroute in improving real-world applications for circumventing internet censorship and preserving anonymity online. \""
        },
        {
            "id": "R186240",
            "label": "Sibyl: A Practical Internet Route Oracle",
            "doi": "",
            "research_field": {
                "id": "R112130",
                "label": "Networking and Internet Architecture"
            },
            "research_problems": [
                {
                    "id": "R186227",
                    "label": "Inference of interdomain routing paths "
                }
            ],
            "abstract": "network operators measure internet routes to troubleshoot problems, and researchers measure routes to characterize the internet. however, they still rely on decades-old tools like traceroute, bgp route collectors, and looking glasses, all of which permit only a single query about internet routes--what is the path from here to there? this limited interface complicates answering queries about routes such as \"find routes traversing the level3/at&t peering in atlanta,\" to understand the scope of a reported problem there. \\n \\nthis paper presents sibyl, a system that takes rich queries that researchers and operators express as regular expressions, then issues and returns traceroutes that match even if it has never measured a matching path in the past. sibyl achieves this goal in three steps. first, to maximize its coverage of internet routing, sibyl integrates together diverse sets of traceroute vantage points that provide complementary views, measuring from thousands of networks in total. second, because users may not knowwhich measurements will traverse paths of interest, and because vantage point resource constraints keep sibyl from tracing to all destinations from all sources, sibyl uses historical measurements to predict which new ones are likely to match a query. finally, based on these predictions, sibyl optimizes across concurrent queries to decide which measurements to issue given resource constraints. we show that sibyl provides researchers and operators with the routing information they need--in fact, it matches 76% of the queries that it could match if an oracle told it which measurements to issue."
        },
        {
            "id": "R36089",
            "label": "Crowdsourced semantic annotation of scientific publications and tabular data in PDF",
            "doi": "https://doi.org/10.1145/2814864.2814887",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R36029",
                    "label": "Table extraction"
                }
            ],
            "abstract": "significant amounts of knowledge in science and technology have so far not been published as linked open data but are contained in the text and tables of legacy pdf publications. making such information available as rdf would, for example, provide direct access to claims and facilitate surveys of related work. a lot of valuable tabular information that till now only existed in pdf documents would also finally become machine understandable. instead of studying scientific literature or engineering patents for months, it would be possible to collect such input by simple sparql queries. the semann approach enables collaborative annotation of text and tables in pdf documents, a format that is still the common denominator of publishing, thus maximising the potential user base. the resulting annotations in rdf format are available for querying through a sparql endpoint. to incentivise users with an immediate benefit for making the effort of annotation, semann recommends related papers, taking into account the hierarchical context of annotations in a novel way. we evaluated the usability of semann and the usefulness of its recommendations by analysing annotations resulting from tasks assigned to test users and by interviewing them. while the evaluation shows that even few annotations lead to a good recall, we also observed unexpected, serendipitous recommendations, which confirms the merit of our low-threshold annotation support for the crowd."
        },
        {
            "id": "R36091",
            "label": "A Large Public Corpus of Web Tables containing Time and Context Metadata",
            "doi": "https://doi.org/10.1145/2872518.2889386",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R36029",
                    "label": "Table extraction"
                }
            ],
            "abstract": "the web contains vast amounts of html tables. most of these tables are used for layout purposes, but a small subset of the tables is relational, meaning that they contain structured data describing a set of entities [2]. as these relational web tables cover a very wide range of different topics, there is a growing body of research investigating the utility of web table data for completing cross-domain knowledge bases [6], for extending arbitrary tables with additional attributes [7, 4], as well as for translating data values [5]. the existing research shows the potentials of web tables. however, comparing the performance of the different systems is difficult as up till now each system is evaluated using a different corpus of web tables and as most of the corpora are owned by large search engine companies and are thus not accessible to the public. in this poster, we present a large public corpus of web tables which contains over 233 million tables and has been extracted from the july 2015 version of the commoncrawl. by publishing the corpus as well as all tools that we used to extract it from the crawled data, we intend to provide a common ground for evaluating web table systems. the main difference of the corpus compared to an earlier corpus that we extracted from the 2012 version of the commoncrawl as well as the corpus extracted by eberius et al. [3] from the 2014 version of the commoncrawl is that the current corpus contains a richer set of metadata for each table. this metadata includes table-specific information such as table orientation, table caption, header row, and key column, but also context information such as the text before and after the table, the title of the html page, as well as timestamp information that was found before and after the table. the context information can be useful for recovering the semantics of a table [7]. the timestamp information is crucial for fusing time-depended data, such as alternative population numbers for a city [8]."
        },
        {
            "id": "R4796",
            "label": "The hierarchy-of-hypotheses approach: A synthesis method for enhancing theory development in ecology and evolution",
            "doi": "10.32942/osf.io/6a85f",
            "research_field": {
                "id": "R24",
                "label": "Ecology and Evolutionary Biology"
            },
            "research_problems": [
                {
                    "id": "R4817",
                    "label": "how to structure data and information"
                }
            ],
            "abstract": "in the current era of big data, existing synthesis tools (e.g. formal meta-analysis) are useful for handling the deluge of data and information. however, there is a need for complementary tools that help to (i) structure data and information, (ii) closely connect evidence to theory and (iii) further develop theory. we present the hierarchy-of-hypotheses (hoh) approach to address these issues. in an hoh, hypotheses are conceptually and visually structured in a hierarchically nested way, where the lower branches can be directly connected to empirical results. used as an evidence-driven, bottom-up approach, it can (i) show connections between empirical results, even when derived through diverse approaches; and (ii) indicate under which circumstances hypotheses are applicable. used as a theory-driven, top-down method, it helps uncover mechanistic components of hypotheses. we offer guidance on how to build an hoh, provide examples from population and evolutionary biology and propose terminological clarifications."
        },
        {
            "id": "R52092",
            "label": "Species composition and diversity affect grassland susceptibility and response to invasion",
            "doi": "",
            "research_field": {
                "id": "R24",
                "label": "Ecology and Evolutionary Biology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in a microcosm experiment, i tested how species composition, species rich- ness, and community age affect the susceptibility of grassland communities to invasion by a noxious weed (centaurea solstitialis l.). i also examined how these factors influenced centaurea\\'s impact on the rest of the plant community. when grown in monoculture, eight species found in california\\'s grasslands differed widely in their ability to suppress centaurea growth. the most effective competitor in monoculture was hemizonia congesta ssp. iuzulifolia, which, like centaurea, is a summer- active annual forb. on average, centaurea growth decreased as the species richness of communities increased. however, no polyculture suppressed centaurea growth more than the monoculture of hemizonia. centaurea generally made up a smaller proportion of com- munity biomass in newly created (\"new\") microcosms than in older (\"established\") mi- crocosms, largely because centaurea\\'s competitors were more productive in the new treat- ment. measures of complementarity suggest that centaurea partitioned resources with an- nual grasses in the new microcosms. this resource partitioning may help to explain cen- taurea\\'s great success in western north american grasslands. centaurea strongly suppressed growth of some species but hardly affected others. an- nual grasses were the least affected species in the new monocultures, and perennial grasses were among the least affected species in the established monocultures. in the new micro- cosms, centaurea\\'s suppression of competing species marginally abated with increasing species richness. this trend was a consequence of the declining success of centaurea in species-rich communities, rather than a change in the vulnerability of these communities to suppression by a given amount of the invader. the impact of the invader was not related to species richness in the-established microcosms. the results of this study suggest that, at the neighborhood level, diversity can limit invasibility and may reduce the impact of an invader."
        },
        {
            "id": "R52094",
            "label": "Limiting similarity between invaders and dominant species in herbaceous plant communities?",
            "doi": "",
            "research_field": {
                "id": "R24",
                "label": "Ecology and Evolutionary Biology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "1 limiting similarity theory predicts that successful invaders should differ functionally from species already present in the community. this theory has been tested by manipulating the functional richness of communities, but not other aspects of functional diversity such as the identity of dominant species. because dominant species are known to have strong effects on ecosystem functioning, i hypothesized that successful invaders should be functionally dissimilar from community dominants. 2 to test this hypothesis, i added seeds of 17 different species to two different experiments: one in a natural oldfield community that had patches dominated by different plant species, and one in grassland mesocosms that varied in the identity of the dominant species but not in species richness or evenness. i used indicator species analyses to test whether invaders had higher establishment success in plots with functionally different dominant species. 3 a large percentage of invader species (47\u201371%) in both experiments showed no difference in affinity across the different dominant treatments, although one\u2010third of species did show some evidence for limiting similarity. exotic invaders had much higher invasion success than native invaders, and seemed to be inhibited by dominant species that were functionally similar. however, even these invasion patterns were not consistent across the two experiments. 4 the results from this study show that there is some evidence that dominant species suppress invasion by functionally similar species, beyond the effect of simple presence or absence of species in communities, although it is not the sole factor affecting invasion success. patterns of invasion success were inconsistent across species and experiments, indicating that other studies using only a single species of invader to make conclusions about community invasibility should be interpreted with caution."
        },
        {
            "id": "R144046",
            "label": "Land Use and Avian Species Diversity Along an Urban Gradient",
            "doi": "10.2307/2269387",
            "research_field": {
                "id": "R24",
                "label": "Ecology and Evolutionary Biology"
            },
            "research_problems": [
                {
                    "id": "R144049",
                    "label": "Urban avoiders"
                }
            ],
            "abstract": "i examined the distribution and abundance of bird species across an urban gradient, and concomitant changes in community structure, by censusing summer resident bird populations at six sites in santa clara county, california (all former oak woodlands). these sites represented a gradient of urban land use that ranged from relatively undisturbed to highly developed, and included a biological preserve, recreational area, golf course, residential neighborhood, office park, and business district. the composition of the bird community shifted from predominantly native species in the undisturbed area to invasive and exotic species in the business district. species richness, shannon diversity, and bird biomass peaked at moderately disturbed sites. one or more species reached maximal densities in each of the sites, and some species were restricted to a given site. the predevelopment bird species (assumed to be those found at the most undisturbed site) dropped out gradually as the sites became more urban. these patterns were significantly related to shifts in habitat structure that occurred along the gradient, as determined by canonical correspondence analysis (cca) using the environmental variables of percent land covered by pavement, buildings, lawn, grasslands, and trees or shrubs. i compared each formal site to four additional sites with similar levels of development within a two-county area to verify that the bird communities at the formal study sites were rep- resentative of their land use category."
        },
        {
            "id": "R193961",
            "label": "Influence of the COVID\u201019 pandemic on amphibian road mortality",
            "doi": "10.1111/csp2.535",
            "research_field": {
                "id": "R24",
                "label": "Ecology and Evolutionary Biology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the covid\u201019 pandemic and its related human activity shutdowns provide unique opportunities for biodiversity monitoring through what has been termed the \u201canthropause\u201d or the \u201cgreat human confinement experiment.\u201d the pandemic caused immense disruption to human activity in the northeastern united states in the spring of 2020, with notable reductions in traffic levels. these shutdowns coincided with the seasonal migration of adult amphibians, which are typically subject to intense vehicle\u2010impact mortality. using data collected as part of an annual community science monitoring program in maine from 2018 to 2021, we examined how amphibian mortality probabilities responded to reductions in traffic during the pandemic. while we detected a 50% decline for all amphibians, this was driven entirely by reductions in frog mortality. wildlife collision data from the maine department of transportation on other wildlife species support our finding of drastic declines in wildlife road mortality in spring 2020 when compared with immediately previous and subsequent years. additionally, we find that frogs suffer significantly higher road mortality than salamanders, particularly when conditions are warmer and wetter."
        },
        {
            "id": "R193966",
            "label": "How Is Wildlife Affected by the COVID-19 Pandemic? Lockdown Effect on the Road Mortality of Hedgehogs",
            "doi": "10.3390/ani11030868",
            "research_field": {
                "id": "R24",
                "label": "Ecology and Evolutionary Biology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "globally, wildlife is affected by unprecedented changes related to the covid-19 pandemic. in this paper, the lockdown effect on the traffic-related mortality in hedgehogs in an urban area was studied. comparing the pre-pandemic (2018 and 2019) and pandemic (2020) years, we showed that hedgehog roadkill levels during the lockdown period were over 50% lower (which means a decrease greater than the decrease in road traffic in the same period measured by the number of accidents or the average number of vehicles per day). based on literature data, we showed that this may mean at least tens of thousands of hedgehogs have survived on a national scale. we report the need to start intensive research on the possible demographic and genetic effects of this unique phenomenon. we also ask how stable the effect of the covid-19 pandemic will be on wildlife and whether the lockdown (which is an anthropause) may reverse the negative trends in the decline in the number of wild species, including hedgehogs."
        },
        {
            "id": "R76020",
            "label": "HealthIoT Ontology for Data Semantic Representation and Interpretation Obtained from Medical Connected Objects",
            "doi": "",
            "research_field": {
                "id": "R32",
                "label": "Environmental Health"
            },
            "research_problems": [
                {
                    "id": "R76038",
                    "label": "semantic interoperability of the medical connected objects and their data"
                }
            ],
            "abstract": "internet of things (iot) covers a variety of applications including the healthcare field. consequently, medical objects become connected to each other with the purpose to share and exchange health data. these medical connected objects raise issues on how to ensure the analysis, interpretation and semantic interoperability of the extensive obtained health data with the purpose to make an appropriate decision. this paper proposes a healthiot ontology for representing the semantic interoperability of the medical connected objects and their data; while an algorithm alleviates the analysis of the detected vital signs and the decision-making of the doctor. the execution of this algorithm needs the definition of several swrl rules (semantic web rule language)."
        },
        {
            "id": "R76023",
            "label": "SAREF4health: IoT Standard-Based Ontology-Driven Healthcare Systems",
            "doi": "",
            "research_field": {
                "id": "R32",
                "label": "Environmental Health"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "recently, a number of ontology-driven healthcare systems have been leveraged by the internet-of-things (iot) technologies, which offer opportunities to improve patient monitoring and abnormal situation detection with support of medical wearables and cloud infrastructure. usually, these systems rely on iot ontologies to represent sensor data observations. the etsi smart appliances reference (saref) iot ontology is an extensible industry-oriented standard. in this paper, we discuss the verbosity problem of saref when used for real-time electrocardiography (ecg), emphasizing the requirement of representing time series. we compared the main ontologies in this context according to quality, message size (payload), iot-orientation and standardization. we also introduce a saref4health extension to tackle the verbosity problem. in the saref4health development we followed ontology-driven conceptual modelling, in which an ecg ontology grounded in the unified foundational ontology (ufo) plays the role of a reference model. the methodology was enhanced by a standardization procedure and considers the rdf serialization of the hl7 fast healthcare interoperability resources (fhir) standard. the validation of saref4health includes the use cases of an early warning system that uses ecg data to detect accidents with truck drivers in a port area. a prototype that integrates an existing ecg wearable with cloud infrastructure demonstrates the performance impact of saref4health considering iot constraints. our results show that saref4health is adequate to enable semantic interoperability of iot solutions that need to deal with frequency-based time series. design decisions regarding the trade-off between ontology quality and aggregation representation are also discussed. \u00a9 2018 the authors and ios press. this article is published online with open access by ios press and distributed under the terms of the creative commons attribution non-commercial license 4.0 (cc by-nc 4.0)."
        },
        {
            "id": "R76026",
            "label": "Design and Implementation of e-Health System Based on Semantic Sensor Network Using IETF YANG",
            "doi": "",
            "research_field": {
                "id": "R32",
                "label": "Environmental Health"
            },
            "research_problems": [
                {
                    "id": "R76288",
                    "label": "semantic interoperability support for the e-Health system"
                }
            ],
            "abstract": "recently, healthcare services can be delivered effectively to patients anytime and anywhere using e-health systems. e-health systems are developed through information and communication technologies (ict) that involve sensors, mobiles, and web-based applications for the delivery of healthcare services and information. remote healthcare is an important purpose of the e-health system. usually, the ehealth system includes heterogeneous sensors from diverse manufacturers producing data in different formats. device interoperability and data normalization is a challenging task that needs research attention. several solutions are proposed in the literature based on manual interpretation through explicit programming. however, programmatically implementing the interpretation of the data sender and data receiver in the e-health system for the data transmission is counterproductive as modification will be required for each new device added into the system. in this paper, an e-health system with the semantic sensor network (ssn) is proposed to address the device interoperability issue. in the proposed system, we have used ietf yang for modeling the semantic e-health data to represent the information of e-health sensors. this modeling scheme helps in provisioning semantic interoperability between devices and expressing the sensing data in a user-friendly manner. for this purpose, we have developed an ontology for e-health data that supports different styles of data formats. the ontology is defined in yang for provisioning semantic interpretation of sensing data in the system by constructing meta-models of e-health sensors. the proposed approach assists in the auto-configuration of ehealth sensors and querying the sensor network with semantic interoperability support for the e-health system."
        },
        {
            "id": "R76029",
            "label": "Towards Consistent Data Representation in the IoT Healthcare Landscape",
            "doi": "",
            "research_field": {
                "id": "R32",
                "label": "Environmental Health"
            },
            "research_problems": [
                {
                    "id": "R76287",
                    "label": "consistently represent health and fitness data from heterogeneous IoT sources"
                }
            ],
            "abstract": "nowadays, the enormous volume of health and fitness data gathered from iot wearable devices offers favourable opportunities to the research community. for instance, it can be exploited using sophisticated data analysis techniques, such as automatic reasoning, to find patterns and, extract information and new knowledge in order to enhance decision-making and deliver better healthcare. however, due to the high heterogeneity of data representation formats, the iot healthcare landscape is characterised by an ubiquitous presence of data silos which prevents users and clinicians from obtaining a consistent representation of the whole knowledge. semantic web technologies, such as ontologies and inference rules, have been shown as a promising way for the integration and exploitation of data from heterogeneous sources. in this paper, we present a semantic data model useful to: (1) consistently represent health and fitness data from heterogeneous iot sources; (2) integrate and exchange them; and (3) enable automatic reasoning by inference engines."
        },
        {
            "id": "R76032",
            "label": "Meaningful Integration of Data from Heterogeneous Health Services and Home Environment Based on Ontology",
            "doi": "",
            "research_field": {
                "id": "R32",
                "label": "Environmental Health"
            },
            "research_problems": [
                {
                    "id": "R76283",
                    "label": "Semantic Web technologies to integrate the health data and home environment data"
                }
            ],
            "abstract": "the development of electronic health records, wearable devices, health applications and internet of things (iot)-empowered smart homes is promoting various applications. it also makes health self-management much more feasible, which can partially mitigate one of the challenges that the current healthcare system is facing. effective and convenient self-management of health requires the collaborative use of health data and home environment data from different services, devices, and even open data on the web. although health data interoperability standards including hl7 fast healthcare interoperability resources (fhir) and iot ontology including semantic sensor network (ssn) have been developed and promoted, it is impossible for all the different categories of services to adopt the same standard in the near future. this study presents a method that applies semantic web technologies to integrate the health data and home environment data from heterogeneously built services and devices. we propose a web ontology language (owl)-based integration ontology that models health data from hl7 fhir standard implemented services, normal web services and web of things (wot) services and linked data together with home environment data from formal ontology-described wot services. it works on the resource integration layer of the layered integration architecture. an example use case with a prototype implementation shows that the proposed method successfully integrates the health data and home environment data into a resource graph. the integrated data are annotated with semantics and ontological links, which make them machine-understandable and cross-system reusable."
        },
        {
            "id": "R109317",
            "label": "Groundwater Arsenic Contamination in the Ganga-Padma-Meghna-Brahmaputra Plain of India and Bangladesh",
            "doi": "10.3200/aeoh.58.11.701-702",
            "research_field": {
                "id": "R66",
                "label": "Environmental Health"
            },
            "research_problems": [
                {
                    "id": "R109296",
                    "label": "Heavy Metals Contamination in Water "
                }
            ],
            "abstract": "magnitude of arsenic groundwater contamination, and its related health effects, in the ganga-meghnabrahmaputra (gmb) plain\u2014an area of 569,749 km2, with a population of over 500 million, which largely comprises the flood plains of 3 major river systems that flow through india and bangladesh. design: on the basis of our 17-yr\u2013long study thus far, we report herein the magnitude of groundwater arsenic contamination, its health effects, results of our analyses of biological and food samples, and our investigation into sources of arsenic in the gmb plain setting: the gmb plain includes the following states in india: uttar pradesh in the upper and middle ganga plain, bihar and jharkhand in the middle ganga plain, west bengal in the lower ganga plain, and assam in the upper brahmaputra plain. the country of bangladesh is located in the padma-meghna-brahmaputra plain. in a preliminary study,1 we identified arsenic in water samples from hand-operated tubewells in the gmb plain. levels in excess of 50 ppb (the permissible limit for arsenic in drinking water in india and bangladesh) were found in samples from 51 villages in 3 arsenic-affected districts of uttar pradesh, 202 villages in 6 districts in bihar, 11 villages in 1 district in jharkhand, 3,500 villages in 9 (of a total of 18) districts in west bengal, 2,000 villages in 50 (of a total of 64) districts in bangladesh, and 17 villages in 2 districts in assam. study populations: because, over time, new regions of arsenic contamination have been found, affecting additional populations, the characteristics of our study subjects have varied widely. we feel that, even after working for 17 yr in the gmb plain, we have had only a glimpse of the full extent of the problem. protocol: thus far, on the gmb plain, we have analyzed 145,000 tubewell water samples from india and 52,000 from bangladesh for arsenic contamination. in india, 3,781 villages had arsenic levels above 50 ppb and 5,380 villages had levels exceeding 10 ppb; in bangladesh, the numbers were 2,000 and 2,450, respectively. we also analyzed 12,954 urine samples, 13,560 hair samples, 13,758 nail samples, and 1,300 skin scale samples from inhabitants of the arsenic-affected villages. groundwater arsenic contamination in the ganga-padma-"
        },
        {
            "id": "R38416",
            "label": "Semantic question answering system over linked data using relational patterns",
            "doi": "10.1145/2457317.2457331",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R9144",
                    "label": "Question Answering in the Semantic Web"
                }
            ],
            "abstract": "question answering is the task of answering questions in natural language. linked data project and semantic web community made it possible for us to query structured knowledge bases like dbpedia and yago. only expert users, however, with the knowledge of rdf and ontology definitions can build correct sparql queries for querying knowledge bases formally. in this paper, we present a method for mapping natural language questions to ontology-based structured queries to retrieve direct answers from open knowledge bases (linked data). our tool is based on translating natural language questions into rdf triple patterns using the dependency tree of the question text. in addition, our method uses relational patterns extracted from the web. we tested our tool using questions from qald-2, question answering over linked data challenge track and found promising preliminary results."
        },
        {
            "id": "R38419",
            "label": "Named entity recognition and disambiguation using linked data and graph-based centrality scoring",
            "doi": "10.1145/2237867.2237871",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R38422",
                    "label": "Named Entity Recongition"
                },
                {
                    "id": "R38423",
                    "label": "Named Entity Disambiguation"
                }
            ],
            "abstract": "named entity recognition (ner) is a subtask of information extraction and aims to identify atomic entities in text that fall into predefined categories such as person, location, organization, etc. recent efforts in ner try to extract entities and link them to linked data entities. linked data is a term used for data resources that are created using semantic web standards such as dbpedia. there are a number of online tools that try to identify named entities in text and link them to linked data resources. although one can use these tools via their apis and web interfaces, they use different data resources and different techniques to identify named entities and not all of them reveal this information. one of the major tasks in ner is disambiguation that is identifying the right entity among a number of entities with the same names; for example \"apple\" standing for both \"apple, inc.\" the company and the fruit. we developed a similar tool called nerso, short for named entity recognition using semantic open data, to automatically extract named entities, disambiguating and linking them to dbpedia entities. our disambiguation method is based on constructing a graph of linked data entities and scoring them using a graph-based centrality algorithm. we evaluate our system by comparing its performance with two publicly available ner tools. the results show that nerso performs better."
        },
        {
            "id": "R38429",
            "label": "A data-model driven web application development framework",
            "doi": "10.1145/2638404.2638522",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "model-driven approach for web application development is an important topic in software engineering. there are many existing tools to support model-driven engineering for web application development. however, most tools and techniques are complex and not very practical when it comes to real-life usage. here we present a simple data model-driven approach for web application development that is based on rdf data model, the basic semantic web data model, and its reasoning capabilities. we introduce a prototype implementation of the data model-driven web application development framework that utilizes semantic web technologies in the backend for the data model. in this framework, the design and development of the application is focused on the rdf data model and its reasoning logic (partially). developers define the data model online using a web application front-end and the framework generates different views of the data elements automatically. this enables the developers to change the data model easily whenever it is needed."
        },
        {
            "id": "R175444",
            "label": "Efficient synthesis of physically valid human motion",
            "doi": "10.1145/882262.882286",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\\n optimization is a promising way to generate new animations from a minimal amount of input data. physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow. traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an\\n o \\n (\\n d \\n 2 \\n ) process, where\\n d \\n is the number of degrees of freedom of the character. in this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives. the surprising finding is that this set includes constraints on physical validity, such as ground contact constraints. considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters. we show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach. our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom.\\n"
        },
        {
            "id": "R175450",
            "label": "Comparing Constraint-Based Motion Editing Methods",
            "doi": "10.1006/gmod.2001.0549",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "tools for assisting with editing human motion have become one of the most active research areas in the field of computer animation. not surprisingly, the area has demonstrated some stunning successes in both research and practice. this paper explores the range of constraint-based techniques used to alter motions while preserving specific spatial features. we examine a variety of methods, defining a taxonomy of these methods that is categorized by the mechanism employed to enforce temporal constraints. we pay particular attention to a less explored category of techniques that we term per-frame inverse kinematics plus filtering, and we show how these methods may provide an easier to implement while retaining the benefits of other approaches."
        },
        {
            "id": "R75340",
            "label": "What Public Transit API Logs Tell Us about Travel Flows",
            "doi": "10.1145/2872518.2891069",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the field of smart cities, researchers need an indication of how people move in and between cities. yet, getting statistics of travel flows within public transit systems has proven to be troublesome. in order to get an indication of public transit travel flows in belgium, we analyzed the query logs of the irail api, a highly expressive route planning api for the belgian railways. we were able to study 100k to 500k requests for each month between october 2012 and november 2015, which is between 0.56% and 1.66% of the amount of monthly passengers. using data visualizations, we illustrate the commuting patterns in belgium and confirm that brussels, the capital, acts as a central hub. the flemish region appears to be polycentric, while in the walloon region, everything converges on brussels. the findings correspond to the real travel demand, according to experts of the passenger federation trein tram bus. we conclude that query logs of route planners are of high importance in getting an indication of travel flows. however, better travel intentions would be acquirable using dedicated http post requests."
        },
        {
            "id": "R175437",
            "label": "Scenario-Based Sensed Human Motion Editing and Validation Through the Motion-Sphere",
            "doi": "10.1109/access.2022.3157939",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "synthesizing realistic human motion data using a real-time motion capture system in a controlled environment is a critical challenge. in addition, effectively manipulating the existing motion data is another primary concern and using such modified data in human motion analysis and activity recognition systems are prone to errors. this paper presents a simplistic and comprehensive system to effortlessly author, edit, and validate human motion data. the system enables a naive user to edit the existing motion data interactively using a humanoid model in a three-dimensional space, based on user-defined scenarios and synthesize numerous variations of the motion sequences. a modular concept of scenario-based sensed unit motion editing has been adopted to demonstrate the proposed system. we employed an efficient analytical kinematic and constraint solver to enforce the inherent body joint limits and external constraints while editing to synthesize complete and meaningful motion sequences. furthermore, we substantiated the proposed sensed unit motion editing framework through a visual validation study using an open-source intuitive visualization tool called the motion-sphere. finally, we compared the resultant synthesized motion against the real-time motion capture system data to verify the body segments\u2019 orientation and position accuracy deviations."
        },
        {
            "id": "R175438",
            "label": "3D Human Motion Editing and Synthesis: A Survey",
            "doi": "10.1155/2014/104535",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the ways to compute the kinematics and dynamic quantities of human bodies in motion have been studied in many biomedical papers. this paper presents a comprehensive survey of 3d human motion editing and synthesis techniques. firstly, four types of methods for 3d human motion synthesis are introduced and compared. secondly, motion capture data representation, motion editing, and motion synthesis are reviewed successively. finally, future research directions are suggested."
        },
        {
            "id": "R175441",
            "label": "Editing dynamic properties of captured human motion",
            "doi": "10.1109/robot.2000.844129",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in contrast to most physically based animation techniques that synthesize human motion from scratch, we take the approach of motion transformation as the underlying paradigm for generating computer animation. in doing so we combine the expressive richness of an input animation sequence with the controllability of space-time optimization to create a wide range of realistic character animation. the space-time dynamics formulation also allows editing of intuitive, high-level motion concepts such as the time and placement of footprints, length and mass of various extremities number of body joints and gravity. our algorithm is well suited for the reuse of highly-detailed captured motion animation. we report application of our algorithm on two such sequences: human run and human jump. as a result, both of these sequences produced a wide range of realistic motions. we show by dof comparison how closely the resulting motion matches the reality."
        },
        {
            "id": "R175447",
            "label": "Motion synthesis and editing in low-dimensional spaces",
            "doi": "10.1002/cav.125",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"human motion is difficult to create and manipulate because of the high dimensionality and spatiotemporal nature of human motion data. recently, the use of large collections of captured motion data has added increased realism in character animation. in order to make the synthesis and analysis of motion data tractable, we present a low\u2010dimensional motion space in which high\u2010dimensional human motion can be effectively visualized, synthesized, edited, parameterized, and interpolated in both spatial and temporal domains. our system allows users to create and edit the motion of animated characters in several ways: the user can sketch and edit a curve on low\u2010dimensional motion space, directly manipulate the character's pose in three\u2010dimensional object space, or specify key poses to create in\u2010between motions. copyright \u00a9 2006 john wiley & sons, ltd.\""
        },
        {
            "id": "R175453",
            "label": "A hierarchical approach to interactive motion editing for human-like figures",
            "doi": "10.1145/311535.311539",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper presents a technique for adapting existing motion of a human-like character to have the desired features that are specified by a set of constraints. this problem can be typically formulated as a spacetime constraint problem. our approach combines a hierarchical curve fitting technique with a new inverse kinematics solver. using the kinematics solver, we can adjust the configuration of an articulated figure to meet the constraints in each frame. through the fitting technique, the motion displacement of every joint at each constrained frame is interpolated and thus smoothly propagated to frames. we are able to adaptively add motion details to satisfy the constraints within a specified tolerance by adopting a multilevel bspline representation which also provides a speedup for the interpolation. the performance of our system is further enhanced by the new inverse kinematics solver. we present a closed-form solution to compute the joint angles of a limb linkage. this analytical method greatly reduces the burden of a numerical optimization to find the solutions for full degrees of freedom of a human-like articulated figure. we demonstrate that the technique can be used for retargetting a motion to compensate for geometric variations caused by both characters and environments. furthermore, we can also use this technique for directly manipulating a motion clip through a graphical interface. cr categories: i.3.7 [computer graphics]: threedimensional graphics\u2014animation; g.1.2 [numerical analysis]: approximation\u2014spline and piecewise polynomial approximation"
        },
        {
            "id": "R175456",
            "label": "A deep learning framework for character motion synthesis and editing",
            "doi": "10.1145/2897824.2925975",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present a framework to synthesize character movements based on high level parameters, such that the produced movements respect the manifold of human motion, trained on a large motion capture dataset. the learned motion manifold, which is represented by the hidden units of a convolutional autoencoder, represents motion data in sparse components which can be combined to produce a wide range of complex movements. to map from high level parameters to the motion manifold, we stack a deep feedforward neural network on top of the trained autoencoder. this network is trained to produce realistic motion sequences from parameters such as a curve over the terrain that the character should follow, or a target location for punching and kicking. the feedforward control network and the motion manifold are trained independently, allowing the user to easily switch between feedforward networks according to the desired interface, without re-training the motion manifold. once motion is generated it can be edited by performing optimization in the space of the motion manifold. this allows for imposing kinematic constraints, or transforming the style of the motion, while ensuring the edited motion remains natural. as a result, the system can produce smooth, high quality motion sequences without any manual pre-processing of the training data."
        },
        {
            "id": "R175459",
            "label": "Kinematically Admissible Editing of the Measured Sensor Motion Data for Virtual Reconstruction of Plausible Human Movements",
            "doi": "10.1109/smc52423.2021.9658750",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "sensor acquired data from inertial measurement unit based motion capture systems often do not conform to human body kinematics. although the data may appear visually correct when reconstructed on a stick model or 3d avatar, it does not represent natural movement when visualized on 3d data analytical tools, such as motion-sphere. this work extends the motion-sphere human motion data visualization and analysis tool to edit sensor acquired human motion data (shmd) to strictly adhere to human body kinematics. we use knee and elbow joint movements from the range of motion data in the totalcapture dataset to compare shmd against edited human motion data. this work proposes a method to edit shmd using motion sphere for kinematic correctness. we verify that edited human motion data is admissible to human body kinematics and improves virtual reconstruction on 3d avatar and joint position estimation accuracy. our results highlight the requirement for data visualization and editing tools, such as motion-sphere to edit and clean shmd."
        },
        {
            "id": "R178308",
            "label": "The KIT whole-body human motion database",
            "doi": "10.1109/icar.2015.7251476",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present a large-scale whole-body human motion database consisting of captured raw motion data as well as the corresponding post-processed motions. this database serves as a key element for a wide variety of research questions related e.g. to human motion analysis, imitation learning, action recognition and motion generation in robotics. in contrast to previous approaches, the motion data in our database considers the motions of the observed human subject as well as the objects with which the subject is interacting. the information about human-object relations is crucial for the proper understanding of human actions and their goal-directed reproduction on a robot. to facilitate the creation and processing of human motion data, we propose procedures and techniques for capturing of motion, labeling and organization of the motion capture data based on a motion description tree, as well as for the normalization of human motion to an unified representation based on a reference model of the human body. we provide software tools and interfaces to the database allowing access and efficient search with the proposed motion representation."
        },
        {
            "id": "R178314",
            "label": "Human motion database with a binary tree and node transition graphs",
            "doi": "10.1007/s10514-010-9206-z",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "database of human motion has been widely used for recognizing human motion and synthesizing humanoid motions. in this paper, we propose a data structure for storing and extracting human motion data and demonstrate that the database can be applied to the recognition and motion synthesis problems in robotics. we develop an efficient method for building a human motion database from a collection of continuous, multi-dimensional motion clips. the database consists of a binary tree representing the hierarchical clustering of the states observed in the motion clips, as well as node transition graphs representing the possible transitions among the nodes in the binary tree. using databases constructed from real human motion data, we demonstrate that the proposed data structure can be used for human motion recognition, state estimation and prediction, and robot motion planning."
        },
        {
            "id": "R178317",
            "label": "HMDB: A large video database for human motion recognition",
            "doi": "10.1109/iccv.2011.6126543",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "with nearly one billion online videos viewed everyday, an emerging new frontier in computer vision research is recognition and search in video. while much effort has been devoted to the collection and annotation of large scalable static image datasets containing thousands of image categories, human action datasets lag far behind. current action recognition databases contain on the order of ten different action categories collected under fairly controlled conditions. state-of-the-art performance on these datasets is now near ceiling and thus there is a need for the design and creation of new benchmarks. to address this issue we collected the largest action video database to-date with 51 action categories, which in total contain around 7,000 manually annotated clips extracted from a variety of sources ranging from digitized movies to youtube. we use this database to evaluate the performance of two representative computer vision systems for action recognition and explore the robustness of these methods under various conditions such as camera motion, viewpoint, video quality and occlusion."
        },
        {
            "id": "R178323",
            "label": "Interactive control of avatars animated with human motion data",
            "doi": "10.1145/566570.566607",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "real-time control of three-dimensional avatars is an important problem in the context of computer games and virtual environments. avatar animation and control is difficult, however, because a large repertoire of avatar behaviors must be made available, and the user must be able to select from this set of behaviors, possibly with a low-dimensional input device. one appealing approach to obtaining a rich set of avatar behaviors is to collect an extended, unlabeled sequence of motion data appropriate to the application. in this paper, we show that such a motion database can be preprocessed for flexibility in behavior and efficient search and exploited for real-time avatar control. flexibility is created by identifying plausible transitions between motion segments, and efficient search through the resulting graph structure is obtained through clustering. three interface techniques are demonstrated for controlling avatar motion using this data structure: the user selects from a set of available choices, sketches a path through an environment, or acts out a desired motion in front of a video camera. we demonstrate the flexibility of the approach through four different applications and compare the avatar motion to directly recorded human motion."
        },
        {
            "id": "R178329",
            "label": "Multimodal Database for Human Activity Recognition and Fall Detection",
            "doi": "10.3390/proceedings2191237",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "fall detection can improve the security and safety of older people and alert when fall occurs. fall detection systems are mainly based on wearable sensors, ambient sensors, and vision. each method has commonly known advantages and limitations. multimodal and data fusion approaches present a combination of data sources in order to better describe falls. publicly available multimodal datasets are needed to allow comparison between systems, algorithms and modal combinations. to address this issue, we present a publicly available dataset for fall detection considering inertial measurement units (imus), ambient infrared presence/absence sensors, and an electroencephalogram helmet. it will allow human activity recognition researchers to do experiments considering different combination of sensors."
        },
        {
            "id": "R184006",
            "label": "A GeoSPARQL Compliance Benchmark",
            "doi": "10.3390/ijgi10070487",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "geosparql is an important standard for the geospatial linked data community, given that it defines a vocabulary for representing geospatial data in rdf, defines an extension to sparql for processing geospatial data, and provides support for both qualitative and quantitative spatial reasoning. however, what the community is missing is a comprehensive and objective way to measure the extent of geosparql support in geosparql-enabled rdf triplestores. to fill this gap, we developed the geosparql compliance benchmark. we propose a series of tests that check for the compliance of rdf triplestores with the geosparql standard, in order to test how many of the requirements outlined in the standard a tested system supports. this topic is of concern because the support of geosparql varies greatly between different triplestore implementations, and the extent of support is of great importance for different users. in order to showcase the benchmark and its applicability, we present a comparison of the benchmark results of several triplestores, providing an insight into their current geosparql support and the overall geosparql support in the geospatial linked data domain."
        },
        {
            "id": "R189621",
            "label": "Inverse Kinematics Techniques in Computer Graphics: A Survey: Inverse Kinematics Techniques in Computer Graphics",
            "doi": "10.1111/cgf.13310",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R128712",
                    "label": "motion retargeting"
                },
                {
                    "id": "R128713",
                    "label": "motion synthesis"
                },
                {
                    "id": "R129103",
                    "label": "3D Rotation Estimation"
                }
            ],
            "abstract": "inverse kinematics (ik) is the use of kinematic equations to determine the joint parameters of a manipulator so that the end effector moves to a desired position; ik can be applied in many areas, including robotics, engineering, computer graphics and video games. in this survey, we present a comprehensive review of the ik problem and the solutions developed over the years from the computer graphics point of view. the paper starts with the definition of forward and ik, their mathematical formulations and explains how to distinguish the unsolvable cases, indicating when a solution is available. the ik literature in this report is divided into four main categories: the analytical, the numerical, the data\u2010driven and the hybrid methods. a timeline illustrating key methods is presented, explaining how the ik approaches have progressed over the years. the most popular ik methods are discussed with regard to their performance, computational cost and the smoothness of their resulting postures, while we suggest which ik family of solvers is best suited for particular problems. finally, we indicate the limitations of the current ik methodologies and propose future research directions."
        },
        {
            "id": "R189637",
            "label": "Human upper-body inverse kinematics for increased embodiment in consumer-grade virtual reality",
            "doi": "10.1145/3281505.3281529",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R124377",
                    "label": "Motion Capture"
                },
                {
                    "id": "R128713",
                    "label": "motion synthesis"
                }
            ],
            "abstract": "having a virtual body can increase embodiment in virtual reality (vr) applications. however, comsumer-grade vr falls short of delivering sufficient sensory information for full-body motion capture. consequently, most current vr applications do not even show arms, although they are often in the field of view. we address this shortcoming with a novel human upper-body inverse kinematics algorithm specifically targeted at tracking from head and hand sensors only. we present heuristics for elbow positioning depending on the shoulder-to-hand distance and for avoiding reaching unnatural joint limits. our results show that our method increases the accuracy compared to general inverse kinematics applied to human arms with the same tracking input. in a user study, participants preferred our method over displaying disembodied hands without arms, but also over a more expensive motion capture system. in particular, our study shows that virtual arms animated with our inverse kinematics system can be used for applications involving heavy arm movement. we demonstrate that our method can not only be used to increase embodiment, but can also support interaction involving arms or shoulders, such as holding up a shield."
        },
        {
            "id": "R189640",
            "label": "Real-Time Inverse Kinematics Techniques for Anthropomorphic Limbs",
            "doi": "10.1006/gmod.2000.0528",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R189731",
                    "label": "Aiming"
                },
                {
                    "id": "R189732",
                    "label": "Orientation"
                }
            ],
            "abstract": "in this paper we develop a set of inverse kinematics algorithms suitable for an anthropomorphic arm or leg. we use a combination of analytical and numerical methods to solve generalized inverse kinematics problems including position, orientation, and aiming constraints. our combination of analytical and numerical methods results in faster and more reliable algorithms than conventional inverse jacobian and optimization-based techniques. additionally, unlike conventional numerical algorithms, our methods allow the user to interactively explore all possible solutions using an intuitive set of parameters that define the redundancy of the system."
        },
        {
            "id": "R189649",
            "label": "Analytical inverse kinematics with body posture control",
            "doi": "10.1002/cav.176",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R189731",
                    "label": "Aiming"
                },
                {
                    "id": "R189743",
                    "label": "Reaching "
                }
            ],
            "abstract": "this paper presents a novel whole\u2010body analytical inverse kinematics (ik) method integrating collision avoidance and customizable body control for animating reaching tasks in real\u2010time. whole\u2010body control is achieved with the interpolation of pre\u2010designed key body postures, which are organized as a function of the direction to the goal to be reached. arm postures are computed by the analytical ik solution for human\u2010like arms and legs, extended with a new simple search method for achieving postures avoiding joint limits and collisions. in addition, a new ik resolution is presented that directly solves for joints parameterized in the swing\u2010and\u2010twist decomposition. the overall method is simple to implement, fast, and accurate, and therefore suitable for interactive applications controlling the hands of characters. the source code of the ik implementation is provided. copyright \u00a9 2007 john wiley & sons, ltd."
        },
        {
            "id": "R191635",
            "label": "A Full-Body Gesture Database for Automatic Gesture Recognition",
            "doi": "10.1109/fgr.2006.8",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper presents a full-body gesture database which contains 2d video data and 3d motion data of 14 normal gestures, 10 abnormal gestures and 30 command gestures for 20 subjects. we call this database the korea university gesture (kug) database. using 3d motion cameras and 3 sets of stereo cameras, we captured 3d motion data and 3 pairs of stereo-video data at 3 different directions for normal and abnormal gestures. in case of command gestures, 2 pairs of stereo-video data is obtained by 2 sets of stereo cameras with different focal length in order to effectively capture views of whole body and upper body, simultaneously. in addition to these, the 2d silhouette data is synthesized by separating a subject and background in 2d stereo-video data and saved as binary mask images. in this paper, we describe the gesture capture system, the organization of database, the potential usages of the database and the way of obtaining the kug database"
        },
        {
            "id": "R191641",
            "label": "The CMU Motion of Body (MoBo) Database",
            "doi": "",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in march 2001 we started to collect the cmu motion of body (mobo) database. to date the database contains 25 individuals walking on a treadmill in the cmu 3d room. the subjects perform four different walk patterns: slow walk, fast walk, incline walk and walking with a ball. all subjects are captured using six high resolution color cameras distributed evenly around the treadmill. in this technical report we describe the capture setup, the collection procedure and the organization of the database."
        },
        {
            "id": "R6943",
            "label": "Nucleation and growth of new particles in Po Valley, Italy",
            "doi": "10.5194/acp-7-355-2007",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R6945",
                    "label": "Temporal characteristics of nucleation events"
                }
            ],
            "abstract": "\" abstract. aerosol number distribution measurements are reported at san pietro capofiume (spc) station (44\u00b039' n, 11\u00b037' e) for the time period 2002\u20132005. the station is located in po valley, the largest industrial, trading and agricultural area in italy with a high population density. new particle formation was studied based on observations of the particle size distribution, meteorological and gas phase parameters. the nucleation events were classified according to the event clarity based on the particle number concentrations, and the particle formation and growth rates. out of a total of 769 operational days from 2002 to 2005 clear events were detected on 36% of the days whilst 33% are clearly non-event days. the event frequency was high during spring and summer months with maximum values in may and july, whereas lower frequency was observed in winter and autumn months. the average particle formation and growth rates were estimated as ~6 cm\u22123 s\u22121 and ~7 nm h\u22121, respectively. such high growth and formation rates are typical for polluted areas. temperature, wind speed, solar radiation, so2 and o3 concentrations were on average higher on nucleation days than on non-event days, whereas relative and absolute humidity and no2 concentration were lower; however, seasonal differences were observed. backtrajectory analysis suggests that during majority of nucleation event days, the air masses originate from northern to eastern directions. we also study previously developed nucleation event correlations with environmental variables and show that they predict po valley nucleation events with variable success.\\n \""
        },
        {
            "id": "R8034",
            "label": "An Overview of CMIP5 and the Experiment Design",
            "doi": "10.1175/bams-d-11-00094.1",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R8037",
                    "label": "climate change"
                },
                {
                    "id": "R8038",
                    "label": "CMIP5"
                },
                {
                    "id": "R8039",
                    "label": "experiment design"
                }
            ],
            "abstract": "\" the fifth phase of the coupled model intercomparison project (cmip5) will produce a state-of-the- art multimodel dataset designed to advance our knowledge of climate variability and climate change. researchers worldwide are analyzing the model output and will produce results likely to underlie the forthcoming fifth assessment report by the intergovernmental panel on climate change. unprecedented in scale and attracting interest from all major climate modeling groups, cmip5 includes \u201clong term\u201d simulations of twentieth-century climate and projections for the twenty-first century and beyond. conventional atmosphere\u2013ocean global climate models and earth system models of intermediate complexity are for the first time being joined by more recently developed earth system models under an experiment design that allows both types of models to be compared to observations on an equal footing. besides the longterm experiments, cmip5 calls for an entirely new suite of \u201cnear term\u201d simulations focusing on recent decades and the future to year 2035. these \u201cdecadal predictions\u201d are initialized based on observations and will be used to explore the predictability of climate and to assess the forecast system's predictive skill. the cmip5 experiment design also allows for participation of stand-alone atmospheric models and includes a variety of idealized experiments that will improve understanding of the range of model responses found in the more complex and realistic simulations. an exceptionally comprehensive set of model output is being collected and made freely available to researchers through an integrated but distributed data archive. for researchers unfamiliar with climate models, the limitations of the models and experiment design are described. \""
        },
        {
            "id": "R8048",
            "label": "Future changes of wind energy potentials over Europe in\u00a0a\u00a0large CMIP5 multi-model ensemble: FUTURE CHANGES OF WIND ENERGY OVER EUROPE IN A CMIP5 ENSEMBLE",
            "doi": "10.1002/joc.4382",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R8052",
                    "label": "wind energy potentials"
                },
                {
                    "id": "R8053",
                    "label": "multi\u2010model ensemble"
                },
                {
                    "id": "R8054",
                    "label": "Europe"
                },
                {
                    "id": "R8055",
                    "label": "future changes"
                }
            ],
            "abstract": "a statistical\u2010dynamical downscaling method is used to estimate future changes of wind energy output (eout) of a benchmark wind turbine across europe at the regional scale. with this aim, 22 global climate models (gcms) of the coupled model intercomparison project phase 5 (cmip5) ensemble are considered. the downscaling method uses circulation weather types and regional climate modelling with the cosmo\u2010clm model. future projections are computed for two time periods (2021\u20132060 and 2061\u20132100) following two scenarios (rcp4.5 and rcp8.5). the cmip5 ensemble mean response reveals a more likely than not increase of mean annual eout over northern and central europe and a likely decrease over southern europe. there is some uncertainty with respect to the magnitude and the sign of the changes. higher robustness in future changes is observed for specific seasons. except from the mediterranean area, an ensemble mean increase of eout is simulated for winter and a decreasing for the summer season, resulting in a strong increase of the intra\u2010annual variability for most of europe. the latter is, in particular, probable during the second half of the 21st century under the rcp8.5 scenario. in general, signals are stronger for 2061\u20132100 compared to 2021\u20132060 and for rcp8.5 compared to rcp4.5. regarding changes of the inter\u2010annual variability of eout for central europe, the future projections strongly vary between individual models and also between future periods and scenarios within single models. this study showed for an ensemble of 22 cmip5 models that changes in the wind energy potentials over europe may take place in future decades. however, due to the uncertainties detected in this research, further investigations with multi\u2010model ensembles are needed to provide a better quantification and understanding of the future changes."
        },
        {
            "id": "R8061",
            "label": "Wind extremes in the North Sea Basin under climate change: An ensemble study of 12 CMIP5 GCMs: WIND EXTREMES IN THE NORTH SEA IN CMIP5",
            "doi": "10.1002/jgrd.50147",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R8063",
                    "label": "CMIP5"
                },
                {
                    "id": "R8064",
                    "label": "wind extremes"
                },
                {
                    "id": "R8065",
                    "label": "climate change"
                },
                {
                    "id": "R8066",
                    "label": "North sea"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "coastal safety may be influenced by climate change, as changes in extreme surge levels and wave extremes may increase the vulnerability of dunes and other coastal defenses. in the north sea, an area already prone to severe flooding, these high surge levels and waves are generated by low atmospheric pressure and severe wind speeds during storm events. as a result of the geometry of the north sea, not only the maximum wind speed is relevant, but also wind direction. climate change could change maximum wind conditions, with potentially negative effects for coastal safety. here, we use an ensemble of 12 coupled model intercomparison project phase 5 (cmip5) general circulation models (gcms) and diagnose the effect of two climate scenarios (rcp4.5 and rcp8.5) on annual maximum wind speed, wind speeds with lower return frequencies, and the direction of these annual maximum wind speeds. the 12 selected cmip5 models do not project changes in annual maximum wind speed and in wind speeds with lower return frequencies; however, we do find an indication that the annual extreme wind events are coming more often from western directions. our results are in line with the studies based on cmip3 models and do not confirm the statement based on some reanalysis studies that there is a climate\u2010change\u2010related upward trend in storminess in the north sea area."
        },
        {
            "id": "R74780",
            "label": "Activity concentration of natural radionuclides in sediments of Bree, Klein-Brak, Bakens, and uMngeni rivers and their associated radiation hazard indices",
            "doi": "10.1080/0035919x.2020.1815894",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R53456",
                    "label": "How can we utilize our understanding of the Earth system (physics of natural phenomenon) to coordinate observations and models to target specific domains (such as climate, natural resource, environment, agriculture, security) for timely data?"
                }
            ],
            "abstract": "a hyper-pure germanium (hpge) detector was used to measure the activity concentrations in sediment samples of rivers in south africa, and the associated radiological hazard indices were evaluated. the results of the study indicated that the mean activity concentrations of 226ra, 232th and 40k in the sediment samples from the oil-rich areas are 11.13, 7.57, 22.5 ; 5.51, 4.62, 125.02 and 7.60, 5.32, 24.12 for the bree, klein-brak and bakens rivers, respectively. in contrast, the control site (umngeni river) values were 4.13, 3.28, and 13.04 for 226ra, 232th, and 40k. the average excess lifetime cancer risks are 0.394 \u00d7 , 0.393\\u2009\u00d7 , 0.277 \u00d7 and 0.163 \u00d7 for sediment samples at bree, klein-brak, bakens, and umngeni rivers. all obtained values indicated a significant difference between the natural radionuclide concentrations in the samples from the rivers in oil-rich areas compared to those of the non-oil-rich area. the values reported for the activity concentrations and radiological hazard indices were below the average world values; hence, the risk of radiation health hazard was negligible in all study areas."
        },
        {
            "id": "R78114",
            "label": "Petroleum Exploration and Production: Past and Present Environmental Issues in the Nigeria\u2019s Niger Delta",
            "doi": "10.12691/env-1-4-2",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R78207",
                    "label": "Activities associated with petroleum exploration, development and production operations have local detrimental and significant impacts on the atmosphere, soils and sediments, surface and groundwater, marine environment and terrestrial ecosystems in the Niger Delta."
                }
            ],
            "abstract": "petroleum exploration and production in the nigeria\u2019s niger delta region and export of oil and gas resources by the petroleum sector has substantially improved the nation\u2019s economy over the past five decades. however, activities associated with petroleum exploration, development and production operations have local detrimental and significant impacts on the atmosphere, soils and sediments, surface and groundwater, marine environment and terrestrial ecosystems in the niger delta. discharges of petroleum hydrocarbon and petroleum\u2013derived waste streams have caused environmental pollution, adverse human health effects, socio\u2013economic problems and degradation of host communities in the 9 oil\u2013producing states in the niger delta region. many approaches have been developed for the management of environmental impacts of petroleum production\u2013related activities and several environmental laws have been institutionalized to regulate the nigerian petroleum industry. however, the existing statutory laws and regulations for environmental protection appear to be grossly inadequate and some of the multinational oil companies operating in the niger delta region have failed to adopt sustainable practices to prevent environmental pollution. this review examines the implications of multinational oil companies operations and further highlights some of the past and present environmental issues associated with petroleum exploitation and production in the nigeria\u2019s niger delta. although effective understanding of petroleum production and associated environmental degradation is importance for developing management strategies, there is a need for more multidisciplinary approaches for sustainable risk mitigation and effective environmental protection of the oil\u2013producing host communities in the niger delta."
        },
        {
            "id": "R78209",
            "label": "Role of Plants and Microbes in Bioremediation of Petroleum Hydrocarbons Contaminated Soils",
            "doi": "",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R78212",
                    "label": "Petroleum hydrocarbons contamination of soil, sediments and marine environment associated with the inadvertent discharges of petroleum\u2013derived chemical wastes and petroleum hydrocarbons associated with spillage and other sources into the environment often pose harmful effects on human health and the natural environment, and have negative socio\u2013economic impacts in the oil\u2013producing host communities. "
                }
            ],
            "abstract": "petroleum hydrocarbons contamination of soil, sediments and marine environment associated with the inadvertent discharges of petroleum\u2013derived chemical wastes and petroleum hydrocarbons associated with spillage and other sources into the environment often pose harmful effects on human health and the natural environment, and have negative socio\u2013economic impacts in the oil\u2013producing host communities. in practice, plants and microbes have played a major role in microbial transformation and growth\u2013linked mineralization of petroleum hydrocarbons in contaminated soils and/or sediments over the past years. bioremediation strategies has been recognized as an environmental friendly and cost\u2013effective alternative in comparison with the traditional physico-chemical approaches for the restoration and reclamation of contaminated sites. the success of any plant\u2013based remediation strategy depends on the interaction of plants with rhizospheric microbial populations in the surrounding soil medium and the organic contaminant. effective understanding of the fate and behaviour of organic contaminants in the soil can help determine the persistence of the contaminant in the terrestrial environment, promote the success of any bioremediation approach and help develop a high\u2013level of risks mitigation strategies. in this review paper, we provide a clear insight into the role of plants and microbes in the microbial degradation of petroleum hydrocarbons in contaminated soil that have emerged from the growing body of bioremediation research and its applications in practice. in addition, plant\u2013microbe interactions have been discussed with respect to biodegradation of petroleum hydrocarbons and these could provide a better understanding of some important factors necessary for development of in situ bioremediation strategies for risks mitigation in petroleum hydrocarbon\u2013contaminated soil."
        },
        {
            "id": "R78224",
            "label": "Assessment of Cadmium and Lead Distribution in the Outcrop Rocks of Abakaliki Anticlinorium in the Southern Benue Trough, Nigeria",
            "doi": "",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this study investigates the distribution of cadmium and lead concentrations in the outcrop rock samples collected from abakaliki anticlinorium in the southern benue trough, nigeria. the outcrop rock samples from seven sampling locations were air\u2013dried for seventy\u2013two hours, homogenized by grinding and pass through < 63 micron mesh sieve. the ground and homogenized rock samples were pulverized and analyzed for cadmium and lead using x-ray fluorescence spectrometer. the concentrations of heavy metals in the outcrop rock samples ranged from < 0.10 \u2013 7.95 mg kg\u20131 for cadmium (cd) and < 1.00 \u2013 4966.00 mg kg\u20131 for lead (pb). apart from an anomalous concentration measured in afikpo shale (middle segment), the results obtained revealed that rock samples from all the sampling locations yielded cadmium concentrations of < 0.10 mg kg\u20131 and the measured concentrations were below the average crustal abundance of 0.50 mg kg\u20131. although background concentration of <1.00 \u00b1 0.02 mg kg\u20131 was measured in abakaliki shale, rock samples from all the sampling locations revealed anomalous lead concentrations above average crustal abundance of 30 mg kg\u20131. the results obtained reveal important contributions towards understanding of heavy metal distribution patterns and provide baseline data that can be used for potential identification of areas at risk associated with natural sources of heavy metals contamination in the region. the use of outcrop rocks provides a cost\u2013effective approach for monitoring regional heavy metal contamination associated with dissolution and/or weathering of rocks or parent materials. evaluation of heavy metals may be effectively used in large scale regional pollution monitoring of soil, groundwater, atmospheric and marine environment. therefore, monitoring of heavy metal concentrations in soils, groundwater and atmospheric environment is imperative in order to prevent bioaccumulation in various ecological receptors."
        },
        {
            "id": "R78247",
            "label": "An Ontology-Based Framework for Publishing and Exploiting Linked Open Data: A Use Case on Water Resources Management",
            "doi": "",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R78254",
                    "label": "An Overview of Water Ontologies"
                }
            ],
            "abstract": "nowadays, the increasing demand of water for electricity production, agricultural and industrial uses are directly affecting the reduction of available quality water for human consumption in the world. efficient and sustainable maintenance of water reservoirs and supply networks implies a holistic strategy that takes into account, as much as possible, information from the stages of water usage. next,-generation decision-making software tools, for supporting water management, require the integration of multiple and heterogeneous data sources of different knowledge domains. in this regard, linked data and semantic web technologies enable harmonization of different data sources, as well as the efficient querying for feeding upper-level business intelligence processes. this work investigates the design, implementation and usage of a semantic approach driven by ontology to capture, store, integrate and exploit real-world data concerning water supply networks management. as a main contribution, the proposal helps with obtaining semantically enriched linked data, enhancing the analysis of water network performance. for validation purposes, in the use case, a series of data sources from different measures have been considered, in the scope of an actual water management system of the mediterranean region of valencia (spain), throughout several years of activity. the obtained experience shows the benefits of using the proposed approach to identify possible correlations between the measures such as the supplied water, the water leaks or the population."
        },
        {
            "id": "R152812",
            "label": "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking",
            "doi": "10.18653/v1/2021.acl-long.64",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R152823",
                    "label": "Short text entity linking"
                },
                {
                    "id": "R122863",
                    "label": "Entity Linking"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "entity linking (el) is the task of disambiguating mentions appearing in text by linking them to entities in a knowledge graph, a crucial task for text understanding, question answering or conversational systems. in the special case of short-text el, which poses additional challenges due to limited context, prior approaches have reached good performance by employing heuristics-based methods or purely neural approaches. here, we take a different, neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. even though constrained to use rules, we show that we reach competitive or better performance with sota black-box neural approaches. furthermore, our framework has the benefits of extensibility and transferability. we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, bert encodings, box embeddings, etc), and even with scores resulting from previous el methods, thus improving on such methods. as an example of improvement, on the lc-quad-1.0 dataset, we show more than 3% increase in f1 score relative to previous sota. finally, we show that the inductive bias offered by using logic results in a set of learned rules that transfers from one dataset to another, sometimes without finetuning, while still having high accuracy."
        },
        {
            "id": "R69996",
            "label": "Exploring the Evolution and Provenance of Git Versioned RDF Data",
            "doi": "",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R2090",
                    "label": "Data Provenance Tracking"
                }
            ],
            "abstract": "the distributed character and the manifold possibilities for interchanging data on the web lead to the problem of getting hold of the provenance of the data. especially in the domain of digital humanities and when dealing with linked data in an enterprise context provenance information is needed to support the collaborative process of data management. we are proposing a possibility for capturing and exploring provenance information, based on the methodology of managing rdf data in a tool stack on top of the decentralized source code management system git. this comprises a queriable history graph, the possibility to query arbitrary revisions of a git versioned store and in the minimal granularity the possibility to annotate individual statements with their provenance information."
        },
        {
            "id": "R74389",
            "label": "Consuming and producing linked open data: The case of OpenCourseWare",
            "doi": "10.1108/PROG-07-2012-0045",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74388",
                    "label": "Linked Data Publishing"
                },
                {
                    "id": "R109057",
                    "label": "Linked Data Publishing"
                }
            ],
            "abstract": "\\n purpose \\n \u2013 the aim of this paper is to present an initiative to apply the principles of linked data to enhance the search and discovery of opencourseware (ocw) contents created and shared by the universities. \\n \\n \\n design/methodology/approach \\n \u2013 this paper is a case study of how linked data technologies can be applied for the enhancement of open learning contents. \\n \\n \\n findings \\n \u2013 results presented under the umbrella of ocw-universia consortium, as the integration and access to content from different repositories ocw and the development of a query method to access these data, reveal that linked data would offer a solution to filter and select semantically those open educational contents, and automatically are linked to the linked open data cloud. \\n \\n \\n originality/value \\n \u2013 the new ocw-universia integration with linked data adds new features to the initial framework including improved query mechanisms and interoperability. \\n"
        },
        {
            "id": "R25763",
            "label": "H-Mine: Fast and space-preserving frequent pattern mining in large databases",
            "doi": "10.1080/07408170600897460",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25727",
                    "label": "Utility Sentient Frequent Itemset Mining and Association Rule Mining"
                }
            ],
            "abstract": "in this study, we propose a simple and novel data structure using hyper-links, h-struct, and a new mining algorithm, h-mine, which takes advantage of this data structure and dynamically adjusts links in the mining process. a distinct feature of this method is that it has a very limited and precisely predictable main memory cost and runs very quickly in memory-based settings. moreover, it can be scaled up to very large databases using database partitioning. when the data set becomes dense, (conditional) fp-trees can be constructed dynamically as part of the mining process. our study shows that h-mine has an excellent performance for various kinds of data, outperforms currently available algorithms in different settings, and is highly scalable to mining large databases. this study also proposes a new data mining methodology, space-preserving mining, which may have a major impact on the future development of efficient and scalable data mining methods. \u2020decreased"
        },
        {
            "id": "R25906",
            "label": "LEPTO dipstick, a dipstick assay for detection of Leptospira-specific immunoglobulin M antibodies in human sera.",
            "doi": "10.1128/jcm.35.1.92-97.1997",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "we studied a dipstick assay for the detection of leptospira-specific immunoglobulin m (igm) antibodies in human serum samples. a high degree of concordance was observed between the results of the dipstick assay and an igm enzyme-linked immunosorbent assay (elisa). application of the dipstick assay for the detection of acute leptospirosis enabled the accurate identification, early in the disease, of a high proportion of the cases of leptospirosis. analysis of a second serum sample is recommended, in order to determine seroconversion or increased staining intensity. all serum samples from the patients who were confirmed to be positive for leptospirosis by either a positive microscopic agglutination test or a positive culture but were found to be negative by the dipstick assay were also judged to be negative by the igm elisa or revealed borderline titers by the igm elisa. some cross-reactivity was observed for sera from patients with diseases other than leptospirosis, and this should be taken into account in the interpretation of test results. the dipstick assay is easy to perform, can be performed quickly, and requires no electricity or special equipment, and the assay components, a dipstick and a staining reagent, can be stored for a prolonged period without a loss of reactivity, even at elevated temperatures."
        },
        {
            "id": "R25908",
            "label": "Development, Characterization, and Diagnostic Applications of Monoclonal Antibodies against Bovine Rotavirus",
            "doi": "10.1128/cdli.7.2.288-292.2000",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "abstract \\n hybridomas secreting monoclonal antibodies (mabs) against the nebraska calf diarrhea strain of bovine rotavirus (brv) were characterized. indirect fluorescent-antibody assay, immunodot assay, and immunoprecipitation were used to select hybridomas that produced anti-brv mabs. seven of the mabs were shown by sodium dodecyl sulfate-polyacrylamide gel electrophoresis and western blot assay to be reactive with the brv outer capsid protein, vp7, which has a molecular mass of 37.5 kda. none of the seven mabs were reactive with canine rotavirus, bovine coronavirus, or uninfected madin-darby bovine kidney cells. two clones, 8b4 (immunoglobulin g2a [igg2a]) and 2b11 (igg1), were found suitable for use in an antigen capture enzyme-linked immunosorbent assay for detecting brv in bovine fecal samples. both were subtype a specific (g6 subtype) but did not react with all isolates of brv group a."
        },
        {
            "id": "R25914",
            "label": "Diagnosis of Schistosomiasis by Reagent Strip Test for Detection of Circulating Cathodic Antigen",
            "doi": "10.1128/jcm.42.12.5458-5461.2004",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "abstract \\n \\n a newly developed reagent strip assay for the diagnosis of schistosomiasis based on parasite antigen detection in urine of infected individuals was evaluated. the test uses the principle of lateral flow through a nitrocellulose strip of the sample mixed with a colloidal carbon conjugate of a monoclonal antibody specific for\\n schistosoma \\n circulating cathodic antigen (cca). the strip assay to diagnose a group of highly infected schoolchildren in mwanza, tanzania, demonstrated a high sensitivity and association with the intensity of infection as measured both by egg counts, and by circulating anodic antigen and cca levels determined by enzyme-linked immunosorbent assay. a specificity of ca. 90% was shown in a group of schistosome-negative schoolchildren from tarime, tanzania, an area where schistosomiasis is not endemic. the test is easy to perform and requires no technical equipment or special training. the stability of the strips and the conjugate in the dry format lasts for at least 3 months at ambient temperature in sealed packages, making it suitable for transport and use in areas where schistosomiasis is endemic. this assay can easily be developed to an end-user format.\\n"
        },
        {
            "id": "R25925",
            "label": "One-step competitive immunochromatographic assay for semiquantitative determination of lipoprotein(a) in plasma",
            "doi": "10.1093/clinchem/39.4.619",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "\" abstract \\n numerous studies have associated high concentrations of lipoprotein(a) [lp(a)] with atherosclerosis. we developed a rapid, one-step competitive immunochromatographic assay to measure lp(a) in plasma. the assay is performed on a nitrocellulose membrane strip and the result is determined by a visual readout of rust-colored colloidal selenium. the assay is based on the principle that lp(a) in the sample will compete with lp(a)-coated colloidal selenium for binding to the anti-lp(a) monoclonal antibody immobilized on the assay strip in the format of four ladder bars. the number of capture bars that appear as a result of the formation of colloidal selenium color is proportional to the concentration of the lp(a) protein in the samples. the strip assay semiquantitatively measures lp(a) concentrations ranging from 0 to 180 mg/l of lp(a) protein in serum, plasma, or fingerstick whole-blood samples. this assay appears very useful for quick identification of individuals with above-normal concentrations of plasma lp(a) protein (&amp;gt; 70 mg/l), and has potential for monitoring a patient's response to treatment with lp(a)-lowering drugs. \""
        },
        {
            "id": "R25927",
            "label": "Lateral Flow Immunoassay Using Europium (III) Chelate Microparticles and Time-Resolved Fluorescence for Eosinophils and Neutrophils in Whole Blood",
            "doi": "10.1373/clinchem.2006.074021",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "abstract \\n background: a simple point-of-care method for measuring leukocyte counts in a doctor\u2019s office or emergency room could be of great importance. we developed a protocol for measuring cell count by disrupting the cell membrane and analyzing specific proteins within the cells and used it to analyze proteins from eosinophils and neutrophils. \\n methods: lateral immunochromatographic (icr) assays have been developed for eosinophil protein x (epx) and human neutrophil lipocalin (hnl) as measures of the concentration of eosinophils and neutrophils. the correlation between the lateral icr assays and cell counting of eosinophils and neutrophils was performed manually and with an automated cell counter. ria assays measuring the same analytes were also compared with the results from cell counting and lateral icr assays. \\n results: the optimized assays showed analytical detection limits below the clinical ranges of 3.36 \u03bcg/l and 2.05 \u03bcg/l for epx and hnl, respectively. the recovery was 114.8%\u2013122.8% for epx and 94.5%\u201396.9% for hnl. the imprecision was 3%\u201317% cv for epx over the whole range and 5%\u201316% cv for hnl. the correlation coefficients between manually counted cells and lateral icr assays were 0.9 and 0.83 for epx and hnl, respectively. \\n conclusion: the numbers of eosinophils and neutrophils in small amounts of blood can be estimated in the point-of-care setting by means of fast lateral icr assays of epx and hnl."
        },
        {
            "id": "R25934",
            "label": "Development of a One Step Strip Test for the Detection of (Dihydro)streptomycin Residues in Raw Milk",
            "doi": "10.1080/09540100099607",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "the one step strip test described is a competitive immunoassay in which the detector reagent consists of colloidal gold particles coated with affinity purified monoclonal anti(dihydro)streptomycin antibodies. the capture reagent in the assay is a streptomycin- bovine serum albumin conjugate which is immobilised on the lateral flow membrane of the test device. in the test procedure, three drops of raw milk are brought into the sample well of the test device and allowed to migrate over the membrane. the more analyte present in the sample, the more effectively it will compete with the streptomycin immobilised on the membrane for binding to the limited amount of antibodies of the detector reagent. a sufficient amount of (dihydro)streptomycin in the sample will thus prevent the binding of the detector reagent to the streptomycin immobilised on the membrane, resulting in disappearance of the test line in the read out zone. using raw milk samples, spiked with either streptomycin or dihydrostreptomycin, complete disappearance of the test line was obtained with 160 ng ml\u22121 and 190 ng ml\u22121, respectively. this demonstrates that the test is applicable for screening raw milk samples for the presence of (dihydro)streptomycin residues at mrl level (eu: 0.2 mg (dihydro)streptomycin kg\u22121 milk). the major advantages of the one step strip test are that results can be obtained within 10 min and that all reagents are included in the test device."
        },
        {
            "id": "R25936",
            "label": "Rapid Determination of Fumonisin B1in Food Samples by Enzyme-Linked Immunosorbent Assay and Colloidal Gold Immunoassay",
            "doi": "10.1021/jf0530401",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "a rapid enzyme-linked immunosorbent assay (elisa) test (microwell plate) and a membrane-based colloidal gold immunoassay in flow-through and lateral-flow formats for the rapid detection of fumonisin b1 (fb1) were developed. the rapid microwell assay can be completed within 20 min with the detection limit of 0.5 +/- 0.2 microg/l. membrane-based colloidal gold immunoassays had a visual detection limit of 1.0 microg/l for fb1 with the detection time of <10 min. matrix interference was eliminated by 15-fold dilutions of methanol extracts with buffer. these immunoassays can be used as quantitative or qualitative tools for the rapid detection of fb1 residues in 10-20 min on-site."
        },
        {
            "id": "R25938",
            "label": "Development of an Ultrarapid One-Step Fluorescence Immunochromatographic Assay System for the Quantification of Microcystins",
            "doi": "10.1021/es026191i",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "microcystins are a family of potent toxic oligopeptides produced by freshwater cyanobacteria genera and have been a great threat to the welfare of humans and animals. there has been a great demand for developing a fast and convenient analytical method to detect microcystins. recently, direct competition elisa using monoclonal or polyclonal antibody has become the prevailing method for detecting microcystins. in this study, we report rapid quantification methods of microcystins using fluorescence for a detection signal and a lateral-flow-type immunochromatography as a separation system. the assay systems consist of a test strip housed in a disposable cartridge and a portable laser-fluorescence scanner. the components of a test strip are as follows: a nitrocellulose membrane, a sample pad, an absorption pad, and a backing card. a fluorescence scanner was designed to fit the cartridge and to quantify the distribution of the fluorescence intensity along the strip. when the calibration curve for an antibody-immobilized system was determined, a good linearity was displayed in the range from 125 to 2000 pg/ml of microcystin-lr. the linear-regression coefficient (r) was 0.938 between relative fluorescence intensity and the microcystin concentration. the limit of detection was determined to be 95.38 pg/ml. we then designed another biosensor system by changing an experimental format from the competition type to the inhibition type. when compared to the antibody-immobilized system, the antigen-immobilized assay detected a lower level of microcystin but did not discern microcystin-lr above 1000 pg/ml. the detection of limit for the antigen-immobilized system was 47.23 pg/ml. the linear regression coefficient (r) in the antigen-immobilized system equaled to 0.927. the reproducibility in the antigen-immobilized system was good through the entire range. the reproducibility in the antibody-immobilized system was relatively poor when compared to a mc-immobilized system. however, it still registered in the acceptable range of 7.32-9.91% except for the extreme ends of the mc concentration. finally, surface water was tested to check for potential matrix interference. the calibration curve displayed a similar pattern as did those for other matrixes, including pbs and tap water, although its sensitivity was a little less due to the interference with certain components in the surface water. overall, either of the biosensor systems can be used as a useful on-site detection tool for checking drinking water or surface water for microcystins. the laser-fluorescence scanner we developed is relatively small, transportable, and easy to use. thus, the samples can be analyzed for microcystins at the test site using a real-time base within 15 min without having to bring the samples back to the laboratory."
        },
        {
            "id": "R25940",
            "label": "Development of a one step strip test for the detection of sulfadimidine residues\u00e2\u0080\u00a0",
            "doi": "10.1039/a804695f",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "the one step strip test described is a competitive immunoassay in which the detector reagent consists of colloidal gold particles coated with affinity purified polyclonal anti-sulfadimidine (sdd) antibodies. the capture reagent in the assay is an sdd-ovalbumin conjugate which is immobilised on the lateral flow membrane of the test device. in the test procedure, 150 microliters (four drops) of a liquid sample (buffer, urine or milk) are brought into the sample well of the test device and allowed to migrate over the membrane. the more analyte present in the sample, the more effectively it will compete with the sdd immobilised on the membrane for binding to the limited amount of antibodies of the detector reagent. a sufficient amount of sdd in the sample will therefore prevent the binding of the detector reagent to the sdd immobilised on the membrane. therefore, a positive sample will not show a test line in the read-out zone. with spiked buffer or calf urine this was obtained at a level of > 10 ng ml-1 of sdd and with spiked (diluted) fresh cow milk at a level > 20 ng ml-1 of sdd. at these levels, the test is applicable only as a qualitative assay. the presence or absence of a test line indicates lower or higher levels of sdd, respectively. the major advantages of the one step strip test are that results can be obtained within 10 min and that all reagents are included in the test device."
        },
        {
            "id": "R25944",
            "label": "Development of an Immunochromatographic Lateral-Flow Test Strip for Rapid Detection of Sulfonamides in Eggs and Chicken Muscles",
            "doi": "10.1021/jf062523h",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "a rapid immunochromatographic lateral-flow test strip was developed in the competitive reaction format for the detection of sulfonamides in eggs and chicken muscle. a monoclonal antibody against the common structure of sulfonamides was conjugated to colloidal gold particles as the detection reagent and an n-sulfanilyl-4-aminobenzoic acid (sul)-bovine serum albumin (bsa) conjugate was immobilized to a nitrocellulose membrane as the capture reagent to prepare the test strip. with this method, it required only 15 min to accomplish the semiquantitative or quantitative detection of sulfonamides. the sensitivity to sulfonamides (sulfamonomethoxine, sulfamethoxydiazine, sulfadimethoxine, and sulfadiazine) was at least 10 ng/ml, as determined with an optical density scanner. by eye measurement, the sensitivity was 20 ng/ml for sulfamonomethoxine, sulfamethoxydiazine, and sulfadimethoxine and 40 ng/ml for sulfadiazine. on the basis of a sulfamonomethoxine standard curve, recoveries were from 89.5 to 95.6% for sulfamonomethoxine, from 89.5 to 95.1% for sulfamethoxydiazine, from 85.0 to 95.6% for sulfadimethoxine, and from 44.8 to 60.9% for sulfadiazine in egg and chicken muscle samples. a parallel analysis of 27 egg samples and 28 chicken muscle samples from the animal experiment showed that the differences between test strips and high-performance liquid chromatography (hplc) were from 0.8 to 11.2% for egg samples and from 2.2 to 34% for chicken muscle samples for the quantitative detection, and the agreement rates between test strips and hplc were 100%, based on the maximum allowed residue level of sulfadiazine (100 ng/g) established by the european union and china. in conclusion, the method is rapid and accurate for the detection of sulfonamides in eggs and chicken muscles."
        },
        {
            "id": "R25946",
            "label": "Principles of some novel rapid dipstick methods for detection and characterization of verotoxigenic Escherichia coli",
            "doi": "10.1046/j.1365-2672.2003.01989.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "aims: the verotoxigenic escherichia coli (vtec) serotype most commonly associated with verotoxin (vt) production is o157:h7, but other serotypes have also been implicated in food\u2010borne illness. these serotypes exhibit much greater genetic and biochemical diversity than e. coli o157:h7, making screening for all vtec difficult. here we describe development and testing of novel multi\u2010analyte antibody\u2010based dipstick methods for presumptive detection of vtec cells and vts, including non\u2010o157 serotypes."
        },
        {
            "id": "R25949",
            "label": "Rapid, Sensitive, and Specific Lateral-Flow Immunochromatographic Device To Measure Anti-Anthrax Protective Antigen Immunoglobulin G in Serum and Whole Blood",
            "doi": "10.1128/cvi.13.5.541-546.2006",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "abstract \\n \\n evidence from animals suggests that anti-anthrax protective antigen (pa) immunoglobulin g (igg) from vaccination with anthrax vaccine adsorbed (ava) is protective against\\n bacillus anthracis \\n infection. measurement of anti-pa igg in human sera can be performed using either enzyme-linked immunosorbent assay or fluorescent covalent microsphere immunoassay (elisa) (r. e. biagini, d. l. sammons, j. p. smith, b. a. mackenzie, c. a. striley, v. semenova, e. steward-clark, k. stamey, a. e. freeman, c. p. quinn, and j. e. snawder, clin. diagn. lab. immunol. 11:50-55, 2004). both these methods are laboratory based. we describe the development of a rapid lateral-flow immunochromatographic assay (lfia) test kit for the measurement of anti-pa igg in serum or whole-blood samples (30-\u03bcl samples) using colloidal gold nanoparticles as the detection reagent and an internal control. using sera from 19 anthrax ava vaccinees (anti-pa igg range, 2.4 to 340 \u03bcg/ml) and 10 controls and pa-supplemented whole-blood samples, we demonstrated that the lfia had a sensitivity of approximately 3 \u03bcg/ml anti-pa igg in serum and \u223c14 \u03bcg/ml anti-pa igg in whole blood. preabsorption of sera with pa yielded negative anti-pa lfias. the diagnostic sensitivity and specificity of the assay were 100% using elisa-measured anti-pa igg as the standard. this kit has utility in determining anti-pa antibody reactivity in the sera of individuals vaccinated with ava or individuals with clinical anthrax.\\n"
        },
        {
            "id": "R25957",
            "label": "A dipstick immunoassay to rapidly measure serum oestrone sulfate concentrations in horses",
            "doi": "10.1071/rd00062",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "\\na dipstick, competitive immunoassay for rapidly measuring serum oestrone\\nsulfate (os) concentrations in horses was developed to distinguish mares 100\\nor more days pregnant from non-pregnant animals. 6-ketoestrone\\n6-carboxymethyloxime conjugated to bovine serum albumin (oestrone cmo-bsa) was\\n\u2018dotted\u2019 25 mm from the bottom edge of 45 5 mm strips of\\npolyester-film-supported cellulose nitrate membrane, pore size 3 m. the strips\\nwere blocked, dried and a 15 5-mm cellulose absorbent sink attached 10 mm from\\nthe top of each strip. the manufactured dipsticks were stored with desiccant\\nat room temperature until used. a monoclonal antibody recognizing os was\\ncoated onto uniform, blue-dyed polystyrene microspheres (mean diameter, 0.31\\nm) by adsorption. after blocking, several washes and resuspension by\\nsonication, the antibody-coated microspheres were stored at 4\u02dac. the\\nconcentrations of oestrone cmo-bsa dotted onto the dipsticks and os antibody\\ncoated onto the microspheres were optimized to produce a test that allowed\\nmaximum discrimination between the concentrations of os found in serum of\\nmares 100 or more days pregnant (i.e. &gt;30 ng os ml\\n\u20131 ) relative to those found in non-pregnant mares\\n(i.e. &lt;10 ng os ml \u20131 ). to perform the\\ndipstick test, 30 l of carrier buffer, 10 l of os antibody-coated microspheres\\nand 10 l of os standard or serum sample were pipetted into a microwell and\\nmixed. a dipstick was placed in the solution. all the liquid migrated up the\\ndipstick into the absorbent sink within 15\u201320 min leaving a blue dot\\nwhere the ocmo-bsa had been placed. the intensity of colour of the blue dot,\\nwhich correlated inversely with the concentration of os in the standard or\\nserum sample, was assessed visually and by computer image analysis. an os\\nconcentration less than 5 ng ml \u20131 produced a deep\\nblue dot, 20 ng/ml a light blue dot and a concentration greater than 50 ng\\nml \u20131 a very faint blue dot, or none at all. serum\\nsamples from 42 non-pregnant mares and 40 mares over 100 days pregnant were\\nanalysed by the dipstick test. all the serum samples from non-pregnant mares\\nproduced dipsticks with deep blue dots that ranged in intensity from 20 to 38\\ncolour intensity units, equivalent to os concentrations less than 7 ng ml\\n\u20131 . sera from all the pregnant mares generated\\ndipsticks with either faint blue dots or none at all (i.e. \u00a3=5\\ncolour intensity units, equivalent to os concentrations &gt;40 ng ml\\n\u20131 ). it is concluded that this novel, rapid\\ndipstick immunoassay offers a practical, alternative means of analysing serum\\nos concentrations in horses, and enables mares that are 100 or more days\\npregnant to be distinguished from those that are not pregnant."
        },
        {
            "id": "R25959",
            "label": "Immunochromatographic Assay for Quantitation of Milk Progesterone.",
            "doi": "10.3891/acta.chem.scand.50-0141",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R25901",
                    "label": "Lateral flow (immuno)assay"
                }
            ],
            "abstract": "\"we describe a rapid immunochromatographic method for the quantitation of progesterone in bovine milk. the method is based on a 'competitive' assay format using the monoclonal antibody to progesterone and a progesterone-protein conjugate labelled with colloidal gold particles. the monoclonal antibody to progesterone is immobilized as a narrow detection zone on a porous membrane. the sample is mixed with colloidal gold particles coated with progesterone-protein conjugate, and the mixture is allowed to migrate past the detection zone. migration is facilitated by capillary forces. the amount of labelled progesterone-protein conjugate bound to the detection zone, as detected by photometric scanning, is inversely proportional to the amount of progesterone present in the sample. analysis is complete in less than 10 min. the method has a practical detection limit of 5 ng of progesterone per ml of bovine milk.\""
        },
        {
            "id": "R26067",
            "label": "Subjective and objective assessment of acoustical and overall environmental quality in secondary school classrooms",
            "doi": "10.1121/1.2816563",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R26064",
                    "label": "Factors influencing human comfort"
                }
            ],
            "abstract": "a subjective survey on perceived environmental quality has been carried out on 51 secondary-school classrooms, some of which have been acoustically renovated, and acoustical measurements were carried out in eight of the 51 classrooms, these eight being representative of the different types of classrooms that are the subject of the survey. a questionnaire, which included items on overall quality and its single aspects such as acoustical, thermal, indoor air and visual quality, has been administered to 1006 students. the students perceived that acoustical and visual quality had the most influence on their school performance and, with the same dissatisfaction for acoustical, thermal and indoor air quality, they attributed more relevance, in the overall quality judgment, to the acoustical condition. acoustical quality was correlated to speech comprehension, which was correlated to the speech transmission index, even though the index does not reflect all the aspects by which speech comprehension can be influenced. acoustical satisfaction was lower in nonrenovated classrooms, and one of the most important consequences of poor acoustics was a decrease in concentration. the stronger correlation between average noise disturbance scores and l(a max) levels, more than l(aeq) and l(a90), showed that students were more disturbed by intermittent than constant noise."
        },
        {
            "id": "R26071",
            "label": "A Comparative Study Of Discomfort Caused By Indoor Air Pollution, Thermal Load And Noisec",
            "doi": "10.1111/j.1600-0668.1993.00006.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R26064",
                    "label": "Factors influencing human comfort"
                }
            ],
            "abstract": "the relative importance of sensory air pollution, thermal load and noise was studied under controlled conditions in two identical environmental chambers. in one chamber subjects were exposed to various levels of either thermal load or poor indoor air quality. for each condition tested in this chamber, the subjects were exposed to a number of noise levels in an adjacent chamber with neutral thermal conditions and good indoor air quality in order to determine a noise level causing the same degree of discomfort. a total of 68 comparisons of the conditions in the two chambers were made by the same group of 16 subjects after one-minute exposure in each chamber. in the operative temperature range of 23\u201329\u00b0c, a 1\u00b0c change in operative temperature was found to have the same effect on human comfort as a change in perceived air quality of 2.4 decipol or a change in noise level of 3.9 db. for levels of perceived air quality up to 10 decipol, a 1 -decipol change in perceived air quality had the same effect on human comfort as a change in noise level of 1.2 db. a relationship between traffic noise level and percentage dissatisfied was established"
        },
        {
            "id": "R26073",
            "label": "Quantifying occupant comfort: are combined indices of the indoor environment practicable?",
            "doi": "10.1080/09613210500161950",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R26064",
                    "label": "Factors influencing human comfort"
                }
            ],
            "abstract": "\"what are the various ways in which evaluation of the several aspects of the indoor environment might combine to form an occupant's overall assessment of that environment? data from an environmental survey of 26 offices in europe (the smart controls and thermal comfort, or scats, project) are used. these show that dissatisfaction with one or more aspects of the indoor environment does not necessarily produce dissatisfaction with the environment overall. conversely, satisfaction with one or more environmental aspect does not necessarily produce satisfaction with the total environment. building occupants balance the good features against the bad to reach their overall assessment. not all aspects are equally important in this subjective averaging process. satisfaction with warmth and air quality is more important than satisfaction with the level of lighting or humidity. the relative importance of the various aspects differed from country to country, making it impossible to develop an internationally valid index to rate office environments by means of a single number. the best linear index constructed from the data failed to rank the indoor environments of the buildings in the correct order, as defined by the occupants' overall assessments. it is therefore wise to assess each of the several aspects separately rather than rely only on a combined index.\""
        },
        {
            "id": "R26077",
            "label": "Perceived Importance of the Quality of the Indoor Environment in Commercial Buildings",
            "doi": "10.1177/1420326x07080463",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R26064",
                    "label": "Factors influencing human comfort"
                }
            ],
            "abstract": "recognition of the importance of the quality of the indoor environment (ieq) to health, comfort and productivity of building end users has produced increasing numbers of voluntary schemes whose assessment embraces a wide spectrum of environmental attributes. studies which aim to derive appropriate weighting factors for these attributes through soliciting the perceived importance from experts are abundant. this article reports the findings of a study which, based on face-to-face interviews with 548 end users and 66 building professionals, processed their perceived importance of ieq using the analytical hierarchy process (ahp). attributes included were thermal comfort, air cleanliness, odor and noise associated with the air conditioning system of typical commercial buildings. correlation analysis of the ranking results of the ahp weights revealed the difference in perceived importance of the attributes according to gender of the respondents. other factors also found to have influence on the perceived importance of the ieq were whether the respondents were professionals or other end users and the reason for them working or visiting the buildings and the duration of their stay. these all varied with psychophysical factors such as personal experiences, needs and expectations. further work is needed to study whether the weighting factors should be derived from the perceptions of experts, end users, or a balance between the two."
        },
        {
            "id": "R27113",
            "label": "Kinetics of acetylcholinesterase immobilized on polyethylene tubing",
            "doi": "10.1139/o79-156",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27070",
                    "label": "Immobilization of Enzymes"
                }
            ],
            "abstract": "acetylcholinesterase was covalently attached to the inner surface of polyethylene tubing. initial oxidation generated surface carboxylic groups which, on reaction with thionyl chloride, produced acid chloride groups; these were caused to react with excess ethylenediamine. the amine groups on the surface were linked to glutaraldehyde, and acetylcholinesterase was then attached to the surface. various kinetic tests showed the catalysis of the hydrolysis of acetylthiocholine iodide to be diffusion controlled. the apparent michaelis constants were strongly dependent on flow rate and were much larger than the value for the free enzyme. rate measurements over the temperature range 6\u201342 \u00b0c showed changes in activation energies consistent with diffusion control."
        },
        {
            "id": "R27270",
            "label": "Building adaptive universities: Emerging organisational forms based on experiences of European and us universities",
            "doi": "10.1080/13583883.2001.9967046",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27265",
                    "label": "University entrepreneurship categories"
                }
            ],
            "abstract": "universities are facing dynamic environments to which they have to respond by developing new organisational forms often to enhance adaptation. thereby, governance,management and leadership structures are changing \u2013 aiming at increased flexibility,efficiency and effectiveness. this involves new procedures to manage the relationship with the environment, new authority structures within universities, and new ways of resource allocation. hence, this paper will present empirical results from a cross-national study of adaptive university structures vis-a-vis a changing socioeconomic environment. based upon that, new organisational forms are introduced which better support and enhance the current trend towards more entrepreneurial universities."
        },
        {
            "id": "R27272",
            "label": "The evolution of the entrepreneurial university",
            "doi": "10.1504/ijtg.2004.004551",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27265",
                    "label": "University entrepreneurship categories"
                }
            ],
            "abstract": "a second academic revolution, integrating a mission for economic and social development is transforming the traditional teaching and research university into an entrepreneurial university. the triple helix thesis postulates that the interaction among university-industry-government is the key to improving the conditions for innovation in a knowledge-based society. more than the development of new products in firms, innovation is the creation of new arrangements among the institutional spheres that foster the conditions for innovation. invention of organisational innovations, new social arrangements and new channels for interaction becomes as important as the creation of physical devices in speeding the pace of innovation. this paper draws for data on interviews conducted by the author in the usa, sweden, brazil, italy, portugal and denmark."
        },
        {
            "id": "R27276",
            "label": "University entrepreneurship: a taxonomy of the literature",
            "doi": "10.1093/icc/dtm023",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27265",
                    "label": "University entrepreneurship categories"
                }
            ],
            "abstract": "the literature on university entrepreneurship is rapidly expanding, in both the united states and europe. since the literature is also fairly fragmented, however, we submit that it is time to take stock of the current knowledge to provide directions for future research and guideposts for policy makers. to accomplish this, we present an unusually comprehensive and detailed literature analysis of the stream of research on university entrepreneurship, now encompassing 173 articles published in a variety of academic journals. four major research streams emerge in this area of study: (i) entrepreneurial research university, (ii) productivity of technology transfer offices, (iii) new firm creation, and (iv) environmental context including networks of innovation. we inductively derive a framework describing the dynamic process of university entrepreneurship based on a synthesis of the literature. we submit that this framework is useful in guiding future research on this important, yet complex and under-researched topic."
        },
        {
            "id": "R27389",
            "label": "Robust load frequency control using genetic algorithms and linear matrix inequalities",
            "doi": "10.1109/tpwrs.2003.811005",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27381",
                    "label": "Power systems"
                }
            ],
            "abstract": "in this paper, two robust decentralized control design methodologies for load frequency control (lfc) are proposed. the first one is based on h/sub /spl infin// control design using linear matrix inequalities (lmi) technique in order to obtain robustness against uncertainties. the second controller has a simpler structure, which is more appealing from an implementation point of view, and it is tuned by a proposed novel robust control design algorithm to achieve the same robust performance as the first one. more specifically, genetic algorithms (gas) optimization is used to tune the control parameters of the proportional-integral (pi) controller subject to the h/sub /spl infin// constraints in terms of lmi. hence, the second control design is called galmi. both proposed controllers are tested on a three-area power system with three scenarios of load disturbances to demonstrate their robust performances."
        },
        {
            "id": "R27394",
            "label": "Application of Linear Matrix Inequalities for Load Frequency Control With Communication Delays",
            "doi": "10.1109/tpwrs.2004.831670",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27381",
                    "label": "Power systems"
                }
            ],
            "abstract": "load frequency control has been used for decades in power systems. traditionally, this has been a centralized control by area with communication over a dedicated and closed network. new regulatory guidelines allow for competitive markets to supply this load frequency control. in order to allow an effective market operation, an open communication infrastructure is needed to support an increasing complex system of controls. while such a system has great advantage in terms of cost and reliability, the possibility of communication signal delays and other problems must be carefully analyzed. this paper presents a load frequency control method based on linear matrix inequalities. the primary aim is to find a robust controller that can ensure good performance despite indeterminate delays and other problems in the communication network."
        },
        {
            "id": "R27396",
            "label": "On Load\u00e2\u0080\u0093Frequency Regulation With Time Delays: Design and Real-Time Implementation",
            "doi": "10.1109/tec.2008.2003205",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27381",
                    "label": "Power systems"
                }
            ],
            "abstract": "this paper addresses a robust decentralized proportional-integral (pi) control design for power system load-frequency regulation with communication delays. in the proposed methodology, the pi-based load-frequency control (lfc) problem is reduced to a static output feedback control synthesis for a multiple-delay system. the proposed control method gives a suboptimal solution using a developed iterative linear matrix inequalities algorithm via the mixed h 2/h infin control technique. the control strategy is suitable for lfc applications that usually employ the pi control. to demonstrate the efficiency of the proposed control strategy, an experimental study has been performed at the research laboratory, kyushu electric power company, japan."
        },
        {
            "id": "R27398",
            "label": "Delay-dependent stability for load frequency control with constant and time-varying delays",
            "doi": "10.1109/pes.2009.5275834",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27381",
                    "label": "Power systems"
                }
            ],
            "abstract": "load frequency control (lfc) requires transmitting measurements from remote rtus to control center and control signals from the control center to plant side. constant delays exist in the conventional dedicated communication channels, while the future usage of open communication networks will introduce time-varying delays. those delays would degrade the dynamic performance of lfc and in the worst case, cause instability. the maximal delay time which allows an lfc scheme embedded with controllers to retain stable is defined as the delay margin. this paper investigates the delay-dependent stability of the lfc scheme by using lyaponuv-theory based delay-dependent criterion and linear matrix inequalities (lmis) techniques. case studies are carried out based on one-area and multi-area lfc schemes installed with proportional-integral (pi) controllers, respectively. relationship between the gains of pi controller and the delay margin of the lfc scheme are investigated and results obtained can be used to tune the pi controllers to achieve a compromise between the dynamic performance and the delay margin. both constant and time-varying delays are considered. the effectiveness of the criterion used is verified by simulation studies."
        },
        {
            "id": "R27466",
            "label": "Productivit\u00c3\u00a9 et salaire des travailleurs \u00c3\u00a2g\u00c3\u00a9s",
            "doi": "10.3406/rfeco.2003.1482",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27465",
                    "label": "Workforce Age and Innovation"
                }
            ],
            "abstract": "\"[fre] nous evaluons de facon conjointe les differences de productivite et de remuneration existant en france entre diverses categories de travailleurs au moyen d'une nouvelle base de donnees qui reunit des informations tant sur les employes que sur leurs employeurs. completant une methodologie nouvelle proposee au depart par heller- stein, neumark et troske [1999], nous adoptons des hypotheses moins contraignantes et fournissons une methode utilisant le cout du travail pour les employeurs. de facon surprenante, les resultats trouves pour la france sont tres differents de ceux obtenus pour les etats-unis, et plus proches des resultats en norvege : dans le secteur manufacturier, nous constatons que les travailleurs \u00e2ges sont plus payes par rapport aux travailleurs jeunes que leur difference de productivite ne le laisserait supposer. la robustesse de ces resultats semble confirmee a travers le temps, les secteurs d'activite et les hypotheses retenues. [eng] in this study we analyse the differences between productivity levels and earnings across a range of categories of workers in france, drawing on a new database which brings together data from employers and employees. we take as our starting point the methodology first introduced by hellerstein, neumark and troske [1999], and develop it further by applying les restrictive assumptions and by using a new method which takes into account labour costs incurred by the employers. the results obtained for france are surprisingly different to those for the united states and in fact are closest to the results obtained for norway. for example, we find that in the manufacturing sector, relatively to younger workers, older workers are paid more than the difference in productivity between the two age groups would suggest. these results appear to be robust over time regardless of the sector studied or the assumptions used.\""
        },
        {
            "id": "R27469",
            "label": "Age, seniority and labour costs: lessons from the Finnish IT revolution",
            "doi": "10.1111/j.1468-0327.2007.00175.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27465",
                    "label": "Workforce Age and Innovation"
                }
            ],
            "abstract": "\"the bad labour market performance of the workforce over 50 indicates that an aged workforce is often a burden for firms. our paper seeks to investigate whether and why this is the case by providing evidence on the relation between age, seniority and experience, on the one hand, and the main components of labour costs, namely productivity and wages, on the other, for a sample of plants in three manufacturing industries (\\'forest\\', \\'industrial machinery\\' and \\'electronics\\') in finland during the it revolution in the 1990s. in \\'average\\' industries - those not undergoing major technological shocks - productivity and wages keep rising almost indefinitely with the accumulation of either seniority (in the forest industry) or experience (in the industry producing industrial machinery). in these industries, the skill depreciation often associated with higher seniority beyond a certain threshold does not seemingly raise labour costs. in electronics, instead, the seniority-productivity profile shows a positive relation first and then becomes negative as one looks at plants with higher average seniority. this body of evidence is consistent with the idea that fast technical change brings about accelerated skill depreciation of senior workers. we cannot rule out, however, that our correlations are also simultaneously produced by worker movements across plants. the seniority-earnings profile in electronics is instead rather similar to that observed for the other industries - a likely symptom of the prevailing finnish wage bargaining institutions which tend to make seniority one essential element of wage determination. in the end, seniority matters for labour costs, not age as such. but only in high-tech industries, not in the economy at large. this is well tuned with previous research on gross flows of workers and jobs in the us and other oecd countries which unveiled the productivity-driving role of resource reallocation (or lack thereof) between plants. to improve the employability of the elderly at times of fast technical change, public policy should thus divert resources away from preserving existing jobs and lend more attention to the retraining of old workers to ease their reallocation away from less productive plants (or plants where they have become less productive) into new jobs.\" copyright (c) cepr, ces, msh, 2007."
        },
        {
            "id": "R27472",
            "label": "Aging, labor turn- over and firm performance",
            "doi": "10.2139/ssrn.984683",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27465",
                    "label": "Workforce Age and Innovation"
                }
            ],
            "abstract": "we study whether older workers are costly to firms. our estimation equations are derived from a variant of the decomposition methods frequently used for measuring micro-level sources of industry productivity growth. by using comprehensive linked employer-employee data from the finnish business sector, we study the productivity and wage effects, and hence the profitability effects, of hiring and separation of younger and older workers. the evidence shows that separations of older workers are profitable to firms, especially in the manufacturing ict-industries. robustness checks include the use of regional labor supply and other variables as instruments for the potential endogeneity of the labor flows."
        },
        {
            "id": "R27480",
            "label": "Does the ageing workforce hamper the innovativeness of firms? (No) evidence from Germany",
            "doi": "10.1504/ijhrdm.2009.023452",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27465",
                    "label": "Workforce Age and Innovation"
                }
            ],
            "abstract": "due to demographic changes, the personnel structure of the workforce in countries like germany and japan will change considerably in the next few years. at the same time, companies need creative and skilled human resources to innovate. we analysed data from the 2001 german community innovation survey to explore the impact of personnel structure (share of older employees, skills shortages, share of highly skilled employees) on innovation input and output. overall, we did not find support for a negative effect of a high share of older employees in a company on innovation output. however, companies with a high share of older employees tended to invest less in further training (considered innovation input). this contradicts the call for lifelong learning. in accordance with our propositions, a high share of highly skilled employees had a positive effect on innovation input and output. companies which experienced skills shortages were more likely to invest in further training. however, they were, somewhat surprisingly, more innovative than companies which did not suffer from skills shortages."
        },
        {
            "id": "R27708",
            "label": "Nuclear energy consumption and economic growth in the US: an empirical note",
            "doi": "10.1080/15567240802533955",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27485",
                    "label": "Energy-economic growth"
                }
            ],
            "abstract": "abstract this empirical note examines the relationship between nuclear energy consumption growth and real gross domestic product (gdp) growth within a neoclassical production function framework for the us using annual data from 1957 to 2006. the toda-yamamoto (1995) test for long-run granger-causality reveals the absence of granger-causality between nuclear energy consumption growth and real gdp growth which supports the neutrality hypothesis within the energy consumption-economic growth literature."
        },
        {
            "id": "R27719",
            "label": "On biomass energy consumption and real Output in the U",
            "doi": "10.1080/15567240903160906",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R27485",
                    "label": "Energy-economic growth"
                }
            ],
            "abstract": "abstract this empirical note utilizes us annual data from 1949 to 2007 to examine the causal relationship between biomass energy consumption and real gross domestic product (gdp) within a multivariate framework. toda-yamamoto causality tests reveal unidirectional causality from biomass energy consumption to real gdp supportive of the growth hypothesis."
        },
        {
            "id": "R28503",
            "label": "Accelerated life testing of a traction inverter",
            "doi": "10.1049/pe:19990511",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28493",
                    "label": "Power Cycle Testing"
                }
            ],
            "abstract": "an igbt based traction inverter drive system has been developed for the new generation of northern line trains for london underground. new inverter designs may experience reliability problems associated with new manufacturing build as well as design integrity. in this case the use of igbts introduces a major change from the switching components used previously in this type of application and the cost implications to the equipment supplier of unreliable operation would be extremely large. assurance that a number of known areas of concern with reliability of the equipment has been adequately covered in the design process is therefore essential. a particular concern is with the igbt wire bonded construction with the wires becoming detached under conditions of severe thermal cycling. the particular concern was the station to station running where the substrate temperature might rise and fall through more than 20\u00b0c, due to load current variation, whilst the heat-sink temperature would stay constant. to ensure that the whole inverter circuit will be sufficiently reliable in service a test system was built which would allow an accelerated life test programme to be carried out on the new inverter design prior to its delivery. an innovative test circuit was used in which the electrical operating conditions are matched to those which would be experienced in service but at an accelerated rate. this is achieved by operating the test circuit continuously under an automatic and unmanned test regime. (4 pages)"
        },
        {
            "id": "R28506",
            "label": "Power cycling with high temperature swing of discrete components based on different technologies",
            "doi": "10.1109/pesc.2004.1355239",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28493",
                    "label": "Power Cycle Testing"
                }
            ],
            "abstract": "we present the results of power cycling tests of transfer molded, dcb and copper based power components at temperature swings up to 155 k. the results of the dcb based components are statistically analysed with weibull distribution. an analysis of the components after the tests provides an overview on the failure mechanisms. the results of the dcb based, transfer molded components exceed the expectations based on extrapolation of lesit results."
        },
        {
            "id": "R28510",
            "label": "Accelerated testing of IGBT power modules to determine time to failure",
            "doi": "10.1049/cp.2010.0123",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28493",
                    "label": "Power Cycle Testing"
                }
            ],
            "abstract": "reliability of igbt power modules is crucial to their use in failure critical systems and with the advent of all electric and hybrid vehicles the need for good reliability data for igbt modules is essential. igbt power modules are constructed of layers and power dies, all of which are interconnected with solder or bond wires. these materials have dissimilar coefficients of thermal expansion and during its life, the igbt module experiences temperature changes which cause stresses to build up in the various materials eventually resulting in the failure of the module. because of the high robustness of these modules, testing in service for time to failure can be a very lengthy process. this paper describes a procedure and test rig which can automatically temperature cycle igbt power modules in a very short time and determine their life expectancy. the paper also shows test results from a number of modules and correlates this data to provide a time to failure for the modules."
        },
        {
            "id": "R28517",
            "label": "Material requirements for high voltage, high power IGBT devices",
            "doi": "10.1016/s0038-1101(98)00209-3",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28493",
                    "label": "Power Cycle Testing"
                }
            ],
            "abstract": "abstract the two basic package types of current igbt modules, which evolved from opposing requirements of traction and power transmission applications, are presented. it is shown that reliability and lifetime aspects given by traction puts most stringent limitations on the choice of materials at given cost targets. the materials used today for high power packaging and the future developments of high power igbt-packages are discussed."
        },
        {
            "id": "R28891",
            "label": "Simulation based comparison of semiconductor AMHS alternatives: continuous flow vs. overhead monorail",
            "doi": "10.1109/wsc.2000.899104",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "\"automation is an essential component in today's semiconductor manufacturing. as factories migrate to 300 mm technology, automated handling becomes increasingly important for variety of ergonomic, safety, and yield considerations. traditional semiconductor amhs systems, such as the overhead monorail vehicles (omv) or overhead hoist, can be overly expensive. cost projections for a 300 mm inter/intrabay amhs installation are in the range of $50 m-$100 m. as an alternative, a lower cost alternative amhs, called continuous flow transport has been proposed. the cft system is similar to what has historically been identified as a conveyor based movement system. the cft system provides cost savings at reduced flexibility and longer delivery time. this study compares the cft to overhead monorail transport, determining a cumulative delivery time distribution. as expected, the cft system requires a longer average delivery time interval than omv, but may provide total savings through reduced transport variability.\""
        },
        {
            "id": "R28898",
            "label": "Integration of 300 mm fab layouts and material handling automation",
            "doi": "10.1109/issm.1999.808729",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "\"we present key approaches and methodologies from intel's 300 mm factory integration efforts. the topics discussed in this paper are aimed at cross-functional optimization of fab layouts, automated material handling systems (amhs) and operations. we discuss the key benefits of up front understanding of the interactions and investigate specific attributes in layouts and amhs configurations where the integrated design/analysis is addressing cost-benefits and flexibility trade-offs needed in the high volume 300 mm factories.\""
        },
        {
            "id": "R28900",
            "label": "A simulation-based experiment for comparing AMHS performance in a semiconductor fabrication facility",
            "doi": "10.1109/66.939828",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "as the cost and complexity of constructing a semiconductor fabrication facility increases, responsive tools are needed for designing and planning its operations. discrete-event simulation paired with design of experiments is an effective combination. this article demonstrates how simulation in combination with design of experiments is used to compare the intrabay layout of two automated material handling systems. the difference in stocker robot utilization, number of vehicle moves per hour, and average delivery time for the two intrabay layouts will be compared using a fractional factorial experimental design. the study demonstrates that the distributed storage option is preferable for maximizing manufacturing performance. the solution procedure has general applicability as a tutorial for practitioners."
        },
        {
            "id": "R28908",
            "label": "An AGV routing policy reflecting the current and future state of semiconductor and LCD production lines",
            "doi": "10.1080/00207540110056261",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "\"this paper presents an efficient policy for agv and part routing in semiconductor and lcd production bays using information on the future state of systems where agvs play a central role in material handling. these highly informative systems maintain a great deal of information on current and near-future status, such as the arrival and operation completion times of parts, thereby enabling a new approach for production shop control. efficient control of agvs is vital in semiconductor and lcd plants because agv systems often limit the total production capacity of these very expensive plants. with the proposed procedure, the cell controller records the future events chronologically and uses this information to determine the destination and source of parts between the parts' operation machine and temporary storage. it is shown by simulation that the new control policy reduces agv requirements and flow time of parts.\""
        },
        {
            "id": "R28912",
            "label": "Capacity calculation of an AGV system in a MP2 wafer fab by means of simulation",
            "doi": "10.1109/issm.2001.962996",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "\"the transport of wafers inside a multiprocess multiproduct wafer factory is a complex logistic process. in philips' mos-3 waferfab this transport is carried out by a so-called automated guided vehicle (agv) system. in this paper a dynamic model is presented of the agv system of mos-3. the advantages of creating such a model are twofold. first of all, the model can be used to analyse the logistics, layout, algorithms and behaviour of the current agv system. secondly, the model can analyse and optimise possible changes that can be made to the agv system in the future.\""
        },
        {
            "id": "R28919",
            "label": "Simulation analysis of dispatching rules for an automated interbay material handling system in wafer fab",
            "doi": "10.1080/00207540010005718",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "here, the performance evaluation of a double-loop interbay automated material handling system (amhs) in wafer fab was analysed by considering the effects of the dispatching rules. discrete event simulation models based on simple++ were developed to implement the heuristic dispatching rules in such an amhs system with a zone control scheme to avoid vehicle collision. the layout of an interbay system is a combination configuration in which the hallway contains double loops and the vehicles have double capacity. the results show that the dispatching rule has a significant impact on average transport time, waiting time, throughput and vehicle utilization. the combination of the shortest distance with nearest vehicle and the first encounter first served rule outperformed the other rules. furthermore, the relationship between vehicle number and material flow rate by experimenting with a simulation model was investigated. the optimum combination of these two factors can be obtained by response surface methodology."
        },
        {
            "id": "R28923",
            "label": "Simulating the transport and scheduling of priority lots in semiconductor factories",
            "doi": "10.1109/wsc.2002.1166407",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "as the high technology product market becomes more dynamic and competitive, chip manufacturers need to bring products to customers in short periods of time. as a result, semiconductor fabrication plants regularly contain lots with priority status. these lots have several unique characteristics compared to other production lots, both in terms of lot transport and scheduling on tools. these lots consume tool capacity that may impact the factory output rate. priority lots also have specific policies for transport. the impact of these priority lots on other lots in the fabrication is not easily quantified, as many factors are involved. dynamic factory and amhs simulation models are capable of capturing the variability of a factory, and the interactions of critical constraints that prevent predictable manufacturing. this paper presents a breakthrough modeling approach to study the behaviors of priority lots, and to quantify their impact to manufacturing."
        },
        {
            "id": "R28926",
            "label": "Operational modeling and simulation of an inter-bay AMHS in semiconductor wafer fabrication",
            "doi": "10.1109/wsc.2002.1166405",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "this paper studies the operational logic in an inter-bay automated material handling system (amhs) in semiconductor wafer fabrication. this system consists of stockers located in a two-floor layout. automated moving devices transfer lots between stockers within the same floor (intra-floor lot transfer) or between different floors (inter-floor lot transfer). intra-floor lot-transferring transports use a two-rail one-directional system, whereas inter-floor lot-transferring transports use lifters. the decision problem consists of selecting rails and lifters that minimize average lot-delivery time. several operation rules to deliver lots from source stocker to destination stocker are proposed and their performance is evaluated by discrete event simulation."
        },
        {
            "id": "R28934",
            "label": "Vehicle positioning in complex automated transport systems",
            "doi": "10.1109/etfa.2005.1612676",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28890",
                    "label": "Automated wafer-transport systems"
                }
            ],
            "abstract": "this paper addresses the problem of vehicle positioning for automated transport in full-automated manufacturing systems. this study is motivated by the complexity of vehicle control found in semiconductor fabrication where the material handling network path is composed of multiple interconnected loops. we propose an integer linear program that minimizes the maximum time needed to serve a transport request. we also present a variant of the model in order to take into account the utilization rate of vehicles. the practical usefulness of the model is also discussed"
        },
        {
            "id": "R28943",
            "label": "Software Risk Management: Principles and Practices",
            "doi": "10.1109/52.62930",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28942",
                    "label": "Software Project Risks"
                }
            ],
            "abstract": "the emerging discipline of software risk management is described. it is defined as an attempt to formalize the risk-oriented correlates of success into a readily applicable set of principles and practices. its objectives are to identify, address, and eliminate risk items before they become either threats to successful software operation or major sources of software rework. the basic concepts are set forth, and the major steps and techniques involved in software risk management are explained. suggestions for implementing risk management are provided. >"
        },
        {
            "id": "R28946",
            "label": "Identifying Software Project Risks: An International Delphi Study\u00e2\u0080\u009d",
            "doi": "10.1080/07421222.2001.11045662",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28942",
                    "label": "Software Project Risks"
                }
            ],
            "abstract": "advocates of software risk management claim that by identifying and analyzing threats to success (i.e., risks) action can be taken to reduce the chance of failure of a project. the first step in the risk management process is to identify the risk itself, so that appropriate countermeasures can be taken. one problem in this task, however, is that no validated lists are available to help the project manager understand the nature and types of risks typically faced in a software project. this paper represents a first step toward alleviating this problem by developing an authoritative list of common risk factors. we deploy a rigorous data collection method called a \"ranking-type\" delphi survey to produce a rank-order list of risk factors. this data collection method is designed to elicit and organize opinions of a panel of experts through iterative, controlled feedback. three simultaneous surveys were conducted in three different settings: hong kong, finland, and the united states. this was done to broaden our view of the types of risks, rather than relying on the view of a single culture-an aspect that has been ignored in past risk management research. in forming the three panels, we recruited experienced project managers in each country. the paper presents the obtained risk factor list, compares it with other published risk factor lists for completeness and variation, and analyzes common features and differences in risk factor rankings in the three countries. we conclude by discussing implications of our findings for both research and improving risk management practice."
        },
        {
            "id": "R28965",
            "label": "Prioritizing Clinical Information System Project Risk Factors: A Delphi Study",
            "doi": "10.1109/hicss.2008.354",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28942",
                    "label": "Software Project Risks"
                }
            ],
            "abstract": "identifying the risks associated with the implementation of clinical information systems (cis) in health care organizations can be a major challenge for managers, clinicians, and it specialists, as there are numerous ways in which they can be described and categorized. risks vary in nature, severity, and consequence, so it is important that those considered to be high-level risks be identified, understood, and managed. this study addresses this issue by first reviewing the extant literature on it/cis project risks, and second conducting a delphi survey among 21 experts highly involved in cis projects in canada. in addition to providing a comprehensive list of risk factors and their relative importance, this study is helpful in unifying the literature on it implementation and health informatics. our risk factor-oriented research actually confirmed many of the factors found to be important in both these streams."
        },
        {
            "id": "R28975",
            "label": "Extensive Facial Landmark Localization with Coarse-to-Fine Convolutional Network Cascade",
            "doi": "10.1109/iccvw.2013.58",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28968",
                    "label": "Facial Landmark Detection"
                }
            ],
            "abstract": "we present a new approach to localize extensive facial landmarks with a coarse-to-fine convolutional network cascade. deep convolutional neural networks (dcnn) have been successfully utilized in facial landmark localization for two-fold advantages: 1) geometric constraints among facial points are implicitly utilized, 2) huge amount of training data can be leveraged. however, in the task of extensive facial landmark localization, a large number of facial landmarks (more than 50 points) are required to be located in a unified system, which poses great difficulty in the structure design and training process of traditional convolutional networks. in this paper, we design a four-level convolutional network cascade, which tackles the problem in a coarse-to-fine manner. in our system, each network level is trained to locally refine a subset of facial landmarks generated by previous network levels. in addition, each level predicts explicit geometric constraints (the position and rotation angles of a specific facial component) to rectify the inputs of the current network level. the combination of coarse-to-fine cascade and geometric refinement enables our system to locate extensive facial landmarks (68 points) accurately in the 300-w facial landmark localization challenge."
        },
        {
            "id": "R28979",
            "label": "Large-Pose Face Alignment via CNN-Based Dense 3D Model Fitting",
            "doi": "10.1109/cvpr.2016.454",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R28968",
                    "label": "Facial Landmark Detection"
                }
            ],
            "abstract": "large-pose face alignment is a very challenging problem in computer vision, which is used as a prerequisite for many important vision tasks, e.g, face recognition and 3d face reconstruction. recently, there have been a few attempts to solve this problem, but still more research is needed to achieve highly accurate results. in this paper, we propose a face alignment method for large-pose face images, by combining the powerful cascaded cnn regressor method and 3dmm. we formulate the face alignment as a 3dmm fitting problem, where the camera projection matrix and 3d shape parameters are estimated by a cascade of cnn-based regressors. the dense 3d shape allows us to design pose-invariant appearance features for effective cnn learning. extensive experiments are conducted on the challenging databases (aflw and afw), with comparison to the state of the art."
        },
        {
            "id": "R29243",
            "label": "Critical elements for a successful enterprise resource planning implementation in small-and medium-sized enterprises",
            "doi": "10.1080/00207540410001671679",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "the body of research relating to the implementation of enterprise resource planning (erp) systems in small- and medium-sized enterprises (smes) has been increasing rapidly over the last few years. it is important, particularly for smes, to recognize the elements for a successful erp implementation in their environments. this research aims to examine the critical elements that constitute a successful erp implementation in smes. the objective is to identify the constituents within the critical elements. a comprehensive literature review and interviews with eight smes in the uk were carried out. the results serve as the basic input into the formation of the critical elements and their constituents. three main critical elements are formed: critical success factors, critical people and critical uncertainties. within each critical element, the related constituents are identified. using the process theory approach, the constituents within each critical element are linked to their specific phase(s) of erp implementation. ten constituents for critical success factors were found, nine constituents for critical people and 21 constituents for critical uncertainties. the research suggests that a successful erp implementation often requires the identification and management of the critical elements and their constituents at each phase of implementation. the results are constructed as a reference framework that aims to provide researchers and practitioners with indicators and guidelines to improve the success rate of erp implementation in smes."
        },
        {
            "id": "R29248",
            "label": "ERP systems and open source: an initial review and some implications for SMEs",
            "doi": "10.1108/17410390810911230",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "purpose the purpose of this paper is to further build up the knowledge about reasons for small and mid\u2010sized enterprises (smes) to adopt open source enterprise resource planning (erp) systems. design/methodology/approach the paper presents and analyses findings in articles about proprietary erps and open source erps. in addition, a limited investigation of the distribution channel sourceforge for open source is made. findings the cost perspective seems to receive a high attention regarding adoption of open source erps. this can be questioned and the main conclusion is that costs seem to have a secondary role in adoption or non adoption of open source erps. research limitations/implications the paper is mainly a conceptual paper written from a literature review. the ambition is to search support for the findings by doing more research in the area. practical implications the findings presented are of interest both for developers of proprietary erps as well as smes since it is shown that there are definitely reasons other than costs involved when deciding on proprietary erps or open source erps. originality/value it can be argued that there is a lack of research conducted and published about why smes choose open source erps instead of proprietary erps. this paper identifies the gap and suggests future research directions about this subject."
        },
        {
            "id": "R29252",
            "label": "The ERP implementation of SME in China",
            "doi": "10.1109/icsssm.2009.5174870",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "enterprise resource planning-erp implementing of small and middle size enterprise \u2014 sme is different from the large one. based on the analysis on the character of erp marketing and smes of china, 6 critical success factors are recommended. the research suggests that the top management support is most important to erp implement in sme of china, in which paternalism prevails. database of management and capital are main obstacles. erp 1 or erp 2 fits to demand of sme; high power project team has tremendous significance in the situation of absence of it engineer for sme; education and training is helpful to successfully erp implementing. the results service as better understanding the erp implementation of sme in china and gaining the good performance of erp implementation."
        },
        {
            "id": "R29255",
            "label": "A Comparative Study of Issues Affecting ERP Implementation in Large Scale and Small Medium Scale Enterprises in India: A Pareto Approach",
            "doi": "10.5120/1192-1670",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "paper attempts to explore and identify issues affecting enterprise resource planning (erp) implementation in context to indian small and medium enterprises (smes) and large enterprises. issues which are considered more important for large scale enterprises may not be of equal importance for a small and medium scale enterprise and hence replicating the implementation experience which holds for large organizations will not a wise approach on the part of the implementation vendors targeting small scale enterprises. this paper attempts to highlight those specific issues where a different approach needs to be adopted. pareto analysis has been applied to identify the issues for indian smes and large scale enterprises as available from the published literature. also by doing comparative analysis between the identified issues for indian large enterprises and smes four issues are proved to be crucial for smes in india but not for large enterprises such as proper system implementation strategy, clearly defined scope of implementation procedure, proper project planning and minimal customization of the system selected for implementation, because of some limitations faced by the indian smes compared to large enterprises."
        },
        {
            "id": "R29268",
            "label": "ERP Systems in SMEs: A Literature Review",
            "doi": "10.1109/hicss.2011.191",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "this review summarizes research on enterprise resource planning (erp) systems in small and medium-size enterprises (smes). due to the close-to-saturation of erp adoptions in large enterprises (les), erp vendors now focus more on smes. moreover, because of globalization, partnerships, value networks, and the huge information flow across and within smes nowadays, more and more smes are adopting erp systems. risks of adoption rely on the fact that smes have limited resources and specific characteristics that make their case different from les. the main focus of this article is to shed the light on the areas that lack sufficient research within the erp in smes domain, suggest future research avenues, as well as, present the current research findings that could aid practitioners, suppliers, and smes when embarking on erp projects."
        },
        {
            "id": "R29279",
            "label": "Re-conceptualizing Information Systems Models: An Experience from ERP Systems Environment",
            "doi": "10.20533/iji.1742.4712.2010.0045",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "\"information systems have transformed organizations, performance and work. hence, the linkage between information systems and individual performance has been an ongoing concern in information systems (is) research. in the last decades, is researchers have concentrated their efforts in developing and testing models that help with the investigation of is and user performance in different environments. as a result, a number of models for studying end users' systems utilization and other related issues including system usefulness, system success and user aspects in business organizations have appeared. a synthesized model consolidating three well known and widely used models in is research is proposed. the model was empirically tested in a sophisticated is environment investigating the impacts of the enterprise recourse planning (erp) systems on user perceived performance. statistical analysis was performed including factors analysis and regression to test the model and prove its validity. the findings demonstrated that the proposed model performed well as most factors had direct and or indirect significant influences on user perceived performance suggesting therefore that the model possesses the ability to explain the main impacts of these factors on user performance.\""
        },
        {
            "id": "R29282",
            "label": "ERP Systems' Usage in the German IT Service Industry: An Exploratory Multi-case Study",
            "doi": "10.1109/edoc.2015.32",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "\"in order to achieve efficiency and effectiveness gains, concepts such as standardization and automation originating in the manufacturing industry are adopted by it service providers. erp systems are tools to implement such concepts in manufacturing companies. this research examines if and how erp systems are used by it service providers. to answer this question, an interview-based exploratory multiple-case study is conducted because only very limited findings on the topic exist. representatives of 24 it service providers and erp vendors were interviewed. we found that erp systems are used by the studied companies: 21 out of 24 use erp systems. seven selected companies are presented in greater detail: one that doesn't use an erp system and six that do. we describe which functional areas are covered by their erp systems and which ones are covered by other application systems. for instance, all of the six companies use the material management module of their erp system, but four out of five cases used a non-erp standard application system for ticketing. finally, we found no case that used traditional production and planning capabilities of erp systems as suggested by previous design science work.\""
        },
        {
            "id": "R29285",
            "label": "ERP systems in public sector",
            "doi": "10.1109/mipro.2014.6859810",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "erp systems are tended to be implemented in the public sector. in this paper the \"industries\" of public sector are identified which are suitable for erp implementation. the systematic review method is used to give an overview of state of the art erp system implementation in the public sector worldwide in the last five years as well as possible directions of future research. finally, the critical review is given regarding potential of erp system implementation in the public sector."
        },
        {
            "id": "R30515",
            "label": "Green enterprise computing data: Assumptions and realities",
            "doi": "10.1109/igcc.2012.6322264",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R30514",
                    "label": "Energy usage for electric loads"
                }
            ],
            "abstract": "\"until now, green computing research has largely relied on few, short-term power measurements to characterize the energy use of enterprise computing. this paper brings new and comprehensive power datasets through powernet, a hybrid sensor network that monitors the power and utilization of the it systems in a large academic building. over more than two years, we have collected power data from 250+ individual computing devices and have monitored a subset of cpu and network loads. this dense, long-term monitoring allows us to extrapolate the data to a detailed breakdown of electricity use across the building's computing systems. our datasets provide an opportunity to examine assumptions commonly made in green computing. we show that power variability both between similar devices and over time for a single device can lead to cost or savings estimates that are off by 15-20%. extending the coverage of measured devices and the duration (to at least one month) significantly reduces errors. lastly, our experiences with collecting data and the subsequent analysis lead to a better understanding of how one should go about power characterization studies. we provide several methodology guidelines for future green computing research.\""
        },
        {
            "id": "R30531",
            "label": "Field surveys of office equipment operating patterns",
            "doi": "10.2172/791184",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R30514",
                    "label": "Energy usage for electric loads"
                }
            ],
            "abstract": "this paper presents the results of 11 after-hours walk-throughs of offices in the san francisco ca and washington d.c. areas. the primary purpose of these walk-throughs was to collect data on turn-off rates for various types of office equipment (computers, monitors, printers, fax machines, copiers, and multifunction products). each piece of equipment observed was recorded and its power status noted (e.g. on, off, low power). whenever possible, we also recorded whether power management was enabled on the equipment. the floor area audited was recorded as well, which allowed us to calculate equipment densities. we found that only 44 percent of computers, 32 percent of monitors, and 25 percent of printers were turned off at night. based on our observations we estimate success rates of 56 percent for monitor power management and 96 percent for enabling of power management on printers."
        },
        {
            "id": "R30534",
            "label": "Electricity used by office equipment and network equipment in the U.S.: Detailed report and appendices",
            "doi": "10.2172/780583",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R30514",
                    "label": "Energy usage for electric loads"
                }
            ],
            "abstract": "in spite of the recent explosive growth in the use of office and network equipment, there has been no recent study that estimates in detail how much electricity is consumed by that equipment in the united states. in this study, we examined energy use by office equipment and network equipment at the end of 1999. we classified office equipment into 11 types; for each type we estimated annual energy consumption for residential, commercial, and industrial use by combining estimates of stock, power requirements, usage, and saturation of power management. we also classified network equipment into six types and estimated the annual energy consumption for each type. we found that total direct power use by office and network equipment is about 74 twh per year, which is about 2% of total electricity use in the u.s. when electricity used by telecommunications equipment and electronics manufacturing is included, that figure rises to 3% of all electricity use (koomey 2000). more than 70% of the 74 twh/year is dedicated to office equipment for commercial use. we also found that power management currently saves 23 twh/year, and complete saturation and proper functioning of power management would achieve additional savings of 17 twh/year. furthermore, complete saturation of night shutdown for equipment not required to operate at night would reduce power use by an additional 7 twh/year. finally, we compared our current estimater with our 1995 forecast for 1999. we found that the total difference between our current estimate and the previous forecast is less than 15% and identified the factors that led to inaccuracies in the previous forecast. we also conducted a sensitivity analysis of the uncertainties in our current forecast and identified the data sets that have the largest impact on our current estimate of energy use."
        },
        {
            "id": "R30542",
            "label": "An SSL-based client-oriented anti-spoofing email application",
            "doi": "10.1109/afrcon.2013.6757757",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R30538",
                    "label": "Social Engineering Attacks"
                }
            ],
            "abstract": "spoofing is a very common security threat to email applications. several powerful techniques have been developed to counteract spoofing, but most of them are server-oriented and transparent to the user. in this paper a client-oriented secure socket layer (ssl)-based anti-spoofing application is proposed. this application allows a client to send trusted emails and authenticate received emails using the ssl protocol. the application has been developed in java and it provides users with a table populated with details of all devices on a subnet. it uses cryptographic self-signed certificates to exchange a secure authentication message alongside the email with a view to prevent spoofing. the application has been tested on devices within the same subnet and it successfully authenticated valid email messages and detected spoofed ones. the main advantages of this application are the incorporation of ssl, its user-friendliness and its ability to allow users to use anti-spoofing measures independently of an email server."
        },
        {
            "id": "R30545",
            "label": "Intelligent Phishing Website Detection and Prevention System by Using Link Guard Algorithm",
            "doi": "10.9790/0661-1432836",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R30538",
                    "label": "Social Engineering Attacks"
                }
            ],
            "abstract": "\"phishing is a new type of network attack where the attacker creates a replica of an existing web page to fool users (e.g., by using specially designed e-mails or instant messages) into submitting personal, financial, or password data to what they think is their service provides' web site. in this research paper, we proposed a new end-host based anti-phishing algorithm, which we call link guard, by utilizing the generic characteristics of the hyperlinks in phishing attacks. these characteristics are derived by analyzing the phishing data archive provided by the anti-phishing working group (apwg). because it is based on the generic characteristics of phishing attacks, link guard can detect not only known but also unknown phishing attacks. we have implemented link guard in windows xp. our experiments verified that link guard is effective to detect and prevent both known and unknown phishing attacks with minimal false negatives. link guard successfully detects 195 out of the 203 phishing attacks. our experiments also showed that link guard is light weighted and can detect and prevent phishing attacks in real time.\""
        },
        {
            "id": "R31241",
            "label": "Middle-Income Traps: A Conceptual and Empirical Survey",
            "doi": "10.1142/s1793993315500131",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31216",
                    "label": "Middle-Income Trap"
                }
            ],
            "abstract": "the term \"middle-income trap\" has entered common parlance in the development policy community, despite the lack of a precise definition. this paper discusses in more detail the definitional issues associated with the term. it also provides evidence on whether the growth performance of middle-income countries (mics) has been different from other income categories, including historical transition phases in the inter-country distribution of income. a transition matrix analysis and an exploration of cross-country growth patterns provide little support for the existence of a middle-income trap."
        },
        {
            "id": "R31283",
            "label": "Expression-Invariant 3D Face Recognition Using Patched Geodesic Texture Transform",
            "doi": "10.1109/dicta.2010.52",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "numerous methods have been proposed for the expression-invariant 3d face recognition, but a little attention is given to the local-based representation for the texture of the 3d images. in this paper, we propose an expression-invariant 3d face recognition approach based on the locally extracted moments of the texture when only one exemplar per person is available. we use a geodesic texture transform accompanied by pseudo zernike moments to extract local feature vectors from the texture of a face. an extensive experimental investigation is conducted using publicly available bu-3dfe face databases covering face recognition under expression variations. the performance of the proposed method is compared with the performance of two benchmark approaches. the encouraging experimental results demonstrate that the proposed method can be used for 3d face recognition in single model databases."
        },
        {
            "id": "R31285",
            "label": "Curvelet Feature Extraction for Face Recognition and Facial Expression Recognition",
            "doi": "10.1109/icnc.2010.5583642",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "to overcome the weakness of the wavelet analysis which is unable to extract curve features of the face image, this paper applies a new multiscale geometric analysis tool \u2014 curvelet transform, for facial processing and feature extraction. a new approach based on curvelet transform and subband weighted fusion algorithm is proposed for face recognition. a novel method based on curvelet transform and support vector machine (svm) is designed to recognize facial expression. face recognition experiments with yale database and facial expression recognition experiments with jaffe database are carried out. the correct recognition rates are 93.33% and 94.73% respectively in \u201ccombined curvelet + svm face recognition\u201d and \u201ccurvelet + svm facial expression recognition\u201d. these results show the advantages of curvelet transform in facial processing and feature extraction."
        },
        {
            "id": "R31287",
            "label": "Face and expression recognition based on bag of words method considering holistic and local image features",
            "doi": "10.1109/iscit.2010.5664923",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "this paper proposes a new framework for extracting facial features based on the bag of words method, and applies it to face and facial expression recognition. recently, the bag of words method has been successfully used in object recognition. however, for recognition problems of facial images, the orderless collection of local patches in bag of words method cannot provide strongly distinctive information since the object category (face image) is the same. in our work, a new framework based on bag of words is presented to extract discriminative local facial features while maintaining holistic spatial information at the same time. the new method is applied to both face and facial expression recognition. experimental results show that only using one neutral expression frame per person for training, our method can obtain the best face recognition performance ever on face images of ar database with extreme expressions, variant illuminations, and partial occlusions. for facial expression recognition, the average rate on the cohn-kanade database is 96.33%, which also outperforms the state of the arts."
        },
        {
            "id": "R31289",
            "label": "Local Directional Number Pattern for Face Analysis: Face and Expression Recognition",
            "doi": "10.1109/tip.2012.2235848",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "this paper proposes a novel local feature descriptor, local directional number pattern (ldn), for face analysis, i.e., face and expression recognition. ldn encodes the directional information of the face's textures (i.e., the texture's structure) in a compact way, producing a more discriminative code than current methods. we compute the structure of each micro-pattern with the aid of a compass mask that extracts directional information, and we encode such information using the prominent direction indices (directional numbers) and sign-which allows us to distinguish among similar structural patterns that have different intensity transitions. we divide the face into several regions, and extract the distribution of the ldn features from them. then, we concatenate these features into a feature vector, and we use it as a face descriptor. we perform several experiments in which our descriptor performs consistently under illumination, noise, expression, and time lapse variations. moreover, we test our descriptor with different masks to analyze its performance in different face analysis tasks."
        },
        {
            "id": "R31291",
            "label": "Regional Registration for Expression Resistant 3-D Face Recognition",
            "doi": "10.1109/tifs.2010.2054081",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "biometric identification from three-dimensional (3-d) facial surface characteristics has become popular, especially in high security applications. in this paper, we propose a fully automatic expression insensitive 3-d face recognition system. surface deformations due to facial expressions are a major problem in 3-d face recognition. the proposed approach deals with such challenging conditions in several aspects. first, we employ a fast and accurate region-based registration scheme that uses common region models. these common models make it possible to establish correspondence to all the gallery samples in a single registration pass. second, we utilize curvature-based 3-d shape descriptors. last, we apply statistical feature extraction methods. since all the 3-d facial features are regionally registered to the same generic facial component, subspace construction techniques may be employed. we show that linear discriminant analysis significantly boosts the identification accuracy. we demonstrate the recognition ability of our system using the multiexpression bosphorus and the most commonly used 3-d face database, face recognition grand challenge (frgcv2). our experimental results show that in both databases we obtain comparable performance to the best rank-1 correct classification rates reported in the literature so far: 98.19% for the bosphorus and 97.51% for the frgcv2 database. we have also carried out the standard receiver operating characteristics (roc iii) experiment for the frgcv2 database. at an far of 0.1%, the verification performance was 86.09%. this shows that model-based registration is beneficial in identification scenarios where speed-up is important, whereas for verification one-to-one registration can be more beneficial."
        },
        {
            "id": "R31293",
            "label": "FARO: FAce Recognition Against Occlusions and Expression Variations",
            "doi": "10.1109/tsmca.2009.2033031",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "face recognition is widely considered as one of the most promising biometric techniques, allowing high recognition rates without being too intrusive. many approaches have been presented to solve this special pattern recognition problem, also addressing the challenging cases of face changes, mainly occurring in expression, illumination, or pose. on the other hand, less work can be found in literature that deals with partial occlusions (i.e., sunglasses and scarves). this paper presents face recognition against occlusions and expression variations (faro) as a new method based on partitioned iterated function systems (pifss), which is quite robust with respect to expression changes and partial occlusions. in general, algorithms based on pifss compute a map of self-similarities inside the whole input image, searching for correspondences among small square regions. however, traditional algorithms of this kind suffer from local distortions such as occlusions. to overcome such limitation, information extracted by pifs is made local by working independently on each face component (eyes, nose, and mouth). distortions introduced by likely occlusions or expression changes are further reduced by means of an ad hoc distance measure. in order to experimentally confirm the robustness of the proposed method to both lighting and expression variations, as well as to occlusions, faro has been tested using ar-faces database, one of the main benchmarks for the scientific community in this context. a further validation of faro performances is provided by the experimental results produced on face recognition grand challenge database."
        },
        {
            "id": "R31295",
            "label": "Gradient Feature Matching for Expression Invariant Face Recognition using Single Reference Image",
            "doi": "10.1109/icsmc.2012.6377834",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "\"automatic recognition of human faces irrespective of the expression variations is a challenging problem. in this paper, we propose a novel method for face recognition based on `edge-strings'. experimental studies on face perception have shown the significance of edge features in visual perception and learning. in the proposed technique, the edges of a face are identified, and a feature string is created from edge pixels. this forms a symbolic descriptor corresponding to the edge image referred to as `edge-string'. the `edge-strings' are then compared using the smith-waterman algorithm to match them. the class corresponding to each image is identified based on the number of string primitives that match. local string alignment algorithm is more robust to noise than global alignment algorithm; it gives better performance even if the input image is noisy. in addition, this method needs only a single training image per class. the proposed technique is a good solution for expression invariant face recognition. the effectiveness of the proposed method is compared with state-of-the-art algorithms on the yale face database, the japanese female face expression database (jaffe) and cmu amp face expression database.\""
        },
        {
            "id": "R31297",
            "label": "A design for Integrated Face and Facial Expression Recognition",
            "doi": "10.1109/iecon.2011.6120016",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R31282",
                    "label": "Face Expression Recognition"
                }
            ],
            "abstract": "\"an integrated face and facial expression recognition system has been designed and tested for robotic applications. facial images from a web camera are first acquired for facial shape and texture model generation using active appearance model (aam). modified lucas-kanade image alignment algorithm was adopted to find facial features as well as the texture model of aam to construct facial texture parameters. these parameters are used to train back propagation neural networks (bpnn) for face and facial expression recognition. a novel design is proposed for an integrated facial expression recognition system. in the first stage, face recognition is performed to find user's identity; then the facial-expression database of the recognized user is employed to recognize his/her facial expressions. experimental result based on bu-3dfe database show that a face recognition rate of 98.3% is achieved. the facial expression recognition rate of the proposed integrated method (using personal facial expression classifiers) is 83.8%, an improvement compared with 69.6% of using conventional classifiers.\""
        },
        {
            "id": "R29273",
            "label": "Enterprise resource planning post-adoption value: a literature review amongst small and medium enterprises",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "it is consensual that enterprise resource planning (erp) after a successful implementation has significant effects on the productivity of firm as well small and medium-sized enterprises (smes) recognized as fundamentally different environments compared to large enterprises. there are few reviews in the literature about the post-adoption phase and even fewer at sme level. furthermore, to the best of our knowledge there is none with focus in erp value stage. this review will fill this gap. it provides an updated bibliography of erp publications published in the is journal and conferences during the period of 2000 and 2012. a total of 33 articles from 21 journals and 12 conferences are reviewed. the main focus of this paper is to shed the light on the areas that lack sufficient research within the erp in sme domain, in particular in erp business value stage, suggest future research avenues, as well as, present the current research findings that could support researchers and practitioners when embarking on erp projects."
        },
        {
            "id": "R29354",
            "label": "Open source ERP in organization: research agenda",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "open source software (oss) is a growing phenomenon, changing the way in which information systems (is) are developed, distributed and implemented. the success of oss in the worldwide market for operating systems, web servers, and other infrastructure software is substantial. however, it is still infrequent in erp type application domains, which are said to be impossible to design from an os angle. while a significant number of research investigate aspects of os, few researches were dedicated to os erp. based on a review of the academic and professional literature, this paper aims to improve our understanding of the current influence of os erp in organizations, to provide a new light on a previously developed topic and to challenge the conventional wisdom in our field which stipulates that there are some areas like erp applications where os could not be developed."
        },
        {
            "id": "R29357",
            "label": "Cloud enterprise systems: a review of literature and its adoption",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "in recent years, cloud computing has revolutionalized the it industry by introducing a whole new concept and platform of enterprise systems (es). the traditional es seem to be too clunky, expensive and complex for most organizations to implement anduse. to improve such situation cloud es concept was recently introduced to offer competitive advantage to organizations through flexibility, scalability and independence in it infrastructure and capabilities. today, this area has not been fully explored in the academia due to little available literature but it has attracted tremendous interest from the general practitioners. this study seeks to contribute to is literature by conceptualising cloud es from a pragmatic understanding between practitioners and academic. it further elaborates the advantages and challenges of cloud es and discussesthe potential of cloud es as an attractive option to sme in solving the problems of high investments in it infrastructures and it resources."
        },
        {
            "id": "R29359",
            "label": "Cloud ERP system customization challenges",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R29113",
                    "label": "Enterprise resource planning"
                }
            ],
            "abstract": "customization is one of the known challenges in traditional erp systems. with the advent of cloud erp systems, a question of determining the state of such systems regarding customization and configuration ability arises. as there are only a few literature sources partially covering this topic, a more comprehensive and systematic literature review is needed. thus, this paper presents a literature review performed in order to give an overview of reported research on \"cloud erp customization\" topic performed in the last 5 years. in two search iterations, a total of 32 relevant papers are identified and analyzed. the results show that several dominant research trends are identified along with 12 challenges and issues. additionally, based on the results, the possible future researches are proposed."
        },
        {
            "id": "R32952",
            "label": "Zinc in wound healing: Theoretical, experimental, and clinical aspects",
            "doi": "10.1111/j.1524-475x.2006.00179.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R32942",
                    "label": "Skin salt interaction"
                }
            ],
            "abstract": "zinc is an essential trace element in the human body and its importance in health and disease is appreciated. it serves as a cofactor in numerous transcription factors and enzyme systems including zinc\u2010dependent matrix metalloproteinases that augment autodebridement and keratinocyte migration during wound repair. zinc confers resistance to epithelial apoptosis through cytoprotection against reactive oxygen species and bacterial toxins possibly through antioxidant activity of the cysteine\u2010rich metallothioneins. zinc deficiency of hereditary or dietary cause can lead to pathological changes and delayed wound healing. oral zinc supplementation may be beneficial in treating zinc\u2010deficient leg ulcer patients, but its therapeutic place in surgical patients needs further clarification. topical administration of zinc appears to be superior to oral therapy due to its action in reducing superinfections and necrotic material via enhanced local defense systems and collagenolytic activity, and the sustained release of zinc ions that stimulates epithelialization of wounds in normozincemic individuals. zinc oxide in paste bandages (unna boot) protects and soothes inflamed peri\u2010ulcer skin. zinc is transported through the skin from these formulations, although the systemic effects seem insignificant. we present here the first comprehensive account of zinc in wound management in relation to current concepts of wound bed preparation and the wound\u2010healing cascade. this review article suggests that topical zinc therapy is underappreciated even though clinical evidence emphasizes its importance in autodebridement, anti\u2010infective action, and promotion of epithelialization."
        },
        {
            "id": "R32955",
            "label": "Topical insulin in wound healing: a randomized, double-blind, placebo-controlled trial",
            "doi": "10.12968/jowc.1999.8.10.26217",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R32942",
                    "label": "Skin salt interaction"
                }
            ],
            "abstract": "two studies were carried out to assess the relative roles of insulin and zinc in the acceleration of wound healing. in the first study, six diabetic and five non-diabetic human volunteers had two uniform cuts created, one on each forearm. one forearm wound was treated with topical regular insulin (iletin-ii) and the other with normal saline four times a day until healed. treatment was double-blind and forearms were assigned randomly. the wounds treated with insulin healed 2.4 \u00b1 0.8 days faster than the wounds treated with saline (p &lt; 0.001 by paired t-test). zinc is used to crystallise insulin. when wounds are treated with insulin, they are therefore also being treated with zinc. if insulin accelerates wound healing, it is not clear if the increase in the rate of healing would be due to insulin (a known growth factor), the zinc it contains, or a combination of the two. the second study used a randomised, double-blind, placebo-controlled design to compare the efficacy of insulin with that of a solution containing the same amount of zinc in accelerating the healing of standardised wounds in rats and humans. although these pilot investigations did not have the power to define the relative roles of insulin and zinc with accuracy, the results suggest that zinc does play a role in the wound healing process. it is concluded that topical insulin accelerates wound healing in humans. more importantly, however, this study describes a method of creating uniform wounds in humans acceptable to an institutional review board, thus solving one of the major impediments to the scientific evaluation of human wound healing."
        },
        {
            "id": "R32957",
            "label": "Zinc and Skin Health: Overview of Physiology and Pharmacology",
            "doi": "10.1111/j.1524-4725.2005.31729",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R32942",
                    "label": "Skin salt interaction"
                }
            ],
            "abstract": "background\\nzinc is known to have a critical role in overall human physiology, which likely explains many of its therapeutic uses for the last several thousand years. the specific roles zinc plays in skin health and function are less widely known yet are likely just as critical based on the manifestations of dietary zinc deprivation, which include moderate to severe dermatitis.\\n\\n\\nobjective\\nto provide a critical review of the scientific literature as to the physiologic importance of zinc to skin, the biochemical basis for these effects, and pharmacologic aspects of zinc therapeutics.\\n\\n\\nresults and conclusions\\nskin is in a continual state of renewal, placing a high demand on zinc-based enzymes and proteins that direct this process. the importance of zinc physiologically is especially evident in studies of wound healing and inflammation reduction. during these processes, the high needs for zinc can be supplemented externally, generally increasing the rates of the natural processes. topical zinc delivery involves the pharmacologic optimization of zinc delivery, often mediated by the solubility of the zinc material and interactions within the product matrix."
        },
        {
            "id": "R33583",
            "label": "Early Intensive Behavioral Treatment",
            "doi": "10.1097/00004703-200604002-00013",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "\"abstract. although previous studies have shown favorable results with early intensive behavioral treatment (eibt) for children with autism, it remains important to replicate these findings, particularly in community settings. the authors conducted a 3-year prospective outcome study that compared 2 groups: (1) 21 children who received 35 to 40 hours per week of eibt from a community agency that replicated lovaas' model of eibt and (2) 21 age- and iq-matched children in special education classes at local public schools. a quasi-experimental design was used, with assignment to groups based on parental preference. assessments were conducted by independent examiners for iq (bayley scales of infant development or wechsler preschool and primary scales of intelligence), language (reynell developmental language scales), nonverbal skill (merrill-palmer scale of mental tests), and adaptive behavior (vineland adaptive behavior scales). analyses of covariance, with baseline scores as covariates and year 1-3 assessments as repeated measures, revealed that, with treatment, the eibt group obtained significantly higher iq (f = 5.21, p = .03) and adaptive behavior scores (f = 7.84, p = .01) than did the comparison group. no difference between groups was found in either language comprehension (f = 3.82, p = .06) or nonverbal skill. six of the 21 eibt children were fully included into regular education without assistance at year 3, and 11 others were included with support; in contrast, only 1 comparison child was placed primarily in regular education. although the study was limited by the nonrandom assignment to groups, it does provide evidence that eibt can be successfully implemented in a community setting.\""
        },
        {
            "id": "R33587",
            "label": "Outcome for Children with Autism who Began Intensive Behavioral Treatment Between Ages 4 and 7",
            "doi": "10.1177/0145445506291396",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "this study extends findings on the effects of intensive applied behavior analytic treatment for children with autism who began treatment at a mean age of 5.5 years. the behavioral treatment group ( n = 13, 8 boys) was compared to an eclectic treatment group ( n = 12, 11 boys). assignment to groups was made independently based on the availability of qualified supervisors. both behavioral and eclectic treatment took place in public kindergartens and elementary schools for typically developing children. at a mean age of 8 years, 2 months, the behavioral treatment group showed larger increases in iq and adaptive functioning than did the eclectic group. the behavioral treatment group also displayed fewer aberrant behaviors and social problems at follow-up. results suggest that behavioral treatment was effective for children with autism in the study."
        },
        {
            "id": "R33589",
            "label": "Long-term outcome of social skills intervention based on interactive LEGO play",
            "doi": "10.1177/1362361306064403",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "lego \u00a9 building materials have been adapted as a therapeutic modality for increasing motivation to participate in social skills intervention, and providing a medium through which children with social and communication handicaps can effectively interact. a 3 year retrospective study of long-term outcome for autistic spectrum children participating in lego \u00a9 therapy ( n = 60) compared vineland adaptive behavior scale socialization domain (vabs\u2013sd) and gilliam autism rating scale social interaction subscale (gars\u2013si) scores preand post-treatment with a matched comparison sample ( n = 57) who received comparable non-lego \u00a9 therapy. although both groups made significant gains on the two outcome measures, lego \u00a9 participants improved significantly more than the comparison subjects. diagnosis and pre-treatment full-scale iq scores did not predict outcome scores; however, vineland adaptive behavior composite, vineland communication domain, and verbal iq all predicted outcome on the vabs\u2013sd, especially for the lego \u00a9 therapy group. results are discussed in terms of implications for methods of social skills intervention for autistic spectrum disorders."
        },
        {
            "id": "R33591",
            "label": "A two-year prospective follow-up study of community-based early intensive behavioural intervention and specialist nursery provision for children with autism spectrum disorders",
            "doi": "10.1111/j.1469-7610.2007.01756.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "background\\nthis prospective study compared outcome for pre-school children with autism spectrum disorders (asd) receiving autism-specific nursery provision or home-based early intensive behavioural interventions (eibi) in a community setting.\\n\\n\\nmethods\\nforty-four 23- to 53-month-old children with asd participated (28 in eibi home-based programmes; 16 in autism-specific nurseries). cognitive, language, play, adaptive behaviour skills and severity of autism were assessed at intake and 2 years later.\\n\\n\\nresults\\nboth groups showed improvements in age equivalent scores but standard scores changed little over time. at follow-up, there were no significant group differences in cognitive ability, language, play or severity of autism. the only difference approaching significance (p = .06), in favour of the eibi group, was for vineland daily living skills standard scores. however, there were large individual differences in progress, with intake iq and language level best predicting overall progress.\\n\\n\\nconclusions\\nhome-based eibi, as implemented in the community, and autism-specific nursery provision produced comparable outcomes after two years of intervention."
        },
        {
            "id": "R33613",
            "label": "Outcome at 7 years of children diagnosed with autism at age 2: predictive validity of assessments conducted at 2 and 3 years of age and pattern of symptom change over time",
            "doi": "10.1111/j.1469-7610.2004.00377.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "objective\\nto examine the predictive validity of symptom severity, cognitive and language measures taken at ages 2 and 3 years to outcome at age 7 in a sample of children diagnosed with autism at age 2.\\n\\n\\nmethod\\ntwenty-six children diagnosed with autism at age 2 were re-assessed at ages 3 and 7 years. at each age symptom severity, cognitive and language assessments were completed.\\n\\n\\nresults\\nthe pattern of autistic symptom severity varied over time by domain. across time, children moved across diagnostic boundaries both in terms of clinical diagnosis and in terms of instrument diagnosis on the autism diagnostic interview-revised (adi-r). on all measures group variability in scores increased with age. although non-verbal iq (nviq) for the group as a whole was stable across the 3 assessments, this masked considerable individual instability. standard assessments at age 2 did not predict outcome at age 7 even within the same domain of functioning. in contrast, standard assessments at age 3 did predict outcome. however, a measure of rate of non-verbal communicative acts taken from an interactive play-based assessment at age 2 was significantly associated with language, communication and social outcomes at age 7.\\n\\n\\nconclusions\\nthe trajectory of autism symptoms over time differed in different domains, suggesting that they may be, at least in part, separable. variability in language, nviq and symptom severity increased over time. caution is required when interpreting the findings from assessments of children with autism at age 2 years. at this age measures of rate of non-verbal communication might be more informative than scores on standard psychometric tests. predictive validity of assessments at age 3 years was greater."
        },
        {
            "id": "R33629",
            "label": "Adult outcome for children with autism",
            "doi": "10.1111/j.1469-7610.2004.00215.x",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "\"background\\ninformation on long-term prognosis in autism is limited. outcome is known to be poor for those with an iq below 50, but there have been few systematic studies of individuals with an iq above this.\\n\\n\\nmethod\\nsixty-eight individuals meeting criteria for autism and with a performance iq of 50 or above in childhood were followed up as adults. their mean age when first seen was 7 years (range 3-15 years); at follow-up the average age was 29 years (range 21-48 years). outcome measures included standardised cognitive, language and attainment tests. information on social, communication and behavioural problems was obtained from the autism diagnostic interview (adi).\\n\\n\\nresults\\nalthough a minority of adults had achieved relatively high levels of independence, most remained very dependent on their families or other support services. few lived alone, had close friends, or permanent employment. communication generally was impaired, and reading and spelling abilities were poor. stereotyped behaviours or interests frequently persisted into adulthood. ten individuals had developed epilepsy. overall, only 12% were rated as having a 'very good' outcome; 10% were rated as 'good' and 19% as 'fair'. the majority was rated as having a 'poor' (46%) or 'very poor' (12%) outcome. individuals with a childhood performance iq of at least 70 had a significantly better outcome than those with an iq below this. however, within the normal iq range outcome was very variable and, on an individual level, neither verbal nor performance iq proved to be consistent prognostic indicators.\\n\\n\\nconclusions\\nalthough outcome for adults with autism has improved over recent years, many remain highly dependent on others for support. this study provides some information on prognostic indicators, but more fine-grained research is needed into the childhood variables that are associated with good or poor outcome.\""
        },
        {
            "id": "R33631",
            "label": "Subgroups of Children With Autism by Cluster Analysis: A Longitudinal Examination",
            "doi": "10.1097/00004583-200003000-00017",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33582",
                    "label": "IQ stability"
                }
            ],
            "abstract": "objectives\\na hierarchical cluster analysis was conducted using a sample of 138 school-age children with autism. the objective was to examine (1) the characteristics of resulting subgroups, (2) the relationship of these subgroups to subgroups of the same children determined at preschool age, and (3) preschool variables that best predicted school-age functioning.\\n\\n\\nmethod\\nninety-five cases were analyzed.\\n\\n\\nresults\\nfindings support the presence of 2 subgroups marked by different levels of social, language, and nonverbal ability, with the higher group showing essentially normal cognitive and behavioral scores. the relationship of high- and low-functioning subgroup membership to levels of functioning at preschool age was highly significant.\\n\\n\\nconclusions\\nschool-age functioning was strongly predicted by preschool cognitive functioning but was not strongly predicted by preschool social abnormality or severity of autistic symptoms. the differential outcome of the 2 groups shows that high iq is necessary but not sufficient for optimal outcome in the presence of severe language impairment."
        },
        {
            "id": "R33955",
            "label": "Techniques for data hiding",
            "doi": "10.1147/sj.353.0313",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33954",
                    "label": "Image Steganographic Techniques"
                }
            ],
            "abstract": "data hiding is the process of embedding data into image and audio signals. the process is constrained by the quantity of data, the need for invariance of the data under conditions where the `host' signal is subject to distortions, e.g., compression, and the degree to which the data must be immune to interception, modification, or removal. we explore both traditional and novel techniques for addressing the data hiding process and evaluate these techniques in light of three applications: copyright protecting, tamper-proofing, and augmentation data embedding."
        },
        {
            "id": "R33957",
            "label": "Reversible data embedding using a difference expansion",
            "doi": "10.1109/TCSVT.2003.815962",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33954",
                    "label": "Image Steganographic Techniques"
                }
            ],
            "abstract": "reversible data embedding has drawn lots of interest recently. being reversible, the original digital content can be completely restored. we present a novel reversible data-embedding method for digital images. we explore the redundancy in digital images to achieve very high embedding capacity, and keep the distortion low."
        },
        {
            "id": "R33961",
            "label": "Hiding Secret Message in Edges of the Image",
            "doi": "10.1109/icict.2007.375384",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33954",
                    "label": "Image Steganographic Techniques"
                }
            ],
            "abstract": "the purpose of steganography is covert communication - to hide the very existence of a message from a third party. the paper proposes a new least significant bit embedding algorithm for hiding secret messages in nonadjacent pixel locations of edges of images. it ensures a better security against eavesdroppers."
        },
        {
            "id": "R33963",
            "label": "Adaptive Data Hiding in Edge Areas of Images With Spatial LSB Domain Systems",
            "doi": "10.1109/tifs.2008.926097",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33954",
                    "label": "Image Steganographic Techniques"
                }
            ],
            "abstract": "\"this paper proposes a new adaptive least-significant- bit (lsb) steganographic method using pixel-value differencing (pvd) that provides a larger embedding capacity and imperceptible stegoimages. the method exploits the difference value of two consecutive pixels to estimate how many secret bits will be embedded into the two pixels. pixels located in the edge areas are embedded by a k-bit lsb substitution method with a larger value of k than that of the pixels located in smooth areas. the range of difference values is adaptively divided into lower level, middle level, and higher level. for any pair of consecutive pixels, both pixels are embedded by the k-bit lsb substitution method. however, the value k is adaptive and is decided by the level which the difference value belongs to. in order to remain at the same level where the difference value of two consecutive pixels belongs, before and after embedding, a delicate readjusting phase is used. when compared to the past study of wu et al.'s pvd and lsb replacement method, our experimental results show that our proposed approach provides both larger embedding capacity and higher image quality.\""
        },
        {
            "id": "R33967",
            "label": "Reversible image watermarking using interpolation technique",
            "doi": "10.1109/TIFS.2009.2035975",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33954",
                    "label": "Image Steganographic Techniques"
                }
            ],
            "abstract": "watermarking embeds information into a digital signal like audio, image, or video. reversible image watermarking can restore the original image without any distortion after the hidden data is extracted. in this paper, we present a novel reversible watermarking scheme using an interpolation technique, which can embed a large amount of covert data into images with imperceptible modification. different from previous watermarking schemes, we utilize the interpolation-error, the difference between interpolation value and corresponding pixel value, to embed bit \u00bf1\u00bf or \u00bf0\u00bf by expanding it additively or leaving it unchanged. due to the slight modification of pixels, high image quality is preserved. experimental results also demonstrate that the proposed scheme can provide greater payload capacity and higher image fidelity compared with other state-of-the-art schemes."
        },
        {
            "id": "R33969",
            "label": "Edge adaptive image steganography based on LSB matching revisited",
            "doi": "10.1109/tifs.2010.2041812",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R33954",
                    "label": "Image Steganographic Techniques"
                }
            ],
            "abstract": "the least-significant-bit (lsb)-based approach is a popular type of steganographic algorithms in the spatial domain. however, we find that in most existing approaches, the choice of embedding positions within a cover image mainly depends on a pseudorandom number generator without considering the relationship between the image content itself and the size of the secret message. thus the smooth/flat regions in the cover images will inevitably be contaminated after data hiding even at a low embedding rate, and this will lead to poor visual quality and low security based on our analysis and extensive experiments, especially for those images with many smooth regions. in this paper, we expand the lsb matching revisited image steganography and propose an edge adaptive scheme which can select the embedding regions according to the size of secret message and the difference between two consecutive pixels in the cover image. for lower embedding rates, only sharper edge regions are used while keeping the other smoother regions as they are. when the embedding rate increases, more edge regions can be released adaptively for data hiding by adjusting just a few parameters. the experimental results evaluated on 6000 natural images with three specific and four universal steganalytic algorithms show that the new scheme can enhance the security significantly compared with typical lsb-based approaches as well as their edge adaptive ones, such as pixel-value-differencing-based approaches, while preserving higher visual quality of stego images at the same time."
        },
        {
            "id": "R34462",
            "label": "Production function, productivities, and capacity utilization of the Port of Mobile",
            "doi": "10.1080/03088837800000020",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R34461",
                    "label": "Production and cost functions"
                }
            ],
            "abstract": "in this study, the author considers the problems related to the expansion of port facilities using economic theory as a basis for discussion and the port of mobile as an example."
        },
        {
            "id": "R34473",
            "label": "The Port of Melbourne Authority's pricing policy: its efficiency and distribution implications",
            "doi": "10.1080/03088839300000012",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R34461",
                    "label": "Production and cost functions"
                }
            ],
            "abstract": "\"the objective of this paper is investigate the extent to which the new (revised) pricing policy has improved the level of efficiency at the port of melbourne and to assess the contributions of the underlying factors of port efficiency. further, it attempts to examine the distribution implications of the pricing policy between the major port users (i.e. shipowners and shippers) and its revenue implication for the port of melbourne. using a conceptual framework derived from economic theories, in-house data and responses from the port users, the study reveals that the efficiency impact has been considerable and varied between berths; land transport links and crane productivity improvements were the major factors of the port's overall efficiency; the initial losers have been the shipowners and initial gainers the shippers; however, the gains have been limited and in some cases have been offset by the introduction of higher port service charges; in the long run it is likely that the shipowners and shippers' si...\""
        },
        {
            "id": "R34478",
            "label": "The structure of production, technical change and productivity in a port\u00e2\u0080\u009d",
            "doi": "10.2307/2098359",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R34461",
                    "label": "Production and cost functions"
                }
            ],
            "abstract": "the primary focus of this paper is the modelling and estimation of the structure of production, technical change and total factor productivity (tfp) growth in a port. special attention is given to the specification of technical change which is measured as the percent of containerization. our findings indicate that technical change has been labour saving and capital using. tfp has been growing from 1966-1983 at an annual average rate of 0.11. the main contribution to tfp growth has been containerization. on the average, 85% of the growth in tfp has been due to containerization and 15% of the growth has been due to economies of scale and output growth."
        },
        {
            "id": "R44575",
            "label": "The reciprocity of data integration in disaster risk analysis",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R44580",
                    "label": "Disaster affected local communities are often excluded from decision making processes that affect their capacities and resilience. Little is known about how data-driven and ICT-supported processes can strengthen local communities' voices in these decision making processes."
                }
            ],
            "abstract": "humanitarian organizations are increasingly challenged by the amount of data available to drive their decisions. useful data can come from many sources, exists in different formats, and merging it into a basis for analysis and planning often exceeds organizations\u2019 capacities and resources. at the same time, affected communities\u2019 participation in decision making processes is often hindered by a lack of information and data literacy capacities within the communities. we describe a participatory disaster risk analysis project in the central philippines where the community and a humanitarian ngo worked towards a joint understanding of disaster risks and coping capacities through data integration and it-supported analysis. we present findings from workshops, focus group discussions and semi-structured interviews, showing the reciprocal effects of the collaborative work. while the community valued the systematically gathered and structured evidence that supported their own risk perceptions and advocacy efforts, the humanitarian ngo revisited established work practices for data collection for analysis and planning."
        },
        {
            "id": "R50025",
            "label": "Segmentation of Ocular Pathologies Using Deep Convolutional Neural Network",
            "doi": "10.1109/icecce47252.2019.8940704",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R50028",
                    "label": "simultaneous delineation of retinal pathologies (hard exudates, soft exudates, hemorrhages, microaneurysms)"
                }
            ],
            "abstract": "diabetes mellitus (dm) is a chronic, progressive and life-threatening disease. the ocular manifestations of dm, diabetic retinopathy (dr) and diabetic macular edema (dme), are the leading causes of blindness in the adult population throughout the world. early diagnosis of dr and dm through screening tests and successive treatments can reduce the threat to visual acuity. in this context, we propose an encoder decoder based semantic segmentation network sop-net (segmentation of ocular pathologies using deep convolutional neural network) for simultaneous delineation of retinal pathologies (hard exudates, soft exudates, hemorrhages, microaneurysms). the proposed semantic segmentation framework is capable of providing segmentation results at pixel-level with good localization of object boundaries. sop-net has been trained and tested on idrid dataset which is publicly available with pixel level annotations of retinal pathologies. the network achieved average accuracies of 98.98%, 90.46%, 96.79%, and 96.70% for segmentation of hard exudates, soft exudates, hemorrhages, and microaneurysms. the proposed methodology has the capability to be used in developing a diagnostic system for organizing large scale ophthalmic screening programs."
        },
        {
            "id": "R50059",
            "label": "Juma Uplift: Using a Block Metaphor for Representing Uplift Mappings",
            "doi": "10.1109/icsc.2018.00037",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a significant part of the linked data web is achieved by converting non-rdf resources into rdf. even though several approaches and mapping languages have been proposed in the literature, the knowledge required for such task is still substantial. in prior work, we proposed a visual representation based on the block metaphor and applied it to r2rml. in this paper, we describe a new implementation of this method, called juma uplift. this implementation is capable of generating mapping definitions for different uplift mapping languages while still being fully compliant to the w3c recommendation r2rml. preliminary findings indicate that juma uplift is expressive enough to generate accurate mappings for the two syntactically distinct mapping languages under examination, r2rml and sml."
        },
        {
            "id": "R50090",
            "label": "Translating the Concept of Goal Setting into Practice: What \u00e2\u0080\u0098else\u00e2\u0080\u0099 Does It Require than a Goal Setting Tool?: ",
            "doi": "10.5220/0009389703880395",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this conceptual paper reviews the current status of goal setting in the area of technology enhanced learning and education. besides a brief literature review, three current projects on goal setting are discussed. the paper shows that the main barriers for goal setting applications in education are not related to the technology, the available data or analytical methods, but rather the human factor. the most important bottlenecks are the lack of students goal setting skills and abilities, and the current curriculum design, which, especially in the observed higher education institutions, provides little support for goal setting interventions."
        },
        {
            "id": "R50147",
            "label": "Improving Wikipedia's accuracy: Is edit age a solution?",
            "doi": "10.1002/asi.20755",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "wikipedia is fast becoming a key information source for many despite criticism that it is unreliable and inaccurate. a number of recommendations have been made to sort the chaff from the wheat in wikipedia, among which is the idea of color-coding article segment edits according to age (cross, 2006). using data collected as part of a wider study published in nature, this article examines the distribution of errors throughout the life of a select group of wikipedia articles. the survival time of each error edit in terms of the edit counts and days was calculated and the hypothesis that surviving material added by older edits is more trustworthy was tested. surprisingly, we find that roughly 20% of errors can be attributed to surviving text added by the first edit, which confirmed the existence of a first-mover effect (viegas, wattenberg, & kushal, 2004) whereby material added by early edits are less likely to be removed. we suggest that the sizable number of errors added by early edits is simply a result of more material being added near the beginning of the life of the article. overall, the results do not provide support for the idea of trusting surviving segments attributed to older edits because such edits tend to add more material and hence contain more errors which do not seem to be offset by greater opportunities for error correction by later edits. \u00a9 2008 wiley periodicals, inc."
        },
        {
            "id": "R50173",
            "label": "Personal Knowledge Graphs: A Research Agenda",
            "doi": "10.1145/3341981.3344241",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "knowledge graphs, organizing structured information about entities, and their attributes and relationships, are ubiquitous today. entities, in this context, are usually taken to be anyone or anything considered to be globally important. this, however, rules out many entities people interact with on a daily basis. in this position paper, we present the concept of personal knowledge graphs: resources of structured information about entities personally related to its user, including the ones that might not be globally important. we discuss key aspects that separate them for general knowledge graphs, identify the main challenges involved in constructing and using them, and define a research agenda."
        },
        {
            "id": "R50376",
            "label": "Inferring Missing Categorical Information in Noisy and Sparse Web Markup",
            "doi": "10.1145/3178876.3186028",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "embedded markup of web pages has seen widespread adoption throughout the past years driven by standards such as rdfa and microdata and initiatives such as schema.org, where recent studies show an adoption by 39% of all web pages already in 2016. while this constitutes an important information source for tasks such as web search, web page classification or knowledge graph augmentation, individual markup nodes are usually sparsely described and often lack essential information. for instance, from 26 million nodes describing events within the common crawl in 2016, 59% of nodes provide less than six statements and only 257,000 nodes (0.96%) are typed with more specific event subtypes. nevertheless, given the scale and diversity of web markup data, nodes that provide missing information can be obtained from the web in large quantities, in particular for categorical properties. such data constitutes potential training data for inferring missing information to significantly augment sparsely described nodes. in this work, we introduce a supervised approach for inferring missing categorical properties in web markup. our experiments, conducted on properties of events and movies, show a performance of 79% and 83% f1 score correspondingly, significantly outperforming existing baselines."
        },
        {
            "id": "R50390",
            "label": "A Technology-enhanced Smart Learning Environment based on the Combination of Knowledge Graphs and Learning Paths: ",
            "doi": "10.5220/0009575104610468",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in our position paper on a technology-enhanced smart learning environment, we propose the innovative combination of a knowledge graph representing what one has to learn and a learning path defining in which order things are going to be learned. in this way, we aim to identify students\u2019 weak spots or knowledge gaps in order to individually assist them in reaching their goals. based on the performance of different learning paths, one might further identify the characteristics of a learning system that leads to successful students. in addition, by studying assessments and the different ways a particular problem can be solved, new methods for a multi-dimensional classification of assessments can be developed. the theoretical findings on learning paths in combination with the classification of assessments will inform the design and development of a smart learning environment. by combining a knowledge graph with different learning paths and the corresponding practical assessments we enable the creation of a smart learning tool. while the proposed approach can be applied to different educational domains and should lead to more effective learning environments fostering deep learning in schools as well as in professional settings, in this paper we focus on the domain of mathematics in primary and high schools as the main use case."
        },
        {
            "id": "R70539",
            "label": "Development of an infection screening system for entry inspection at airport quarantine stations using ear temperature, heart and respiration rates",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "after the outbreak of severe acute respiratory syndrome (sars) in 2003, many international airport quarantine stations conducted fever-based screening to identify infected passengers using infrared thermography for preventing global pandemics. due to environmental factors affecting measurement of facial skin temperature with thermography, some previous studies revealed the limits of authenticity in detecting infectious symptoms. in order to implement more strict entry screening in the epidemic seasons of emerging infectious diseases, we developed an infection screening system for airport quarantines using multi-parameter vital signs. this system can automatically detect infected individuals within several tens of seconds by a neural-network-based discriminant function using measured vital signs, i.e., heart rate obtained by a reflective photo sensor, respiration rate determined by a 10-ghz non-contact respiration radar, and the ear temperature monitored by a thermography. in this paper, to reduce the environmental effects on thermography measurement, we adopted the ear temperature as a new screening indicator instead of facial skin. we tested the system on 13 influenza patients and 33 normal subjects. the sensitivity of the infection screening system in detecting influenza were 92.3%, which was higher than the sensitivity reported in our previous paper (88.0%) with average facial skin temperature."
        },
        {
            "id": "R70541",
            "label": "A Pediatric Infection Screening System with a Radar Respiration Monitor for Rapid Detection of Seasonal Influenza among Outpatient Children",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background: seasonal influenza virus outbreaks cause annual epidemics, mostly during winter in temperate zone countries, especially resulting in increased morbidity and higher mortality in children. in order to conduct rapid screening for influenza in pediatric outpatient units, we developed a pediatric infection screening system with a radar respiration monitor. \\nmethods: the system conducts influenza screening within 10 seconds based on vital signs (i.e., respiration rate monitored using a 24 ghz microwave radar; facial temperature, using a thermopile array; and heart rate, using a pulse photosensor). a support vector machine (svm) classification method was used to discriminate influenza children from healthy children based on vital signs. to assess the classification performance of the screening system that uses the svm, we conducted influenza screening for 70 children (i.e., 27 seasonal influenza patients (11 \u00b1 2 years) at a pediatric clinic and 43 healthy control subjects (9 \u00b1 4 years) at a pediatric dental clinic) in the winter of 2013-2014. \\nresults: the screening system using the svm identified 26 subjects with influenza (22 of the 27 influenza patients and 4 of the 43 healthy subjects). the system discriminated 44 subjects as healthy (5 of the 27 influenza patients and 39 of the 43 healthy subjects), with sensitivity, specificity, positive predictive value (ppv), and negative predictive value (npv) of 81.5%, 90.7%, 84.6%, and 88.6%, respectively. \\nconclusion: the svm-based screening system achieved classification results for the outpatient children based on vital signs with comparatively high npv within 10 seconds. at pediatric clinics and hospitals, our system seems potentially useful in the first screening step for infections in the future."
        },
        {
            "id": "R140145",
            "label": "Assessment of Cities in Russia According to the Concept of \"Smart City\" in the Context of the Application of Information and Communication Technologies",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the article deals with the \"smart city\" concept, which is understood as such a model of the city, which provides, on the one hand, the sustainability of its development, and on the other - to stay in the comfort of its occupants. to analyze and assess the state of affairs, we have chosen one of the five \u201csmart city\u201d key elements, namely, the information-communication technologies including the following: new urban technologies, ict in education, ict in public health care, in electronic government and public services. the situation in three biggest volga federal region cities (kazan, samara and nizhniy novgorod) has been analyzed. recommendations on how to implement the \u201csmart city\u201d concept in other russia\u2019s cities are made. doi: 10.5901/mjss.2014.v5n18p55"
        },
        {
            "id": "R140147",
            "label": "The Role of Advanced Sensing in Smart Cities",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in a world where resources are scarce and urban areas consume the vast majority of these resources, it is vital to make cities greener and more sustainable. advanced systems to improve and automate processes within a city will play a leading role in smart cities. from smart design of buildings, which capture rain water for later use, to intelligent control systems, which can monitor infrastructures autonomously, the possible improvements enabled by sensing technologies are immense. ubiquitous sensing poses numerous challenges, which are of a technological or social nature. this paper presents an overview of the state of the art with regards to sensing in smart cities. topics include sensing applications in smart cities, sensing platforms and technical challenges associated with these technologies. in an effort to provide a holistic view of how sensing technologies play a role in smart cities, a range of applications and technical challenges associated with these applications are discussed. as some of these applications and technologies belong to different disciplines, the material presented in this paper attempts to bridge these to provide a broad overview, which can be of help to researchers and developers in understanding how advanced sensing can play a role in smart cities."
        },
        {
            "id": "R140151",
            "label": "Smart cities as corporate storytelling",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"on 4 november 2011, the trademark \u2018smarter cities\u2019 was officially registered as belonging to ibm. this was an important milestone in a struggle between it companies over visibility and legitimacy in the smart city market. drawing on actor-network theory and critical planning theory, the paper analyzes ibm's smarter city campaign and finds it to be storytelling, aimed at making the company an \u2018obligatory passage point\u2019 in the implementation of urban technologies. our argument unfolds in three parts. we first trace the emergence of the term \u2018smart city\u2019 in the public sphere. secondly, we show that ibm's influential story about smart cities is far from novel but rather mobilizes and revisits two long-standing tropes: systems thinking and utopianism. finally, we conclude, first by addressing two critical questions raised by this discourse: technocratic reductionism and the introduction of new moral imperatives in urban management; and second, by calling for the crafting of alternative smart city stories.\""
        },
        {
            "id": "R145280",
            "label": "Spectral line profiles of n=4 to n=5 transitions in C IV, N V and O VI",
            "doi": "10.1088/0953-4075/27/22/010",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R145287",
                    "label": "Spectral lines broadening in plasmas"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we report on measurements of stark profiles of the n=4 to n=5 transitions in the lithium-like ions c iv, n v and o vi. the measurements were performed in a plasma of the gas-liner pinch discharge where electron densities and temperatures are determined independently by 90 degrees thomson scattering. the comparison of the experimental data with theoretical calculations shows good agreement for all spectra especially when ion dynamics effects are taken into account."
        },
        {
            "id": "R151147",
            "label": "Open source software for disaster management",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "evaluating how the sahana disaster information system coordinates disparate institutional and technical resources in the wake of the indian ocean tsunami."
        },
        {
            "id": "R151149",
            "label": "Recovering IT in a disaster: Lessons from Hurricane Katrina",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "on august 29, 2005, hurricane katrina destroyed a data center and much of the communications infrastructure at the pascagoula and gulfport, mississippi, operations of the ship systems sector of northrop grumman corporation. simultaneously, the hurricane put a second data center out of commission in a shipyard near new orleans. the storm disrupted the lives of the sector\u2019s 20,000 employees and their dependents located in the gulf coast, caused over us$1 billion in damage for the company, and, for two weeks, brought two of the nation\u2019s largest shipyards to a standstill.2"
        },
        {
            "id": "R151196",
            "label": "Emergency! Web 2.0 to the Rescue!",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "emergent serendipity fosters volunteerism driven by creative problem solving, not simply following directions."
        },
        {
            "id": "R151208",
            "label": "Crisis Response Information Networks",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the past two decades, organizational scholars have focused significant attention on how organizations manage crises. while most of these studies concentrate on crisis prevention, there is a growing emphasis on crisis response. because information that is critical to crisis response may become outdated as crisis conditions change, crisis response research recognizes that the management of information flows and networks is critical to crisis response. yet despite its importance, little is known about the various types of crisis information networks and the role of it in enabling these information networks. employing concepts from information flow and social network theories, this paper contributes to crisis management research by developing four crisis response information network prototypes. these networks are based on two main dimensions: (1) information flow intensity and (2) network density. we describe how considerations of these two dimensions with supporting case evidence yield four prototypical crisis information response networks: information star, information pyramid, information forest, and information black-out. in addition, we examine the role of it within each information network structure. we conclude with guidelines for managers to deploy appropriate information networks during crisis response and with suggestions for future research related to it and crisis management."
        },
        {
            "id": "R151238",
            "label": "Social Media and Emergency Management: Exploring State and Local Tweets",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"social media for emergency management has emerged as a vital resource for government agencies across the globe. in this study, we explore social media strategies employed by governments to respond to major weather-related events. using social media monitoring software, we analyze how social media is used in six cities following storms in the winter of 2012. we listen, monitor, and assess online discourse available on the full range of social media outlets (e.g., twitter, facebook, blogs). to glean further insight, we conduct a survey and extract themes from citizen comments and government's response. we conclude with recommendations on how practitioners can develop social media strategies that enable citizen participation in emergency management.\""
        },
        {
            "id": "R151268",
            "label": "Social Media in Crisis: When Professional Responders Meet Digital Volunteers",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract in this paper, we examine the socio-technical impact that social media has had on coordination between professional emergency responders and digital volunteers. drawing from the research literature, we outline the problem space and explore ways to improve coordination and collaboration between these two groups. possible improvements include mediators, revisiting trust, emergency policy and process changes, a bounded social environment, digital volunteer data as context, and computational solutions. as the space matures and collaboration improves, we predict that professional responders will begin to rely on the data and products produced by digital volunteers. volunteer groups will be challenged to mature as well, to develop volunteer management systems, permanent staff, data management practices, and training for new volunteers to ensure consistent response to professional responders as needed."
        },
        {
            "id": "R151278",
            "label": "Do ICTs Help To Maintain Social Capital In The Disaster Recovery Phase? A Case Study Of The L'aquila Earthquake",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the use of information and communication technologies (icts), especially of the social networking sites (snss), in emergency situations is constantly on the rise. with this study, we have investigated the use of information and communication technologies (icts) after the massive changes that occurred in the physical environment following the l\u2019aquila earthquake (central italy) in 2009. two years after the disaster, thirteen key individuals affected by the earthquake were interviewed through semi-structured interviews. results suggest that new media can serve, to some extent, similar functions of sustaining the creation and maintenance of social relationships as the ones previously fulfilled by physical spaces. although limited, this research may have the potential to open up an interesting debate on the web-mediated construction of the concept of \u201cplace\u201d in the wake of a disaster.\\xa0"
        },
        {
            "id": "R151304",
            "label": "Effective use of information systems for emergency management: A representation theory perspective",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "effective use theory (eut) has emerged as a promising native information systems (is) theory to understand a central phenomenon of interest to the discipline: the effective use of information systems. while eut is widely accepted in operational control and management control contexts, its validity in chaotic environments has yet to be demonstrated. to contribute to the research program in eut, scholars called for contextualizing and assessing eut in chaotic environment, such as emergencies or crises events. this research seeks to apply eut to understand the effective use of emergency information systems (emis). seeking a grand theory of effective use in emis helps the onset of a structured research program and the development of a cumulative research tradition. that fosters emis as a would-be reference discipline for cross-disciplinary scholarship in emergency management. moreover, assessing eut in the edge context of emergencies, contributes to theory development by problematizing on assumptions that scholars have been considering unproblematic."
        },
        {
            "id": "R151306",
            "label": "Effective Use of Mobile-Enabled Emergency Warning Systems",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "effective warning can be life-saving in the event of an emergency. the pervasiveness of smartphones among the population affords public authorities a distributed network they can leverage for emergency notification. in germany, for instance, warning apps (e.g., nina, katwarn) are integrated within emergency warning systems (ews) authorities use for emergency communication. online reviews by users of two major warning apps, however, indicate the public is mildly unsatisfied with how they communicate emergency-related information. drawing on a representational perspective of information systems, we postulate that the intended use of ews is enabling the population to retrieve faithful digital representations of emergencies for informing protective counteractions. we test this theoretical claim by analyzing warning app online reviews and interviews with emergency management experts. in doing so, we identified 11 enabling dimensions of effective use of mobile-enabled warning systems. the dimensions constitute a model for studying the effective use of ews from a representational theory perspective. the a from an dimensions of representational fidelity: currency, completeness, exactitude, trust, and relevance."
        },
        {
            "id": "R151308",
            "label": "Twitter for Crisis Communication: Lessons Learned from Japan's Tsunami Disaster",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "two weeks after the great tohoku earthquake followed by the devastating tsunami, we have sent open-ended questionnaires to a randomly selected sample of twitter users and also analysed the tweets sent from the disaster-hit areas. we found that people in directly affected areas tend to tweet about their unsafe and uncertain situation while people in remote areas post messages to let their followers know that they are safe. our analysis of the open-ended answers has revealed that unreliable retweets (rts) on twitter was the biggest problem the users have faced during the disaster. some of the solutions offered by the respondents included introducing official hash tags, limiting the number of rts for each hash tag and adding features that allow users to trace information by maintaining anonymity."
        },
        {
            "id": "R152991",
            "label": "Assessing Risk Following a Wireless Emergency Alert: Are 90 Characters Enough?",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract in a relatively new initiative, homeland security and other emergency management officials use wireless cell technology to communicate wireless emergency alert (wea) messages to an increasingly mobile public. severe weather warnings represent one type of wea message that the public can receive on their cell phone. so far, officials have limited wea messages to 90 characters of text and therefore have excluded information-rich weather graphics like warning polygons and radar images. the question remains if this lean messaging strategy effectively communicates the risk and severity of the storm. in the current study, the researchers created prototype wea tornado warning messages equivalent to both popular mobile weather apps on the market and the national weather service\u2019s inws service to compare to typical wea text-only warnings. the study therefore investigates wea weather warning message effectiveness across one of four conditions: (1) wea (text-only) alert; (2) wea text+nws warning polygon; (3) wea text+radar image; and (4) wea text+warning polygon+radar image. participants were told they were driving through an unknown region of the us. the researchers asked participants to assess the perceived risk, perceived severity, and likelihood to contact a loved one for each message. the results indicate the decisions did not differ as a function of warning type. also, the participants\u2019 times to make the three decisions were equivalent across all four types of messages."
        },
        {
            "id": "R152993",
            "label": "Citizens\u00e2\u0080\u0099 adaptive or avoiding behavioral response to an emergency message on their mobile phone",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract since november 2012, dutch civil defense organizations employ nl-alert, a cellular broadcast-based warning system to inform the public. individuals receive a message on their mobile phone about the actual threat, as well as some advice how to deal with the situation at hand. this study reports on the behavioral effects of nl-alert (n = 643). the current risk communication literature suggested underlying mechanisms as perceived threat, efficacy beliefs, social norms, information sufficiency, and perceived message quality. results indicate that adaptive behavior and behavioral avoidance can be predicted by subsets of these determinants. affective and social predictors appear to be more important in this context that socio-cognitive predictors. implications for the use of cellular broadcast systems like nl-alert as a warning tool in emergency situations are discussed."
        },
        {
            "id": "R152995",
            "label": "Communicating with the Workforce during Emergencies: Developing an Employee Text Messaging Program in a Local Public Health Setting",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "short message service (sms) text messaging can be useful for communicating information to public health employees and improving workforce situational awareness during emergencies. we sought to understand how the 1,500 employees at public health \u2013 seattle &amp; king county, washington, perceived barriers to and benefits of participation in a voluntary, employer-based sms program. based on employee feedback, we developed the system, marketed it, and invited employees to opt in. the system was tested during an ice storm in january 2012. employee concerns about opting into an sms program included possible work encroachment during non-work time and receiving excessive irrelevant messages. employees who received messages during the weather event reported high levels of satisfaction and perceived utility from the program. we conclude that text messaging is a feasible form of communication with employees during emergencies. care should be taken to design and deploy a program that maximizes employee satisfaction."
        },
        {
            "id": "R152997",
            "label": "Disaster Warnings in Your Pocket: How Audiences Interpret Mobile Alerts for an Unfamiliar Hazard",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this study investigates how people interpret wireless emergency alerts (weas) and twitter\u2010length messages (\u2018tweets\u2019) delivered over mobile devices for an unfamiliar hazard. specifically, through four (n = 31) focus groups and 31 think\u2010out\u2010loud interviews, participants\u2019 understanding of, belief in and personalisation of weas and tweets were assessed for a mock improvised nuclear device detonation in a major u.s. metropolitan area. while participants offered a wide variety of interpretations, weas and tweets were often deemed confusing, difficult to believe and impersonal. participants also consistently found weas and tweets to be fear inducing and uninformative. the findings compel improvements in the way that weas and tweets are currently written, as well as indicate future directions for applied risk and crisis communication theory development."
        },
        {
            "id": "R153001",
            "label": "Milling and Public Warnings",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "given the potential of modern warning technology to save lives, discovering whether it is possible to craft mobile alerts for imminent events in a way that reduces people\u2019s tendency to seek and confirm information before initiating protective action is essential. the purpose of this study was to examine the possibility of designing messages for mobile devices, such as wireless emergency alert (wea) messages, to minimize action delay. the impact of messages with varied amounts of information on respondents\u2019 understanding, believing, personalizing, deciding, and intended milling was used to test emergent norm theory, using quantitative and qualitative methods. relative to shorter messages, longer public warning messages reduced people\u2019s inclination to search for and confirm information, thereby shortening warning response delay. the emergent norm theory used herein is broader in application than the context-specific models provided by leading warning scholars to date and yields deeper understanding about how people respond to warnings."
        },
        {
            "id": "R153502",
            "label": "THIS IS NOT A DRILL: Mobile Telephony, Information Verification, and Expressive Communication During Hawaii\u00e2\u0080\u0099s False Missile Alert",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "on saturday, 13 january 2018, residents of hawaii received a chilling message through their smartphones. it read, in all caps, ballistic missile threat inbound to hawaii. seek immediate shelter. this is not a drill. the message was mistakenly sent, but many residents lived in a threatened state of mind for the 38\\u2009minutes it took before a retraction was made. this study is based on a survey of 418 people who experienced the alert, recollecting their immediate responses, including how they attempted to verify the alert and how they used their mobile devices and social media for expressive interactions during the alert period. with the ongoing testing in the united states of nationwide wireless emergency alerts, along with similar expansions of these systems in other countries, the event in hawaii serves to illuminate how people understand and respond to mobile-based alerts. it shows the extreme speed that information\u2014including misinformation\u2014can flow in an emergency, and, for many, expressive communication affects people\u2019s reactions."
        },
        {
            "id": "R158044",
            "label": "Software Cinema-Video-based Requirements Engineering",
            "doi": "10.1109/re.2006.59",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "the dialogue between end-user and developer presents several challenges in requirements development. one issue is the gap between the conceptual models of end-users and formal specification/analysis models of developers. this paper presents a novel technique for the video analysis of scenarios, relating the use of video-based requirements to process models of software development. it uses a knowledge model-an rdf graph-based on a semiotic interpretation of film language, which allows mapping conceptual into formal models. it can be queried with rdql, a query language for rdf. the technique has been implemented with a tool which lets the analyst annotate objects as well as spatial or temporal relationships in the video, to represent the conceptual model. the video can be arranged in a scenario graph effectively representing a multi-path video. it can be viewed in linear time order to facilitate the review of individual scenarios by end-users. each multi-path scene from the conceptual model is mapped to a uml use case in the formal model. a uml sequence diagram can also be generated from the annotations, which shows the direct mapping of film language to uml. this sequence diagram can be edited by the analyst, refining the conceptual model to reflect deeper understanding of the application domain. the use of the software cinema technique is demonstrated with several prototypical applications. one example is a loan application scenario for a financial services consulting firm which acted as an end-user"
        },
        {
            "id": "R159585",
            "label": "On the effect of visual refinement upon user feedback in the context of video prototyping",
            "doi": "10.1145/2038476.2038497",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "there has been extensive discussion and research surrounding fidelity or refinement of prototypes in paper and software form, especially focusing on how the nature of prototypes influences the feedback that this prototype can help elicit during user testing. we extend this debate to the domain of video prototypes, where use scenarios are acted out on video. this study examines how the visual refinement (a.k.a. visual fidelity) of design representations presented in such videos impacts user feedback. an experiment was performed where two video prototypes were compared, one where the product is portrayed with high visual refinement and the other looking rough and sketchy. our results could not identify any significant effects upon the number or type of comments returned by users. this finding contrasts widely held contentions relating to fidelity of software and paper prototypes, though it agrees with similar experiments done with non video prototypes. in practice our results support the validity of testing with low fidelity videos and suggest that the choice of visual fidelity in video prototypes should be based on pragmatic project concerns, e.g., whether the video should be used also for communication and the resources that are available for prototyping."
        },
        {
            "id": "R159590",
            "label": "Interactive Multimedia Storyboard for Facilitating Stakeholder Interaction: Supporting Continuous Improvement in IT-ecosystems",
            "doi": "10.1109/quatic.2012.35",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "in order to stay competitive, elicitation and validation of user requirements are crucial tasks of a software system provider. however, reaching common ground among stakeholders and engineers is still difficult. in the special context of it-ecosystems, continuous improvement efforts call for non-standard requirements engineering methods. we propose a new kind of interaction between engineers and stakeholders that is based on multimedia technologies. our interactive storyboard aims to facilitate stakeholder interaction and enable requirements engineering optimized for fast-paced situations with severe time limitations. requirements and visions of new systems are documented in a multimedia representation. this representation is easy to create and requires no formal preparation for stakeholders to understand. thereby, we aim to improve comprehension of requirements in stakeholder meetings and strengthen stakeholder involvement. the use of video, photo and audio acts as a catalyst for fast-paced stakeholder interaction."
        },
        {
            "id": "R159596",
            "label": "At home with agents: exploring attitudes towards future smart energy infrastructures",
            "doi": "10.1145/2470654.2466152",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "energy systems researchers are proposing a broad range of future \"smart\" energy infrastructures to promote more efficient management of energy resources. this paper considers how consumers might relate to these future smart grids within the uk. to address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. users\\' reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. users showed a considerable lack of trust in energy companies raising a dilemma of design. while users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. this suggests the need to consider how to design software agents to enhance trust in these socio-economic settings."
        },
        {
            "id": "R159604",
            "label": "Speculative Requirements: Design Fiction and RE",
            "doi": "10.1109/re.2018.00-20",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "\"many innovative software products are conceived, developed and deployed without any conventional attempt to elicit stakeholder requirements. rather, they are the result of the vision and intuition of a small number of creative individuals, facilitated by the emergence of a new technology. in this paper we consider how the conditions that enable new products' emergence might be better anticipated, making innovations a little less reliant on individual vision and a little more informed by stakeholder need. this is particularly important where a new technology would have the potential for social impact, good or bad. speculative design seeks to explore this landscape. we describe a case study using a variant called design fiction to explore how plausible new technologies might impact on dementia care.\""
        },
        {
            "id": "R159618",
            "label": "From pixels to bytes: evolutionary scenario based design with video",
            "doi": "10.1145/2393596.2393631",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "change and user involvement are two major challenges in agile software projects. as change and user involvement usually arise spontaneously, reaction to change, validation and communication are thereby expected to happen in a continuous way in the project lifecycle. we propose evolutionary scenario based design, which employs video in fulfilling this goal, and present a new idea that supports video production using secondlife-like virtual world technology."
        },
        {
            "id": "R159623",
            "label": "User model and system model: the yin and yang in user-centered software development",
            "doi": "10.1145/2509578.2514737",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "software systems can be viewed from both external and internal perspectives. they are called user model and system model respectively in the human-computer interaction community. in this paper, we employ the yin-yang principle as an analytical tool for reviewing the relationship between the user model and the system model. in the traditional system-centered approach, the engineer is more concerned with the system model and does not pay much attention to the user model. however, as the user-centered approach has gained increasing acceptance in a number of projects, we claim that the user model and system model are the yin and yang in user-centered software development and, following the yin-yang principle, call for equal emphasis on both models. particularly, we propose using video-based scenarios as the representation of user models and reveal the benefits of the use of video in software development. as a case study, we describe how we have employed scenario videos in a project course and share best practices that we have identified for the creation of demo scenario videos."
        },
        {
            "id": "R159632",
            "label": "A multimedia computer supported cooperative work environment for requirements engineering",
            "doi": "10.1109/icsmc.1992.271669",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the authors describe the architecture and the main features of a multimedia computer supported cooperative work environment (mcscwe) and its application in requirements engineering. the mcscwe has been utilized in several requirements engineering activities, and the use of the mcscwe in a case study conducted for the sacramento area council of governments (sacog) is presented. for the sacog case study, 85 participants were convened by sacog and divided into seven spatially distributed groups working on the same problem sets, i.e., the problem of coming up with a strategic plan to reduce congestion and meet clean air requirements as required by federal law. the results of the case study demonstrate that the mcscwe was effective and efficient in assisting this group to come to consensus on the issues and strategies necessary to achieve these goals. >"
        },
        {
            "id": "R159637",
            "label": "Using video to re-present the user",
            "doi": "10.1145/203356.203368",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "advocates of user-centered design and participatory design, also referred to as \u201cwork practice practitioners\u201d include computer scientists, systems designers, software engineers, social scientists, industrial and graphic designers, marketing, sales, and service personnel. working singly or in teams, we have been identifying and combining effective techniques and methods of: gathering data, interacting with user participants, representing activities and observations, and integrating findings with the design and construction of new technologies."
        },
        {
            "id": "R159642",
            "label": "Requirements elicitation and validation with real world scenes",
            "doi": "10.1109/32.738338",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "a requirements specification defines the requirements for the future system at a conceptual level (i.e., class or type level). in contrast, a scenario represents a concrete example of current or future system usage. in early re phases, scenarios are used to support the definition of high level requirements (goals) to be achieved by the new system. in many cases, those goals can to a large degree be elicited by observing, documenting and analyzing scenarios about current system usage. to support the elicitation and validation of the goals achieved by the existing system and to illustrate problems of the old system, we propose to capture current system usage using rich media (e.g., video, speech, pictures, etc.) and to interrelate those observations with the goal definitions. thus, we aim at making the abstraction process which leads to the definition of the conceptual models more transparent and traceable. we relate the parts of the observations which have caused the definition of a goal or against which a goal was validated with the corresponding goal. these interrelations provide the basis for: 1) explaining and illustrating a goal model to, e.g., untrained stakeholders and/or new team members; 2) detecting, analyzing, and resolving a different interpretation of the observations; 3) comparing different observations using computed goal annotations; and 4) refining or detailing a goal model during later process phases. using the prime implementation framework, we have implemented the prime-crews environment, which supports the interrelation of conceptual models and captured system usage observations. we report on our experiences with prime-crews gained in an experimental case study."
        },
        {
            "id": "R159647",
            "label": "Video brainstorming and prototyping: techniques for participatory design",
            "doi": "10.1145/632716.632790",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "this tutorial is designed for hci designers and researchers interested in learning specific techniques for using video to support a range of participatory design activities. based on a combination of lectures, video demonstrations and hands-on exercises, the tutorial will give participants practical experience using video to observe users in laboratory and field settings, to analyze multimedia data, to explore and capture design ideas (video brainstorming), to simulate interaction techniques with users (wizard-of-oz and video prototyping) and to present video-based design ideas to users and managers. participants will gain experience shooting video and will address practical issues such as maintaining video archives and ethical issues such as obtaining informed consent. although these video techniques are applicable in a variety of design settings, the emphasis here is on participatory design, using video as a tool to help users, researchers and designers gather and communicate design ideas."
        },
        {
            "id": "R159657",
            "label": "Supporting requirements with video-based analysis",
            "doi": "10.1109/ms.2006.84",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "the dealing-room study is one of many studies that have used video to support requirements elicitation and the general design process. a growing body of experience with video-based ethnographies supports technology development in various domains, including air traffic and other control rooms, healthcare, public settings such as museums, and more experimental technologies, including media spaces and ubiquitous computing"
        },
        {
            "id": "R159662",
            "label": "Capturing Multimedia Requirements Descriptions with Mobile RE Tools",
            "doi": "10.1109/mere.2006.1",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "as tools for requirements engineering (re) become available on mobile devices using their multimedia capabilities to capture requirements descriptions is an obvious opportunity. this paper reports on two different approaches enabling mobile analysts and endusers to add multimedia descriptions to requirements. based on our mobile tool for scenario-based re we compare a solution based on the cots package microsoft pocket word with a novel plug-in solution providing more flexibility for tool users."
        },
        {
            "id": "R159671",
            "label": "MEGORE: Multimedia Enhanced Goal-Oriented Requirement Elicitation Experience in China",
            "doi": "10.1109/mere.2008.4",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "based on the survey results of chinese requirements engineering practices, this paper reports a few general patterns of chinese-culture-related ways of thinking and their influence to requirements elicitation activities. a multimedia enhanced goal oriented requirement elicitation method is proposed, in which media measures are used to help capture user requirements and preferences more easily. the method is applied in the design of an electronic marine chart navigation system. some lessons are summarized. we argue that a media-enhanced approach can help improve the efficiency of requirement elicitation process."
        },
        {
            "id": "R159675",
            "label": "Applying a Video-based Requirements Engineering Technique to an Airport Scenario",
            "doi": "10.1109/mere.2008.2",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "in the development of software-intensive systems, the interaction between customer and supplier is usually text-based. we argue that with agile project management gaining momentum, the inclusion of end-user feedback and a better mutual understanding between customer and supplier on hardware and software design goals becomes increasingly important. we propose the use of video techniques, video-based requirements engineering (vbre), to support the communication between all stakeholders. the key ingredients of vbre are user-centric videos and an exploratory environment for creating multi-path scenarios. in this workshop session, the participants will get hands-on experience with vbre techniques and tools while working on a fictitious airport baggage handling system."
        },
        {
            "id": "R159681",
            "label": "An experiment in teaching innovation in software engineering: video presentation",
            "doi": "10.1145/1449814.1449868",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R175350",
                    "label": "Effects of a shift from traditional to agile processes in a student project"
                }
            ],
            "abstract": "the dolli project was a large-scale educational student project course with a real customer, offered to students in their second year. in the time frame of a single semester a functional system was developed and delivered to the customer. we experimented with a shift from a traditional life-cycle to an agile process during the project, and used video techniques for defining requirements and meeting capture."
        },
        {
            "id": "R159686",
            "label": "Contravision: exploring users' reactions to futuristic technology",
            "doi": "10.1145/1753326.1753350",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "\"how can we best explore the range of users' reactions when developing future technologies that may be controversial, such as personal healthcare systems? our approach -- contravision -- uses futuristic videos, or other narrative forms, that convey either negative or positive aspects of the proposed technology for the same scenarios. we conducted a user study to investigate what range of responses the different versions elicited. our findings show that the use of two systematically comparable representations of the same technology can elicit a wider spectrum of reactions than a single representation can. we discuss why this is so and the value of obtaining breadth in user feedback for potentially controversial technologies.\""
        },
        {
            "id": "R159690",
            "label": "Focusing spontaneous feedback to support system evolution",
            "doi": "10.1109/re.2011.6051645",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "modern software systems are rarely built from scratch. they rather evolve over a long period of time while components and subsystems are developed independently. during that evolution, new and changing requirements emerge when end-users interact with the system. users encounter situations that provoke spontaneous complaints or suggestions, which may be the seed of new requirements. however, there are two challenges: how to capture spontaneous reactions and how to focus and let them mature into valid requirements? we propose concepts that enable citizens to report a problem or make a suggestion by smartphone. a key for preserving the spontaneous impetus is to lower the threshold for composing and sending feedback. software providers who are interested in feedback can define filtering and focusing aids; they guide end-users in giving focused feedback. focused feedback is also better prepared to be transformed to requirements. our con-texter tool demonstrates technical feasibility of these concepts. we explore and characterize a potential application domain empirically. based on the findings, we discuss potentials and limitations of our approach."
        },
        {
            "id": "R159700",
            "label": "Feed me, feed me: an exemplar for engineering adaptive software",
            "doi": "10.1145/2897053.2897071",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "the internet of things (iot) promises to deliver improved quality of life for citizens, through pervasive connectivity and quantified monitoring of devices, people, and their environment. as such, the iot presents a major new opportunity for research in adaptive software engineering. however, there are currently no shared exemplars that can support software engineering researchers to explore and potentially address the challenges of engineering adaptive software for the iot, and to comparatively evaluate proposed solutions. in this paper, we present feed me, feed me, an exemplar that represents an iot-based ecosystem to support food security at different levels of granularity: individuals, families, cities, and nations. we describe this exemplar using animated videos which highlight the requirements that have been informally observed to play a critical role in the success or failure of iot-based software systems. these requirements are: security and privacy, interoperability, adaptation, and personalisation. to elicit a wide spectrum of user reactions, we created these animated videos based on the contravision empirical methodology, which specifically supports the elicitation of end-user requirements for controversial or futuristic technologies. our deployment of contravision presented our pilot study subjects with an equal number of utopian and dystopian scenarios, derived from the food security domain, and described them at the different level of granularity. our synthesis of the preliminary empirical findings suggests a number of key requirements and software engineering research challenges in this area. we offer these to the research community, together with a rich exemplar and associated scenarios available in both their textual form in the paper, and as a series of animated videos (http://sead1.open.ac.uk/fmfm/)"
        },
        {
            "id": "R159710",
            "label": "Video Variants for CrowdRE: How to Create Linear Videos, Vision Videos, and Interactive Videos",
            "doi": "10.1109/rew.2019.00039",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "in crowdre, heterogenous crowds of stakeholders are involved in requirements elicitation. one major challenge is to inform several people about a complex and sophisticated piece of software so that they can effectively contextualize and contribute their opinions and insights. overly technical or boring textual representations might lead to misunderstandings or even repel some people. videos may be better suited for this purpose. there are several variants of video available: linear videos have been used for tutorials on youtube and similar platforms. interactive media have been proposed for activating commitment and valuable feedback. vision videos were explicitly introduced to solicit feedback about product visions and software requirements. in this paper, we describe essential steps of creating a useful video, making it interactive, and presenting it to stakeholders. we consider four potentially useful types of videos for crowdre and how to produce them. to evaluate feasibility of this approach for creating video variants, all presented steps were performed in a case study."
        },
        {
            "id": "R159714",
            "label": "Towards a Framework for Real Time Requirements Elicitation",
            "doi": "10.1109/mere.2006.6",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "eliciting complete and correct requirements is a major challenge in software engineering and incorrect requirements are a constant source of defects. it often happens that requirements are either recorded only partially or not at all. also, commonly, the rationale behind the requirements is not recorded or may be recorded, but is not accessible for the developers who need this information to support the decision making process when requirements change or need clarification. our proposed framework is designed to solve those problems by using video to record the requirements elicitation meetings and automatically extract important stakeholder statements. those statements are made available to the project members as video clips by using an re database to access the statements and/or by the integration with the sysiphus system."
        },
        {
            "id": "R159719",
            "label": "Design of a hyper media tool to support requirements elicitation meetings",
            "doi": "10.1109/case.1995.465308",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "\"introduces a hypermedia tool for requirements elicitation meetings. we consider such a meeting to be a consensus-making process among the participants, who have their own roles. participants in the meeting usually repeat the following activities to reach the final specification: (a) preparing the agenda and/or final specification for the next meeting while referring both to their own memory and the secretary's minutes, if accessible; and (b) pursuing the arguments in a meeting while referring either to the agenda for the meeting or to the minutes and their own memory about previous meetings. from observations of several real meetings, most of the final specifications were inconsistent, and unnecessary and redundant communication had occurred in the meetings because a large amount of verbal data in the meetings made each participant's memory and meeting minutes incomplete and ambiguous. from this point of view, our tool gives the participants the following facilities: (1) a plain record of the meetings; (2) a repository for the minutes and agenda extracted from the record; and (3) multi-modal and graphical user interfaces for referring to the repository. such facilities can be available for the participants to develop both suitable minutes and agendas. our tool improves the efficiency of a consensus-making process by suppressing unnecessary and redundant communication. >\""
        },
        {
            "id": "R159735",
            "label": "Software Professionals are Not Directors: What Constitutes a Good Video?",
            "doi": "10.1109/d4re.2018.00011",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "videos are one of the best documentation options for a rich and effective communication. they allow experiencing the overall context of a situation by representing concrete realizations of certain requirements. despite 35 years of research on integrating videos in requirements engineering (re), videos are not an established documentation option in terms of re best practices. several approaches use videos but omit the details about how to produce them. software professionals lack knowledge on how to communicate visually with videos since they are not directors. therefore, they do not necessarily have the required skills neither to produce good videos in general nor to deduce what constitutes a good video for an existing approach. the discipline of video production provides numerous generic guidelines that represent best practices on how to produce a good video with specific characteristics. we propose to analyze this existing know-how to learn what constitutes a good video for visual communication. as a plan of action, we suggest a literature study of video production guidelines. we expect to identify quality characteristics of good videos in order to derive a quality model. software professionals may use such a quality model for videos as an orientation for planning, shooting, post-processing, and viewing a video. thus, we want to encourage and enable software professionals to produce good videos at moderate costs, yet sufficient quality."
        },
        {
            "id": "R159762",
            "label": "Video artifacts for design: bridging the Gap between abstraction and detail",
            "doi": "10.1145/347642.347666",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "video artifacts help bridge the gap between abstraction and detail in the design process. this paper describes how our use and re-use of video artifacts affected the re-design of a graphical editor for building, simulating, and analyzing coloured petri nets. the two primary goals of the project were to create design abstractions that integrate recent advances in graphical interaction techniques and to explicitly support specific patterns of use of petri nets in real-world settings.\\nusing a participatory design process, we organized a series of video-based design activities that helped us manage the tension between finding useful design abstractions and specifying the details of the user interface. video artifacts resulting from one activity became the basis for the next, facilitating communication among members of the multi-disciplinary design team. the video artifacts provided an efficient way of capturing and incorporating subtle aspects of petri nets in use into our design and ensured that the implementation of our design principles was grounded in real-world work practices."
        },
        {
            "id": "R159774",
            "label": "Reframing Societal Discourse as Requirements Negotiation: Vision Statement",
            "doi": "10.1109/rew.2017.17",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "challenges in spatial planning include adjusting settlement patterns to increasing or shrinking populations; it also includes organizing food delivery in rural and peripheral environments. discourse typically starts with an open problem and the search for a holistic and innovative solution. software will often be needed to implement the innovation. spatial planning problems are characterized by large and heterogeneous groups of stakeholders, such as municipalities, companies, interest groups, citizens, women and men, young people and children. current techniques for participation are slow, laborious and costly, and they tend to miss out on many stakeholders or interest groups.we propose a triple shift in perspective: (1) discourse is reframed as a requirements process with the explicit goal to state software, hardware, and organizational requirements. (2) due to the above-mentioned characteristics of spatial planning problems, we suggest using techniques of requirements engineering (re) and crowdre for getting stakeholders (e.g. user groups) involved. (3) we propose video as a medium for communicating problems, solution alternatives, and arguments effectively within a mixed crowd of officials, citizens, children and elderly people.although few spatial planning problems can be solved by software alone, this new perspective helps to focus discussions anyway. re techniques can assist in finding common ground despite the heterogeneous group of stakeholders, e.g. citizens. digital requirements and video are well-suited for facilitating distribution, feedback, and discourse via the internet. in this paper, we propose this new perspective as a timely opportunity for the spatial planning domain \u2013 and as an increasingly important application domain of crowdre."
        },
        {
            "id": "R159798",
            "label": "Keep Your Stakeholders Engaged: Interactive Vision Videos in Requirements Engineering",
            "doi": "10.1109/rew53955.2021.00014",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172981",
                    "label": "Keep Stakeholders Focussed with Interactive Video Elements"
                }
            ],
            "abstract": "one of the most important issues in requirements engineering (re) is the alignment of stakeholders\u2019 mental models. making sure that all stakeholders share the same vision of a changing system is crucial to the success of any project. misaligned mental models of stakeholders can lead to conflicting requirements. a promising approach to this problem is the use of video showing a system vision, so-called vision videos, which help stakeholders to disclose, discuss, and align their mental models of the future system. however, videos have the drawback of allowing viewers to adopt a passive role, as has been shown in research on e-learning. in this role, viewers tend to be inactive, unfocused and bored while watching a video. in this paper, we learn and adopt findings from scientific literature in the field of e-learning on how to mitigate this passive role while watching vision videos in requirements engineering. in this way, we developed concepts that incorporate interactive elements into vision videos to help viewers stay focused. these elements include questions that are asked during the video and ways for viewers to decide what happens next in the video. in a preliminary evaluation with twelve participants, we found statistically significant differences when comparing the interactive vision videos with their traditional form. using an interactive vision videos, viewers are noticeably more engaged and gather more information on the shown system."
        },
        {
            "id": "R159971",
            "label": "Fabrication of polycrystalline 3C-SiC micro pressure sensors for hightemperature applications",
            "doi": "10.5369/JSST.2010.19.1.031",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "high temperature micro pressure sensors were fabricated by using polycrystalline 3c-sic piezoresistors grown on oxidized soi substrates by apcvd. these have been made by bulk micromachining under diaphragm and si membrane thickness of . the pressure sensitivity of implemented pressure sensors was 0.1 mv/. the nonlinearity and the hysteresis of sensors were and . in the temperature range of with 5 bar fs, tcs (temperature coefficient of sensitivity), tcr (temperature coefficient of resistance), and tcgf (temperature coefficient of gauge factor) of the sensor were -1867 ppm/, -792 ppm/, and -1042 ppm/, respectively."
        },
        {
            "id": "R159975",
            "label": "Improved reliability of SiC pressure sensors for long term high temperature applications",
            "doi": "10.1109/transducers.2011.5969561",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we report advancement in the reliability of silicon carbide pressure sensors operating at 600 \u00b0c for extended periods. the large temporal drifts in zero pressure offset voltage at 600 \u00b0c observed previously were significantly suppressed to allow improved reliable operation. this improvement was the result of further enhancement of the electrical and mechanical integrity of the bondpad/contact metallization, and the introduction of studded bump bonding on the pad. the stud bump contact promoted strong adhesion between the au bond pad and the au die-attach. the changes in the zero offset voltage and bridge resistance over time at temperature were explained by the microstructure and phase changes within the contact metallization, that were analyzed with auger electron spectroscopy (aes) and field emission scanning electron microscopy (fe-sem)."
        },
        {
            "id": "R159979",
            "label": "Silicon carbide pressure sensor for high temperature and high pressure applications: Influence of substrate material on performance",
            "doi": "10.1109/transducers.2011.5969209",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we have studied the effect of substrate material related to thermal mismatch for silicon carbide (sic) diaphragm-based capacitive pressure sensors. two sets of devices, with identical dimensions and fabrication processes were made on poly-sic and si substrates. designed for a maximum pressure of 4.83 mpa (700 psi), these devices were operated in small-deflection mode and tested at room temperature and 500oc. at room temperature, the sic- and si-substrate devices showed sensitivities of 6.5e-04 and 6.1e-04 ff/pa, nonlinearities of 5.0% and 3.9%, and resolutions of 0.2% and 0.3%, respectively. at 500oc, the sic- and si-substrate devices showed sensitivities of 1.2e-02 and 1.1e-02 ff/pa, nonlinearities of 2.6% and 3.8%, and resolutions of 0.5% and 1.8%, respectively. for the chosen design parameters, the results show little influence of substrate material on sensor performance."
        },
        {
            "id": "R159984",
            "label": "4H-SiC Piezoresistive Pressure Sensors at 800 \u00c2\u00b0C With Observed Sensitivity Recovery",
            "doi": "10.1109/led.2014.2379262",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "uncooled mems-based 4h-sic wheatstone bridge configured piezoresistive pressure sensors were demonstrated from 23 \u00b0c to 800 \u00b0c. the full-scale output (fso) voltage exhibited gradual decrease with increasing temperature from 23 \u00b0c to 400 \u00b0c, then swung upward as temperature increased further to where the values measured at 800 \u00b0c were nearly equal to or higher than the room temperature values. this newly observed fso behavior in 4h-sic contrasts sharply with the fso behavior of silicon piezoresistive sensors that decrease continuously with increasing temperature. the increase in the sensor output sensitivity at 800 \u00b0c implies higher signal to noise ratio and improved fidelity, thereby offering promise of further insertion into >600 \u00b0c environments without the need for cooling and complex signal conditioning."
        },
        {
            "id": "R160000",
            "label": "Piezoresistive n-type 4H-SiC pressure sensor with membrane formed by mechanical milling",
            "doi": "10.1109/icsens.2011.6126936",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a 4h-sic pressure sensor with piezoresistive transducers, for harsh environment applications, e.g., high temperature (\u223c650\u00b0c) and/or in corrosive chemicals is presented. the sensing membrane, 1 mm in diameter and 50 \u00b5m in thickness, was formed by milling (drilling) a bulk single crystal sic wafer. both transverse and longitudinal piezoresistors were formed on the membrane out of an n-type sic epitaxial layer. ohmic contacts were obtained with ta/ni/pt metallization followed by annealing at 1000\u00b0c for 20 min. the sensor was assembled on a small board and characterized under hydrostatic pressures up to 60 bar at room temperature. the obtained pressure sensitivity was 268 \u00b5v/v/bar. the sensor chip was exposed in air at 600\u00b0c for 165 hours and changes in bridge resistance were measured."
        },
        {
            "id": "R160004",
            "label": "A 350 \u00c2\u00b0C piezoresistive n-type 4H-SiC pressure sensor for hydraulic and pneumatic pressure tests",
            "doi": "10.1088/1361-6439/ab7785",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "it has been a challenge to develop pressure sensors that can work in harsh environments. in this work, a piezoresistive n-type 4h-sic pressure sensor is demonstrated, capable of working at 350 \u00b0c under hydraulic and pneumatic pressure. the pressure measuring range of this sensor is 7 mpa and the chip dimension is 2.5 mm \u00d7 2.5 mm \u00d7 0.23 mm. a reliable ti/tasi2/pt metal ohmic contact is used in the sensor and experimental results show that the metal combination can withstand a wide temperature range of 30 \u00b0c\u2013350 \u00b0c. in order to avoid thermal stress induced by the mismatch of thermal expansion coefficients of different packaging materials when increasing temperature, a double-layer bonding scheme of cement glue and epoxy is proposed. the inner layer of the chip and the kovar alloy base are directly bonded with the epoxy, while the outer layer is wrapped with the high-temperature cement glue. experiments confirm that this method can achieve reliable packaging with temperatures up to 350 \u00b0c for 5 h. based on the above key technologies, the sensitivity of this sensor can reach 13.2 mv v\u22121 kpa\u22121 and the test data exhibit high linearity and repeatability. static tests prove that the sensor has good media compatibility which can operate under a hydraulic pressure load at 220 \u00b0c and a barometric pressure load under 350 \u00b0c. the sensor in this work can provide a reference for pressure measurements at high temperature and in complex media environments."
        },
        {
            "id": "R160010",
            "label": "Development of All-SiC Absolute Pressure Sensor Based on Sealed Cavity Structure",
            "doi": "10.1109/jsen.2021.3121882",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "silicon carbide has promising potential in high temperature pressure sensors due to its excellent material properties. this paper presents a piezoresistive n-type 4h-sic absolute pressure sensor based on an all-sic sealed cavity structure, which provides a new approach for the development of sic pressure sensors. firstly, the structural design of the pressure sensor with the measurement range of 10 mpa was conducted through the finite element method. after that, a sic diaphragm with controllable thickness and high surface quality was achieved through grinding and chemical mechanical polishing process, which indicated that the root mean square surface roughness was 0.168 nm and the relative standard deviation of diaphragm thickness was 0.24%. a patterned sic substrate with shallow grooves obtained by shallow etching process was directly bonded onto the sic diaphragm to form the sealed cavity structure. finally, the performance test of the fabricated sensor at 30 \u00b0c indicated that the sensitivity was 1.56 mv/v/mpa, the nonlinearity was 0.034% fs, and the accuracy was 0.29% fs. the temperature coefficient of sensitivity exhibited a negative value of \u22120.134% fs/\u00b0c at 250 \u00b0c. moreover, the maximum temporal drift of zero pressure output at 250 \u00b0c was only 0.12 mv in 14 hours after several high temperature aging tests. the above research demonstrates the application potential of the proposed sic sealed cavity structure in all-sic pressure sensors, which provides a technical foundation for the development of high temperature pressure sensors."
        },
        {
            "id": "R160015",
            "label": "Demonstration of SiC Pressure Sensors at 750 \u00c2\u00b0C",
            "doi": "10.4071/hitec-ta21",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we report the first demonstration of mems-based 4h-sic piezoresistive pressure sensors tested at 750 \u00b0c and in the process confirmed the existence of strain sensitivity recovery with increasing temperature above 400 \u00b0c, eventually achieving near or up to 100 % of the room temperature values at 750 \u00b0c. this strain sensitivity recovery phenomenon in 4h-sic is uncharacteristic of the well-known monotonic decrease in strain sensitivity with increasing temperature in silicon piezoresistors. for the three sensors tested, the room temperature full-scale output (fso) at 200 psig ranged between 29 and 36 mv. although the fso at 400 \u00b0c dropped by about 60 %, full recovery was achieved at 750 \u00b0c. this result will allow the operation of sic pressure sensors at higher temperatures, thereby permitting deeper insertion into the engine combustion chamber to improve the accurate quantification of combustor dynamics."
        },
        {
            "id": "R160019",
            "label": "Design of SiC-Doped Piezoresistive Pressure Sensor for High-Temperature Applications",
            "doi": "10.3390/s21186066",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "within these studies the piezoresistive effect was analyzed for 6h-sic and 4h-sic material doped with various elements: n, b, and sc. bulk sic crystals with a specific concentration of dopants were fabricated by the physical vapor transport (pvt) technique. for such materials, the structures and properties were analyzed using x-ray diffraction, sem, and hall measurements. the samples in the form of a beam were also prepared and strained (bent) to measure the resistance change (gauge factor). based on the results obtained for bulk materials, piezoresistive thin films on 6h-sic and 4h-sic substrate were fabricated by chemical vapor deposition (cvd). such materials were shaped by focus ion beam (fib) into pressure sensors with a specific geometry. the characteristics of the sensors made from different materials under a range of pressures and temperatures were obtained and are presented herewith."
        },
        {
            "id": "R160025",
            "label": "Toward a Self-Sensing Piezoresistive Pressure Sensor for All-SiC Monolithic Integration",
            "doi": "10.1109/jsen.2020.2998915",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this work focusses on the design and fabrication of surface micromachined pressure sensors, designed in a modular way for the integration with analog front-end read-out electronics. polycrystalline 3c silicon carbide (sic) was used to fabricate free-standing high topography cavities exploiting surface micromaching. the poly-sic was in-situ doped and the membrane itself is used as piezoresistive element, thereby forming a so-called self-sensing membrane, easing fabrication. after sacrificial release, the cavity is sealed by conformal deposition of poly-sic whereby the reference pressure of the absolute pressure sensor is determined. aluminum and titanium metallizations were used and ohmic contacts were confirmed by wafer-scale measurements. measurements were carried out on different devices ranging from 100 kpa down to 10 pa at room temperature. the wheatstone bridge yields a logarithmic response of 1.1 mvbar $^{-}1\\\\text{v}^{-}1$ . a square 300 $\\\\mu \\\\text{m}$ device exhibits a logarithmic impedance behavior yielding a response of $\\\\delta {r} / {r}$ of $1.6\\\\times 10^{-3}$ bar $^{-1}$ . the realized pressure devices are a first step toward a sic asic + mems platform for intended operation in harsh environments, such as industrial process monitoring, combustion control or structural health monitoring. the future outlook of the integration concept implies extended functionality by front-end transducer read-out, signal amplification and communication."
        },
        {
            "id": "R160032",
            "label": "Fabrication of SiC Sealing Cavity Structure for All-SiC Piezoresistive Pressure Sensor Applications",
            "doi": "10.3390/ma14010128",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "high hardness and corrosion resistance of sic (silicon carbide) bulk materials have always been a difficult problem in the processing of an all-sic piezoresistive pressure sensor. in this work, we demonstrated a sic sealing cavity structure utilizing sic shallow plasma-etched process (\u226420 \u03bcm) and sic\u2013sic room temperature bonding technology. the sic bonding interface was closely connected, and its average tensile strength could reach 6.71 mpa. in addition, through a rapid thermal annealing (rta) experiment of 1 min and 10 mins in n2 atmosphere of 1000 \u00b0c, it was found that si, c and o elements at the bonding interface were diffused, while the width of the intermediate interface layer was narrowed, and the tensile strength could remain stable. this sic sealing cavity structure has important application value in the realization of an all-sic piezoresistive pressure sensor."
        },
        {
            "id": "R160037",
            "label": "Design and Fabrication of Bulk Micromachined 4H-SiC Piezoresistive Pressure Chips Based on Femtosecond Laser Technology",
            "doi": "10.3390/mi12010056",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "silicon carbide (sic) has promising potential for pressure sensing in a high temperature and harsh environment due to its outstanding material properties. in this work, a 4h-sic piezoresistive pressure chip fabricated based on femtosecond laser technology was proposed. a 1030 nm, 200 fs yb: kgw laser with laser average powers of 1.5, 3 and 5 w was used to drill blind micro holes for achieving circular sensor diaphragms. an accurate per lap feed of 16.2 \u03bcm was obtained under laser average power of 1.5 w. after serialized laser processing, the machining depth error of no more than 2% and the surface roughness as low as 153 nm of the blind hole were measured. the homoepitaxial piezoresistors with a doping concentration of 1019 cm\u22123 were connected by a closed-loop wheatstone bridge after a rapid thermal annealing process, with a specific contact resistivity of 9.7 \u00d7 10\u22125 \u03c9 cm2. our research paved the way for the integration of femtosecond laser micromachining and sic pressure sensor chips manufacturing."
        },
        {
            "id": "R160049",
            "label": "Development of a 4H-SiC Piezoresistive Pressure Sensor for High Temperature Applications",
            "doi": "10.1109/nems.2019.8915652",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a piezoresistive pressure sensor based on 4h-sic was developed for working over 500\u00b0c. the designed pressure range is 0-7mpa for special aviation applications. as demonstrated with experimental results, in this pressure range, the sensor shows excellent accuracy and repeatability from 30\u00b0c to 500\u00b0c. compared with previous studies, in mems processing of the sensor chip, a suitable alloy system was determined to form a stable high-temperature ohmic contact. besides, the chip was packaged with mechanical structure and ceramic glue of similar thermal expansion coefficient to avoid thermal stress induced when increasing temperature. with the above measures taken, the sensor performance can be significantly improved. the design, fabrication, and package of this sensor provide support for high-temperature use. additionally, this work can be a reference for future research in this field."
        },
        {
            "id": "R160053",
            "label": "Characterization of Silicon Carbide Pressure Sensors at 800 \u00c2\u00b0C",
            "doi": "10.1109/transducers.2019.8808553",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "initial characterization of mems-based single crystal 4h-sic piezoresistive pressure sensors has been performed to determine the operational reliability over time at 800 \u00b0c. important parameters such as the zero pressure offset, bridge resistance, and pressure sensitivity as affected by temperature were extracted. these parameters showed relative stability within the prescribed operational window of the sensor at 800 \u00b0c. of significance was the increase in pressure sensitivity with increasing temperature beyond 400 \u00b0c, to the extent that the sensitivity at 800 \u00b0c equal to or higher than the room temperature value. the sensor can, therefore, be inserted further into the higher temperature section of the test article, thereby making it possible to capture higher frequency bandwidths of the thermoacoustic instabilities, which is critical for the validation of computational fluid dynamics predictive models."
        },
        {
            "id": "R160061",
            "label": "Fabrication and testing of bulk micromachined silicon carbide piezoresistive pressure sensors for high temperature applications",
            "doi": "10.1109/jsen.2006.870145",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper explores the development of high-temperature pressure sensors based on polycrystalline and single-crystalline 3c-sic piezoresistors and fabricated by bulk micromachining the underlying 100-mm diameter (100) silicon substrate. in one embodiment, phosphorus-doped apcvd polycrystalline 3c-sic (poly-sic) was used for the piezoresistors and sensor diaphragm, with lpcvd silicon nitride employed to electrically isolate the piezoresistor from the diaphragm. these piezoresistors fabricated from poly-sic films deposited at different temperatures and doping levels were characterized, showing -2.1 as the best gauge factor and exhibited a sensitivities up to 20.9-mv/v*psi at room temperature. in a second embodiment, epitaxially-grown unintentionally nitrogen-doped single-crystalline 3c-sic piezoresistors were fabricated on silicon diaphragms, with thermally grown silicon dioxide employed for the piezoresistor electrical isolation from the diaphragm. the associated 3c-sic/sio/sub 2//si substrate was fabricated by bonding a (100) silicon wafer carrying the 3c-sic onto a silicon wafer with thermal oxide covering its surface. the 3c-sic handle wafer was then etched away in koh. the diaphragm was fabricated by time etching the silicon substrate. the sensors were tested at temperatures up to 400/spl deg/c and exhibited a sensitivity of 177.6-mv/v*psi at room temperature and 63.1-mv/v*psi at 400/spl deg/c. the estimated longitudinal gauge factor of 3c-sic piezoresistors along the [100] direction was estimated at about -18 at room temperature and -7 at 400/spl deg/c."
        },
        {
            "id": "R160069",
            "label": "A high temperature pressure sensor with \u00ce\u00b2-SiC piezoresistors on SOI substrates",
            "doi": "10.1109/sensor.1997.635502",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper reports about the first piezoresistive pressure sensor for high operating temperatures using single crystalline, n-type /spl beta/-sic piezoresistors on silicon on insulator (soi) substrates. the new silicon carbide on insulator (sicoi) layer structure prevents a leakage current flow through the substrate at high temperatures up to 723 k. the sensor was tested in the temperature range between room temperature and 573 k. the sensitivity of the device at room temperature is approximately 20.2 /spl mu/v/vkpa. this corresponds to a longitudinal gauge factor of -32 in the [100]-direction. the temperature coefficient of sensitivity (tcs) is -0.16 %k/sup -1/ at 573 k."
        },
        {
            "id": "R160077",
            "label": "6H-SiC pressure sensor operation at 600\u00c2\u00b0C",
            "doi": "10.1109/hitec.1998.676799",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "experimental results of batch-microfabricated 6h-sic piezoresistive pressure sensors operational between room temperature to 600/spl deg/c are reported. for a diaphragm thickness of 30 /spl mu/m, the typical room temperature full-scale output for maximum pressure of 1000 psi was 66.41 mv, with a hysteresis and nonlinearity of less than 1%fso across the range of operating temperature. for a diaphragm thickness of 40 /spl mu/m, the typical room temperature full-scale output for maximum pressure of 1000 psi was between 39 mv and 42 mv, also with a hysteresis and nonlinearity of less than 1% across the range of operating temperature. the temperature coefficient of resistance (tcr) had negative values from room temperature to 350/spl deg/c due to the gradual drop in input resistance. the temperature coefficient of gauge factor (tcgf) averaged about -0.14%//spl deg/c from room temperature to 600/spl deg/c. these values obtained were consistent with the characteristics of 6h-sic epilayer having an impurity concentration of 2/spl times/10/sup 19/ cm/sup -3/."
        },
        {
            "id": "R160081",
            "label": "\u00ce\u00b1(6H)-SiC pressure sensors for high temperature applications",
            "doi": "10.1109/memsys.1996.493844",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a batch-microfabricated 6h-sic diaphragm-based piezoresistive pressure sensors with working temperature range between 80/spl deg/f to 500/spl deg/f had been produced. the net output voltage shows an output voltage of 131.59 mv at full-scale pressure of 1000 psi. the net output voltage response to temperature up to 500/spl deg/f is also presented. the temperature coefficient of resistance (tcr) of the device exhibits a tcr of -3.07%/100/spl deg/f at 180/spl deg/f and eventually becomes a positive value of 4.24%/100/spl deg/f at 500/spl deg/f. the temperature coefficient of gage factor (tcgf) exhibits negative values of -15%/100/spl deg/f and -10%/100/spl deg/f at 180/spl deg/f and 500/spl deg/f, respectively. the problem of micropipes in 6h-sic was effectively resolved, making it possible to fabricate thin diaphragms of about 25 /spl mu/m."
        },
        {
            "id": "R160093",
            "label": "Effects of annealing on irradiated sic piezoresistive pressure sensor",
            "doi": "10.3938/jkps.61.1005",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the effects of temperature on the annealing of a silicon carbide (sic) piezoresistive pressure sensor exposed to high-fluence neutron irradiation were investigated. the, sic piezoresistive sensor was irradiated with gamma rays with the 60co gamma-ray irradiator, and fast neutrons at beam port 1 (bp1) and at the auxiliary irradiation facility (aif) of ohio state university\u2019s nuclear reactor laboratory (osunrl). annealing temperatures up to 400 \u00b0c were applied to the pressure sensor. the pressure-output voltage results showed recovery after the sic piezoresistive pressure sensor had been annealed. the bridge resistances of the sic pressure sensor stayed at the same level for annealing temperatures up to 300 \u00b0c. after annealing at 400 \u00b0c, the resistance values of the sensor changed dramatically."
        },
        {
            "id": "R160097",
            "label": "\u00ce\u00b1(6H)-SiC pressure sensors at 350\u00c2\u00b0C",
            "doi": "10.1109/iedm.1996.554038",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "6h-sic piezoresistive pressure sensors operational at 350/spl deg/c, with potential to operate up to 600/spl deg/c, were batch fabricated and tested. the full scale output (fso) was 87.89 mv and 38.21 mv at 23/spl deg/c and 350/spl deg/c, respectively, at full scale pressure of 1000 psi. no serious degradation was observed when operated for ten hours at 308/spl deg/c. the temperature coefficient of resistance (tcr) was 1.52%/100/spl deg/c and 16%/100/spl deg/c at 140/spl deg/c and 350/spl deg/c, respectively. the temperature coefficient of gauge factor (tcgf) exhibited negative values of -26.1%/100/spl deg/c and -17.55%/100/spl deg/c at 140/spl deg/c and 350/spl deg/c, respectively. this work demonstrated batch manufacturing and operation of pressure sensors for temperatures beyond silicon technology."
        },
        {
            "id": "R160101",
            "label": "Zero offset drift suppression in SiC pressure sensors at 600",
            "doi": "10.1109/icsens.2010.5690714",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "temporal drifts in zero pressure offset voltage, voz, observed in piezoresistive silicon carbide (sic) pressure sensors at 600 \u00b0c were significantly suppressed to allow reliable operation. by modifying the bondpad/contact metallization, the voz relative drift velocity at 600 \u00b0c was suppressed to within \u00b1 0.5 mv.hr\u22121, for over 1000 hours. microstructural changes within the contact metallization were analyzed with auger electron spectroscopy (aes) and scanning electron microscopy (sem). this metallization scheme may improve sic pressure sensor reliability in short duration ground/flight tests and lower temperature (\u223c300 \u00b0c) remote pressure monitoring (i.e., geothermal, and deep well drilling)."
        },
        {
            "id": "R160105",
            "label": "High temperature SiC pressure sensors with low offset voltage shift",
            "doi": "10.1117/12.2050812",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "very low (~0.125 mv) shifts in offset voltage were achieved in silicon carbide (sic) piezoresistive pressure sensors during thermal cycling between 25 and 500 \u00b0c for 500 hours. it resulted in reduced measurement error to ~ 0.36 % and ~ 0.9 % of the full-scale output at 25 and 500 \u00b0c, respectively. the reduction in the offset shift was the result of the advancement made in controlling the intermetallic diffusion and microstructural phase changes within the contact metallization. the low offset voltage results provide critical figures of merit needed for quantifying the measurement error and correction when the sic pressure sensors are used. the results demonstrate more robust and reliable sic pressure sensors operating with significantly reduced fso errors at 500 \u00b0c."
        },
        {
            "id": "R160109",
            "label": "Piezoresistive 4H-Silicon Carbide (SiC) pressure sensor",
            "doi": "10.1109/sensors47087.2021.9639506",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a novel 4h sic piezoresistive pressure sensor has been fabricated using a high temperature metallization system. the sensor has been fabricated using 100 mm 4h- sic wafers with an double epi layer. while the top has been etched to form the piezoresistors, the lower epi-layer is oppositely doped acts as an isolation layer. the formation of the membrane has been performed by a reactive ion etching (rie) process enabling etch rates of up to 4 \u00b5m/min through bulk sic. the gold-based metallization system is able to withstand high temperatures."
        },
        {
            "id": "R161423",
            "label": "Atomic Layer Deposition of Nanostructured TiO2 Photocatalysts via Template Approach",
            "doi": "10.1021/cm062576e",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "two kinds of tio2 nanostructures, i.e., tio2-coated alumina membranes and tio2-coated ni nanowires, were prepared by combining different kinds of porous alumina, template-directed electrodeposition..."
        },
        {
            "id": "R161427",
            "label": "Atomic Layer Deposition of TiO2 on Aerogel Templates: New Photoanodes for Dye-Sensitized Solar Cells",
            "doi": "10.1021/jp802216p",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "high surface area mesoporous aerogel films were prepared on conductive glass substrates. atomic layer deposition was employed to coat the aerogel template conformally with various thicknesses of tio2 with subnanometer precision. the tio2-coated aerogel membranes were incorporated as photoanodes in dye-sensitized solar cells. the charge diffusion length was found to increase with increasing thickness of tio2 leading to increasing current and efficiency. initial devices exhibited power conversion efficiencies of up to 4.3% under 100 w m\u22122 light intensity. the novel fabrication technique provides a facile, oxide materials general method to prepare high surface area pseudo-one-dimensional dssc photoanodes with promising performance."
        },
        {
            "id": "R161431",
            "label": "Toward Plasmonic Solar Cells: Protection of Silver Nanoparticles via Atomic Layer Deposition of TiO2",
            "doi": "10.1021/la900113e",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "plasmonic silver nanoparticles have unique properties that lend themselves to unusual optical applications, potentially including use as absorption amplifiers in dye-sensitized solar cells (dsscs). however, these particles are easily damaged under oxidizing conditions. atomic layer deposition of tio2 onto transparent-conductive-oxide-supported silver particles was examined as a means of protecting particles while simultaneously incorporating them into dssc-functional photoelectrodes. the resulting assemblies were exposed to corrosive i-/i3- solutions, and the degree of silver etching was determined via scanning electron microscopy and ultraviolet-visible spectroscopy. to form a pinhole-free (i.e., fully protective) crystalline tio2 layer, 7.7 nm (300 cycles) must be deposited. if, however, a 0.2 nm (2 cycles) al2o3 adhesion layer is included, only 5.8 nm (211 cycles) of tio2 are necessary for the formation of a pinhole-free coating."
        },
        {
            "id": "R161435",
            "label": "Solar cells based on atomic layer deposition",
            "doi": "10.1049/cp.2010.1227",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the advantages of atomic layer deposition (ald) include highly controlled deposition parameters, deposition uniformity, ultra-precise film thickness and good step coverage. its prominent characteristics have drew attention to researchers in the fields of solar cells. the heterojunction, core-shell structure and surface passivation of solar cells can be preparated by ald to get better system performance. for example, the photoelectric conversion efficiency is improved by reducing electrons and holes recombination and protecting the cells to fulfill the utilization of energy."
        },
        {
            "id": "R161439",
            "label": "Atomic Layer Deposition of Ta-doped TiO2 Electrodes for Dye-Sensitized Solar Cells",
            "doi": "10.1149/1.3582765",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "ta-doped tio 2 inverse opals were obtained by selective etching of a silica template after atomic layer deposition (ald) of ta-doped tio 2 films and were applied as an electrode for dye-sensitized solar cells (dsscs). ta content in the ta-doped tio 2 film was controlled by the ta/(ta+ti) unitcycle ratios in the ta\u2015tio 2 supercycle of ald. also, excellent step coverage of nearly 100% in the inverse opal structure was confirmed by field-emission scanning electron microscopy (fe-sem). maximum photo-conversion efficiency of 1.56% was achieved with the ta (3.4 atom %)-doped tio 2 inverse opal electrode due to increased photocurrent density. however, further ta doping (> 4.9 atom %) decreased the j sc and photoconversion efficiency."
        },
        {
            "id": "R161443",
            "label": "Development of Inverted Organic Solar Cells with TiO2 Interface Layer by Using Low-Temperature Atomic Layer Deposition",
            "doi": "10.1021/am302252p",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "organic solar cells (oscs) with inverted structure have attracted much attention in recent years because of their improved device air stability due to the use of stable materials for electrodes and interface layers. in this work, tio(2) films, fabricated using low temperature (e.g., 130-170 \u00b0c) atomic layer deposition (ald) on ito substrates, are used as electron selective interface layers to investigate inverted oscs. it is found that though the as-deposited tio(2) films are high resistive due to the presence of oxygen defects, the defects can be significantly reduced by light soaking. pv cells with 15-nm-thick amorphous-tio(2) layers fabricated at low temperature show better performance than those with poly crystal tio(2) with same thickness deposited at 250 \u00b0c. the low temperature ald-grown tio(2) films are dense, stable and robust with capability of conformal coating on nanostructural surfaces, showing a promising interface layer for achieving air-stable plastic oscs with roll-to-roll mass production potential."
        },
        {
            "id": "R161446",
            "label": "TiO2inverse-opal electrode fabricated by atomic layer deposition for dye-sensitized solar cell applications",
            "doi": "10.1039/c0ee00086h",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "tio2 inverse opals (tio) fabricated by the atomic layer deposition (ald) technique showed a superior infiltration result when compared to those fabricated by the conventional nanoparticles-infiltration method reported in previous studies. the ald can achieve high filling fractions of more than ca. 96% of the maximum possible infiltration by conformal filling of 288, 390 and 510 nm opals, giving rise to high quality tio. the photoelectrochemical performances of the ald-fabricated tio photoanodes of different sizes are investigated systematically for the first time in dye-sensitized solar cells (dscs). when the tio with a size of 288 nm was used as photoanode and indoline dye as a sensitizer in dscs, the power conversion efficiency of the cell could attain 2.22% (air mass 1.5). it is found that the efficiency increases with decreasing lattice size of tio electrode due to the larger surface area for dye loading. owing to the selective reflectivity of the inverse opal, ipce spectra of tio electrodes revealed a strong wavelength dependence. strategies relating to the characteristics of selective reflection and the design of composite photoanodes to enhance the efficiency of dscs are discussed."
        },
        {
            "id": "R161450",
            "label": "Low-Temperature Crystalline Titanium Dioxide by Atomic Layer Deposition for Dye-Sensitized Solar Cells",
            "doi": "10.1021/am400866s",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "low-temperature processing of dye-sensitized solar cells (dscs) is crucial to enable commercialization with low-cost, plastic substrates. prior studies have focused on mechanical compression of premade particles on plastic or glass substrates; however, this did not yield sufficient interconnections for good carrier transport. furthermore, such compression can lead to more heterogeneous porosity. to circumvent these problems, we have developed a low-temperature processing route for photoanodes where crystalline tio2 is deposited onto well-defined, mesoporous templates. the tio2 is grown by atomic layer deposition (ald), and the crystalline films are achieved at a growth temperature of 200 \u00b0c. the ald tio2 thickness was systematically studied in terms of charge transport and performance to lead to optimized photovoltaic performance. we found that a 15 nm tio2 overlayer on an 8 \u03bcm thick sio2 film leads to a high power conversion efficiency of 7.1% with the state-of-the-art zinc porphyrin sensitizer and cobalt bipyridine redox mediator."
        },
        {
            "id": "R161453",
            "label": "Atomic Layer Deposition of TiO2 on Mesoporous nanoITO: Conductive Core\u00e2\u0080\u0093Shell Photoanodes for Dye-Sensitized Solar Cells",
            "doi": "10.1021/nl5006433",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "core-shell structures consisting of thin shells of conformal tio2 deposited on high surface area, conductive sn-doped in2o3 nanoparticle. mesoscopic films were synthesized by atomic layer deposition and studied for application in dye-sensitized solar cells. results obtained with the n719 dye show that short-circuit current densities, open-circuit voltages, and back electron transfer lifetimes all increased with increasing tio2 shell thickness up to 1.8-2.4 nm and then decline as the thickness was increased further. at higher shell thicknesses, back electron transfer to -ru(iii) is increasingly competitive with transport to the nanoito core resulting in decreased device efficiencies."
        },
        {
            "id": "R161457",
            "label": "High-speed atmospheric atomic layer deposition of ultra thin amorphous TiO2\n blocking layers at 100\u00e2\u0080\u0089\u00c2\u00b0C for inverted bulk heterojunction solar cells: AALD for inverted bulk heterojunction solar cells",
            "doi": "10.1002/pip.2380",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "ultrafast, spatial atmospheric atomic layer deposition, which does not involve vacuum steps and is compatible with roll\u2010to\u2010roll processing, is used to grow high quality tio2 blocking layers for organic solar cells. dense, uniform thin tio2 films are grown at temperatures as low as 100\\u2009\u00b0c in only 37\\u2009s (~20\\u2009nm/min growth rate). incorporation of these films in p3ht\u2010pcbm\u2010based solar cells shows performances comparable with cells made using tio2 films deposited with much longer processing times and/or higher temperatures. copyright \u00a9 2013 john wiley & sons, ltd."
        },
        {
            "id": "R161466",
            "label": "Atomic Layer Deposition of TiO2 ultrathin films on 3D substrates for energy applications",
            "doi": "10.1557/opl.2012.913",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract in the present global environmental context, it becomes more and more critical to find efficient solutions to lower our energy consumption on one hand, and to produce energy from clean renewable sources on the other hand. consequently, research efforts on materials for energy applications are intensifying. the present work aims at developing optoelectrical components usable for both energy saving (light emitting diodes) and renewable energy production (solar cells) by fabricating p-n heterojunctions based on a single semiconductor, titanium dioxide. tio 2 is indeed a very promising candidate: it is chemically and physically stable under irradiation, transparent to visible and near-infrared light (e g = 3 \u2013 3.5 ev), presents photocatalytic activity, is non-toxic and low cost, which permits to envisage its large scale use. in the present paper, the proposed architecture for both solar cells and leds is original as well as common for both applications: a three-dimensional architecture based on an anodic alumina nanoporous membrane which serves as nanomask for tio 2 growth in order to enlarge the effective surface of the components. tio 2 is synthesized by atomic layer deposition (ald), a technique particularly well adapted to the deposition of ultrathin films (from one monolayer to few tens of nanometers) on 3d porous substrates patterned with high aspect ratio nanopores. in this work, the capacity of synthesizing 3d nanostructures is demonstrated. tio 2 ultrathin films (10 to 100 nm) were grown by ald on flat, micropatterned, microporous and nanoporous anodic alumina membranes (aam) substrates. the films were highly conformal, as confirmed by sem and tem imaging. both eds and xps analyses validated the dioxide film stoichiometry."
        },
        {
            "id": "R161470",
            "label": "Ultrathin Atomic Layer Deposited TiO2 for Surface Passivation of Hydrothermally Grown 1D TiO2 Nanorod Arrays for Efficient Solid-State Perovskite Solar Cells",
            "doi": "10.1021/cm504558g",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the current work, we studied the effect of the passivation of atomic layer deposited (ald) ultrathin tio2 on hydrothermally grown one-dimensional (1d) tio2 nanorod (nr) arrays for solid-state perovskite-sensitized solar cells. different thicknesses of ald-passivated tio2 were deposited on the hydrothermally grown 1d tio2 nr samples. the ald tio2 thickness was varied from 1 to 5 nm by variation of the growth cycle. our controlled results revealed that the 4 nm thin-layer-passivated tio2 nr sample shows a power conversion efficiency (pce) as high as \u03b7 = 12.53% (without masking) for the ch3nh3pbi3 perovskite absorbing layer. our results revealed that the solar cell performance with different ald passivation thicknesses strongly affects the open-circuit voltage (voc) as well as the short-circuit current density (jsc). however, compared with high-temperature-processed standard device configurations based on ticl4-treated mesoporous tio2 (mp-tio2) (\u223c10%) and ticl4-treated tio2 nr (\u223c9%) perovskite solar cells..."
        },
        {
            "id": "R161474",
            "label": "Atomic Layer Deposition of TiO2 for a High-Efficiency Hole-Blocking Layer in Hole-Conductor-Free Perovskite Solar Cells Processed in Ambient Air",
            "doi": "10.1021/acsami.6b02701",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this study we design and construct high-efficiency, low-cost, highly stable, hole-conductor-free, solid-state perovskite solar cells, with tio2 as the electron transport layer (etl) and carbon as the hole collection layer, in ambient air. first, uniform, pinhole-free tio2 films of various thicknesses were deposited on fluorine-doped tin oxide (fto) electrodes by atomic layer deposition (ald) technology. based on these tio2 films, a series of hole-conductor-free perovskite solar cells (pscs) with carbon as the counter electrode were fabricated in ambient air, and the effect of thickness of tio2 compact film on the device performance was investigated in detail. it was found that the performance of pscs depends on the thickness of the compact layer due to the difference in surface roughness, transmittance, charge transport resistance, electron-hole recombination rate, and the charge lifetime. the best-performance devices based on optimized tio2 compact film (by 2000 cycles ald) can achieve power conversion efficiencies (pces) of as high as 7.82%. furthermore, they can maintain over 96% of their initial pce after 651 h (about 1 month) storage in ambient air, thus exhibiting excellent long-term stability."
        },
        {
            "id": "R161477",
            "label": "Optimization of TiO2 compact layer formed by atomic layer deposition for efficient perovskite solar cells",
            "doi": "10.1063/1.5120307",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the microstructure of the compact tio2 (c-tio2) layer formed by atomic layer deposition (ald) was investigated for optimization of organometal halide perovskite solar cells (pscs). the ald c-tio2 layer has an amorphous structure alleviating performance deterioration of the pscs caused by defects. to apply the optimized ald c-tio2 layer to the pscs, an efficiency of 18.36% was achieved. it is the top record among the pscs using a compact tio2 layer formed by ald.the microstructure of the compact tio2 (c-tio2) layer formed by atomic layer deposition (ald) was investigated for optimization of organometal halide perovskite solar cells (pscs). the ald c-tio2 layer has an amorphous structure alleviating performance deterioration of the pscs caused by defects. to apply the optimized ald c-tio2 layer to the pscs, an efficiency of 18.36% was achieved. it is the top record among the pscs using a compact tio2 layer formed by ald."
        },
        {
            "id": "R161482",
            "label": "Atomic layer deposition of TiO2 blocking layers for dye-sensitized solar cells",
            "doi": "10.1108/mi-01-2020-0007",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\\n purpose \\n the purpose of this paper is to improve the efficiency of dye-sensitized solar cells (dsscs) which present promising low-cost alternative to the conventional silicon solar cells mainly due to comparatively low manufacturing cost, ease of fabrication and relatively good efficiency. one of the undesirable factor in dsscs is the electron recombination process that takes place at the transparent conductive oxide/electrolyte interface, on the side of photoelectrode. to reduce this effect in the structure of the solar cell, a tio 2 blocking layer (bl) by atomic layer deposition (ald) was deposited. \\n \\n \\n design/methodology/approach \\n scanning electron microscope, raman and uv-vis spectroscopy were used to evaluate the influence of bl on the photovoltaic properties. electrical parameters of manufactured dsscs with and without bl were characterized by measurements of current-voltage characteristics under standard am 1.5 radiation. \\n \\n \\n findings \\n the tio 2 bl prevents the physical contact of fluorine-doped tin oxide (fto) and the electrolyte and leads to increase in the cell\u2019s overall efficiency, from 5.15 to 6.18%. higher density of the bl, together with larger contact area and improved adherence between the tio 2 layer and fto surface provide more electron pathways from tio 2 to fto which facilitates electron transfer. \\n \\n \\n originality/value \\n this paper demonstrates that the introduction of a bl into the photovoltaic device structure is an important step in technology of dsscs to improve its efficiency. moreover, the ald is a powerful technique which allows for the highly reproducible growth of pinhole-free thin films with excellent thickness accuracy and conformality at low temperature. \\n"
        },
        {
            "id": "R161490",
            "label": "Tantalum-Doped TiO2 Prepared by Atomic Layer Deposition and Its Application in Perovskite Solar Cells",
            "doi": "10.3390/nano11061504",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "tantalum (ta)-doped titanium oxide (tio2) thin films are grown by plasma enhanced atomic layer deposition (peald), and used as both an electron transport layer and hole blocking compact layer of perovskite solar cells. the metal precursors of tantalum ethoxide and titanium isopropoxide are simultaneously injected into the deposition chamber. the ta content is controlled by the temperature of the metal precursors. the experimental results show that the ta incorporation introduces oxygen vacancies defects, accompanied by the reduced crystallinity and optical band gap. the peald ta-doped films show a resistivity three orders of magnitude lower than undoped tio2, even at a low ta content (0.8\u20130.95 at.%). the ultraviolet photoelectron spectroscopy spectra reveal that ta incorporation leads to a down shift of valance band and conduction positions, and this is helpful for the applications involving band alignment engineering. finally, the perovskite solar cell with ta-doped tio2 electron transport layer demonstrates significantly improved fill factor and conversion efficiency as compared to that with the undoped tio2 layer."
        },
        {
            "id": "R161497",
            "label": "In situ growth of an opal-like TiO2 electron transport layer by atomic layer deposition for perovskite solar cells",
            "doi": "10.1039/d0se01558j",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "here, we use an atomic layer deposition system and different sizes of polystyrene colloidal spheres to in situ prepare an opal-like tio 2 mesoporous electron transport layer for perovskite solar cells."
        },
        {
            "id": "R161648",
            "label": "Charm and beauty in the deconfined plasma from quenched lattice QCD",
            "doi": "10.1103/physrevd.104.114508",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present continuum extrapolated results of charmonium and bottomonium correlators in the vector channel at several temperatures below and above tc. the continuum extrapolation jointly performed with the interpolations to have physical values of j/\u03c8 and \u03c5 masses in the confined phase is based on calculations on several large quenched isotropic lattices using clover-improved wilson valence fermions carrying different quark masses. the extrapolated lattice correlators are confronted with perturbation theory results incorporating resummed thermal effects around the threshold from pnrqcd and vacuum asymptotics above the threshold. an additional transport peak is modelled below the threshold allowing for an estimate of the diffusion coefficients for charm and bottom quarks. we find that charmonium correlators in the vector channel can be well reproduced by perturbative spectral functions above tc where no resonance peaks for j/\u03c8 are needed at and above 1.1 tc, while for bottomonium correlators a resonance peak for \u03c5 is still needed up to 1.5 tc. by analyzing the transport contribution to the correlators we find that the drag coefficient of a charm quark is larger than that of a bottom quark."
        },
        {
            "id": "R164396",
            "label": "Engaging older people using participatory design",
            "doi": "10.1145/2207676.2208570",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "the use of digital technologies is increasingly proposed in health and social care to address the aging population phenomenon but, in practice, the designers of these technologies are ill equipped to design for older people. we suggest participatory design as an approach to improving the quality of design for older people but, based on previous work and our own experiences, identify four central issues that participatory design approaches need to address. we describe an approach to early engagement in design with older people that address each of these issues and some of our experiences applying the approach in a variety of different design projects. we conclude by discussing some of the issues that have been highlighted when attempting apply this approach in different design contexts and the issues that have been raised when working with partners who are less committed to the idea of engaging with older adults in participatory design."
        },
        {
            "id": "R164400",
            "label": "Invisible design: exploring insights and ideas through ambiguous film scenarios",
            "doi": "10.1145/2317956.2318036",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "invisible design is a technique for generating insights and ideas with workshop participants in the early stages of concept development. it involves the creation of ambiguous films in which characters discuss a technology that is not directly shown. the technique builds on previous work in hci on scenarios, persona, theatre, film and ambiguity. the invisible design approach is illustrated with three examples from unrelated projects; biometric daemon, panini and smart money. the paper presents a qualitative analysis of data from a series of workshops where these invisible designs were discussed. the analysis outlines responses to the films in terms of; existing problems, concerns with imagined technologies and design speculation. it is argued that invisible design can help to create a space for critical and creative dialogue during participatory concept development."
        },
        {
            "id": "R166672",
            "label": "THE GENUINE NEEDS OF CONFERENCE ATTENDEES: AN ANALYSIS BY THE MODERN QUALITY FUNCTION DEPLOYMENT",
            "doi": "10.24874/IJQR13.01-02",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the primary purpose of this research is to understand the genuine needs of conference attendees regarding conference participation within a multi-dimensional perspective and to identify the priority of those needs via modern qfd methodology. the findings support the early studies on the fact that academic development and networking are the most important needs towards conferences. following these two primary need categories, organization-related needs are also given importance by the participants of this research. offering free time for leisure and recreation activities within conference programs is valued more than pre-arranged social activities by attendees. it is anticipated that the research offers insight into the development and improvement of conference services through the identification of value-adding attributes, which would have practical implications for conference organizers and destination marketers. unlike most of the extant literature in event management, this research employs the in-depth interviews, focus group, kj method and ahp within modern qfd methodology."
        },
        {
            "id": "R166682",
            "label": "The effects of perceived conference quality on attendees' behavioural intentions",
            "doi": "10.1080/13032917.2020.1729215",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract we examined the relationships between dimensions of perceived quality, attendees\u2019 needs and behavioural intentions in conferences. our findings are based on sem-pls of a convenience sample of 295 international attendees participated in 14 academic conferences in malaysia. we find that only accessibility and self-congruity are positively associated with behavioural intentions. perceived conference quality is associated with the attendees\u2019 needs and in turn, influences the strength of behavioural intentions. we conclude by discussing the theoretical and practical implications of our model. this study may also give benefits to conference planners with information that allows them to attract and retaining repeat attendees."
        },
        {
            "id": "R166689",
            "label": "A Fuzzy Cognitive Mapping Approach to the Conference Selection Problem",
            "doi": "10.1142/S0219622020500352",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "academic conferences are popular platforms for academicians to share their research with colleagues, get feedback, and stay up to date on recent academic studies. conferences also provide opportunities for the participants to express themselves, expand their network, and become socialized. however, academicians are forced to choose a limited number of conferences to participate due to several different factors such as time required for preparing a research, traveling and lodging expenses, and conference fees. at this multi-criteria decision problem, relevant factors can be used to evaluate the alternatives (i.e., academic conferences to participate) and prioritization of these factors would be necessary in advance. to address this issue, this study suggests an improved fuzzy cognitive mapping (fcm) approach to analyze factors affecting the choice of academic conferences to participate. the classical fcm allows to observe the dynamic behavior of complex systems during time. while the approach is widely used in different areas, it has considerable drawbacks: (i) producing same steady state values under different initial conditions and (ii) yielding completely different steady state values when different threshold functions are used. the new approach provides a mathematical formulation that produces steady state values sensitive to initial conditions. since the selection of the threshold function in classical fcm is a highly subjective choice, the proposed approach offers an alternative way to obtain comparable values."
        },
        {
            "id": "R166697",
            "label": "Factors affecting conference participation decision-making",
            "doi": "10.2298/IJGI2001031P",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"business travel, as the sector with the fastest growth in the tourism industry globally, has received increased attention from both countries and cities, particularly from emerging destinations. in developing economies, business travel, including attending meetings, conferences, incentives and other business events, often plays a leading role in the growth of the wider travel and tourism sector. therefore, tourism authorities and convention bureaus at the national and city levels have been struggling to attract international conferences and a larger number of participants to conferences. understanding factors, which appear to be important in the conference participation decision-making process, can help conference organizers and destinations to attract more participants and thus gain more benefit from this growing sector of the tourism industry. therefore, this study aims to examine factors affecting the conference participation decision-making from the academics' perspective. furthermore, it investigates how different socio-demographic characteristics of the respondents influence the extracted factors of the conference participation decision-making process. the data was collected from the academics employed at the university of novi sad in serbia. the findings reveal six dimensions of conference participation decision-making: destination stimuli, costs and destination accessibility, educational and professional opportunities, intervening opportunities, location factors, and conference factors. the results also show that there are statistically significant differences in some extracted factors between respondents of different gender, age, education level, and academic position, while the frequency of participation in international conferences does not influence the factors. the results could be of interest to all stakeholders in the business travel and tourism industry.\""
        },
        {
            "id": "R166705",
            "label": "A Theoretical Model for the Associative Nature of Conference Participation",
            "doi": "10.1371/journal.pone.0148528",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "participation in conferences is an important part of every scientific career. conferences provide an opportunity for a fast dissemination of latest results, discussion and exchange of ideas, and broadening of scientists\u2019 collaboration network. the decision to participate in a conference depends on several factors like the location, cost, popularity of keynote speakers, and the scientist\u2019s association with the community. here we discuss and formulate the problem of discovering how a scientist\u2019s previous participation affects her/his future participations in the same conference series. we develop a stochastic model to examine scientists\u2019 participation patterns in conferences and compare our model with data from six conferences across various scientific fields and communities. our model shows that the probability for a scientist to participate in a given conference series strongly depends on the balance between the number of participations and non-participations during his/her early connections with the community. an active participation in a conference series strengthens the scientist\u2019s association with that particular conference community and thus increases the probability of future participations."
        },
        {
            "id": "R74118",
            "label": "Organizing Spaces: Meeting Arenas as a Social Movement Infrastructure between Organization, Network, and Institution",
            "doi": "10.1177/0170840613479232",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in recent years, social movement scholars have shown increasing interest in the internal lives of social movements, but this turn from \u201csocial movements as actors\u201d to \u201csocial movements as spaces\u201d has not yet led to a conceptual apparatus that addresses the key role of face-to-face meetings, especially in the inter-organizational domain of mesomobilization. building on the concept of \u201cpartial organization\u201d, the paper develops the concept of \u201cmeeting arena\u201d as a hybrid of three forms of social order: organization, institution, and network. it is argued that the complex figuration of meeting arenas in a social movement or protest mobilization constitutes an infrastructure that synchronizes the dispersed activities of movement actors in time and space. this infrastructure is not an entirely emergent phenomenon but is also the result of conscious decisions by organizers. heuristic, methodological, and theoretical implications of this novel perspective on social movements are discussed, highlighting especially the potential of the distinction between organizing and mobilizing as two intertwined but essentially different types of social movement activity."
        },
        {
            "id": "R108382",
            "label": "Data-driven Topological Filtering based on Orthogonal Minimal Spanning Trees: Application to Multi-Group MEG Resting-State Connectivity",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract in the present study a novel data-driven topological filtering technique is introduced to derive the backbone of functional brain networks relying on orthogonal minimal spanning trees (omst). the method aims to identify the essential functional connections to ensure optimal information flow via the objective criterion of global efficiency minus the cost of surviving connections. the omst technique was applied to multichannel, resting-state neuromagnetic recordings from four groups of participants: healthy adults (n=50), adults who have suffered mild traumatic brain injury (n=30), typically developing children (n=27), and reading-disabled children (n=25). weighted interactions between network nodes (sensors) were computed using an integrated approach of dominant intrinsic coupling modes based on two alternative metrics (symbolic mutual information and phase lag index), resulting in excellent discrimination of individual cases according to their group membership. classification results using omst-derived functional networks were clearly superior to results using either relative power spectrum features or functional networks derived through the conventional minimal spanning trees algorithm."
        },
        {
            "id": "R108386",
            "label": "Aberrant Whole-Brain Transitions and Dynamics of Spontaneous Network Microstates in Mild Traumatic Brain Injury",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "dynamic functional connectivity (dfc) analysis is a promising approach for the characterization of brain electrophysiological activity. in this study, we investigated abnormal alterations due to mild traumatic brain injury (mtbi) using dfc of the source reconstructed magnetoencephalographic (meg) resting-state recordings. brain activity in several well-known frequency bands was first reconstructed using beamforming of the meg data to determine ninety anatomical brain regions of interest. a dfc graph was formulated using the imaginary part of phase-locking values, which were obtained from 30 mtbi patients and 50 healthy controls (hc). subsequently, we estimated normalized laplacian transformations of individual, statistically and topologically filtered quasi-static graphs. the corresponding eigenvalues of each node synchronization were then computed and through the neural-gas algorithm, we quantized the evolution of the eigenvalues resulting in distinct network microstates (nmstates). the discrimination level between the two groups was assessed using an iterative cross-validation classification scheme with features either the nmstates in each frequency band, or the combination of the so-called chronnectomics (flexibility index, occupancy time of nmstate, and dwell time) with the complexity index over the evolution of the nmstates across all frequency bands. classification performance based on chronnectomics showed 80% accuracy, 99% sensitivity, and 49% specificity. however, performance was much higher (accuracy: 91\u201397%, sensitivity: 100%, and specificity: 77\u201393%) when focusing on the microstates. exploring the mean node degree within and between brain anatomical networks (default mode network, frontoparietal, occipital, cingulo-opercular, and sensorimotor), a reduced pattern occurred from lower to higher frequency bands, with statistically significant stronger degrees for the hc than the mtbi group. a higher entropic profile on the temporal evolution of the modularity index was observed for both nmstates for the mtbi group across frequencies. a significant difference in the flexibility index was observed between the two groups for the \u03b2 frequency band. the latter finding may support a central role of the thalamus impairment in mtbi. the current study considers a complete set of frequency-dependent connectomic markers of mtbi-caused alterations in brain connectivity that potentially could serve as markers to assess the return of an injured subject back to normality."
        },
        {
            "id": "R108390",
            "label": "A novel method for calibrating head models to account for variability in conductivity and its evaluation in a sphere model",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the accuracy in electroencephalography (eeg) and combined eeg and magnetoencephalography (meg) source reconstructions as well as in optimized transcranial electric stimulation (tes) depends on the conductive properties assigned to the head model, and most importantly on individual skull conductivity. in this study, we present an automatic pipeline to calibrate head models with respect to skull conductivity based on the reconstruction of the p20/n20 response using somatosensory evoked potentials and fields. in order to validate in a well-controlled setup without interplay with numerical errors, we evaluate the accuracy of this algorithm in a 4-layer spherical head model using realistic noise levels as well as dipole sources at different eccentricities with strengths and orientations related to somatosensory experiments. our results show that the reference skull conductivity can be reliably reconstructed for sources resembling the generator of the p20/n20 response. in case of erroneous assumptions on scalp conductivity, the resulting skull conductivity parameter counterbalances this effect, so that eeg source reconstructions using the fitted skull conductivity parameter result in lower errors than when using the standard value. we propose an automatized procedure to calibrate head models which only relies on non-invasive modalities that are available in a standard meg laboratory, measures under in vivo conditions and in the low frequency range of interest. calibrated head modeling can improve eeg and combined eeg/meg source analysis as well as optimized tes."
        },
        {
            "id": "R108392",
            "label": "Parametrizing the Conditionally Gaussian Prior Model for Source Localization with Reference to the P20/N20 Component of Median Nerve SEP/SEF",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this article, we focused on developing the conditionally gaussian hierarchical bayesian model (cg-hbm), which forms a superclass of several inversion methods for source localization of brain activity using somatosensory evoked potential (sep) and field (sef) measurements. the goal of this proof-of-concept study was to improve the applicability of the cg-hbm as a superclass by proposing a robust approach for the parametrization of focal source scenarios. we aimed at a parametrization that is invariant with respect to altering the noise level and the source space size. the posterior difference between the gamma and inverse gamma hyperprior was minimized by optimizing the shape parameter, while a suitable range for the scale parameter can be obtained via the prior-over-measurement signal-to-noise ratio, which we introduce as a new concept in this study. in the source localization experiments, the primary generator of the p20/n20 component was detected in the brodmann area 3b using the cg-hbm approach and a parameter range derived from the existing knowledge of the tikhonov-regularized minimum norm estimate, i.e., the classical gaussian prior model. moreover, it seems that the detection of deep thalamic activity simultaneously with the p20/n20 component with the gamma hyperprior can be enhanced while using a close-to-optimal shape parameter value."
        },
        {
            "id": "R108394",
            "label": "Synchronization coupling investigation using ICA cluster analysis in resting MEG signals in Reading Difficulties",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the understanding of the mechanisms of human brain is a demanding issue for neuroscience research. physiological studies acknowledge the usefulness of synchronization coupling in the study of dysfunctions associated with reading difficulties. magnetoencephalogram (meg) is a useful tool towards this direction having been assessed for its superior accuracy over other modalities. in this paper we consider synchronization features for identifying brain operations. independent component analysis (ica) is applied on meg surface signals in controls and children with reading difficulties and are clustered to representative components. then, coupling measures of mutual information and partial directed coherence are estimated in order to reveal dysfunction of cerebral networks and its related coordination."
        },
        {
            "id": "R108396",
            "label": "A Minimal Spanning Tree Analysis of EEG Responses to Complex Visual Stimuli",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "human brain is the most complicated network and its functional mechanism is a demanding concept in neuroscience research. graph theory and forms an interesting tool for modeling the brain interactions and estimated brain parameters. in this paper, we consider synchronization features for modeling brain operations in electro-encephalogram (eeg) responses to kanizsa and fractal stimuli, using minimal spanning tree (mst) on a network of phase synchronization eeg channels. graphs of phase-synchronization activity and mst structures are computed using these graphs. the proposed approach yields evidence that the fractal stimuli generate stronger energy response and synchronization of theta band in occipital lobe."
        },
        {
            "id": "R108400",
            "label": "Comparison of Brain Network Models using Cross-Frequency Coupling and Attack Strategies",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"several neuroimaging studies have suggested that functional brain connectivity networks exhibit \u201csmall-world\u201d characteristics, whereas recent studies based on structural data have proposed a \u201crich-club\u201d organization of brain networks, whereby hubs of high connection density tend to connect among themselves compared to nodes of lower density. in this study, we adopted an \u201cattack strategy\u201d to compare the rich-club and small-world organizations and identify the model that describes best the topology of brain connectivity. we hypothesized that the highest reduction in global efficiency caused by a targeted attack on each model's hubs would reveal the organization that better describes the topology of the underlying brain networks. we applied this approach to magnetoencephalographic data obtained at rest from neurologically intact controls and mild traumatic brain injury patients. functional connectivity networks were computed using phase-to-amplitude cross-frequency coupling between the \u03b4 and \u03b2 frequency bands. our results suggest that resting state meg connectivity networks follow a rich-club organization.\""
        },
        {
            "id": "R108402",
            "label": "Color Characteristics for the Evaluation of Suspended Sediments",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this study focuses on a significant issue of the environmental monitoring application area, which is the suspended sediment concentration estimation. more specifically, the purpose of the current work is to provide a new non-intrusive way to estimate the suspended sediment (ss) distribution. the proposed methodology uses the color characteristics of river flow images and provides a high correlation factor with the suspended sediment measurements. in our opinion, the importance of the current work derives from the fact that it provides an alternative and effective way of estimating ss distribution rather as opposed to the conventional method that requires human presence, especially if we consider the difficulty of taking measurements of the river pollution during flush flood events when the sediment distribution is increased and is directly related to water quality."
        },
        {
            "id": "R108404",
            "label": "Lung Tissue Evaluation Detecting and Measuring Morphological Characteristics of Cell Regions",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the goal of this study is to develop an automated, accurate and time efficient image processing algorithmic scheme, capable of segmenting lung tissue slides and quantitatively detecting any possible morphological characteristic that may differentiate healthy cells from adenocarcinoma. microscopy images are segmented into the key regions via a proposed clever, sequential fusion methodology, combining image clustering, the watershed transform and mathematical morphology and analyzed utilizing an innovative tissue evaluation approach based on quantitative assessments of the extracted cell regions shape and size. the preliminary results of this work indicate that it is possible to discriminate healthy cells from cancerous ones considering their overall morphology within the tissue and measuring possible indices that may reveal an evolving neoplasia, a tumor growth or a malfunction in cell proliferation. applying the proposed method to a much larger and more variform dataset is our next plan for the upcoming future in order to validate and ensure the robustness and accuracy of the proposed classification scheme, making it an extremely valuable assisting tool for medical experts for cancer diagnosis and prognosis."
        },
        {
            "id": "R108406",
            "label": "Mining Cross-Frequency Coupling Microstates from Resting State MEG: An Application to Mild Traumatic Brain Injury",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "recent studies have investigated the possible role of dynamic functional connectivity and the role of cross-frequency coupling (cfc) to provide the substrate for reliable biomarkers of brain disorders. in this study, we analyzed time-varying cfc profiles from resting state magnetoencephal-ographic recordings of 30 mild traumatic brain injury (mtbi) patients and 50 normal controls. interactions among sensors at specific pairs of frequency bands were computed via estimation of phase-to-amplitude couplings. we then computed time-varying functional connectivity graphs that were described in terms of segregation (local efficiency, le) and integration (global efficiency, ge) and mapped those graphs to time series of ge/le estimates. the resulting dynamic network revealed transitions between a limited number of microstates for mtbi subjects compared to controls. the significant differences in transition probability between the two groups, along with the limited repertoire of possible states, can form the basis for a robust dynamic connectomic biomarker for the diagnosis of mtbi."
        },
        {
            "id": "R108422",
            "label": "Constrained maximum intensity optimized multi-electrode tDCS targeting of human somatosensory network",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "transcranial direct current stimulation (tdcs) is a noninvasive method that delivers current through the scalp to enhance or suppress brain activity. the standard way of applying tdcs is by the use of two large rectangular sponge electrodes on the scalp. the resulting currents often stimulate a broad region of the brain distributed over brain networks. in order to address this issue, recently, multi-electrode transcranial direct current stimulation with optimized montages has been used to stimulate brain regions of interest (roi) with improved trade-off between focality and intensity of the electrical current at the target brain region. however, in many cases only the location of target region is considered and not the orientation. here we emphasize the importance of calculating the individualized target location and orientation by combined electroencephalography and magnetoencephalography (emeg) source analysis in individualized skull-conductivity calibrated finite element method (fem) head models and stimulate the target region by four different tdcs montages. we have chosen the generator of the p20/n20 component, located at brodmann area 3b and oriented mainly from posterior to anterior directions as our target for stimulation because it can be modeled as a single dipole source with a fixed position and orientation. the simulations will deliver optimized excitatory and inhibitory electrode montages that are in future investigations compared to standard and sham tdcs in a somatosensory experiment. we also present a new constrained maximum intensity (cmi) optimization approach that better distributes the currents over multiple electrodes, therefore should lead to less tingling and burning sensations at the skin, and thus allows an easier realization of the sham condition significantly reducing the current intensity parallel to the target."
        },
        {
            "id": "R108424",
            "label": "Individualized targeting and optimization of multi-channel transcranial direct current stimulation in drug-resistant epilepsy",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the principle of epilepsy surgery in patients with drug-resistant focal epilepsy is to localize and then to resect the epileptogenic zone. however, epilepsy surgery might not be feasible if a cortical malformation or focal cortical dysplasia (fcd), is located very close to eloquent areas of the brain. non-invasive brain stimulation is a promising technique for modulating brain activity and may become a neurotherapeutic approach for suppressing long term epileptic seizures. in the present study, we optimize a multi-channel transcranial direct current stimulation (tdcs) montage based on electro-(eeg) and magneto-encephalography (meg) source analysis for the therapeutic stimulation of a patient with drug-resistant epilepsy due to an fcd located very close to broca's area. we first construct a realistic volume conductor finite element method (fem) model of the patient's head, including skull defects, calibrated skull conductivities and white matter conductivity anisotropy. single modality (eeg or meg) and combined eeg/meg (emeg) source analysis is performed for localizing the irritative zone that caused interictal epileptic discharges (ieds). we then adopt a novel optimization algorithm, alternating direction method of multipliers (admm), in order to optimize the multichannel tdcs montage for distributing the injected currents in the target brain region. the patient's source analysis indicates localizations very close to the fcd and orientations to a different cortical side depending on the used measurement modality. the resulting tdcs optimized montage is based on the source reconstruction which is closer to the fcd and the occurred stimulation montage is focal over the detected fcd. the combination of individual source analysis for targeting and optimization algorithms for the estimation of a tdcs montage is a promising neurotherapeutic approach of suppressing long term epileptic seizures.\""
        },
        {
            "id": "R108426",
            "label": "Effective Connectivity in the Primary Somatosensory Network using Combined EEG and MEG",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the primary somatosensory cortex remains one of the most investigated brain areas. however, there is still an absence of an integrated methodology to describe the early temporal alterations in the primary somatosensory network. source analysis based on combined electro-(eeg) and magneto-(meg) encephalography (emeg) has been recently shown to outperform the one's based on single modality eeg or meg. the study and potential of combined emeg form the goal of the current study, which investigates the time-variant connectivity of the primary somatosensory network. a subject-individualized pipeline combines a functional source separation approach with the effective connectivity analysis of different spatiotemporal source patterns using a realistic and skull-conductivity calibrated head model. three-time windows are chosen for each modality eeg, meg, and emeg to highlight the thalamocortical and corticocortical interactions. the results show that emeg is promising in suppressing a so-called connectivity 'leakage' effect when later components seem to influence earlier components, just due to too similar leadfields. our current results support the notion that emeg is superior in suppressing the spurious flows within a network of very rapid alterations.\""
        },
        {
            "id": "R108428",
            "label": "Combined EEG/MEG Source Reconstruction of Epileptic Activity using a Two-Phase Spike Clustering Approach",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in recent years, several approaches have been introduced for estimating the spike onset zone within the irritative zone in epilepsy diagnosis for presurgical planning. one important direction utilizes source analysis from combined electroencephalography (eeg) and magnetoencephalography (meg), emeg, leveraging the benefits from the complementary properties of the two modalities. for emeg source reconstruction, an average across the annotated epileptic spikes is often used to improve the signal-to-noise-ratio (snr). in this contribution, we propose a two-phase clustering of interictal spikes with unsupervised learning methods, namely self organizing maps (som) and k-means. in addition, we investigate the accuracy of combined emeg source analysis on the sorted activity, using an individualized (with regard to both geometry and conductivity) six-compartment finite element head model with calibrated skull conductivity and white matter conductivity anisotropy. the results indicate that som eliminates the random variations of k-means and stabilizes the clustering efficiency. in terms of source reconstruction accuracy, this study demonstrates that the combined use of modalities reveals activity around two focal cortical dysplasias (fcds), of one epilepsy patient, one in the right frontal area and one smaller in the left premotor cortex. it is worth mentioning that only emeg could localize the left premotor fcd, which was then also found in surgery to be the responsible for triggering the epilepsy."
        },
        {
            "id": "R108440",
            "label": "Reconstruction of the Very Early Thalamo-Cortical Network with Combined EEG and MEG on Realistic Head Modeling",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the early primary somatosensory network remains a rarely investigated brain area due to the fast transitions among the involved cortical and subcortical regions. in this regard, a non-invasive and subject-specific method that quantifies the very early temporal interdependences in the thalamo-cortical/cortico-cortical pathway of the primary somatosensory network would be of particular significance. combined electro- (eeg) and magneto- (meg) encephalography (emeg) source analysis has been shown to exploit the complementary content of the single modalities eeg and meg based on subject-specific and realistic head modeling. the current study aims to investigate the connectivity of the very early primary somatosensory network using emeg source analysis with functionally-based decomposition and time-variant effective connectivity. three-time temporally determined components are chosen based on the combined somatosensory evoked responses to highlight the thalamo-cortical and cortico-cortical interactions. the results confirm that electrophysiological activity flows from the thalamic regions of the brain to the first tangentially oriented neurological somatosensory brain region (broadman area 3b, thalamo-cortical connection) and then to the radially-oriented brain region (broadman area 3a, cortico-cortical connection). we also present that the flows between the investigated components that do not fit to the flow of the neurological activity from the wrist to the somatosensory network, when increasing the confidence interval (ci). overall, emeg source analysis with realistic head modeling and a functionally-based connectivity estimator is able to capture very fast transitions on the early-involved somatosensory network."
        },
        {
            "id": "R108458",
            "label": "Dynamic Proofs of Retrievability with Low Server Storage",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "proofs of retrievability (pors) are protocols which allow a client to store data remotely and to efficiently ensure, via audits, that the entirety of that data is still intact. a dynamic por system also supports efficient retrieval and update of any small portion of the data. we propose new, simple protocols for dynamic por that are designed for practical efficiency, trading decreased persistent storage for increased server computation, and show in fact that this tradeoff is inherent via a lower bound proof of time-space for any por scheme. notably, ours is the first dynamic por which does not require any special encoding of the data stored on the server, meaning it can be trivially composed with any database service or with existing techniques for encryption or redundancy. our implementation and deployment on google cloud platform demonstrates our solution is scalable: for example, auditing a 1tb file takes 16 minutes at a monetary cost of just $0.23 usd. we also present several further enhancements, reducing the amount of client storage, or the communication bandwidth, or allowing public verifiability, wherein any untrusted third party may conduct an audit."
        },
        {
            "id": "R108460",
            "label": "Outsourcing Proofs of Retrievability",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "proofs of retrievability (por) are cryptographic proofs that enable a cloud provider to prove that a user can retrieve his file in its entirety. por need to be frequently executed by the user to ensure that their files stored in the cloud can be fully retrieved at any point in time. to conduct and verify por, users need to be equipped with devices that have network access, and that can tolerate the (non-negligible) computational overhead incurred by the verification process. this clearly hinders the large-scale adoption of por by cloud users, since many users increasingly rely on portable devices that have limited computational capacity, or might not always have network access. in this paper, we introduce the notion of outsourced proofs of retrievability ( $\\\\sf{ opor}$ opor ), in which users can task an external auditor to perform and verify por with the cloud provider. we argue that the $\\\\sf{ opor}$ opor setting is subject to security risks that have not been covered by existing por security models. to remedy that, we propose a formal framework and a security model for $\\\\sf{ opor}$ opor . we then propose a generic procedure for transforming a public por into an opor and we show the security of the resulting opor in our proposed security model. we demonstrate the transformation on two different instantiations of public por schemes due to shacham and waters (asiacrypt\\'08)\u2014one based on bls signatures and one using rsa signatures. a shortcoming of this transformation is that the generated opor inherits the high computational overhead from the underlying public key cryptography. consequently, we propose afterwards an opor that is build from a private por by shacham and waters. we implement a prototype based on our solutions, and evaluate their performance in a realistic cloud setting. our evaluation results show that our proposals minimize user effort, and incur negligible overhead on the auditor."
        },
        {
            "id": "R108462",
            "label": "Partial Binary Encoding for Slepian-Wolf Based Proof of Retrievability",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloud storage is a storage service offered by cloud service provider (csp) to data client, where the data is outsourced to distributed servers in cloud, while data client has to pay upon usage. as integrity and availability are the pre-conditions for the existence of a cloud storage system, proof of retrievability (por) is introduced to cloud storage. recently, slepian-wolf based proof of retrievability (sw-por) was introduced that provides cost-efficient and time consistent exact repair mechanism for erroneous outsourced data. however, the encoding process of sw-por requires a certain amount of computation time, which considerably long compared to conventional storage method involving replication. hence, this paper proposed an extension work to sw-por, named partial binary encoding for sw-por (pbe-sw-por) to address the limitation. simulation was conducted to evaluate the performance of the proposed work by means of comparison to the original sw-por scheme in term of computation time. in our simulation, result obtained has shown a significant performance improvement in computation time for pbe-sw-por compared to original sw-por."
        },
        {
            "id": "R108464",
            "label": "Proofs of Retrievability: Theory and Implementation",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"a proof of retrievability (por) is a compact proof by a file system (prover) to a client (verifier) that a target file f is intact, in the sense that the client can fully recover it. as pors incur lower communication complexity than transmission of f itself, they are an attractive building block for high-assurance remote storage systems.\\n in this paper, we propose a theoretical framework for the design of pors. our framework improves the previously proposed por constructions of juels-kaliski and shacham-waters, and also sheds light on the conceptual limitations of previous theoretical models for pors. it supports a fully byzantine adversarial model, carrying only the restriction---fundamental to all pors---that the adversary's error rate be bounded when the client seeks to extract f. we propose a new variant on the juels-kaliski protocol and describe a prototype implementation. we demonstrate practical encoding even for files f whose size exceeds that of client main memory.\""
        },
        {
            "id": "R108468",
            "label": "BOSSA: A Decentralized System for Proofs of Data Retrievability and Replication",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "proofs of retrievability and proofs of replication are two cryptographic tools that enable a remote server to prove that the users\u2019 data has been correctly stored. nevertheless, the literature either requires the users themselves to perform expensive verification jobs, or relies on a \u201cfully trustworthy\u201d third party auditor (tpa) to execute the public verification. in addition, none of existing solutions consider the underlying incentive issues behind a rational server who is motivated to collect users\u2019 data but tries to evade the replication checking in order to save storage resources. in this article, we propose the first decentralized system for proofs of data retrievability and replication\u2014 ${\\\\sf bossa}$ bossa , which is incentive-compatible for each party and realizes automated auditing atop off-the-shelf blockchain platforms. we deal with issues such as proof enforcements to catch malicious behaviors, new metrics to measure the contributions, and reward distributions to create a fair reciprocal environment. ${\\\\sf bossa}$ bossa also incorporates privacy-enhancing techniques to prevent decentralized peers (including blockchain nodes) from inferring private information about the outsourced data. security analysis is presented in the context of integrity, privacy, and reliability. we implement a prototype based on ${\\\\sf bossa}$ bossa leveraging the smart contracts of ethereum blockchain. our extensive experimental evaluations demonstrate the practicality of our proposal."
        },
        {
            "id": "R108470",
            "label": "Dynamic Provable Data Possession",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we consider the problem of efficiently proving the integrity of data stored at untrusted servers. in the provable data possession (pdp) model, the client preprocesses the data and then sends it to an untrusted server for storage, while keeping a small amount of meta-data. the client later asks the server to prove that the stored data has not been tampered with or deleted (without downloading the actual data). however, the original pdp scheme applies only to static (or append-only) files.\\n we present a definitional framework and efficient constructions for dynamic provable data possession (dpdp), which extends the pdp model to support provable updates to stored data. we use a new version of authenticated dictionaries based on rank information. the price of dynamic updates is a performance change from o(1) to o(logn) (or o(n\u03b5log n), for a file consisting of n blocks, while maintaining the same (or better, respectively) probability of misbehavior detection. our experiments show that this slowdown is very low in practice (e.g. 415kb proof size and 30ms computational overhead for a 1gb file). we also show how to apply our dpdp scheme to outsourced file systems and version control systems (e.g. cvs)."
        },
        {
            "id": "R108472",
            "label": "PoReps: Proofs of Space on Useful Data",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a proof-of-replication (porep) is an interactive proof system in which a prover defends a publicly verifiable claim that it is dedicating unique resources to storing one or more retrievable replicas of a data file. in this sense a porep is both a proof of space (pos) and a proof of retrievability (por). this paper establishes a foundation for poreps, exploring both their capabilities and their limitations. while poreps may unconditionally demonstrate possession of data, they fundamentally cannot guarantee that the data is stored redundantly. furthermore, as poreps are proofs of space, they must rely either on rational time/space tradeoffs or timing bounds on the online prover\u2019s runtime. we introduce a rational security notion for poreps called -rational replication based on the notion of an -nash equilibrium, which captures the property that a server does not gain any significant advantage by storing its data in any other (non-redundant) format. we apply our definitions to formally analyze two recently proposed porep constructions based on verifiable delay functions and depth robust graphs. lastly, we reflect on a notable application of poreps\u2014its unique suitability as a nakamoto consensus mechanism that replaces proof-of-work with poreps on real data, simultaneously incentivizing and subsidizing the cost of file storage."
        },
        {
            "id": "R34428",
            "label": "Noise reduction by electric vehicles in the Netherlands",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R34412",
                    "label": "Electric vehicles noise"
                }
            ],
            "abstract": "as an alternative for vehicles with gasoline or diesel engines, electric and hybrid motor vehicles have received increasing interest in the past years. large scale application of electrical and hybrid vehicles in urban environments may have favorable effects on both noise and air quality. this paper explores the effects on urban noise exposure, in case of a large scale transition in transportation means towards the use of electrical and hybrid road traffic vehicles. the first results indicate that in urban areas, reduction of engine noise by large scale use of e-vehicles will cause a significant reduction of traffic noise emissions, particularly if combined with the introduction of silent tires or silent pavings."
        },
        {
            "id": "R34470",
            "label": "The development of a production function for a container terminal in the port of Melbourne",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R34461",
                    "label": "Production and cost functions"
                }
            ],
            "abstract": "dconned transport openuions and reuarch manager port of melbourne authority d i ross port statistician port of melbourne authority it is generally accepted that for australia to be competitive on world markets it must become more productive. as a trading nation it is dependent on a reliable transportation system in which container terminals are a vitalhnk for the shipment of goods and commodities. the waterfront in particular\u00b7 has been criticised for disadvantaging local exporters because of inefficiencies, an accusation that is all the more significant because of the large percentage of cargo that is carried by sea in order to find ways of increasing port productivity it is essential that it can be suitably measured. this paper is the study of an attempt to develop a production function for a container terminal in the port of melbourne as an alternative performance indicator to partial factor productivity measurement contact author: rudy reker port of melbourne authority world trade centre melbourne vie 3005 telephone: (03) 611 1895 fax: (03) 629 8121"
        },
        {
            "id": "R50018",
            "label": "Content Authoring with Markdown for Visually Impaired and Blind Users",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "e-learning accessibility is a well studied topic that aims at making online educational resources accessible for everyone, including disabled users. the focus of these efforts is mainly on making content consumption more accessible while content creation is often neglected. this means that the perspectives of disabled users are not accommodated and that full inclusiveness cannot be reached. in this work we introduce a novel interface to author educational content, in particular presentation slides. this interface is specifically designed for visually impaired and blind users. the interface is implemented in the opencourseware platform slidewiki. instead of the default visual wysiwyg interface, the alternative editor uses the lightweight markup language markdown to support content authoring."
        },
        {
            "id": "R50113",
            "label": "Falcon 2.0: An Entity and Relation Linking Tool over Wikidata",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the natural language processing (nlp) community has significantly contributed to the solutions for entity and relation recognition from a natural language text, and possibly linking them to proper matches in knowledge graphs (kgs). considering wikidata as the background kg, there are still limited tools to link knowledge within the text to wikidata. in this paper, we present falcon 2.0, the first joint entity and relation linking tool over wikidata. it receives a short natural language text in the english language and outputs a ranked list of entities and relations annotated with the proper candidates in wikidata. the candidates are represented by their internationalized resource identifier (iri) in wikidata. falcon 2.0 resorts to the english language model for the recognition task (e.g., n-gram tiling and n-gram splitting), and then an optimization approach for the linking task. we have empirically studied the performance of falcon 2.0 on wikidata and concluded that it outperforms all the existing baselines. falcon 2.0 is open source and can be reused by the community; all the required instructions of falcon 2.0 are well-documented at our github repository (https://github.com/sdm-tib/falcon2.0). we also demonstrate an online api, which can be run without any technical expertise. falcon 2.0 and its background knowledge bases are available as resources at https://labs.tib.eu/falcon/falcon2/."
        },
        {
            "id": "R50180",
            "label": "multimodal speech emotion recognition using audio and text",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R50182",
                    "label": "    MULTIMODAL SPEECH EMOTION RECOGNITION"
                }
            ],
            "abstract": "speech emotion recognition is a challenging task, and extensive reliance has been placed on models that use audio features in building well-performing classifiers. in this paper, we propose a novel deep dual recurrent encoder model that utilizes text data and audio signals simultaneously to obtain a better understanding of speech data. as emotional dialogue is composed of sound and spoken content, our model encodes the information from audio and text sequences using dual recurrent neural networks (rnns) and then combines the information from these sources to predict the emotion class. this architecture analyzes speech data from the signal level to the language level, and it thus utilizes the information within the data more comprehensively than models that focus on audio features. extensive experiments are conducted to investigate the efficacy and properties of the proposed model. our proposed model outperforms previous state-of-the-art methods in assigning data to one of four emotion categories (i.e., angry, happy, sad and neutral) when the model is applied to the iemocap dataset, as reflected by accuracies ranging from 68.8% to 71.8%."
        },
        {
            "id": "R50206",
            "label": "FunMap: Efficient Execution of Functional Mappings for Knowledge Graph Creation",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "data has exponentially grown in the last years, and knowledge graphs constitute powerful formalisms to integrate a myriad of existing data sources. transformation functions -- specified with function-based mapping languages like funul and rml+fno -- can be applied to overcome interoperability issues across heterogeneous data sources. however, the absence of engines to efficiently execute these mapping languages hinders their global adoption. we propose funmap, an interpreter of function-based mapping languages; it relies on a set of lossless rewriting rules to push down and materialize the execution of functions in initial steps of knowledge graph creation. although applicable to any function-based mapping language that supports joins between mapping rules, funmap feasibility is shown on rml+fno. funmap reduces data redundancy, e.g., duplicates and unused attributes, and converts rml+fno mappings into a set of equivalent rules executable on rml-compliant engines. we evaluate funmap performance over real-world testbeds from the biomedical domain. the results indicate that funmap reduces the execution time of rml-compliant engines by up to a factor of 18, furnishing, thus, a scalable solution for knowledge graph creation."
        },
        {
            "id": "R50227",
            "label": "OER Recommendations to Support Career Development",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this work in progress research paper departs from the recent, turbulent changes in global societies, forcing many citizens to re-skill themselves to (re)gain employment. learners therefore need to be equipped with skills to be autonomous and strategic about their own skill development. subsequently, high-quality, on-line, personalized educational content and services are also essential to serve this high demand for learning content. open educational resources (oers) have high potential to contribute to the mitigation of these problems, as they are available in a wide range of learning and occupational contexts globally. however, their applicability has been limited, due to low metadata quality and complex quality control. these issues resulted in a lack of personalised oer functions, like recommendation and search. therefore, we suggest a novel, personalised oer recommendation method to match skill development targets with open learning content. this is done by: 1) using an oer quality prediction model based on metadata, oer properties, and content; 2) supporting learners to set individual skill targets based on actual labour market information, and 3) building a personalized oer recommender to help learners to master their skill targets. accordingly, we built a prototype focusing on data science related jobs, and evaluated this prototype with 23 data scientists in different expertise levels. pilot participants used our prototype for at least 30 minutes and commented on each of the recommended oers. as a result, more than 400 recommendations were generated and 80.9% of the recommendations were reported as useful."
        },
        {
            "id": "R50289",
            "label": "Message Passing for Hyper-Relational Knowledge Graphs",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "hyper-relational knowledge graphs (kgs) (e.g., wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. in this work, we propose a message passing based graph encoder - stare capable of modeling such hyper-relational kgs. unlike existing approaches, stare can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. we also demonstrate that existing benchmarks for evaluating link prediction (lp) performance on hyper-relational kgs suffer from fundamental flaws and thus develop a new wikidata-based dataset - wd50k. our experiments demonstrate that stare based lp model outperforms existing approaches across multiple benchmarks. we also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 mrr points compared to triple-based representations."
        },
        {
            "id": "R50309",
            "label": "Inferring the location of authors from words in their texts",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "for the purposes of computational dialec- tology or other geographically bound text analysis tasks, texts must be annotated with their or their authors\u2019 location. many texts are locatable but most ..."
        },
        {
            "id": "R50429",
            "label": "Situation Recognition with Graph Neural Networks",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we address the problem of recognizing situations in images. given an image, the task is to predict the most salient verb (action), and fill its semantic roles such as who is performing the action, what is the source and target of the action, etc. different verbs have different roles (e.g. attacking has weapon), and each role can take on many possible values (nouns). we propose a model based on graph neural networks that allows us to efficiently capture joint dependencies between roles using neural networks defined on a graph. experiments with different graph connectivities show that our approach that propagates information between roles significantly outperforms existing work, as well as multiple baselines. we obtain roughly 3-5% improvement over previous work in predicting the full situation. we also provide a thorough qualitative analysis of our model and influence of different roles in the verbs."
        },
        {
            "id": "R50671",
            "label": "Querying the Semantic Web for Concept Identifiers to Annotate Research Datasets",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "researchers are encouraged to describe and publish research datasets so that others can find and reuse it. following a semantic approach, well-known concept identifiers are necessary that can be used as values for meta-data properties to describe relevant characteristics of such a research artifact. multiple research disciplines, communities or initiatives have already created and published standardized terms as taxonomies or ontologies for that. however, these developments are distributed on the web. as a consequence, it can be difficult for researchers to become aware of already recommended structured terminologies. thus, they will further rely on ambiguous, literal annotations. in this paper, we investigate existing data sources in the semantic web that contain relevant terms to describe a research dataset in a structured, content-oriented and fine-grained way and how to integrate it in corresponding applications. we therefore analyze both linked data services and traditional terminology services on how to retrieve and filter terms for particular research-relevant characteristics. it is shown that a variety of well-structured communityspecific terminologies with relevant concepts already exist, but that community-overspanning building blocks are nevertheless missing. furthermore, filtering and mapping particular concepts is still a challenge to improve interdisciplinary publishing. keywords\u2013linked data; research data management; data publishing; fair; nfdi."
        },
        {
            "id": "R52278",
            "label": "Measuring the predictability of life outcomes with a scientific mass collaboration",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "significance hundreds of researchers attempted to predict six life outcomes, such as a child\u2019s grade point average and whether a family would be evicted from their home. these researchers used machine-learning methods optimized for prediction, and they drew on a vast dataset that was painstakingly collected by social scientists over 15 y. however, no one made very accurate predictions. for policymakers considering using predictive models in settings such as criminal justice and child-protective services, these results raise a number of concerns. additionally, researchers must reconcile the idea that they understand life trajectories with the fact that none of the predictions were very accurate. how predictable are life trajectories? we investigated this question with a scientific mass collaboration using the common task method; 160 teams built predictive models for six life outcomes using data from the fragile families and child wellbeing study, a high-quality birth cohort study. despite using a rich dataset and applying machine-learning methods optimized for prediction, the best predictions were not very accurate and were only slightly better than those from a simple benchmark model. within each outcome, prediction error was strongly associated with the family being predicted and weakly associated with the technique used to generate the prediction. overall, these results suggest practical limits to the predictability of life outcomes in some settings and illustrate the value of mass collaborations in the social sciences."
        },
        {
            "id": "R159667",
            "label": "Using Video Clips to Support Requirements Elicitation in Focus Groups - An Experience Report.",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R74559",
                    "label": "Analyzing a video for requirements elicitation"
                }
            ],
            "abstract": "abstract this paper reports on a methodological experiment, which was carried out in two large collaborative research projects targeted at innovative products. video material was produced in order to visualize the project vision and solution ideas, and this video material was used in focus group discussions. the paper describes the process, the experiences gained and gives a number of hints which may be helpful for projects planning to use a similar approach."
        },
        {
            "id": "R159739",
            "label": "An Interdisciplinary Guideline for the Production of Videos and Vision Videos by Software Professionals",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background and motivation: in recent years, the topic of applying videos in requirements engineering has been discussed and its contributions are of interesting potential. in the last 35 years, several researchers proposed approaches for applying videos in requirements engineering due to their communication richness and effectiveness. however, these approaches mainly use videos but omit the details about how to produce them. this lack of guidance is one crucial reason why videos are not an established documentation option for successful requirements communication and thus shared understanding. software professionals are not directors and thus they do not necessarily know what constitutes a good video in general and for an existing approach. therefore, this lack of knowledge and skills on how to produce and use videos for visual communication impedes the application of videos by software professionals in requirements engineering. \\nhow to create effective videos and vision videos?: this technical report addresses this lack of knowledge and skills by software professionals. we provide two guidelines that can be used as checklists to avoid frequent flaws in the production and use of videos respectively vision videos. software professionals without special training should be able to follow these guidelines to achieve the basic capabilities to produce (vision) videos that are accepted by their stakeholders. these guidelines represent a core set of those capabilities in the preproduction, shooting, postproduction, and viewing of (vision) videos. we do not strive for perfection in any of these capabilities, .e.g., technical handling of video equipment, storytelling, or video editing. instead, these guidelines support all steps of the (vision) video production and use process to a balanced way."
        },
        {
            "id": "R159783",
            "label": "Anforderungen kl\u00c3\u00a4ren mit Videoclips",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "viele gro\u00dfe softwaresysteme sind heute vernetzt, in ger\u00e4te eingebettet und mit anzeigesystemen verbunden. sie erscheinen den nutzern als komplizierte, computergest\u00fctzte umwelt, deren bestandteile kaum zu unterscheiden sind. die ger\u00e4te und ihre umgebung, die software und die bed\u00fcrfnisse der benutzer entwickeln sich w\u00e4hrend des betriebs st\u00e4ndig weiter. damit ein systemteil n\u00fctzlich und wettbewerbsf\u00e4hig bleibt, braucht man fortw\u00e4hrend r\u00fcckmeldungen und bewertungen. die techniken des klassischen requirements engineering reichen dazu aber nicht aus. in diesem beitrag stellen wir einen ansatz vor, um mit kurzen und einfachen videoclips in dieser situation an feedback heranzukommen. bei deren auswertung werden aktuelle anforderungen identifiziert und gekl\u00e4rt."
        },
        {
            "id": "R159803",
            "label": "Using Vision Videos in a Virtual Focus Group: Experiences and Recommendations",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R172543",
                    "label": "Video production and application"
                }
            ],
            "abstract": "facilitated meetings are an established practice for the requirements engineering activities elicitation and validation. focus groups are one well-known technique to implement this practice. several researchers already reported the successful use of vision videos to stimulate active discussions among the participants of on-site focus groups, e.g., for validating scenarios and eliciting feedback. these vision videos show scenarios of a system vision. in this way, the videos serve all parties involved as a visual reference point to actively disclose, discuss, and align their mental models of the future system to achieve shared understanding. in the joint project trusd, we had planned to conduct such an on-site focus group using a vision video to validate a scenario of a future software tool, the so-called privacy dashboard. however, the covid-19 pandemic and its associated measures led to an increase in home and remote working, which also affected us. therefore, we had to replan and conduct the focus group virtually. in this paper, we report about our experiences and recommendations for the use of vision videos in virtual focus groups."
        },
        {
            "id": "R166677",
            "label": "Conference Indexing in Digital Libraries: A Ranking Model and Case Study on dblp",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "digital library curators make relevance decisions in their daily work to prioritize the most urgent metadata updates. in this work, we propose a complex relevance and ranking model to support the decision and prioritization process of digital library curators. our approach incorporates different aspects of relevance decisions into a framework for feasible data quality management in digital libraries. a case study demonstrates the effects of the factors we use to model these aspects."
        },
        {
            "id": "R108476",
            "label": "Publicly Verifiable Proofs of Data Replication and Retrievability for Cloud Storage",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "proofs of retrievability (pors) permit a cloud provider to prove to the client (owner) that her files are correctly stored. extensions of pors, called proofs of retrievability and reliability (porrs), enable to check in a single instance that replicas of those files are correctly stored as well.in this paper, we propose a publicly verifiable porr using verifiable delay functions, which are special functions being slow to compute and easy to verify. we thus ensure that the cloud provider stores both original files and their replicas at rest, rather than computing the latter on the fly when requested to prove fair storage. moreover, the storage verification can be done by anyone, not necessarily by the client. to our knowledge, this is the first porr that offers public verification. future work will include implementation and evaluation of our solution in a realistic cloud setting."
        },
        {
            "id": "R108480",
            "label": "Homomorphic Authentication Scheme for Proof of Retrievability with Public Verifiability",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloud storages are the cloud computing model that stores, manages, and operates data storage as a service. these are widely used nowadays and are being adopted by many organizations or individuals. the ease of using cloud storage is that the users can upload the data in remote cloud storage and can be accessed by any device through the internet. these cloud storage are managed by cloud service providers. despite having benefits, users don\u2019t get physical access to the servers that store their data. thus, users need some integrity verification techniques that confirm that data stored in the data center is intact. this paper presents the public verifiability service that provides integrity verification of data placed in the cloud. the proposed system is built on pseudorandom functions (prfs) which rely on homomorphic linear property. we also considered the third party auditor (tpa) to confirm the integrity of cloud data through auditing. our experimental study shows that the proposed method is provably secure."
        },
        {
            "id": "R108482",
            "label": "Pors: Proofs of Retrievability for Large Files",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper, we define and explore proofs of retrievability (pors). a por scheme enables an archive or back-up service (prover) to produce a concise proof that a user (verifier) can retrieve a target file f, that is, that the archive retains and reliably transmits file data sufficient for the user to recover f in its entirety.\\n a por may be viewed as a kind of cryptographic proof of knowledge (pok), but one specially designed to handle a large file (or bitstring) f. we explore por protocols here in which the communication costs, number of memory accesses for the prover, and storage requirements of the user (verifier) are small parameters essentially independent of the length of f. in addition to proposing new, practical por constructions, we explore implementation considerations and optimizations that bear on previously explored, related schemes.\\n in a por, unlike a pok, neither the prover nor the verifier need actually have knowledge of f. pors give rise to a new and unusual security definition whose formulation is another contribution of our work.\\n we view pors as an important tool for semi-trusted online archives. existing cryptographic techniques help users ensure the privacy and integrity of files they retrieve. it is also natural, however, for users to want to verify that archives do not delete or modify files prior to retrieval. the goal of a por is to accomplish these checks without users having to download the files themselves. a por can also provide quality-of-service guarantees, i.e., show that a file is retrievable within a certain time bound."
        },
        {
            "id": "R108484",
            "label": "IPOR: An Efficient IDA-Based Proof of Retrievability Scheme for Cloud Storage Systems",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "with the arrival of big data era, cloud storage has become more ubiquitous. a growing number of consumers remote their data into cloud, as cloud can provide them with ample storage space and powerful computational capacity. however, storing data in cloud means that data is out of their control. how to verify the integrity of stored data and retrieve the corrupted data has become an urgent security problem. in this paper, we propose a new efficient proof of retrievability scheme, named as ipor, for cloud storage systems. the ipor not only can verify the integrity of remote data, but also can retrieve the original data of corrupted blocks from the healthy servers with probability 100%. moreover, ipor obviously decreases the complexity of data integrity tags and it requires performing a few multiplication and addition operations to retrieve the corrupted data. therefore, our scheme is much more efficient than the state-of-the-art schemes. in addition, the security analysis indicates that our scheme is provably secure."
        },
        {
            "id": "R108488",
            "label": "Outsourced Proof of Data Retrievability and Recovery in Hybrid Cloud",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloud computing moves the application software and databases to the centralized large data centers, where the management of the data and services may not be fully trustworthy. in this work, we study the problem of ensuring the integrity of data storage in cloud computing. to reduce the computational cost at user side during the integrity verification of their data, the notion of public verifiability has been proposed. however, the challenge is that the computational burden is too huge for the users with resource-constrained devices to compute the public authentication tags of file blocks. to tackle the challenge, we propose opdr, a new cloud storage scheme involving a cloud storage server and a cloud audit server, where the latter is assumed to be semi-honest. in particular, we consider the task of allowing the cloud audit server, on behalf of the cloud users, to preprocess the data before uploading to the cloud storage server and later verifying the data integrity. opdr outsources and offloads the heavy computation of the tag generation to the cloud audit server and eliminates the involvement of user in the auditing and in the pre-processing phases. furthermore, we strengthen the proof of retrievability (por) model to support dynamic data operations, as well as ensure security against reset attacks launched by the cloud storage server in"
        },
        {
            "id": "R108494",
            "label": "Dynamic Outsourced Proofs of Retrievability Enabling Auditing Migration for Remote Storage Security",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "remote data auditing service is important for mobile clients to guarantee the intactness of their outsourced data stored at cloud side. to relieve mobile client from the nonnegligible burden incurred by performing the frequent data auditing, more and more literatures propose that the execution of such data auditing should be migrated from mobile client to third-party auditor (tpa). however, existing public auditing schemes always assume that tpa is reliable, which is the potential risk for outsourced data security. although outsourced proofs of retrievability (opor) have been proposed to further protect against the malicious tpa and collusion among any two entities, the original opor scheme applies only to the static data, which is the limitation that should be solved for enabling data dynamics. in this paper, we design a novel authenticated data structure called bv23tree, which enables client to batch-verify the indices and values of any number of appointed leaves all at once for efficiency. by utilizing bv23tree and a hierarchical storage structure, we present the first solution for dynamic opor (dopor), which extends the opor model to support dynamic updates of the outsourced data. extensive security and performance analyses show the reliability and effectiveness of our proposed scheme."
        },
        {
            "id": "R108496",
            "label": "Dynamic Proofs of Retrievability for Coded Cloud Storage Systems",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloud storage allows users to store their data in a remote server to get rid of expensive local storage and management costs and then access data of interest anytime anywhere. a number of solutions have been proposed to tackle the verification of remote data integrity and retrievability in cloud storage systems. most of existing schemes, however, do not support efficient data dynamics and/or suffer from security vulnerabilities when involving dynamic data operations. in this paper, we propose a dynamic proof of retrievability scheme supporting public auditability and communication-efficient recovery from data corruptions. to this end, we split up the data into data blocks and encode each data block individually using outer code and inner code before outsourcing so that i) an update inside any data block only affects a few codeword symbols and ii) communication-efficient data repair for a breakdown server can be achieved and communication overhead for small data corruptions within a server can be eliminated. based on the encoded data blocks, we utilize rb23tree to enforce the data sequence for dynamic operations, preventing the cloud service provider from manipulating data block to pass the integrity check in the dynamic scenario. formal security analysis and extensive experimental evaluations are conducted, showing that the proposed scheme is practical for use in cloud storage systems."
        },
        {
            "id": "R108500",
            "label": "Efficient Proofs of Retrievability with Public Verifiability for Dynamic Cloud Storage",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloud service providers offer various facilities to their clients. the clients with limited resources opt for some of these facilities. they can outsource their bulk data to the cloud server. the cloud server maintains these data in lieu of monetary benefits. however, a malicious cloud server might delete some of these data to save some space and offer this extra amount of storage to another client. therefore, the client might not retrieve her file (or some portions of it) as often as needed. proofs of retrievability (por) provide an assurance to the client that the server is actually storing all of her data appropriately and they can be retrieved at any point of time. in a dynamic por scheme, the client can update her data after she uploads them to the cloud server. moreover, in publicly verifiable por schemes, the client can delegate her auditing task to some third party specialized for this purpose. in this work, we exploit the homomorphic hashing technique to design a publicly verifiable dynamic por scheme that is more efficient (in terms of bandwidth required between the client and the server) than the \u201cstate-of-the-art\u201d publicly verifiable dynamic por scheme. we also analyze security and performance of our scheme."
        },
        {
            "id": "R108505",
            "label": "Proof of Retrievability with Efficient Verification",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the computationally sound proof (cs proof) is a proof system which reduces the verifier\u2019s computation to a level polylogarithmic in that of accepting. if used in cloud computing, cs proof will significantly reduce computation of the client whose computation resources are much more limited than that of the cloud server. we are the first to introduce cs proof belonging to complexity theory into cloud computing, where a protocol for data integrity verification is proposed to reduce the customer\u2019s computation. concretely, the customer\u2019s computation is only poly-logarithmic in that of the traditional protocols. however, in our opinion, the significance of this study is not the improved efficiency, but that we introduce a new way to achieve integrity verification. the proposed protocol supports public verification even without the customer\u2019s public key and satisfies the security against semi-honest adversaries. the customer\u2019s privacy holds against both the cloud and the third-party verifier. the proposed protocol can be considered as a proper application of cs proof to integrity verification in cloud computing."
        },
        {
            "id": "R108509",
            "label": "SW-POR: A Novel POR Scheme Using Slepian-Wolf Coding for Cloud Storage",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloud computing is a service by which the clients can outsource their data to the cloud storage server to deal with the local storage limitation. however, the cloud storage providers are untrustworthy, which can lead to several security challenges, such as data availability, data integrity, and data confidentiality. to mitigate the issues of data availability and data integrity, a novel slepian-wolf-based proof of retrievability (sw-por) scheme is proposed to enable the client to check whether the distributed data stored in the cloud servers is intact or not. the proposed sw-por scheme not only can obtain an optimal coded block size, but also it can provide the exact-repair feature and low complexity. in this paper, the security analysis and efficiency analysis are provided. simulation results show that the sw-por scheme can accomplish a significant improvement in computation time."
        },
        {
            "id": "R108513",
            "label": "Towards Efficient Provable Data Possession in Cloud Storage",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "provable data possession (pdp) allows data owner to periodically and remotely audit integrity of their data stored in a cloud storage, without retrieving the file and without keeping a local copy. ateniese et al. (ccs 07, acm tiss \u201911) proposed the first pdp scheme, which is very efficient in communication and storage. however their scheme requires a lot of group exponentiation operations: in the setup, one group exponentiation is required to generate a tag per each data block. in each verification, (equivalently) (m+ `) group exponentiations are required to generate a proof, where m is the size of a data block and ` is the number of blocks accessed during a verification. this paper proposed an efficient pdp scheme. compared to ateniese et al. (ccs 07, acm tiss \u201911), the proposed scheme has the same complexities in communication and storage, but is much more efficient in computation: in the setup, no expensive group exponentiations are required. in each verification, only m group exponentiations are required to generate a proof. our experiment shows that our scheme is about 400 times faster than ateniese et al. (ccs 07, acm tiss \u201911) in the setup phase. the security of the proposed scheme is proved under knowledge of exponent assumption and factorization assumption."
        },
        {
            "id": "R108515",
            "label": "A Novel Zero Knowledge Proof of Retrievability",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "proof of retrievability is a cryptographic tool which interacts between the data user and the server, and the server proves to the data user the integrity of data which he will download. it is a crucial problem in outsourcing storage such as cloud computing. in this paper, a novel scheme called the zero knowledge proof of retrievability is proposed, which combines proof of retrievability and zero knowledge proof. it has lower computation and communication complexity and higher security than the previous schemes."
        },
        {
            "id": "R108517",
            "label": "Proofs of Retrievability from Linearly Homomorphic Structure-Preserving Signatures",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "proofs of retrievability (por) enables clients to outsource huge amount of data to cloud servers, and provides an efficient audit protocol, which can be employed to check that all the data is being maintained properly and can be retrieved from the server. in this paper, we present a generic construction of por from linearly homomorphic structure-preserving signature (lhsps), which makes public verification possible. authenticity and retrievability of our por scheme are guaranteed by the unforgeability of lhsps. we further extend our result to dynamic por, which supports dynamic update of outsourced data. our construction is free of complicated data structures like merkle hash tree. with an instantiation of a recent lhsps scheme proposed by kiltz and wee (eurocrypt15), we derive a publicly verifiable (dynamic) por scheme. the security is based on standard assumptions and proved in the standard model."
        },
        {
            "id": "R137023",
            "label": "Increased attention for computer-tailored health communications: an event-related potential study",
            "doi": "10.1037/0278-6133.25.3.300",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R107733",
                    "label": "Effective Messaging"
                }
            ],
            "abstract": "the authors tested whether individually tailored health communications receive more attention from the reader than nontailored health communications in a randomized, controlled trial among student volunteers (n = 24). they used objective measures of attention allocation during the message exposure. in a between-subjects design, participants had to read tailored or nontailored nutrition education messages and at the same time had to pay attention to specific odd auditory stimuli in a sequence of frequent auditory stimuli (odd ball paradigm). the amount of attention allocation was measured by recording event-related potentials (erps; i.e., n100 and p300 erps) and reaction times. for the tailored as opposed to the nontailored group, results revealed larger amplitudes for the n100 effect, smaller amplitudes for the p300 effect, and slower reaction times. resource allocation theory and these results suggest that those in the tailored group allocated more attention resources to the nutrition message than those in the nontailored group."
        },
        {
            "id": "R186589",
            "label": "Low-Dimensional Model for Bike-Sharing Demand Forecasting that Explicitly Accounts for Weather Data",
            "doi": "https://doi.org/10.1177/0361198120932160",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R189028",
                    "label": "optimisation of  a three-level data clustering method to  predict  the demand pattern of New York City bikes "
                },
                {
                    "id": "R189029",
                    "label": "optimisation of a predictive model for hourly rental rates at a  zonal level"
                }
            ],
            "abstract": "with the increasing availability of big, transport-related datasets, detailed data-driven mobility analysis is becoming possible. trips with their origins, destinations, and travel times are now collected in publicly available databases, allowing for detailed demand forecasting with methods exploiting big and accurate data. in this paper, we predict the demand pattern of new york city bikes with a low-dimensional approach utilizing three-level data clustering. we use historical demand data along with temperature and precipitation to first aggregate and then decompose data to obtain meaningful clusters. the core of this approach lies in the proposed clustering technique, which reduces the dimension of the problem and, differently from other machine learning techniques, requires limited assumptions on the model or its parameters. the proposed method allows, for the given temperature and precipitation method, to obtain expected vector of movement (mean number and direction of trips) for each zone. in this paper, we synthesize more than 17 million trips into daily and zonal vectors of movement, which combined with weather data allow forecasting of the trip demand. the method allows us to predict the demand with over 75% accuracy, as shown in series of experiments in which various settings and parameterizations are validated against 25% holdout data."
        },
        {
            "id": "R186659",
            "label": "Built Environment Factors Affecting Bike Sharing Ridership: Data-Driven Approach for Multiple Cities",
            "doi": "https://doi.org/10.1177/0361198119849908",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "identification of factors influencing ridership is necessary for policy-making, as well as, when examining transferability and aspects of performance and reliability. in this work, a data-driven method is formulated to correlate arrivals and departures of station-based bike sharing systems with built environment factors in multiple cities. ridership data from stations of multiple cities are pooled in one data set regardless of their geographic boundaries. the method bundles the collection, analysis, and processing of data, as well as, the model\u2019s estimation using statistical and machine learning techniques. the method was applied on a national level in six cities in germany, and also on an international level in three cities in europe and north america. the results suggest that the model\u2019s performance did not depend on clustering cities by size but by the relative daily distribution of the rentals. selected statistically significant factors were identified to vary temporally (e.g., nightclubs were significant during the night). the most influencing variables were related to the city population, distance to city center, leisure-related establishments, and transport-related infrastructure. this data-driven method can help as a support decision-making tool to implement or expand bike sharing systems."
        },
        {
            "id": "R186674",
            "label": "Analysing the relationship between weather, built environment, and public transport ridership",
            "doi": "https://doi.org/10.1049/iet-its.2020.0469",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "for a sustainable public transport system, it is important to unveil the spatiotemporal characteristics of ridership and identify the influence mechanisms. some studies analysed the effects of weather and built environment separately, however, their effects when incorporated remains to be determined. using smart card data, weather information, and point of interest data from beijing, the light gradient boosted machine was employed to investigate the relative importance of weather and built environment variables contributing to daily ridership at the traffic analysis zone level, and investigate the non-linear relationship and interaction effects between them. weather conditions and built environment contribute 30.22 and 55.83% to ridership fluctuations, respectively. most variables show complex non-linear and threshold effects on ridership. the interaction effects of weather and weekend/public holiday have a more substantial influence on ridership than weekdays, indicating weather conditions have less impact on regular commuting trips than discretionary trips. the ridership fluctuations in response to changing weather conditions vary with spatial locations. adverse weather, such as strong wind, high humidity, or heavy rainfall, has a more disruptive impact on leisure-related areas than on residence and office areas. this study can benefit stakeholders in making decisions about optimising public transport networks and scheduling service frequency."
        },
        {
            "id": "R192299",
            "label": "Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network",
            "doi": "10.1007/s10489-020-01829-7",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R192312",
                    "label": "Covid-19 detection or diagnosis"
                }
            ],
            "abstract": "abstract chest x-ray is the first imaging technique that plays an important role in the diagnosis of covid-19 disease. due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks ( cnn s) for image recognition and classification. however, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. in this paper, we validate and a deep cnn , called decompose, transfer, and compose ( detrac ), for the classification of covid-19 chest x-ray images. detrac can deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. the experimental results showed the capability of detrac in the detection of covid-19 cases from a comprehensive image dataset collected from several hospitals around the world. high accuracy of 93.1% (with a sensitivity of 100%) was achieved by detrac in the detection of covid-19 x-ray images from normal, and severe acute respiratory syndrome cases."
        },
        {
            "id": "R192303",
            "label": "COVID-19 detection from chest X-Ray images using Deep Learning and Convolutional Neural Networks",
            "doi": "10.1101/2020.05.22.20110817",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "R192312",
                    "label": "Covid-19 detection or diagnosis"
                }
            ],
            "abstract": "a bstract the covid-19 pandemic in 2020 has highlighted the need to pull all available resources towards the mitigation of the devastating effects of such \u201cblack swan\u201d events. towards that end, we investigated the option to employ technology in order to assist the diagnosis of patients infected by the virus. as such, several state-of-the-art pre-trained convolutional neural networks were evaluated as of their ability to detect infected patients from chest x-ray images. a dataset was created as a mix of publicly available x-ray images from patients with confirmed covid-19 disease, common bacterial pneumonia and healthy individuals. to mitigate the small number of samples, we employed transfer learning, which transfers knowledge extracted by pre-trained models to the model to be trained. the experimental results demonstrate that the classification performance can reach an accuracy of 95% for the best two models."
        },
        {
            "id": "R210141",
            "label": "Constructing citations: reviewing chat transcripts to improve citation assistance as a service",
            "doi": "10.1108/rsr-03-2021-0007",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose using chat transcripts from indiana university libraries, the authors examined a subset of transcripts involving citations. from this analysis, they propose improvements for citation assistance as a holistic service. design/methodology/approach two years of chat transcripts were examined and questions containing citation-related keywords were segregated for further examination. the authors used a test data set to create a coding scheme for the questions and responses. this scheme was then applied to all the citation-related transcripts. findings 390 of 11,553 transcripts included interactions about citations. in 42% of the transcripts, no specific citation style was mentioned. american psychological association and modern language association were the most frequently mentioned citation styles by chat users. business reports (company data and market research), periodicals (journal, newspaper or magazine articles), websites and government documents were the most often asked about formats, but there was a wide variety of other unusual formats. questions about endnote were more common than other types of citation management software. chat staff utilized a variety of responses including guiding the student by example, directing to an online resource for more information (85% of the responses) or referring to a citation management expert. an unexpected amount of hedging words in the responses indicates the presence of anxiety on the part of chat staff in responding to these types of questions. originality/value this paper goes beyond most existing studies of chat transcripts by using chat transcripts as data to guide service improvements for a commonly asked but not typically discussed set of questions."
        },
        {
            "id": "R210144",
            "label": "Web-Based Software Tools for Systematic Literature Review in Medicine: Systematic Search and Feature Analysis",
            "doi": "10.2196/33219",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background systematic reviews (srs) are central to evaluating therapies but have high costs in terms of both time and money. many software tools exist to assist with srs, but most tools do not support the full process, and transparency and replicability of sr depend on performing and presenting evidence according to established best practices. objective this study aims to provide a basis for comparing and selecting between web-based software tools that support sr, by conducting a feature-by-feature comparison of sr tools. methods we searched for sr tools by reviewing any such tool listed in the sr toolbox, previous reviews of sr tools, and qualitative google searching. we included all sr tools that were currently functional and required no coding, and excluded reference managers, desktop applications, and statistical software. the list of features to assess was populated by combining all features assessed in 4 previous reviews of sr tools; we also added 5 features (manual addition, screening automation, dual extraction, living review, and public outputs) that were independently noted as best practices or enhancements of transparency and replicability. then, 2 reviewers assigned binary present or absent assessments to all sr tools with respect to all features, and a third reviewer adjudicated all disagreements. results of the 53 sr tools found, 55% (29/53) were excluded, leaving 45% (24/53) for assessment. in total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. distillersr (evidence partners; 26/30, 87%), nested knowledge (nested knowledge; 25/30, 83%), and eppi-reviewer web (eppi-centre; 24/30, 80%) support the most features followed by giotto compliance (giotto compliance; 23/30, 77%), litstream (icf), and srdb.pro (vts software). fewer than half of all the features assessed are supported by 7 tools: robotanalyst (national centre for text mining), srdr (agency for healthcare research and quality), syrf (systematic review facility), data abstraction assistant (center for evidence synthesis in health), sr accelerator (institute for evidence-based healthcare), robotreviewer (robotreviewer), and covid-nma (covid-nma). notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. conclusions distillersr, nested knowledge, and eppi-reviewer web each offer a high density of sr-focused web-based tools. by transparent comparison and discussion regarding sr tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews."
        },
        {
            "id": "R210147",
            "label": "Literature Mapper: A QGIS Plugin for Georeferencing Citations in Zotero",
            "doi": "10.20944/preprints202012.0577.v1",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "here we introduce literature mapper, a python qgis plugin that provides a method for creating a spatial bibliography manager as well as a specification for storing spatial data in a bibliography manager. literature mapper uses qgis&amp;rsquo; spatial capabilities to allow users to add location information to a zotero library, a free and open source bibliography manager. literature mapper enhances the citations in a user&amp;rsquo;s online zotero database with geo-locations by storing spatial coordinates as part of traditional citation entries. literature mapper receives data from and sends data to the user&amp;rsquo;s online database via zotero&amp;rsquo;s web api. by using zotero as the backend data storage, literature mapper benefits from all of its features including shared citation collections, public sharing, and an open web api usable by additional applications, such as web mapping libraries. we evaluate literature mapper&amp;rsquo;s ability to provide insights into the spatial distribution of published literature by mapping the study sites described in academic publications related to california&amp;rsquo;s coastal strand vegetation. the results of this exercise are presented in static and web map form."
        },
        {
            "id": "R210149",
            "label": "Web-Based Software Tools for Systematic Literature Review in Medicine: Systematic Search and Feature Analysis (Preprint)",
            "doi": "10.2196/preprints.33219",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background systematic reviews (srs) are central to evaluating therapies but have high costs in terms of both time and money. many software tools exist to assist with srs, but most tools do not support the full process, and transparency and replicability of sr depend on performing and presenting evidence according to established best practices. objective this study aims to provide a basis for comparing and selecting between web-based software tools that support sr, by conducting a feature-by-feature comparison of sr tools. methods we searched for sr tools by reviewing any such tool listed in the sr toolbox, previous reviews of sr tools, and qualitative google searching. we included all sr tools that were currently functional and required no coding, and excluded reference managers, desktop applications, and statistical software. the list of features to assess was populated by combining all features assessed in 4 previous reviews of sr tools; we also added 5 features (manual addition, screening automation, dual extraction, living review, and public outputs) that were independently noted as best practices or enhancements of transparency and replicability. then, 2 reviewers assigned binary &lt;i&gt;present&lt;/i&gt; or &lt;i&gt;absent&lt;/i&gt; assessments to all sr tools with respect to all features, and a third reviewer adjudicated all disagreements. results of the 53 sr tools found, 55% (29/53) were excluded, leaving 45% (24/53) for assessment. in total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. distillersr (evidence partners; 26/30, 87%), nested knowledge (nested knowledge; 25/30, 83%), and eppi-reviewer web (eppi-centre; 24/30, 80%) support the most features followed by giotto compliance (giotto compliance; 23/30, 77%), litstream (icf), and srdb.pro (vts software). fewer than half of all the features assessed are supported by 7 tools: robotanalyst (national centre for text mining), srdr (agency for healthcare research and quality), syrf (systematic review facility), data abstraction assistant (center for evidence synthesis in health), sr accelerator (institute for evidence-based healthcare), robotreviewer (robotreviewer), and covid-nma (covid-nma). notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. conclusions distillersr, nested knowledge, and eppi-reviewer web each offer a high density of sr-focused web-based tools. by transparent comparison and discussion regarding sr tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews."
        },
        {
            "id": "R210151",
            "label": "AN OPTIMIZED PAGE RANK ALGORITHM WITH WEB MINING, WEB CONTENT MINING AND WEB STRUCTURE MINING",
            "doi": "10.29121/ijetmr.v4.i8.2017.91",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "with the rapid increase in internet technology, users get easily confused in large hypertext structure. the primary goal of the web site owner is to provide the relevant information to the users to fulfill their needs. in order to achieve this goal, they use the concept of web mining. web mining is used to categorize users and pages by analyzing the users\u201f behaviour, the content of the pages, and the order of the urls that tend to be accessed in order. most of the search engines are ranking their search results in response to users' queries to make their search navigation easier. with a web browser, one can view web pages that may contain text, images, videos, and other multimedia, and navigate between them via hyperlinks. it is very difficult for a user to find the high quality information which he wants. page ranking algorithm is needed which provide the higher ranking to the important pages. in this paper, we discuss the improvement of page ranking algorithm to provide the higher ranking to important pages. most of the search engines are ranking their search results in response to user\u2019s queries to make their search navigations easier."
        },
        {
            "id": "R210155",
            "label": "Publishing with Open Journal Systems (OJS): the engaged university and library support at the University of Stavanger",
            "doi": "10.7557/5.5604",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "increasing the role of libraries in academic journal publishing activities and journal hosting has become an important subject in the library world in the past few years. the purpose of this study is to present the role of the libraries at university of stavanger (uis) in the context of library-as-publisher. within this category, open access (oa) journal publishing has been a popular service offered by libraries, rapidly attracting researchers' attention. the university libraries at university of stavanger (uis) have a long history of promoting and supporting open access initiatives. the libraries have established and continue to build, host and maintain an operative open access institutional repository (uis brage) for scientific works in full text.&#x0d; from 2018, uis libraries started using a journal management system to facilitate the open access scholarly publishing and therefore support transferring and updating of established the existing journals and the lunching of new ones. the open journal systems (ojs) from public knowledge project (pkp) is used which is the most common journal management system being discussed frequently in literature.&#x0d; currently, the uis libraries repository host four active open access journals, with some others under development. all these journals reside within the same ojs implementation with the same design and layout on top, however, at the individual journal level there are also options for some customization.&#x0d; uis libraries initially support all the steps of the journal creation and development process but train the editors and the subsequent users to engage in some part of the process. the library it-engineer and information technology department (it) manage ojs server, maintain the ojs database and software, and performs the layout and design customization and development and initial technical configuration for the new journals.&#x0d; from the viewpoint of it, there is a need for several technical skills such as web design skills to customize the style sheets and web layout, graphic design skills to produce banners, logos and cover pages whereas the editorial workflow process may require skills on copy-editing and proofreading of articles. ojs is a template-based platform but when it comes to front-end design, it has its limitation. there are certain limitations which make it difficult to get to the details of the article. for instance, when an article comes with a long abstract or number of references, the web-page becomes unfriendly. another challenge is when pkp launches a new ojs update. some features cannot be migrated, and you may lose them. furthermore, users may find it hard to adapt to the new version. the biggest challenge to the ojs is the learning curve. there are some faculty members who have had some frustrations with the software.&#x0d; while it is a free and open source platform, the time, technical skills and programming abilities are still associated with the costs. in this poster we provide you with the challenges and lessons learned so far by the libraries at stavanger university."
        },
        {
            "id": "R210158",
            "label": "3B G\u00c3\u00b6rselle\u00c5\u009ftirme Ortam\u00c4\u00b1 Olarak Web Taray\u00c4\u00b1c\u00c4\u00b1lar\u00c4\u00b1",
            "doi": "10.17671/gazibtd.1072993",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "y\u00fcksek kaliteli 3b imajlar\u0131n elde edilebildi\u011fi modelleme ve bilgisayar programlar\u0131nda kar\u015f\u0131la\u015f\u0131lan i\u015flem zorlu\u011fu, yeni platformlar\u0131n geli\u015ftirilmesini gerekli k\u0131lan \u00f6nemli bir etkendir. web taray\u0131c\u0131lar\u0131 ile \u00e7al\u0131\u015fan ve ger\u00e7ek zamanl\u0131 etkile\u015fime izin veren 3b grafik kitapl\u0131klar\u0131, tasar\u0131m ve yaz\u0131l\u0131m\u0131n birlikte y\u00fcr\u00fct\u00fclebildi\u011fi platformlar haline gelmektedir. bu \u00e7al\u0131\u015fman\u0131n amac\u0131, web ortam\u0131n\u0131n kullan\u0131m \u015fekillerini ve 3b g\u00f6rselle\u015ftirmedeki potansiyellerini ke\u015ffetmektir. 3b grafiklerde bildirimsel ve zorunlu s\u0131n\u0131fland\u0131rman\u0131n incelenmesinden sonra, web uygulamas\u0131 ve i\u00e7erik \u00fcretiminde zorunlu olan ve son zamanlarda \u00f6n plana \u00e7\u0131kan webgl standard\u0131na odaklan\u0131lmaktad\u0131r. bu ba\u011flamda, tasar\u0131mlar\u0131n temsil s\u00fcrecinde etkile\u015fimli 3b web grafiklerinin kullan\u0131m\u0131na y\u00f6nelik tart\u0131\u015f\u0131lan yakla\u015f\u0131mlar \u015funlard\u0131r: 1. ger\u00e7ek zamanl\u0131 etkile\u015fime ve komut dosyas\u0131 arac\u0131l\u0131\u011f\u0131yla 3b modellemeye izin veren web grafi\u011fi kitapl\u0131klar\u0131. 2. web taray\u0131c\u0131lar\u0131ndan yararlanman\u0131n ikinci yolu olarak, masa\u00fcst\u00fc bilgisayarlarda 3d modelleme programlar\u0131na eklenti olarak geli\u015ftirilen ve web entegrasyonu sa\u011flayan ara\u00e7lar. 3. hem bir web taray\u0131c\u0131s\u0131nda modeller sunan hem de e\u015f zamanl\u0131 kodlamaya izin veren k\u00fct\u00fcphane tabanl\u0131 edit\u00f6rler incelenmi\u015ftir. \u00e7al\u0131\u015fmada haz\u0131rlanan genel \u00e7er\u00e7eve, bu yakla\u015f\u0131mlar\u0131n modelleme ve g\u00f6rselle\u015ftirme odakl\u0131 kullan\u0131m\u0131n\u0131 web grafik k\u00fct\u00fcphaneleri ba\u011flam\u0131nda sunarak; avantaj ve dezavantajlar\u0131n\u0131 ele almaktad\u0131r."
        },
        {
            "id": "R210164",
            "label": "Ontological methods and tools for semantic extension of the media WIKI technology",
            "doi": "10.15407/pp2020.02-03.061",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "practical aspects of ontological approach to organization of intelligent wiki-based information resources (ir) are considered. we analyze the main features, capabilities and limitations of mediawiki as a technological platform for development of the web-based information resource and suggest main directions of its refinement. we propose an abstract model of mediawiki architecture that formalizes relations between the main components of this software environment and analyze the ways of its semantic extensions based on ontological representation of domain knowledge. an original algorithm of semantic wiki pages matching with domain ontology is developed. we propose an ontological model of ir that formalizes its knowledge base structure and explicitly performs main features of typical information objects (tio) of this ir. such tios depend on domain specifics and purposes of ir, therefore their development has to involve domain experts and knowledge engineers. use of ontology corresponding to the set of wiki pages (either with semantic markup or without it) provides new ir functions associated with semantic search and navigation. other important aspect of intelligent wiki resource development deals with adaptation of user interface to the specifics of ir: enabling various tools of navigation, visualization and content analysis by processing of tio features enriches ir functionality, reduces access time to information and makes usage of ir more efficient. developing additional mediawiki functionality with new requests to the mediawiki api using tio templates, extends data analysis and integration capabilities, and offers different, user-focused, ir content views expands the possibilities of data integration and proposes various user-oriented representations of ir content. wiki resource semantization allows the use knowledge acquired from such ir by external application, or example, by search engines for intelligent web retrieval. domain ontologies based on various subsets of the wiki pages and generated by them thesauri can be used by various semantic web applications, both independently or in general technological chain for personified retrieval focused on individual users and their tasks. approbation of this approach is demonstrated by maips retrieval system. we consider the use semantic similarity of concepts represented by wiki-pages of ir as an additional way of intelligent navigation between these pages. such approach allows to group wiki pages according to user interests by different aspects of their content and structure. wiki ontologies are considered as the basis for estimation of semantic similarity between domain concepts pertinent to user task. such elements of wiki ontology as classes, property values of class instances and relations between them are used as parameters for the quantitative assessment of semantic similarity of wiki pages. we propose to use local similarity and generate the sets of semantically similar concepts (ssc) that takes into account some subset of page properties and categories defined by user needs. such sets of sscs can be considered as user task thesauri for other applications. in addition, we propose to enrich the basic tools of mediawiki used for access management to the ir content with specialized software code that performs content classification that take into consideration separate namespaces, categories, templates and semantic properties of tio acquired from wiki markup. we demonstrate the software implementation of proposed solutions by developing of portal version of the great ukrainian encyclopedia (e-vue) that contains heterogeneous multimedia content with complex structure. we analyze the specifics of e-vue knowledge system and develop its formalized tio representation based on semantic web technologies and ontological analysis. ontological model of e-vue and original methods of its processing used for this project extend the functionality of the portal in the area of search, navigation, integration and protection of content based on background domain knowledge. in addition, original user interface of e-vue is developed with an allowance for encyclopedia knowledge specifics, substantially differs from the standard wiki, meets the requirements, goals and objectives of this ir and provides a lot of additional features."
        },
        {
            "id": "R210167",
            "label": "Web software to create thematic maps for precision agriculture",
            "doi": "10.1590/s1678-3921.pab2020.v55.00735",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract: the objective of this work was to develop and provide a free web application able to generate thematic maps. the initiative aims to incorporate the functionalities of the \u201csoftware para defini\u00e7\u00e3o de unidades de manejo\u201d (sdum) desktop application, which has proven to be suitable for working with thematic maps and management zones, but that was only available for desktop computers. the developed web application was tested with real data from two agricultural fields located in the state of paran\u00e1, brazil. thematic maps of soil and plant characteristics relevant to precision agriculture were created through the following interpolation methods: inverse distance, moving average, and nearest neighbor. the obtained results show that the usage of this web tool allows identifying areas with the same behavior toward soil variables, making it possible for the user to have a better and more accurate vision of the area to be worked on and to identify possible causes of variation in productivity. because it is installed in a server with on-demand features, the software has a satisfactory performance from a functional point of view and can be accessed from any web environment."
        },
        {
            "id": "R210170",
            "label": "Considerations for conducting systematic reviews: evaluating the performance of different methods for de-duplicating references",
            "doi": "10.1186/s13643-021-01583-y",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract background systematic reviews involve searching multiple bibliographic databases to identify eligible studies. as this type of evidence synthesis is increasingly pursued, the use of various electronic platforms can help researchers improve the efficiency and quality of their research. we examined the accuracy and efficiency of commonly used electronic methods for flagging and removing duplicate references during this process. methods a heterogeneous sample of references was obtained by conducting a similar topical search in medline, embase, cochrane central register of controlled trials, and psycinfo databases. references were de-duplicated via manual abstraction to create a benchmark set. the default settings were then used in ovid multifile search, endnote desktop, mendeley, zotero, covidence, and rayyan to de-duplicate the sample of references independently. using the benchmark set as reference, the number of false-negative and false-positive duplicate references for each method was identified, and accuracy, sensitivity, and specificity were determined. results we found that the most accurate methods for identifying duplicate references were ovid, covidence, and rayyan. ovid and covidence possessed the highest specificity for identifying duplicate references, while rayyan demonstrated the highest sensitivity. conclusion this study reveals the strengths and weaknesses of commonly used de-duplication methods and provides strategies for improving their performance to avoid unintentionally removing eligible studies and introducing bias into systematic reviews. along with availability, ease-of-use, functionality, and capability, these findings are important to consider when researchers are selecting database platforms and supporting software programs for conducting systematic reviews."
        },
        {
            "id": "R210176",
            "label": "Educating PhD students for knowledge-driven society",
            "doi": "10.7557/5.5391",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "universities educate students for working in knowledge-driven societies. whereas subject-related knowledge is part of every curriculum, institutions of higher education fail to teach systematically how to utilize and benefit from today\u2019s variety of digital tools. students and researchers are mostly unaware of what they lack to work more effectively and efficiently and to benefit from existing knowledge. since this lack of awareness is not obvious to students and researchers (unknown unknowns; you cannot miss something that you do not know), it is difficult to convince them that there is a gap that needs to be filled. &#x0d; in 2014, we decided to tackle this problem by creating and developing the course \u201cscientific information retrieval &amp; management in life sciences and chemistry\u201d. the unique 2 ects course features a multi-level approach to obtain and employ scientific information and to get students information savvy. on one hand, the course demonstrates the bigger picture: we discuss the aspects of scientific writing and publishing, critical choice of data sources, patents, visualisation and design, text mining and data pipelining, knowledge generation, outreach and impact of publications. on the other hand, we highlight an extensive list of field-proven tools that can assist researchers in their daily activities. &#x0d; we also wanted to foster a lasting impact on how students utilize databases, tools, software, and web services. thus, at the end of the course students have to write an essay describing their current information workflow or their (un)met information needs. these essays confirm and explain how the students changed their information use, and which parts of the course they may have not understood. moreover, essays that describe unmet information needs allow us to explore possible solutions and to work with our vendors. in our talk, we will share the concept for the course and report on our experiences."
        },
        {
            "id": "R210179",
            "label": "Dual-Component Ontograph Visualization",
            "doi": "10.1088/1757-899x/1031/1/012119",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract today there are several generally accepted methods of storing data in an information network. one of the most modern is the presentation of data in the form of a semi-structured (with the possibility of fuzzy formalization) set \u2013 a knowledge base. compared to databases, this view has several advantages: the ability to store complex heterogeneous information; the ability to expand and supplement the description of the subject area without reprogramming; visibility and accessibility of knowledge presentation to the user. but this advantage of them turns into a problem, which currently has been only partially solved. the data in the knowledge base can be in such a form that their presentation according to formalized rules and algorithms is impossible or ineffective. currently, the most promising in terms of representing data structures is considered to be an ontological representation that copes well with displaying an arbitrary structure. most of the visual representations of ontologies (prot\u00e9g\u00e9 in integration with owlviz, ontograf, 3d hyperbolyc, tree, etc.) are images of nodes as a set of conditional points (small geometric shapes) connected by lines \u2013ontographs. this approach to visualization is less informative and inconvenient to apply to the educational process. the need to create new approaches to the presentation of information, implement its accessibility and efficiency of usage is becoming increasingly important. along with traditional information support in the form of databases, knowledge bases have begun to develop at a tremendous pace, which, when used effectively, provide significant competitive advantages. an important feature of knowledge bases is the ability to work with approximate sets. the authors developed ontograph visualization technology, partially implemented on the ontos.xyz web resource. this resource allows you to visualize the vertices of the ontograph, the connections between them and assign each set of contexts that are related to it. each of the nodes of the ontograph contains a specific descriptive context. the main feature of the ontos editor is the ability to assign each node a context of all types supported by the browser. including html pages, web 2.0 resources, etc. also, the proposed system implements the visualization of knowledge bases, consisting of two components: a navigator that determines the path to some node of the ontograph that has children and a visualization slider for this node that displays these elements. the knowledge base viewer is a slider that resembles a photo gallery slider with advanced navigation. the ontological approach to servicing knowledge bases can be not only a means of organizing knowledge. the knowledge bases developed on the basis of the ontological approach make it possible to work actively with knowledge, to solve problems associated with education, the development of artificial intelligence, decision-making systems, and many other areas where approximate sets can be used."
        },
        {
            "id": "R210182",
            "label": "NEST Desktop - An educational application for neuroscience",
            "doi": "10.1101/2021.06.15.444791",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract simulation software for spiking neuronal network models matured in the past decades regarding performance and flexibility. but the entry barrier remains high for students and early career scientists in computational neuroscience since these simulators typically require programming skills and a complex installation. here, we describe an installation-free graphical user interface (gui) running in the web browser, which is distinct from the simulation engine running anywhere, on the student\u2019s laptop or on a supercomputer. this architecture provides robustness against technological changes in the software stack and simplifies deployment for self-education and for teachers. our new open source tool, nest desktop, comprises graphical elements for creating and configuring network models, running simulations, and visualizing and analyzing the results. nest desktop allows students to explore important concepts in computational neuroscience without the need to learn a simulator control language before. our experiences so far highlight that nest desktop helps advancing both quality and intensity of teaching in computational neuroscience in regular university courses. we view the availability of the tool on public resources like the european ict infrastructure for neuroscience ebrains as a contribution to equal opportunities. significance statement the graphical user interface nest desktop makes neuronal network simulations accessible to non-programmers. it facilitates the interactive exploration of neuronal network models by integrating the whole workflow of wiring up the setup, simulating the neuronal dynamics, and analyzing the recorded activity data into a single tool. nest desktop effectively supports teaching the concepts and methods of computational neuroscience. due to its installation-free web-based implementation, it is in particularly suitable for online courses."
        },
        {
            "id": "R210184",
            "label": "Enhancing coding skills with CloudStor SWAN",
            "doi": "10.24135/pjtel.v4i1.148",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cloudstor swan (aarnet, 2022) is a research-focused web service for running analyses that is available to staff and students at many research institutes and universities across australia and new zealand. in 2021, we used swan as a teaching tool in the master-level subject, computational genomics (comp90016) at the university of melbourne. this subject aims to teach students how to analyse large genomic datasets using best practices software tools, pipelines and student-written, custom code. &#x0d; &#x0d; although cloudstor swan was not conceived as a teaching tool, we worked with their technical staff to tailor the service to our use case. this innovative use of existing research infrastructure allowed us to effectively transition the subject to remote learning. students and staff could log in to the service using their existing university credentials, from anywhere in the world, without the use of a vpn. the ability to access the platform from a web browser allowed for a consistent computing environment for all students regardless of operating system, and without having to worry about software installations on local machines. this presented a significantly improved experience from the custom servers that had been used in the past.&#x0d; &#x0d; we used swan for weekly workshops during semester and for assessment in the form of assignments and an exam. it allowed us to format subject material in jupyter notebooks where we could seamlessly integrate text, graphics and code. additionally, assessed code questions can incorporate automatic marking and written submissions can be checked for plagiarism. swan also allowed us to introduce students to the unix command line, an important skillset that was not previously taught in the university of melbourne master of science (bioinformatics) program.&#x0d; &#x0d; from a student perspective, swan allowed for a practical skillset to be developed alongside theoretical knowledge from other aspects of the course. the platform was simple to learn and allowed students to focus on the subject content and the tasks asked of them, rather than on the interface. from a teacher\u2019s perspective, having a unified platform allowed for a single set of clear instructions, improved troubleshooting and clearer management of tool versions and software dependencies. the use of jupyter notebooks simplified lesson plans and assessments by integrating multiple elements into single documents. this element also made the lessons more easily sharable between colleagues and collaborators.&#x0d; &#x0d; our integration of this technology into our tertiary teaching has served as a model for a similar use at a different australian university. we hope to share the lessons learned from this subject, the advantages of using cloudstor swan in a teaching environment for both staff and students and provide some advice for others who may want to adapt it to fit their own teaching needs.&#x0d; presentation link: https://youtu.be/8tutco1hd9c&#x0d; references&#x0d; &#x0d; aarnet. (2022). cloudstor: access, store, share and work with your data in one place. https://www.aarnet.edu.au/network-and-services/cloud-services/cloudstor"
        },
        {
            "id": "R210187",
            "label": "The atlas of aging society 2.0",
            "doi": "10.5194/ica-abs-2-27-2020",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract. most of the western countries currently experience a demographic change. it is essential catching this structural change with all its socio-spatial and life-specific dimensions and make it visible in a generally understandable way.the atlas of the aging society 2.0, based on a first version launched in 2017, aims to visualize age-related information in an interactive web application that supports not only the content but also engages the users, is accessible to a broad audience, offers opportunities for different stakeholders and levels of interest, and can accommodate a high range of data as well as future updates.as in the initial version, the atlas of aging society 2.0 operates with a novel concept called the story-network principle which connects briefly introduced visualizations such that a braid of age-related information develops. like conventional atlases, the dimensions of information are divided into different topic areas. each topic comprises several stories consisting of multiple information cards. various connecting lines link the cards together and integrate all of them into an informational network. storylines connect cards in a directional order such that their information covers a particular aspect of a topic. related-card lines link cards that have similar content but do not belong to the same story, while recommended-card lines prevent users from dead ends by connecting story ending cards with different story starting cards. the user decides at any time whether he/she wants to follow a storyline through a whole topic aspect or if he/she interrupts the story and navigates into other topics to explore further information.the story-network is visibly displayed on the web application\u2019s landing page and follows the reverse conclusion from tobler's first law of geography. the similarity in the content of information cards reflects their spatial position in the network. the information cards are displayed as nodes. the appearance of the edges explains the type of connection between the nodes. to immerse oneself in the informational network of the atlas of aging society 2.0, different options are available. it is possible to navigate directly from the story-network view on the landing page to a specific card by a single click on the representative node. to give the user an idea of what information is hidden behind the nodes, the title of the nodes can be displayed in the story network view using an on-touch function. the topic-entry option is ideal for users who search for specific information. therefore, an interactive and hierarchically organized bubble plot was created. when hovered, the bubble plot first divides into topic-area bubbles. on a second level, these are divided into individual stories, from which the user can choose. a third option is the usage of the coincidence-button, leading the user to a random card.each card includes a visualization, a descriptive text, and some additional information compromised in the metadata. the visualizations follow a uniform visual language, by using a constant colour concept and an overarching design language. the graphical representations use the d3.js and dc.js javascript libraries. one aim of the atlas of aging society 2.0 was to make visualizations more interactive by working with hover- and click-functions and by the implementation of interactive dashboards. the ability to interact with selected visualizations intends to motivate users to explore and display data according to their interests.the atlas of aging society 2.0 is currently optimized for tablets while a desktop version is in progress. in this version, there are many new exciting subject areas and contents, which can be explored. the use of the story-network principle as implemented in this project is also conceivable for other applications due to its linking and ordering properties and its easy scalability."
        },
        {
            "id": "R210190",
            "label": "Interfaces to Scripting Languages in Visual Analytics Applications",
            "doi": "10.31219/osf.io/9mjv5",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the need to use data visualization and visual analysis in various fields has led to the development of feature-rich standalone applications such as tableau and ms power bi. these applications provide ready-to-use functionality for loading, analyzing and visualizing data, even for users who are not familiar with programming and scripting. meanwhile, data scientists have to combine many different tools and techniques in their daily work, since no standalone application can yet cover the entire workflow. as a result, a rich landscape of open source libraries is available today, covering various tasks from data analysis to modeling and visualization. to combine the best of two worlds, interfaces for scripting languages have been integrated into standalone applications in recent years. we analyzed which interfaces to six common scripting languages are offered. the interfaces offer different levels of integration and therefore support different steps of the data science workflow. in this paper we investigated the integration levels of script languages in standalone applications and divided them into four groups. we used this classification to evaluate 13 standalone visual analysis applications currently available on the market. we then analyzed which groups of applications best support which steps in the data science workflow. we found that a tight integration of scripting languages can especially support the explorative analysis and modeling phase of the data science workflow. we also discuss our results in the light of visual analysis research and give suggestions for future research directions."
        },
        {
            "id": "R210192",
            "label": "PYTHON FOR WEB DEVELOPMENT",
            "doi": "10.47760/ijcsmc.2022.v11i04.006",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "with evolution of web, several competitive languages such as java, php, python, ruby are catching the attention of the developers. recently python has emerged as a popular and the preferred web programming language, because of its simplicity to code and ease of learning. being a flexible language, it offers fast development of web-based applications. it offers development using cgi and wsgi. web development in python is aided by the powerful frameworks such as django, web2py, pyramid, and flask that python supports. thus, python promises to emerge as one of the preferred choice language for web applications. web is a rapidly growing repository of resources. internet is used as a medium for accessing these resources. web architecture mainly comprises of two entities, namely client and server. web client is an application (browser) on host machine that urges these resources, and web server is a machine on web that is responsible for fulfilling the request issued by client. hypertext transfer protocol (http) is the most popular protocol used by client and server for web communication. in a static web, browser issues http request to the http server, which searches for the requisite resource in its database and returns it as an http response. to avoid any compatibility issues, every request issued by browser is in form of a url (uniform resource locator). the url protocol defines the rules for communication between client and server. it comprise of host name (ip address) which helps in identifying the server system on the web, port number which determines the service (for example, ftp, email service) on the server that should respond to request, and the access path of the resource (web page) on server. the web where responses are already stored in server database in form of static web pages is termed static web. however, response returned by server to the client may be generated on the fly depending upon the request of the client. web applications offer several benefits over traditional applications that are required to be installed at each host computer that wishes to use them. web applications do not incur publishing and distribution costs as opposed to traditional applications where the software (applications) were published using cd\u2019s and distributed. they need not be installed at each client host; rather they are placed at a central server and accessed by large number of clients. since a web application is managed centrally, application updates and data backups can be performed easily. the web applications are easily accessible irrespective of the boundaries of space and time. since, they are accessed through browser, the platform accessing them is not an issue, and thus they provide cross-platform compatibility. inspite of above- mentioned advantages, web applications have a few limitations. internet connectivity and server availability is required for accessing web application through browser. however, accessing them through internet my take more time as compared to applications installed on host systems. also, web applications require compatible web browsers. since they are deployed on web, they are vulnerable to several internet attacks. web programming using cgi and wsgi requires building web applications from the scratch by using python standard libraries. python provides with web frameworks in the form of packages/ modules that simplify the task of writing application programs. these frameworks lighten tedious job of developers. they support server and client side programming by providing support for several activities such as request interpretation (getting form parameters, handling cookies and sessions), response generation (generating data in html or other format such as pdf, excel), and storing data. the web frameworks are further categorized as full- stack and non-full-stack frameworks. full-stack frameworks provide components for every phase of programming in contrast to non-full-stack frameworks. all the frameworks include templates and data persistence as key ingredients for constructing web. templates are used to avoid complex code that results when html and python code is mixed in a single file. templates are html files with placeholder for the data depending upon user input. data persistence deals with storing and retrieving data and maintaining consistency. the data can be stored and maintained using plain text files, relational database engines such as mysql, oracle, or some object-oriented databases. the web framework providing support for wsgi should be preferred. this makes deploying an application easier."
        },
        {
            "id": "R210195",
            "label": "How to create an interactive dashboard using R: the example of the Queensland COVID-19 tracker",
            "doi": "10.37970/aps.v4i2.72",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background interactive tools like data dashboards enable users both to view and interact with data. in today\u2019s data-driven environment it is a priority for researchers and practitioners alike to be able to develop interactive data visualisation tools easily and where possible at a low cost.&#x0d; aims here, we provide a guide on how to develop and create an interactive online data dashboard in r, using the covid-19 tracker for health and hospital regions in queensland, australia as an example. we detail a series of steps and explain choices made to design, develop, and easily maintain the dashboard and publish it online.&#x0d; data and methods the dashboard visualises publicly available data from the queensland health web page. we used the programming language r and its free software environment. the dashboard webpage is hosted publicly on github pages updated via github desktop.&#x0d; results our interactive dashboard is available at https://qcpr.github.io/.&#x0d; conclusions interactive dashboards have many applications such as dissemination of research and other data. this guide and the supplementary material can be adjusted to develop a new dashboard for a different set of data and needs."
        },
        {
            "id": "R210198",
            "label": "Immersive Captioning: Developing a framework for evaluating user needs",
            "doi": "10.1109/aivr50618.2020.00063",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this article focuses on captioning for immersive environments and the research aims to identify how to display them for an optimal viewing experience. this work began four years ago with some partial findings. this second stage of research, built from the lessons learnt, focuses on the design requirements cornerstone: prototyping. a tool has been developed towards quick and realistic prototyping and testing. the framework integrates methods used in existing solutions. given how easy it is to contrast and compare, the need to further the first framework was obvious. a second improved solution was developed, almost as a showcase on how ideas can quickly be implemented for user testing. after an overview on captions in immersive environments, the article describes its implementation, based on web technologies opening for any device with a web browser. this includes desktop computers, mobile devices and head mounted displays. the article finishes with a description of the new caption modes and methods, hoping to be a useful tool towards testing and standardisation."
        },
        {
            "id": "R210201",
            "label": "Reference management training at the postgraduate program of State Islamic Institute of Samarinda",
            "doi": "10.31603/ce.5974",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the purpose of the community service is to provide reference management training for postgraduate of state islamic institute of samarinda. the training method used is direct practice in the classroom using three reference management software, namely endnote, mendeley, and zotero. this activity was attended by 16 postgraduate students and they followed with great enthusiasm. after the training, the knowledge and abilities of postgraduate students experienced a significant increase and were committed to using the software in writing scientific papers."
        },
        {
            "id": "R210207",
            "label": "Grammarly as AI-powered English Writing Assistant: Students\u00e2\u0080\u0099 Alternative for Writing English",
            "doi": "10.31002/metathesis.v5i1.3519",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "&lt;p class=\"abstracttext\"&gt;the presence of \u2018grammarly\u2019 as one of the online grammar checkers as the impact of technology development. this paper aims to reveal an overview of \u2018grammarly\u2019 as an ai-powered english writing assistant for efl students in writing english. this research applies descriptive qualitative research. based on the analysis, using grammarly software shows the performance increased. before using grammarly, the performance of the test score is 34 out of 100. after using grammarly, the performance text score is 77 out of 100. this score shows the quality of writing in this text increased. the performance can be increased based on grammarly's suggestions in a premium account. the researcher recommends the students to use grammarly. grammarly is a web tool to perform grammar checks well, starting from the spelling of words, sentence structure to standard grammar. grammarly is free, so it is recommended for students who want to check various documents or articles in english. grammarly helps check the grammatical rule, the spelling rule in english structure, also correct errors in writing such as punctuation and capitalization. grammarly runs on an artificial intelligence (ai) system, which is built to analyze english sentences relying on a set of rules. grammarly takes context when showing corrections or suggestions, and inform the students quickly but still precisely. for accuracy, two service options available both free and paid features. of course, the grammarly free version still has limitations and in-service features, unlike the paid version (premium) which has full advantages and benefits, many features, and complete.&lt;/p&gt;"
        },
        {
            "id": "R210213",
            "label": "Knowledge Extraction System from English Newspaper",
            "doi": "10.47191/etj/v6i6.08",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "web has tens of millions of files on any subject matter which can be from any field. it may be very tough for anybody to examine loads of documents to apprehend knowledge approximately any occasion. the aim of my research is to apply extraction technique that can be used for tracking topics. creating a user interface (ui) where user can communicate with application. extract records from newspapers, articles which can be in e-form as well as from newspapers. information plays an important role in the human society. information can be related to many important issues in finance, social science, and marketing. the system is based on the concept that will extract text and altering the structure of web page and the contents which are not relevant like ads and user comments will be excluded."
        },
        {
            "id": "R210216",
            "label": "Web Crawler: Design And Implementation For Extracting Article-Like Contents",
            "doi": "10.35470/2226-4116-2020-9-3-144-151",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the world wide web is a large, wealthy, and accessible information system whose users are increasing rapidly nowadays. to retrieve information from the web as per users\u2019 requests, search engines are built to access web pages. as search engine systems play a significant role in cybernetics, telecommunication, and physics, many efforts were made to enhance their capacity.however, most of the data contained on the web are unmanaged, making it impossible to access the entire network at once by current search engine system mechanisms. web crawler, therefore, is a critical part of search engines to navigate and download full texts of the web pages. web crawlers may also be applied to detect missing links and for community detection in complex networks and cybernetic systems. however, template-based crawling techniques could not handle the layout diversity of objects from web pages. in this paper, a web crawler module was designed and implemented, attempted to extract article-like contents from 495 websites. it uses a machine learning approach with visual cues, trivial html, and text-based features to filter out clutters. the outcomes are promising for extracting article-like contents from websites, contributing to the search engine systems development and future research gears towards proposing higher performance systems."
        },
        {
            "id": "R210219",
            "label": "Persistent URLs and Citations Offered for Digital Objects by Digital Libraries",
            "doi": "10.6017/ital.v40i2.12987",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "as libraries, archives, and museums make unique digital collections openly available via digital library platforms, they expose these resources to users who may wish to cite them. often several urls are available for a single digital object, depending on which route a user took to find it, but the chosen citation url should be the one most likely to persist over time. catalyzed by recent digital collections migration initiatives at indiana university libraries, this study investigates the prevalence of persistent urls for digital objects at peer institutions and examines the ways their platforms instruct users to cite them. this study reviewed institutional websites from the digital library federation\u2019s (dlf) published list of 195 members and identified representative digital objects from unique digital collections navigable from each institution\u2019s main web page in order to determine persistent url formats and citation options.&#x0d; findings indicate an equal split between offering and not offering discernible persistent urls with four major methods used: handle, doi, ark, and purl. significant variation in labeling persistent urls and inclusion in item-specific citations uncovered areas where the user experience could be improved for more reliable citation of these unique resources."
        },
        {
            "id": "R210222",
            "label": "PLeveraging Django and Redis using Web Scraping",
            "doi": "10.35940/ijrte.a1916.059120",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "web scraping is also known as data scraping and it is used for extracting data from sites. the software used for this may directly access the world wide web by using the hypertext transfer protocol or by using a web browser. over the years, due to advancements in web development and its technology, various frameworks have come in use and almost all of websites are dynamic with their content being served from cms. this makes it tough to extract data since there is no common template for extracting data. hence, we use rss. rich site summary is a kind of timeline allowing users and also applications to gain access to the updates on websites in a standardized, computer-readable format. this project combines the use of rss to extract data from websites and serve users in a robust and easy way. the differentiation is that this project uses server side caching to serve users almost instantaneously without the need to perform data extraction from the requested site all over again. this is done using redis and django."
        },
        {
            "id": "R210225",
            "label": "A Mixed-Method Analysis of Text and Audio Search Interfaces with Varying Task Complexity",
            "doi": "10.1145/3409256.3409822",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "voice-based assistants have become a popular tool for conducting web search, particularly for factoid question answering. however, for more complex web searches, their functionality remains limited, as does our understanding of the ways in which users can best interact with audio-based search results. in this paper, we compare and contrast user behaviour through the representation of search results over two mediums: text and audio. we begin by conducting a crowdsourced study exposing the differences in user selection of search results when those are presented in text and audio formats. we further confirm these differences and investigate the reasons behind them through a mixed-methods laboratory study. through a qualitative analysis of the collected data, we produce a list of guidelines for an audio-based presentation of search results."
        },
        {
            "id": "R210232",
            "label": "Bridging the Open Web and APIs: Alternative Social Media Alongside the Corporate Web",
            "doi": "10.1177/20563051221077032",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "concentrations of power over the internet among a small number of corporate platforms have motivated attempts to build alternative social media. using the contemporary internet routinely involves relying on a small number of dominant corporate platforms. in reaction against this centralization of power, there are many attempts to build alternative web technologies that reconfigure the internet\u2019s power structures and enact their own values. however, given the entrenchment of large corporate platforms, this typically involves co-existing with rather than replacing them, at least in the present. accordingly, it is important to investigate challenges arising when alternative social media operate alongside and even within the systems to which they propose an alternative. we investigate this through an empirical study of the indieweb, a community of personal websites with social networking features including syndication to and from corporate platforms. using github data, we study the development of a tool for this syndication called bridgy, focusing on its relationship with the facebook api. by identifying breakdowns in this relationship, we identify the following challenges: translating differing logics between the open web and apis, occasional ambiguity in facebook\u2019s presentation of privacy settings, and ongoing precarity due to api updates. our analysis illustrates the reality of maintaining alternative technical systems as part of present-day infrastructures and generates insights for building socially empowering technologies for the future."
        },
        {
            "id": "R210235",
            "label": "Evolution of the Web: from Web 1.0 to 4.0",
            "doi": "10.48161/qaj.v1n3a75",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the internet has become a vital component of the twenty-first century as technology has advanced. the number of new technologies emerging in tandem with the qualities supplied by the internet is rapidly increasing. the world wide web (www), which is commonly referred to as the world's largest information environment, is a vital virtual environment in which internet users may trade, read, and publish information using a web browser. web 1.0, web 2.0, and web 3.0 technologies have all been seen and are still being observed in this review paper. however, there is no clear definition for web 4.0, which is a 4th generation web technology, in the literature. web 4.0 has multiple dimensions, as seen by the first examples that have appeared. big data, augmented reality, machine-to-machine communication (m2m), cloud computing, and artificial intelligence (ai) technologies, as well as smart agents, will be able to integrate in the future years. web 4.0 is a web technology revolution that includes a new internet of things (iot) that interacts with a variety of models. the goal of this study is to clarify the notion of web 4.0, which is viewed as an intelligent and symbiotic (human-machine interaction) network with massive interfaces and linkages, as well as to contribute to the literature by studying its many dimensions and investigating its links with new generation technologies."
        },
        {
            "id": "R210238",
            "label": "Tyche: a free novel web-based solution for efficient and unbiased analysis of scientific images",
            "doi": "10.21203/rs.3.rs-1343726/v1",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract background scientific image analysis is crucial in many research fields but it can be hampered by subjectivity and bias. thus, image analysis should be performed anonymized by multiple observers and images displayed in a random order. yet in radiology for example most pacs-viewers display patient metadata which could influence the analysis. although desirable, including multiple observers can be logistically difficult as files have to be provided including spreadsheets to document the analyzed parameters. methods to address these challenges we created a browser-based program displaying scientific images anonymized and in a random order. observers are invited by the project master via a project-specific url that is only temporarily valid. the project master can design an unlimited number of project-specific questions which will be displayed next to each image. as the analysis is performed online, results from all observers are summarized in real-time and the data are immediately visible to the project master. in this study, we present the process of analysis using histological and radiological images and compare tyche with the traditional \u201coffline\u201d desktop bound way. results tyche allows users to upload anonymized images and create single choice and numeric questions specifically for these images. via temporarily active urls, access to the data can be provided to observers who can analyze images within any web browser using the integrated tools (zoom, length, etc.). next to each image, the defined questions and answers are displayed and results are immediately visible. aspects of traditional image analysis like laborious file sharing via clouds or e-mail with observers and data gathering via potentially error-prone spreadsheets become obsolete. performing a histologic image analysis, no difference in results comparing tyche with the offline analysis were found. conclusion tyche is a lightweight, web-based tool that facilitates anonymized image analysis by multiple observers and reduces subjectivity and bias."
        },
        {
            "id": "R210242",
            "label": "Collaborative web extensions: a P2P approach",
            "doi": "10.55612/s-5002-049-006",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "web extensions are powerful software artifacts that allow end-users to adapt and enrich a website. these extensions run on the user's web browser as a single-user software that manipulates available third-party web contents. many of them offer some collaborative features that depend on a web application. the need of two co-depending software artifacts (the web application as back-end and the web extensions as front-end) increases complexity, making the system harder to develop and maintain. in this paper we tackle this problem by proposing a p2p approach to build collaborative web extensions. the approach involves a middleware and a framework. on the one hand, the middleware serves to manage the resources offered by the browser so multiple p2p extensions can coexist. it ensures that the overall performance of the browser is not degraded by the collaborative web extension. on the other hand, the proposed framework is intended to allow developers without experience in p2p to create collaborative web extensions on top of the middleware. this paper discusses the main challenges of building p2p web extensions, presents the approach, and two case studies focused on the use of the framework for inexperienced developers."
        },
        {
            "id": "R210247",
            "label": "Extraction Of Wikidata Knowledge For The Metadata Formation For Documents of Digital Mathematical Collections",
            "doi": "10.26907/1562-5419-2021-24-6-1023-1059",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "methods for creating digital mathematical collections that include unstructured sets of documents are presented. these sets contain materials from scientific conferences, as well as articles from the archives of mathematical journals of the \"pre-digital\" period. using the software tools of the metadata factory of the digital mathematical library lobachevskii dml, a mandatory set of metadata for digital collection documents was formed. to refine and replenish the metadata sets, knowledge extraction methods from wikidata were used. to search wikidata for information about digital collection documents and their authors, a system of sparql queries has been developed. a set of wikidata entities is defined, which determine the features of the search, as well as the subsequent filtering of the results. methods for clarifying and supplementing the bibliographic references given in the articles are proposed. when forming the metadata of documents of retrocollections, a search was made in wikidata for information about the years of life of the authors of articles, as well as urls of web pages with information about articles and their authors. the results of the formation of several new digital collections of the lobachevskii-dml digital library are presented."
        },
        {
            "id": "R210254",
            "label": "A Google Sheet Add-on for Biodiversity Data Standardization and Sharing",
            "doi": "10.3897/biss.4.59228",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "for those biologists and biodiversity data managers who are unfamiliar with information science data practices of data standardization, the use of complex software to assist in the creation of standardized datasets can be a barrier to sharing data. since the ratification of the darwin core standard (dwc) (darwin core task group 2009) by the biodiversity information standards (tdwg) in 2009, many datasets have been published and shared through a variety of data portals. in the early stages of biodiversity data sharing, the protocol distributed generic information retrieval (digir), progenitor of dwc, and later the protocols biocase and tdwg access protocol for information retrieval (tapir) (de giovanni et al. 2010) were introduced for discovery, search and retrieval of distributed data, simplifying data exchange between information systems. although these protocols are still in use, they are known to be inefficient for transferring large amounts of data (gbif 2017). because of that, in 2011 the global biodiversity information facility (gbif) introduced the darwin core archive (dwc-a), which allows more efficient data transfer, and has become the preferred format for publishing data in the gbif network. dwc-a is a structured collection of text files, which makes use of the dwc terms to produce a single, self-contained dataset. many tools for assisting data sharing using dwc-a have been introduced, such as the integrated publishing toolkit (ipt) (robertson et al. 2014), the darwin core archive assistant (gbif 2010) and the darwin core archive validator. despite promoting and facilitating data sharing, many users have difficulties using such tools, mainly because of the lack of training in information science in the biodiversity curriculum (convention on biological diversiity 2012, enke et al. 2012). however, most users are very familiar with spreadsheets to store and organize their data, but the adoption of the available solutions requires data transformation and training in information science and more specifically, biodiversity informatics. for an example of how spreadsheets can simplify data sharing see stoev et al. (2016). in order to provide a more \"familiar\" approach to data sharing using dwc-a, we introduce a new tool as a google sheet add-on. the add-on, called darwin core archive assistant add-on can be installed in the user's google account from the g suite marketplace and used in conjunction with the google sheets application. the add-on assists the mapping of spreadsheet columns/fields to dwc terms (fig. 1), similar to ipt, but with the advantage that it does not require the user to export the spreadsheet and import it into another software. additionally, the add-on facilitates the creation of a star schema in accordance with dwc-a, by the definition of a \" core_id \" (e.g. occurrenceid, eventid, taxonid) field between sheets of a document (fig. 2). the add-on also provides an ecological metadata language (eml) (jones et al. 2019) editor (fig. 3) with minimal fields to be filled in (i.e., mandatory fields required by ipt), and helps users to generate and share dwc-archives stored in the user's google drive, which can be downloaded as a dwc-a or automatically uploaded to another public storage resource like a user's zenodo account (fig. 4). we expect that the google sheet add-on introduced here, in conjunction with ipt, will promote biodiversity data sharing in a standardized format, as it requires minimal training and simplifies the process of data sharing from the user's perspective, mainly for those users not familiar with ipt, but that historically have worked with spreadsheets. although the dwc-a generated by the add-on still needs to be published using ipt, it does provide a simpler interface (i.e., spreadsheet) for mapping data sets to dwc than ipt. even though the ipt includes many more features than the darwin core assistant add-on, we expect that the add-on can be a \"starting point\" for users unfamiliar with biodiversity informatics before they move on to more advanced data publishing tools. on the other hand, zenodo integration allows users to share and cite their standardized data sets without publishing them via ipt, which can be useful for users without access to an ipt installation. additionally, we are working on new features and future releases will include the automatic generation of global unique identifiers for shared records, the possibility of adding additional data standards and dwc extensions, integration with gbif rest api and with ipt rest api."
        },
        {
            "id": "R210261",
            "label": "STML (Sketch to Markup Language)",
            "doi": "10.2139/ssrn.3740413",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\u201cweb development encompasses many stages, which involve designing the website done by making a wireframe first, after which the code for the frontend and backend is appropriately written over many iterations until the developers arrive at a fully functional and satisfying website for their need. we see how every website starts with the basic idea and structure of the website that can be described using a wireframe. it shows the basic elements and gives developers an idea about the structure of the website. it is given to the developers to create the boilerplate code that places all the elements into place accordingly. the task of converting the wireframe to html code is tedious and time-consuming. at present, the boilerplate code is mostly written manually. currently, the users have to write the html code for structuring the elements on the webpage, which leads to a lot of redundant work and users investing their precious time into it. generally, where the structure of web pages is the same, users would tend to maintain a copy of the pre-existing boilerplate code for reusability. in most cases, the boilerplate code differs for web pages despite the code for the html elements being the same. in such situations, the work becomes redundant. however, this process can be automated to ease the world of the web developer community. to make this process effortless, we propose a machine learning model. it will be trained to identify specific symbols and shapes as elements, recognize texts from the wireframe. the model will take in wireframe images as input through the web application. the idea is to process input, recognize each element in the wireframe using the open source computer vision library (opencv). identified elements will each have a corresponding code in the backend. once the elements on the wireframe are identified, the corresponding code is written into an html file. the user gets the html file as an output. the creation of the boilerplate code for a website becomes much less time-consuming, which gives developers the freedom to test out many different designs and layouts before opting for the one that best suits their needs.\u201d"
        },
        {
            "id": "R210267",
            "label": "Citationchaser: A tool for transparent and efficient forward and backward citation chasing in systematic searching",
            "doi": "10.1002/jrsm.1563",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "systematic searching aims to find all possibly relevant research from multiple sources, the basis for an unbiased and comprehensive evidence base. along with bibliographic databases, systematic reviewers use a variety of additional methods to minimise procedural bias. citation chasing exploits connections between research articles to identify relevant records for a review by making use of explicit mentions of one article within another. citation chasing is a popular supplementary search method because it helps to build on the work of primary research and review authors. it does so by identifying potentially relevant studies that might otherwise not be retrieved by other search methods; for example, because they did not use the review authors' search terms in the specified combinations in their titles, abstracts, or keywords. here, we briefly provide an overview of citation chasing as a method for systematic reviews. furthermore, given the challenges and high resource requirements associated with citation chasing, the limited application of citation chasing in otherwise rigorous systematic reviews, and the potential benefit of identifying terminologically disconnected but semantically linked research studies, we have developed and describe a free and open source tool that allows for rapid forward and backward citation chasing. we introduce citationchaser, an r package and shiny app for conducting forward and backward citation chasing from a starting set of articles. we describe the sources of data, the backend code functionality, and the user interface provided in the shiny app."
        },
        {
            "id": "R210270",
            "label": "The Analysis of a Learning Management System from a Design and Development Perspective",
            "doi": "10.18178/ijiet.2022.12.4.1616",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the use of information technology as a means of educating students has become a popular trend. for this purpose, a special type of content management system was used, called learning management systems (lms) and course management systems (cms). often all of these platforms offer similar features and users cannot choose the one that best suits them. this article proposes an analysis of the usability and functionality of software in lms frameworks. based on the integration of parallel work on the same database, you can automatically synchronize and manage accounts, users, sessions, and distribute (session and user) easily. there is no need to manually enter data in two different systems. this increases the value of the learning management system used by improving time and accuracy. by first, reducing the time creating learning materials within the lms. second, the accuracy in creating the learning materials within the lms. third: accuracy in distributing students and teachers to the course. fourth, configure the class room inside the lms that matches the cms one hundred percent. it includes subjects, departments, faculties and users (students and teachers). the contribution of this paper provides a rich recent direction of software methodologies for web-based learning management systems from a design and development perspective."
        },
        {
            "id": "R210273",
            "label": "Searching for Knowledge: Teaching Information Technology to Secondary Students",
            "doi": "10.29173/iasl8087",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper discusses the importance of accurate knowledge to a knowledge-based society and presents the rationale, organization, and content of a short course in electronic search skills that enables students to retrieve accurate information by evaluating their searches, citations, and resources in a variety of databases. focusing on the seven steps in the electronic search process, the course develops students' skills in thinking, computer literacy, and the ethical use of information. students learn the concepts, process, and skills of information literacy and technology as they integrate the results of their searches into subject areas across the secondary curriculum. a syllabus and daily topics are included."
        },
        {
            "id": "R210276",
            "label": "CREATING STYLE SHEET BY USING SPEECH RECOGNITION",
            "doi": "10.36713/epra4478",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "today\u2019s rich web applications use a mix of java script and asynchronous communication with the application server. this mechanism is also known as ajax: asynchronous javascript and xml. the intent of ajax is to exchange small pieces of data between the browser and the application server, and in doing so, use partial page refresh instead of reloading the entire web page. ajax (asynchronous javascript and xml.) is a powerful web development model for browser-based web applications. this project is designed and developed keeping that factor into mind, and a little effort is made to achieve this aim. our project is capable to recognize the speech and convert the input audio into text &amp; style sheet it also enables a user to perform operations \u201csave, open, exit\u201d a file by providing voice input."
        },
        {
            "id": "R210279",
            "label": "When Push Comes to Ads: Measuring the Rise of (Malicious) Push Advertising",
            "doi": "10.1145/3419394.3423631",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the rapid growth of online advertising has fueled the growth of ad-blocking software, such as new ad-blocking and privacy-oriented browsers or browser extensions. in response, both ad publishers and ad networks are constantly trying to pursue new strategies to keep up their revenues. to this end, ad networks have started to leverage the web push technology enabled by modern web browsers. as web push notifications (wpns) are relatively new, their role in ad delivery has not yet been studied in depth. furthermore, it is unclear to what extent wpn ads are being abused for malvertising (i.e., to deliver malicious ads). in this paper, we aim to fill this gap. specifically, we propose a system called pushadminer that is dedicated to (1) automatically registering for and collecting a large number of web-based push notifications from publisher websites, (2) finding wpn-based ads among these notifications, and (3) discovering malicious wpn-based ad campaigns. using pushadminer, we collected and analyzed 21,541 wpn messages by visiting thousands of different websites. among these, our system identified 572 wpn ad campaigns, for a total of 5,143 wpn-based ads that were pushed by a variety of ad networks. furthermore, we found that 51% of all wpn ads we collected are malicious, and that traditional ad-blockers and url filters were mostly unable to block them, thus leaving a significant abuse vector unchecked."
        },
        {
            "id": "R210282",
            "label": "Monitoring of historical and cultural heritage objects based on modern information technologies",
            "doi": "10.35595/2414-9179-2021-4-27-434-444",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the results of research in the field of forms and methods of preserving and increasing the historical and cultural heritage in rostov-on-don present in this article. the list of objects of cultural heritage of rostov-on-don includes more than 600 items, including objects of history, art, architecture, and urban planning, among which are monuments of federal, regional, and local (municipal) significance and objects of valuable historical and urban planning environment. as part of the study, the geoinformation system \u201cmonuments, memorable places and memorials in rostov-on-don\u201d was developed. the main goal of this gis is to provide a wide range of the public (including researchers and students) with access to georeferenced data. the information basis of the system is represented by data on the location of cultural heritage objects, information about objects, as well as photographs and extended reference data about objects. archival and bibliographic information about the monuments has been processed, checked, and entered the database. to accomplish the tasks, the following software was chosen\u2014excel, arcgis pro, arcgis online. the choice of software products is due to the availability of licensed software and experience in the field of gis creation. gis is implemented in two versions\u2014local (loading the initial data and preparing for publication on the internet) and the internet version (creating a web map with the ability to make changes and replenish the database, as well as create a web application \u201cmonuments, memorable places and memorials in rostov-on-don\u201d). the developed application allows you to assess the state of cultural heritage objects, allows you to get acquainted with research on the monuments and memorable places included in the database, to determine the direction and prospects of scientific research, to follow the dynamics of the process, consider new and forgotten objects of historical and cultural heritage."
        },
        {
            "id": "R210285",
            "label": "Information resources for communication of priests with parishioners",
            "doi": "10.15421/172064",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the article considers the problem of using modern means of communication in the field of religion. this topic has become extremely relevant today, given the unfavorable situation due to the establishment of quarantine restrictions that directly affect the communication process between priests and parishioners.the main information resources for providing religious communications in the modern world are analyzed in the work, their main advantages and disadvantages are highlighted. particular attention is paid to comprehensive religious web resources. all web resources are divided into 6 categories: christian sites, religious portals, sites of individual religious institutions, societies, youtube channels, sites of electronic christian libraries and electronic databases. it was found that the main disadvantage of most of the analyzed resources is the poor design and disorder of information. based on the analysis of religious web resources, it is proposed to develop a website for the parish. such a site has a complex structure in the form of the main and additional menus, which, in turn, are structured by sections, and sections - by subsections. thanks to the sections of the main menu, users will be able to see when, where, at what time an event will take place. using the additional menu \"communication\", the user will be able to anonymously send questions to the priest using the service \"ask a priest\" and receive a response to the specified e-mail address. equally important is the section \"library\", which contains religious publications, and which are structured in alphabetical order and by category. the conclusion of the article presents the prospects of development of religious information resources on the basis of their comprehensive and complex analysis. recommendations for improving religious communication web resources are offered. in particular, it is recommended to conduct constant monitoring in the world of internet technologies, to research the preferences of users, and on this basis, to make changes to existing web resources in the field of religion."
        },
        {
            "id": "R210288",
            "label": "Intellectual analysis of information about users of social networks",
            "doi": "10.15593/2499-9873/2021.4.05",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "social networks began to play an important role in the informatization of society. experts from all over the world are researching social network data to solve various tasks, such as creating popular content, conducting advertising campaigns, meeting the information needs of society, ensuring state security, etc. the analysis of social networks is understood as the solution of such tasks as determining the tonality of the text, determining the target portrait of the audience, searching for associative rules, calculating community performance indicators and data visualization. the article considers the relevance of solving the problem, analyzes the results of previous work, examines the audience's reaction to content, builds a target portrait of subscribers of various communities, examines the relationship between user interests. the initial data of the study are social networks, or rather informational messages, opinions, subnets and communities, individual users, external nodes.the paper considers the classification of social network analysis systems (such as brand analytics, iqbuzz, agorapulse, semantic force, talkwalker) according to the following criteria: users, analysis methods, objects of analysis, data sources, features.to determine the audience's reaction to the content, the method of determining the tonality of the text was applied by analyzing comments to the content. the cluster analysis method was used to determine the target profile of users in a particular community. to find patterns between the user's interests in the work, the frequency analysis of sets of elements was considered. the search for associative rules was carried out using the apriori algorithm. as a result, the works are presented in the form of graphs and diagrams. in the course of the work, an integrated approach to solving problems was used, which made it possible to create an automated information and analytical system that can be used as analytical tools in this area."
        },
        {
            "id": "R214233",
            "label": "Reinforced Spatiotemporal Attentive Graph Neural Networks for Traffic Forecasting",
            "doi": "10.1109/JIOT.2020.2974494",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the advances in the internet of things (iot) and increased availability of the road sensors allow for fine-grained traffic forecasting, which is of particular importance toward building an intelligent transportation system. in the literature, recent efforts have applied various deep learning methods for traffic forecasting, e.g., leveraging graph convolutional networks (gcns) for spatial dependency modeling, and utilizing recurrent neural networks (rnns) for capturing temporal dynamics. however, most of the existing approaches assume that spatial correlations are static and temporal correlations have only sequential dependencies and do not consider temporal periodicity of traffic across multiple time steps. the real challenge lies in using the dynamic spatiotemporal correlations while also considering the influence of the nontraffic-related factors, such as time-of-day and weekday-or-weekend in the learning architectures. we propose a novel framework titled \u201creinforced spatial\u2013temporal attention graph (rstag) neural networks\u201d for traffic prediction. our method captures dynamic spatial correlations through diffusion network graphs, while temporal dependencies are represented through the sequence-to-sequence model with an attention mechanism. in addition, we utilize the policy gradient to update the model parameters while largely alleviating the exposure bias issue that exists in previous traffic prediction models. we conduct extensive experiments on two large-scale traffic data sets collected from the road sensor networks in los angles and bay area of california. the results demonstrate that our method significantly outperforms the state-of-the-art baselines."
        },
        {
            "id": "R214251",
            "label": "AST-GCN: Attribute-Augmented Spatiotemporal Graph Convolutional Network for Traffic Forecasting",
            "doi": "10.1109/ACCESS.2021.3062114",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "traffic forecasting is a fundamental and challenging task in the field of intelligent transportation. accurate forecasting not only depends on the historical traffic flow information but also needs to consider the influence of a variety of external factors, such as weather conditions and surrounding poi distribution. recently, spatiotemporal models integrating graph convolutional networks and recurrent neural networks have become traffic forecasting research hotspots and have made significant progress. however, few works integrate external factors. therefore, based on the assumption that introducing external factors can enhance the spatiotemporal accuracy in predicting traffic and improving interpretability, we propose an attribute-augmented spatiotemporal graph convolutional network (ast-gcn). we model the external factors as dynamic attributes and static attributes and design an attribute-augmented unit to encode and integrate those factors into the spatiotemporal graph convolution model. experiments on real datasets show the effectiveness of considering external information on traffic speed forecasting tasks when compared with traditional traffic prediction methods. moreover, under different attribute-augmented schemes and prediction horizon settings, the forecasting accuracy of the ast-gcn is higher than that of the baselines. the source code of the ast-gcn is available at https://github.com/lehaifeng/t-gcn/ast-gcn."
        },
        {
            "id": "R214259",
            "label": "ST-TrafficNet: A Spatial-Temporal Deep Learning Network for Traffic Forecasting",
            "doi": "10.3390/electronics9091474",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper presents a spatial-temporal deep learning network, termed st-trafficnet, for traffic flow forecasting. recent deep learning methods highly relate accurate predetermined graph structure for the complex spatial dependencies of traffic flow, and ineffectively harvest high dimensional temporal features of the traffic flow. in this paper, a novel multi-diffusion convolution block constructed by an attentive diffusion convolution and bidirectional diffusion convolution is proposed, which is capable to extract precise potential spatial dependencies. moreover, a stacked long short-term memory (lstm) block is adopted to capture high-dimensional temporal features. by integrating the two blocks, the st-trafficnet can learn the spatial-temporal dependencies of intricate traffic data accurately. the performance of the st-trafficnet has been evaluated on two real-world benchmark datasets by comparing it with three commonly-used methods and seven state-of-the-art ones. the mean absolute error (mae), root mean square error (rmse), and mean absolute percentage error (mape) of the proposed method outperform not only the commonly-used methods, but also the state-of-the-art ones in 15 min, 30 min, and 60 min time-steps."
        },
        {
            "id": "R214278",
            "label": "Bidirectional Spatial\u00e2\u0080\u0093Temporal Network for Traffic Prediction with Multisource Data",
            "doi": "10.1177/0361198120927393",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "urban traffic congestion has an obvious spatial and temporal relationship and is relevant to real traffic conditions. traffic speed is a significant parameter for reflecting congestion of road networks, which is feasible to predict. traditional traffic forecasting methods have poor accuracy for complex urban road networks, and do not take into account weather and other multisource data. this paper proposes a convolutional neural network (cnn)-based bidirectional spatial\u2013temporal network (cnn-bdstn) using traffic speed and weather data by crawling electric map information. in cnn-bdstn, the spatial dependence of traffic network is captured by cnn to compose the time-series input dataset. bidirectional long short-term memory (lstm) is introduced to train the convolutional time-series dataset. compared with linear regression, autoregressive integrated moving average, extreme gradient boosting, lstm, and cnn-lstm, cnn-bdstn presents its ability of spatial and temporal extension and achieves more accurately predicted results. in this case study, traffic speed data of 155 roads and weather information in urumqi, xinjiang, people\u2019s republic of china, with 1-min interval for 5 months are tested by cnn-bdstn. the experiment results show that the accuracy of cnn-bdstn with input of weather information is better than the scenario of no weather information, and the average predicted error is less than 5%."
        },
        {
            "id": "R137374",
            "label": "Investigating Interactive Search Behaviour of Medical Students: An Exploratory Survey",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"in this paper, we investigate medical students medical search behavior on a medical domain. we use two behavioral signals: detailed query analysis (qualitative and quantitative) and task completion time to understand how medical students perform medical searches based on varying task complexity. we also investigate how task complexity and topic familiarity affect search behavior. we gathered 80 interactive search sessions from an exploratory survey with 20 medical students. we observe information searching behavior using 3 simulated work task scenarios and 1 personal scenario. we present quantitative results from two perspectives: overall and user perceived task complexity. we also analyze query properties from a qualitative aspect. our results show task complexity and topic familiarity affect search behavior of medical students. in some cases, medical students demonstrate different search traits on a personal task in comparison to the simulated work task scenarios. these findings help us better understand medical search behavior. medical search engines can use these findings to detect and adapt to medical students' search behavior to enhance a student's search experience.\""
        },
        {
            "id": "R189991",
            "label": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in distributed learning, local sgd (also known as federated averaging) and its simple baseline minibatch sgd are widely studied optimization methods. most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. in contrast, we study shuffling-based variants: minibatch and local random reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. for smooth functions satisfying the polyak-{\\\\l}ojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. moreover, we prove matching lower bounds showing that our convergence analysis is tight. finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings."
        },
        {
            "id": "R189995",
            "label": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices ) of data. identifying underperforming slices is particularly challenging when working with high-dimensional inputs ( e.g. images, audio), where important slices are often unlabeled. in order to address this issue, recent studies have proposed automated slice discovery methods (sdms), which leverage learned model representations to mine input data for slices on which a model performs poorly. to be useful to a practitioner, these methods must identify slices that are both underperforming and coherent ( i.e. united by a human-understandable concept). however, no quantitative evaluation framework currently exists for rigorously assessing sdms with respect to these criteria. ad-ditionally, prior qualitative evaluations have shown that sdms often identify slices that are incoherent. in this work, we address these challenges by \ufb01rst designing a principled evaluation framework that enables a quantitative comparison of sdms across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data). then, motivated by the recent development of powerful cross-modal representation learning approaches, we present domino , an sdm that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. we \ufb01nd that domino accurately identi\ufb01es 36% of the 1,235 slices in our framework \u2013 a 12 percentage point improvement over prior methods. further, domino is the \ufb01rst sdm that can provide natural language descriptions of identi\ufb01ed slices, correctly generating the exact name of the slice in 35% of settings."
        },
        {
            "id": "R210228",
            "label": "TeamTat: a collaborative text annotation tool",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract manually annotated data is key to developing text-mining and information-extraction algorithms. however, human annotation requires considerable time, effort and expertise. given the rapid growth of biomedical literature, it is paramount to build tools that facilitate speed and maintain expert quality. while existing text annotation tools may provide user-friendly interfaces to domain experts, limited support is available for figure display, project management, and multi-user team annotation. in response, we developed teamtat (https://www.teamtat.org), a web-based annotation tool (local setup available), equipped to manage team annotation projects engagingly and efficiently. teamtat is a novel tool for managing multi-user, multi-label document annotation, reflecting the entire production life cycle. project managers can specify annotation schema for entities and relations and select annotator(s) and distribute documents anonymously to prevent bias. document input format can be plain text, pdf or bioc (uploaded locally or automatically retrieved from pubmed/pmc), and output format is bioc with inline annotations. teamtat displays figures from the full text for the annotator's convenience. multiple users can work on the same document independently in their workspaces, and the team manager can track task completion. teamtat provides corpus quality assessment via inter-annotator agreement statistics, and a user-friendly interface convenient for annotation review and inter-annotator disagreement resolution to improve corpus quality."
        },
        {
            "id": "R214248",
            "label": "Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting",
            "doi": "",
            "research_field": {
                "id": "R11",
                "label": "Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "traffic forecasting is of great importance to transportation management and public safety, and very challenging due to the complicated spatial-temporal dependency and essential uncertainty brought about by the road network and traffic conditions. latest studies mainly focus on modeling the spatial dependency by utilizing graph convolutional networks (gcns) throughout a fixed weighted graph. however, edges, i.e., the correlations between pair-wise nodes, are much more complicated and interact with each other. in this paper, we propose the multi-range attentive bicomponent gcn (mra-bgcn), a novel deep learning model for traffic forecasting. we first build the node-wise graph according to the road network distance and the edge-wise graph according to various edge interaction patterns. then, we implement the interactions of both nodes and edges using bicomponent graph convolution. the multi-range attention mechanism is introduced to aggregate information in different neighborhood ranges and automatically learn the importance of different ranges. extensive experiments on two real-world road network traffic datasets, metr-la and pems-bay, show that our mra-bgcn achieves the state-of-the-art results."
        },
        {
            "id": "R35052",
            "label": "Investigating Correlations of Automatically Extracted Multimodal Features and Lecture Video Quality",
            "doi": "10.1145/3347451.3356731",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R35059",
                    "label": "Knowledge Gain Prediction"
                },
                {
                    "id": "R35060",
                    "label": "Video Quality Prediction"
                }
            ],
            "abstract": "\"ranking and recommendation of multimedia content such as videos is usually realized with respect to the relevance to a user query. however, for lecture videos and moocs (massive open online courses) it is not only required to retrieve relevant videos, but particularly to find lecture videos of high quality that facilitate learning, for instance, independent of the video's or speaker's popularity. thus, metadata about a lecture video's quality are crucial features for learning contexts, e.g., lecture video recommendation in search as learning scenarios. in this paper, we investigate whether automatically extracted features are correlated to quality aspects of a video. a set of scholarly videos from a mass open online course (mooc) is analyzed regarding audio, linguistic, and visual features. furthermore, a set of cross-modal features is proposed which are derived by combining transcripts, audio, video, and slide content. a user study is conducted to investigate the correlations between the automatically collected features and human ratings of quality aspects of a lecture video. finally, the impact of our features on the knowledge gain of the participants is discussed.\""
        },
        {
            "id": "R38461",
            "label": "Rich Representations of Visual Content for Screen Reader Users",
            "doi": "10.1145/3173574.3173633",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R38460",
                    "label": "Web accessibility for visually impaired users"
                }
            ],
            "abstract": "alt text (short for \"alternative text\") is descriptive text associated with an image in html and other document formats. screen reader technologies speak the alt text aloud to people who are visually impaired. introduced with html 2.0 in 1995, the alt attribute has not evolved despite significant changes in technology over the past two decades. in light of the expanding volume, purpose, and importance of digital imagery, we reflect on how alt text could be supplemented to offer a richer experience of visual content to screen reader users. our contributions include articulating the design space of representations of visual content for screen reader users, prototypes illustrating several points within this design space, and evaluations of several of these new image representations with people who are blind. we close by discussing the implications of our taxonomy, prototypes, and user study findings."
        },
        {
            "id": "R50542",
            "label": "GizMO -- A Customizable Representation Model for Graph-Based Visualizations of Ontologies",
            "doi": "10.1145/3360901.3364431",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R50327",
                    "label": "Ontology and Knowledge Graph Visualizations"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "visualizations can support the development, exploration, communication, and sense-making of ontologies. suitable visualizations, however, are highly dependent on individual use cases and targeted user groups. in this article, we present a methodology that enables customizable definitions for the visual representation of ontologies. the methodology describes visual representations using the owl annotation mechanisms and separates the visual abstraction into two information layers. the first layer describes the graphical appearance of owl constructs. the second layer addresses visual properties for conceptual elements from the ontology. annotation ontologies and a modular architecture enable separation of concerns for individual information layers. furthermore, the methodology ensures the separation between the ontology and its visualization. we showcase the applicability of the methodology by introducing gizmo, a representation model for graph-based visualizations in the form of node-link diagrams. the graph visualization meta ontology (gizmo) provides five annotation object types that address various aspects of the visualization (e.g., spatial positions, viewport zoom factor, and canvas background color). the practical use of the methodology and gizmo is shown using two applications that indicate the variety of achievable ontology visualizations."
        },
        {
            "id": "R51059",
            "label": "Semantic Zooming for Ontology Graph Visualizations",
            "doi": "10.1145/3148011.3148015",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R50327",
                    "label": "Ontology and Knowledge Graph Visualizations"
                },
                {
                    "id": "R50329",
                    "label": "Information and Cognitive Overload"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "visualizations of ontologies, in particular graph visualizations in the form of node-link diagrams, are often used to support ontology development, exploration, verification, and sensemaking. with growing size and complexity of ontology graph visualizations, their represented information tend to become hard to comprehend due to visual clutter and information overload. we present a new approach of semantic zooming for ontology graph visualizations that abstracts and simplifies the underlying graph structure. it separates the comprised information into three layers with discrete levels of detail. the approach is applied to a force-directed graph layout using the vowl notation. the mental map is preserved by using smart expanding and ordering of elements in the layout. navigation and sensemaking are supported by local and global exploration methods, halo visualization, and smooth zooming. the results of a user study confirm an increase in readability, visual clarity, and information clarity of ontology graph visualizations enhanced with our semantic zooming approach."
        },
        {
            "id": "R8345",
            "label": "Decentralised Authoring, Annotations and Notifications for a Read-Write Web with dokieli",
            "doi": "10.1007/978-3-319-60131-1_33",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R8343",
                    "label": "Semantic representation of scholarly communication"
                }
            ],
            "abstract": "abstract while the web was designed as a decentralised environment, individual authors still lack the ability to conveniently author and publish documents, and to engage in social interactions with documents of others in a truly decentralised fashion. we present dokieli , a fully decentralised, browser-based authoring and annotation platform with built-in support for social interactions, through which people retain ownership of and sovereignty over their data. the resulting \u201cliving\u201d documents are interoperable and independent of dokieli since they follow standards and best practices, such as html+rdfa for a fine-grained semantic structure, linked data platform for personal data storage, and linked data notifications for updates. this article describes dokieli\u2019s architecture and implementation, demonstrating advanced document authoring and interaction without a single point of control. such an environment provides the right technological conditions for independent publication of scientific articles, news, and other works that benefit from diverse voices and open interactions. to experience the described features please open this document in your web browser under its canonical uri: http://csarven.ca/dokieli-rww ."
        },
        {
            "id": "R8348",
            "label": "Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles",
            "doi": "10.7717/peerj-cs.132",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R8343",
                    "label": "Semantic representation of scholarly communication"
                }
            ],
            "abstract": "purpose this paper introduces the research articles in simplified html (or rash), which is a web-first format for writing html-based scholarly papers; it is accompanied by the rash framework, a set of tools for interacting with rash-based articles. the paper also presents an evaluation that involved authors and reviewers of rash articles submitted to the save-sd 2015 and save-sd 2016 workshops. design rash has been developed aiming to: be easy to learn and use; share scholarly documents (and embedded semantic annotations) through the web; support its adoption within the existing publishing workflow. findings the evaluation study confirmed that rash is ready to be adopted in workshops, conferences, and journals and can be quickly learnt by researchers who are familiar with html. research limitations the evaluation study also highlighted some issues in the adoption of rash, and in general of html formats, especially by less technically savvy users. moreover, additional tools are needed, e.g., for enabling additional conversions from/to existing formats such as openxml. practical implications rash (and its framework) is another step towards enabling the definition of formal representations of the meaning of the content of an article, facilitating its automatic discovery, enabling its linking to semantically related articles, providing access to data within the article in actionable form, and allowing integration of data between papers. social implications rash addresses the intrinsic needs related to the various users of a scholarly article: researchers (focussing on its content), readers (experiencing new ways for browsing it), citizen scientists (reusing available data formally defined within it through semantic annotations), publishers (using the advantages of new technologies as envisioned by the semantic publishing movement). value rash helps authors to focus on the organisation of their texts, supports them in the task of semantically enriching the content of articles, and leaves all the issues about validation, visualisation, conversion, and semantic data extraction to the various tools developed within its framework."
        },
        {
            "id": "R8356",
            "label": "The anatomy of a nanopublication",
            "doi": "10.3233/ISU-2010-0613",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R8343",
                    "label": "Semantic representation of scholarly communication"
                }
            ],
            "abstract": "as the amount of scholarly communication increases, it is increasingly difficult for specific core scientific statements to be found, connected and curated. additionally, the redundancy of these statements in multiple fora makes it difficult to determine attribution, quality and provenance. to tackle these challenges, the concept web alliance has promoted the notion of nanopublications (core scientific statements with associated context). in this document, we present a model of nanopublications along with a named graph/rdf serialization of the model. importantly, the serialization is defined completely using already existing community-developed technologies. finally, we discuss the importance of aggregating nanopublications and the role that the concept wiki plays in facilitating it."
        },
        {
            "id": "R111420",
            "label": "Empirical Validation of Component-based Software Systems Generation and Evaluation Approaches",
            "doi": "10.19153/cleiej.13.1.6",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "component-based software development needs to formalize a process of generation, evaluation andselection of composite cots-based software systems (ccss), enabling software architects to make earlydecisions; the azimut approach and its associated software tool were proposed to tackle this problem.this article presents an experimental study conduced to compare azimut approach with a systematizedad-hoc approach, regarding generated solutions quality, cost and e\u00aeort. results suggest that: (1) azimutgenerate better quality solutions at lower cost, but not statistically signi\u00afcant, and (2) there is strongevidence showing that the e\u00aeort required is higher than for systematized ad-hoc approach; re-samplingmethods (bootstrap and jackknife) were applied to reinforce these conclusions. also this study serves asa framework for validating approaches, process and tools for generating and evaluating component-basedsoftware systems."
        },
        {
            "id": "R111436",
            "label": "Generalized Haptic Relief Atlas for Rendering Surface Detail",
            "doi": "",
            "research_field": {
                "id": "R136",
                "label": "Graphics"
            },
            "research_problems": [
                {
                    "id": "R111434",
                    "label": "Haptic perception"
                }
            ],
            "abstract": "a fast global approach that encodes haptic surface relief detail using an image-based hybrid rugosity mesostructure atlas (hyrma) shell is presented. it is based on a depth/normal texture computed from surfacedifferences of the same mesh object at different resolutions (a dense one with thousands/millions of triangles, and a highly decimated version). per-face local depth differences are warped from volume space into tangent space, and stored in a sorted relief atlas. next, the atlas is sampled by a vertex/fragment shader pair, unwarped,displacing the pixels at each face of the decimated mesh to render the original mesh detail with quite fewer triangles. we achieve accurate correspondence between visualization of surface detail and perception of itsfine features without compromising rendering framerates, with some loss of detail at mesostructure \u00e2\u20ac\u0153holes\u00e2\u20ac(cid:157)."
        },
        {
            "id": "R175037",
            "label": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
            "doi": "10.1257/aer.100.1.541",
            "research_field": {
                "id": "R302",
                "label": "Economics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\" one lingering puzzle is why voluntary contributions to public goods decline over time in experimental and real-world settings. we show that the decline of cooperation is driven by individual preferences for imperfect conditional cooperation. many people's desire to contribute less than others, rather than changing beliefs of what others will contribute over time or people's heterogeneity in preferences makes voluntary cooperation fragile. universal free riding thus eventually emerges, despite the fact that most people are not selfish. (d12, d 83, h41, z13) \""
        },
        {
            "id": "R44099",
            "label": "Big Data analysis process",
            "doi": "10.1080/20964471.2019.1611175",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R44376",
                    "label": "Big Data infrastructure"
                },
                {
                    "id": "R44378",
                    "label": "Big Earth Data applications"
                },
                {
                    "id": "R44379",
                    "label": "Big Earth Data analysis"
                }
            ],
            "abstract": "abstract big earth data are produced from satellite observations, internet-of-things, model simulations, and other sources. the data embed unprecedented insights and spatiotemporal stamps of relevant earth phenomena for improving our understanding, responding, and addressing challenges of earth sciences and applications. in the past years, new technologies (such as cloud computing, big data and artificial intelligence) have gained momentum in addressing the challenges of using big earth data for scientific studies and geospatial applications historically intractable. this paper reviews the big earth data analytics from several aspects to capture the latest advancements in this fast-growing domain. we first introduce the concepts of big earth data. the architecture, various functionalities, and supporting modules are then reviewed from a generic methodology aspect. analytical methods supporting the functionalities are surveyed and analyzed in the context of different tools. the driven questions are exemplified through cutting-edge earth science researches and applications. a list of challenges and opportunities are proposed for different stakeholders to collaboratively advance big earth data analytics in the near future."
        },
        {
            "id": "R46146",
            "label": "A hybrid of CdS/HCa2Nb3O10 ultrathin nanosheets for promoting photocatalytic hydrogen eVolution",
            "doi": "10.1039/C7DT03027D",
            "research_field": {
                "id": "R122",
                "label": "Chemistry"
            },
            "research_problems": [
                {
                    "id": "R46145",
                    "label": "Niobium-Based Materials for Photocatalytic Solar Fuel Production"
                }
            ],
            "abstract": "a hybrid of cds/hca 2 nb 3 o 10 ultrathin nanosheets with a tough heterointerface was successfully fabricated. efficient interfacial charge transfer from cds to hca 2 nb 3 o 10 nanosheets was achieved to realize the enhanced photocatalytic h 2 evolution activity."
        },
        {
            "id": "R76130",
            "label": "The role of alkali metal cations in the stabilization of guanine quadruplexes: why K+ is the best",
            "doi": "10.1039/c6cp01030j",
            "research_field": {
                "id": "R122",
                "label": "Chemistry"
            },
            "research_problems": [
                {
                    "id": "R76133",
                    "label": "G-Quadruplex Ionic Selectivity"
                }
            ],
            "abstract": "the desolvation and size of monovalent alkali metal ions are of equal importance for the cation affinity of guanine quadruplexes."
        },
        {
            "id": "R76134",
            "label": "The Selectivity for K+versus Na+in DNA Quadruplexes Is Dominated by Relative Free Energies of Hydration:\u00a0 A Thermodynamic Analysis by1H NMR\u2020",
            "doi": "10.1021/bi9620565",
            "research_field": {
                "id": "R122",
                "label": "Chemistry"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we have studied the competition between na+ and k+ for coordination by g quartets using the oligonucleotide d(g3t4g3) as a model system. d(g3t4g3) forms a dimeric foldback structure containing three g quartets in the presence of either nacl or kcl. proton chemical shifts, which are particular to the species of coordinated ion, have been used to monitor the conversion between the sodium and potassium forms under equilibrium conditions. analysis of titration experiments indicates that at least two k+ are coordinated by the three quartets of the dimeric molecule, and perfect fits of the data are obtained for two na+ being displaced by two k+. our results also indicate that the conversion of [d(g3t4g3)]2 from the sodium to the potassium form is associated with a net free energy change (delta g degrees) of -1.7 +/- 0.15 kcal/mol. it has long been suggested that the greater thermal stability of dna quadruplex structures in the presence of k+ is primarily a result of the optimal fit of this ion in the coordination sites formed by g quartets. however, a consideration of the relatively small change in free energy associated with the conversion from the sodium to the potassium form and the relatively large difference between the free energy of hydration for na+ and k+ indicates that this cannot be correct. rather, the preferred coordination of k+ over na+ is actually driven by the greater energetic cost of na+ dehydration with respect to k+ dehydration."
        },
        {
            "id": "R76168",
            "label": "Selective Binding of Monovalent Cations to the Stacking G-Quartet Structure Formed by Guanosine 5\u2018-Monophosphate:\u00a0 A Solid-State NMR Study",
            "doi": "10.1021/ja0302174",
            "research_field": {
                "id": "R122",
                "label": "Chemistry"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"we report a solid-state multinuclear ((23)na, (15)n, (13)c, and (31)p) nmr study on the relative affinity of monovalent cations for a stacking g-quartet structure formed by guanosine 5'-monophosphate (5'-gmp) self-association at ph 8. two major types of cations are bound to the 5'-gmp structure: one at the surface and the other within the channel cavity between two g-quartets. the channel cation is coordinated to eight carbonyl oxygen atoms from the guanine bases, whereas the surface cation is close to the phosphate group and likely to be only partially hydrated. on the basis of solid-state (23)na nmr results from a series of ion titration experiments, we have obtained quantitative thermodynamic parameters concerning the relative cation binding affinity for each of the two major binding sites. for the channel cavity site, the values of the free energy difference (delta g degrees at 25 degrees c) for ion competition between m(+) and na(+) ions are k(+) (-1.9 kcal mol(-1)), nh(4)(+) (-1.8 kcal mol(-1)), rb(+) (-0.3 kcal mol(-1)), and cs(+) (1.8 kcal mol(-1)). for the surface site, the values delta g degrees are k(+) (2.5 kcal mol(-1)), nh(4)(+) (-1.3 kcal mol(-1)), rb(+) (1.1 kcal mol(-1)), and cs(+) (0.9 kcal mol(-1)). solid-state nmr data suggest that the affinity of monovalent cations for the 5'-gmp structure follows the order nh(4)(+) > na(+) > cs(+) > rb(+) > k(+) at the surface site and k(+) > nh(4)(+) > rb(+) > na(+) > cs(+) > li(+) at the channel cavity site. we have found that the cation-induced stability of a 5'-gmp structure is determined only by the affinity of monovalent cations for the channel site and that the binding of monovalent cations to phosphate groups plays no role in 5'-gmp self-ordered structure. we have demonstrated that solid-state (23)na and (15)n nmr can be used simultaneously to provide mutually complementary information about competitive binding between na(+) and nh(4)(+) ions.\""
        },
        {
            "id": "R187558",
            "label": "The Pandemic Penalty: The Gendered Effects of COVID-19 on Scientific Productivity",
            "doi": "10.1177/23780231211006977",
            "research_field": {
                "id": "R354",
                "label": "Sociology"
            },
            "research_problems": [
                {
                    "id": "R5105",
                    "label": "gender"
                },
                {
                    "id": "R175174",
                    "label": "impact of COVID-19 pandemic on academics"
                },
                {
                    "id": "R178510",
                    "label": "research productivity"
                },
                {
                    "id": "R178512",
                    "label": "publication"
                },
                {
                    "id": "R187504",
                    "label": "COVID-19 pandemic"
                },
                {
                    "id": "R187506",
                    "label": "research"
                }
            ],
            "abstract": "academia serves as a valuable case for studying the effects of social forces on workplace productivity, using a concrete measure of output: scholarly papers. many academics, especially women, have experienced unprecedented challenges to scholarly productivity during the coronavirus disease 2019 (covid-19) pandemic. the authors analyze the gender composition of more than 450,000 authorships in the arxiv and biorxiv scholarly preprint repositories from before and during the covid-19 pandemic. this analysis reveals that the underrepresentation of women scientists in the last authorship position necessary for retention and promotion in the sciences is growing more inequitable. the authors find differences between the arxiv and biorxiv repositories in how gender affects first, middle, and sole authorship submission rates before and during the pandemic. a review of existing research and theory outlines potential mechanisms underlying this widening gender gap in productivity during covid-19. the authors aggregate recommendations for institutional change that could ameliorate challenges to women\u2019s productivity during the pandemic and beyond."
        },
        {
            "id": "R49045",
            "label": "Differential climate impacts for policy-relevant limits to global warming: the case of 1.5\u202f\u00b0C and 2\u202f\u00b0C",
            "doi": "10.5194/esd-7-327-2016",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "R48245",
                    "label": "Global Mean Sea Level Rise Projections"
                }
            ],
            "abstract": "abstract. robust appraisals of climate impacts at different levels of global-mean temperature increase are vital to guide assessments of dangerous anthropogenic interference with the climate system. the 2015\\xa0paris agreement includes a two-headed temperature goal: \"holding the increase in the global average temperature to well below 2\\u202f\u00b0c above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5\\u202f\u00b0c\". despite the prominence of these two temperature limits, a comprehensive overview of the differences in climate impacts at these levels is still missing. here we provide an assessment of key impacts of climate change at warming levels of 1.5\\u202f\u00b0c and 2\\u202f\u00b0c, including extreme weather events, water availability, agricultural yields, sea-level rise and risk of coral reef loss. our results reveal substantial differences in impacts between a 1.5\\u202f\u00b0c and 2\\u202f\u00b0c warming that are highly relevant for the assessment of dangerous anthropogenic interference with the climate system. for heat-related extremes, the additional 0.5\\u202f\u00b0c increase in global-mean temperature marks the difference between events at the upper limit of present-day natural variability and a new climate regime, particularly in tropical regions. similarly, this warming difference is likely to be decisive for the future of tropical coral reefs. in a scenario with an end-of-century warming of 2\\u202f\u00b0c, virtually all tropical coral reefs are projected to be at risk of severe degradation due to temperature-induced bleaching from\\xa02050 onwards. this fraction is reduced to about 90\\u202f% in\\xa02050 and projected to decline to 70\\u202f% by\\xa02100 for a 1.5\\u202f\u00b0c scenario. analyses of precipitation-related impacts reveal distinct regional differences and hot-spots of change emerge. regional reduction in median water availability for the mediterranean is found to nearly double from 9\\u202f% to 17\\u202f% between 1.5\\u202f\u00b0c and 2\\u202f\u00b0c, and the projected lengthening of regional dry spells increases from 7\\xa0to 11\\u202f%. projections for agricultural yields differ between crop types as well as world regions. while some (in particular high-latitude) regions may benefit, tropical regions like west africa, south-east asia, as well as central and northern south america are projected to face substantial local yield reductions, particularly for wheat and maize. best estimate sea-level rise projections based on two illustrative scenarios indicate a 50\\u202fcm rise by 2100\\xa0relative to year\\xa02000-levels for a 2\\u202f\u00b0c scenario, and about 10\\xa0cm lower levels for a 1.5\\u202f\u00b0c scenario. in a 1.5\\u202f\u00b0c scenario, the rate of sea-level rise in\\xa02100 would be reduced by about 30\\u202f% compared to a 2\\u202f\u00b0c scenario. our findings highlight the importance of regional differentiation to assess both future climate risks and different vulnerabilities to incremental increases in global-mean temperature. the article provides a consistent and comprehensive assessment of existing projections and a good basis for future work on refining our understanding of the difference between impacts at 1.5\\u202f\u00b0c and 2\\u202f\u00b0c warming."
        },
        {
            "id": "R49056",
            "label": "Global mean sea-level rise in a world agreed upon in Paris",
            "doi": "10.1088/1748-9326/aa9def",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "R48245",
                    "label": "Global Mean Sea Level Rise Projections"
                }
            ],
            "abstract": "although the 2015 paris agreement seeks to hold global average temperature to \u2018well below 2\\u2009\u00b0c above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5\\u2009\u00b0c above pre-industrial levels\u2019, projections of global mean sea-level (gmsl) rise commonly focus on scenarios in which there is a high probability that warming exceeds 1.5\\u2009\u00b0c. using a semi-empirical model, we project gmsl changes between now and 2150 ce under a suite of temperature scenarios that satisfy the paris agreement temperature targets. the projected magnitude and rate of gmsl rise varies among these low emissions scenarios. stabilizing temperature at 1.5\\u2009\u00b0c instead of 2\\u2009\u00b0c above preindustrial reduces gmsl in 2150 ce by 17 cm (90% credible interval: 14\u201321 cm) and reduces peak rates of rise by 1.9 mm yr\u22121 (90% credible interval: 1.4\u20132.6 mm yr\u22121). delaying the year of peak temperature has little long-term influence on gmsl, but does reduce the maximum rate of rise. stabilizing at 2\\u2009\u00b0c in 2080 ce rather than 2030 ce reduces the peak rate by 2.7 mm yr\u22121 (90% credible interval: 2.0\u20134.0 mm yr\u22121)."
        },
        {
            "id": "R49068",
            "label": "21st Century Sea-Level Rise in Line with the Paris Accord",
            "doi": "10.1002/2017ef000688",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "R48245",
                    "label": "Global Mean Sea Level Rise Projections"
                }
            ],
            "abstract": "\"as global average sea\u2010level rises in the early part of this century there is great interest in how much global and local sea level will change in the forthcoming decades. the paris climate agreement's proposed temperature thresholds of 1.5\u00b0c and 2\u00b0c have directed the research community to ask what differences occur in the climate system for these two states. we have developed a novel approach to combine climate model outputs that follow specific temperature pathways to make probabilistic projections of sea\u2010level in a 1.5\u00b0c and 2\u00b0c world. we find median global sea\u2010level (gsl) projections for 1.5\u00b0c and 2\u00b0c temperature pathways of 44 and 50\\u2009cm, respectively. the 90% uncertainty ranges (5%\u201395%) are both around 48\\u2009cm by 2100. in addition, we take an alternative approach to estimate the contribution from ice sheets by using a semi\u2010empirical gsl model. here we find median projections of 58 and 68\\u2009cm for 1.5\u00b0c and 2\u00b0c temperature pathways. the 90% uncertainty ranges are 67 and 82\\u2009cm respectively. regional projections show similar patterns for both temperature pathways, though differences vary between the median projections (2\u201310 cm) and 95th percentile (5\u201320\\u2009cm) for the bulk of oceans using process\u2010based approach and 10\u201315\\u2009cm (median) and 15\u201325\\u2009cm (95th percentile) using the semi\u2010empirical approach.\""
        },
        {
            "id": "R49078",
            "label": "Community climate simulations to assess avoided impacts in 1.5 and 2\u202f\u2009\u00b0C futures",
            "doi": "10.5194/esd-8-827-2017",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "R48245",
                    "label": "Global Mean Sea Level Rise Projections"
                }
            ],
            "abstract": "abstract. the paris agreement of december 2015 stated a\\xa0goal to pursue efforts to keep global temperatures below 1.5\\u202f\u00b0c above preindustrial levels and well below 2\\u202f\u00b0c. the ipcc was charged with assessing climate impacts at these temperature levels, but fully coupled equilibrium climate simulations do not currently exist to inform such assessments. in this study, we produce a\\xa0set of scenarios using a\\xa0simple model designed to achieve long-term 1.5 and 2\\u202f\u00b0c temperatures in a\\xa0stable climate. these scenarios are then used to produce century-scale ensemble simulations using the community earth system model, providing impact-relevant long-term climate data for stabilization pathways at 1.5 and 2\\u202f\u00b0c levels and an overshoot 1.5\\u202f\u00b0c case, which are realized (for the 21st century) in the coupled model and are freely available to the community. here we describe the design of the simulations and a\\xa0brief overview of their impact-relevant climate response. exceedance of historical record temperature occurs with 60\\u202f% greater frequency in the 2\\u202f\u00b0c climate than in a\\xa01.5\\u202f\u00b0c climate aggregated globally, and with twice the frequency in equatorial and arid regions. extreme precipitation intensity is statistically significantly higher in a\\xa02.0\\u202f\u00b0c climate than a\\xa01.5\\u202f\u00b0c climate in some specific regions (but not all). the model exhibits large differences in the arctic, which is ice-free with a\\xa0frequency of 1 in 3\\xa0years in the 2.0\\u202f\u00b0c scenario, and 1 in 40\\xa0years in the 1.5\\u202f\u00b0c scenario. significance of impact differences with respect to multi-model variability is not assessed.\\n"
        },
        {
            "id": "R49096",
            "label": "Stabilization of global temperature at 1.5\u00b0C and 2.0\u00b0C: implications for coastal areas",
            "doi": "10.1098/rsta.2016.0448",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "R48245",
                    "label": "Global Mean Sea Level Rise Projections"
                }
            ],
            "abstract": "the effectiveness of stringent climate stabilization scenarios for coastal areas in terms of reduction of impacts/adaptation needs and wider policy implications has received little attention. here we use the warming acidification and sea level projector earth systems model to calculate large ensembles of global sea-level rise (slr) and ocean ph projections to 2300 for 1.5\u00b0c and 2.0\u00b0c stabilization scenarios, and a reference unmitigated rcp8.5 scenario. the potential consequences of these projections are then considered for global coastal flooding, small islands, deltas, coastal cities and coastal ecology. under both stabilization scenarios, global mean ocean ph (and temperature) stabilize within a century. this implies significant ecosystem impacts are avoided, but detailed quantification is lacking, reflecting scientific uncertainty. by contrast, slr is only slowed and continues to 2300 (and beyond). hence, while coastal impacts due to slr are reduced significantly by climate stabilization, especially after 2100, potential impacts continue to grow for centuries. slr in 2300 under both stabilization scenarios exceeds unmitigated slr in 2100. therefore, adaptation remains essential in densely populated and economically important coastal areas under climate stabilization. given the multiple adaptation steps that this will require, an adaptation pathways approach has merits for coastal areas. \\n this article is part of the theme issue \u2018the paris agreement: understanding the physical and social challenges for a warming world of 1.5\u00b0c above pre-industrial levels\u2019."
        },
        {
            "id": "R49577",
            "label": "From Governance of Innovation to Innovations in Governance",
            "doi": "10.5465/amp.2017.0011",
            "research_field": {
                "id": "R369",
                "label": "Theory, Knowledge and Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the last few decades, many new phenomena, such as globalization and digitization, have changed the world by enabling the connection between organizations and individuals across geographies, institutions, and industries. the resulting complex nexus of interdependent relationships has dramatically altered the way in which firms innovate and govern themselves. as a consequence of this fast-changing world, both innovation and governance become strategic priorities. on the one hand, innovation is a fundamental antecedent of competitive advantage, and hence the ability to innovate determines the fate of firms, regions, and countries. on the other hand, the value from innovation can only be created, captured, and distributed when there exists effective corporate governance. this proposed presenter symposium seeks to examine the tight, yet unexplored, relationships between these two critical strategic dimensions.\" innovation in the boardroom presenter: matthew semadeni; arizona state u. corporate governance fo..."
        },
        {
            "id": "R75084",
            "label": "A Survey on Knowledge Graph Embedding: Approaches, Applications and Benchmarks",
            "doi": "",
            "research_field": {
                "id": "R369",
                "label": "Theory, Knowledge and Science"
            },
            "research_problems": [
                {
                    "id": "R75092",
                    "label": "systematically introduce the existing state-of-the-art approaches and a variety of applications"
                }
            ],
            "abstract": "a knowledge graph (kg), also known as a knowledge base, is a particular kind of network structure in which the node indicates entity and the edge represent relation. however, with the explosion of network volume, the problem of data sparsity that causes large-scale kg systems to calculate and manage difficultly has become more significant. for alleviating the issue, knowledge graph embedding is proposed to embed entities and relations in a kg to a low-, dense and continuous feature space, and endow the yield model with abilities of knowledge inference and fusion. in recent years, many researchers have poured much attention in this approach, and we will systematically introduce the existing state-of-the-art approaches and a variety of applications that benefit from these methods in this paper. in addition, we discuss future prospects for the development of techniques and application trends. specifically, we first introduce the embedding models that only leverage the information of observed triplets in the kg. we illustrate the overall framework and specific idea and compare the advantages and disadvantages of such approaches. next, we introduce the advanced models that utilize additional semantic information to improve the performance of the original methods. we divide the additional information into two categories, including textual descriptions and relation paths. the extension approaches in each category are described, following the same classification criteria as those defined for the triplet fact-based models. we then describe two experiments for comparing the performance of listed methods and mention some broader domain tasks such as question answering, recommender systems, and so forth. finally, we collect several hurdles that need to be overcome and provide a few future research directions for knowledge graph embedding."
        },
        {
            "id": "R78256",
            "label": "How to Assess Visual Communication of Uncertainty? A Systematic Review of Geospatial Uncertainty Visualisation User Studies",
            "doi": "10.1179/1743277414y.0000000099",
            "research_field": {
                "id": "R317",
                "label": "Geographic Information Sciences"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract for decades, uncertainty visualisation has attracted attention in disciplines such as cartography and geographic visualisation, scientific visualisation and information visualisation. most of this research deals with the development of new approaches to depict uncertainty visually; only a small part is concerned with empirical evaluation of such techniques. this systematic review aims to summarize past user studies and describe their characteristics and findings, focusing on the field of geographic visualisation and cartography and thus on displays containing geospatial uncertainty. from a discussion of the main findings, we derive lessons learned and recommendations for future evaluation in the field of uncertainty visualisation. we highlight the importance of user tasks for successful solutions and recommend moving towards task-centered typologies to support systematic evaluation in the field of uncertainty visualisation."
        },
        {
            "id": "R140827",
            "label": "Sub-pixel mineral mapping using EO-1 Hyperion hyperspectral data",
            "doi": "10.5194/isprsarchives-XL-8-455-2014",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R140826",
                    "label": "Sub-pixel mineral investigation using Hyperion data in Rajasthan, India"
                }
            ],
            "abstract": "abstract. this study describes the utility of earth observation (eo)-1 hyperion data for sub-pixel mineral investigation using mixture tuned target constrained interference minimized filter (mttcimf) algorithm in hostile mountainous terrain of rajsamand district of rajasthan, which hosts economic mineralization such as lead, zinc, and copper etc. the study encompasses pre-processing, data reduction, pixel purity index (ppi) and endmember extraction from reflectance image of surface minerals such as illite, montmorillonite, phlogopite, dolomite and chlorite. these endmembers were then assessed with usgs mineral spectral library and lab spectra of rock samples collected from field for spectral inspection. subsequently, mttcimf algorithm was implemented on processed image to obtain mineral distribution map of each detected mineral. a virtual verification method has been adopted to evaluate the classified image, which uses directly image information to evaluate the result and confirm the overall accuracy and kappa coefficient of 68 % and 0.6 respectively. the sub-pixel level mineral information with reasonable accuracy could be a valuable guide to geological and exploration community for expensive ground and/or lab experiments to discover economic deposits. thus, the study demonstrates the feasibility of hyperion data for sub-pixel mineral mapping using mttcimf algorithm with cost and time effective approach.\\n"
        },
        {
            "id": "R4511",
            "label": "Is knowledge and skills sought by employers: A content analysis of Australian is early career online job advertisements",
            "doi": "",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4519",
                    "label": "Finding Information System knowledge, skills, competencies which are required by the Australian employers"
                }
            ],
            "abstract": "\"the purpose of this paper is to develop an understanding of the knowledge, skills and competencies demanded of early career information systems (is) graduates in australia. online job advertisements from 2006 were collected and investigated using content analysis software to determine the frequencies and patterns of occurrence of specific requirements. this analysis reveals a dominant cluster of core is knowledge and competency skills that revolves around is development as the most frequently required category of knowledge (78% of ads) and is strongly associated with: business analysis, systems analysis; management; operations, maintenance & support; communication skills; personal characteristics; computer languages; data & information management; internet, intranet, web applications; and software packages. identification of the core cluster of is knowledge and skills - in demand across a wide variety of jobs - is important to better understand employers' needs for and expectations from is graduates and the implications for education programs. much less prevalent is the second cluster that includes knowledge and skills at a more technical side of is (architecture and infrastructure, operating systems, networks, and security). issues raised include the nature of entry level positions and their role in the preparation of their incumbents for future more senior positions. the findings add an australian perspective to the literature on information systems job ads and should be of value to educators, employers, as well as current and future is professionals.\""
        },
        {
            "id": "R169619",
            "label": "Quantifying and Mapping the Supply of and Demand for Carbon Storage and Sequestration Service from Urban Trees",
            "doi": "10.1371/journal.pone.0136392",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "studies that assess the distribution of benefits provided by ecosystem services across urban areas are increasingly common. nevertheless, current knowledge of both the supply and demand sides of ecosystem services remains limited, leaving a gap in our understanding of balance between ecosystem service supply and demand that restricts our ability to assess and manage these services. the present study seeks to fill this gap by developing and applying an integrated approach to quantifying the supply and demand of a key ecosystem service, carbon storage and sequestration, at the local level. this approach follows three basic steps: (1) quantifying and mapping service supply based upon light detection and ranging (lidar) processing and allometric models, (2) quantifying and mapping demand for carbon sequestration using an indicator based on local anthropogenic co2 emissions, and (3) mapping a supply-to-demand ratio. we illustrate this approach using a portion of the twin cities metropolitan area of minnesota, usa. our results indicate that 1735.69 million kg carbon are stored by urban trees in our study area. annually, 33.43 million kg carbon are sequestered by trees, whereas 3087.60 million kg carbon are emitted by human sources. thus, carbon sequestration service provided by urban trees in the study location play a minor role in combating climate change, offsetting approximately 1% of local anthropogenic carbon emissions per year, although avoided emissions via storage in trees are substantial. our supply-to-demand ratio map provides insight into the balance between carbon sequestration supply in urban trees and demand for such sequestration at the local level, pinpointing critical locations where higher levels of supply and demand exist. such a ratio map could help planners and policy makers to assess and manage the supply of and demand for carbon sequestration."
        },
        {
            "id": "R171570",
            "label": "If there\u00e2\u0080\u0099s a penis, it\u00e2\u0080\u0099s most likely a man: Investigating the social construction of gender using eye tracking",
            "doi": "10.1371/journal.pone.0193616",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in their foundational work on the social construction of gender, kessler and mckenna (1978) investigated the relationship between gender attribution and genital attribution. we used digital reproductions of the original stimuli to replicate their findings in the current social context. to further investigate the underlying decision processes we applied eye tracking. the stimuli shown varied in the composition of gender cues: from those more commonly associated with maleness to associated with femaleness. applying the ethnomethodological approach originally used, participants were asked to decide for each stimulus whether they saw a man or a woman and to indicate subjective confidence with the decision. in line with the original results we found that the genital attribution contributed immensely to the gender attribution. also, male gender was ascribed more often when the penis was present than was female gender when the vulva was shown. eye tracking revealed that overall most dwell time as a proxy for important information was dedicated to the head, chest and genital areas of all the stimuli. total dwell time depended on whether the gender attribution was made in line with the depicted genital, if the genital was a penis. attributing female gender when a penis was present was associated with longer total dwell time, unlike attributing male gender with a vulva shown. this is indicative of higher cognitive effort and more difficulty ignoring the penis as opposed to the vulva. we interpret this finding in context of the persistent male dominance as well as to the socio-cultural understanding of the vulva as a concealed and therefore seemingly absent organ. in summary, we were able to show that the gender attribution is still closely linked to genital attribution when having a binary forced choice task and that the penis is a special cue in this attribution process."
        },
        {
            "id": "R44961",
            "label": "RCT of a psychological intervention for patients with cancer: I. mechanisms of change",
            "doi": "10.1037/0022-006x.75.6.927",
            "research_field": {
                "id": "R343",
                "label": "Psychology"
            },
            "research_problems": [
                {
                    "id": "R44946",
                    "label": "Psychotherapeutic Interventions in Cancer"
                }
            ],
            "abstract": "little is known about the therapeutic processes contributing to efficacy of psychological interventions for patients with cancer. data from a randomized clinical trial yielding robust biobehavioral and health effects (b. l. andersen et al., 2004, 2007) were used to examine associations between process variables, treatment utilization, and outcomes. novel findings emerged. patients were highly satisfied with the treatment, but their higher levels of felt support (group cohesion) covaried with lower distress and fewer symptoms. also, specific treatment strategies were associated with specific outcomes, including lower distress, improved dietary habits, reduced symptomatology, and higher chemotherapy dose intensity. these data provide a comprehensive test of multiple therapeutic processes and mechanisms for biobehavioral change with an intervention including both intensive and maintenance phases."
        },
        {
            "id": "R74401",
            "label": "A rating system that open-data repositories must satisfy to be considered OER: Reusing open data resources in teaching",
            "doi": "10.1109/EDUCON.2017.7943089",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74400",
                    "label": "Open Data"
                },
                {
                    "id": "R109065",
                    "label": "Open Data"
                }
            ],
            "abstract": "the re-use of digital content is an essential part of the knowledge-based economy. the online accessibility of open materials will make possible for teachers, students and self-learners to use them for leisure, studies or work. recent studies have focused on the use or reuse of digital resources with specific reference to the open data field. moreover, open data can be reused \u2014 for both commercial and non-commercial purposes \u2014 for uses such as developing learning and educational content, with full respect for copyright and related rights. this work presents a rating system for open data as oer is proposed. this rating system present a framework to search, download and re-use digital resources by teachers and students. the rating system proposed is built from the ground upwards on open data principles and semantic web technologies. by following open data best practices and linked data principles, open data initiative ensures that data hosted can be fully connected into a web of linked data. this work aims at sharing good practices for administrative/academics/researchers on gathering and disseminating good quality data, using interoperable standards and overcoming legal obstacles. in this way, open data becomes a tool for teaching and educational environments to improve engagement and student learning. designing an open data repository that manages and shares information of different catalogues and an evaluation tool to oer will allow teachers and students to increase educational contents and to improve relationship between open data initiatives and education context."
        },
        {
            "id": "R69721",
            "label": "Measuring completeness as metadata quality metric in Europeana",
            "doi": "10.1109/bigdata.2018.8622487",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R69724",
                    "label": "How to measure the quality of the Europeana records"
                }
            ],
            "abstract": "europeana, the european digital platform for cultural heritage, has a heterogeneous collection of metadata records ingested from more than 3200 data providers. the original nature and context of these records were different. in order to create effective services upon them we should know the strength and weakness or in other words the quality of these data. this paper proposes a method and an open source implementation to measure some structural features of these data, such as completeness, multilinguality, uniqueness, record patterns, to reveal quality issues."
        },
        {
            "id": "R171295",
            "label": "How Many Patients Become Functionally Dependent after a Stroke? A 3-Year Population-Based Study in Joinville, Brazil",
            "doi": "10.1371/journal.pone.0170204",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the decrease in stroke mortality will increase the burden of survivors with functional dependence (fd). the aim of this study was to evaluate how many patients become functionally dependent over 3 years after an incident event in joinville, brazil. the proportion of fd (defined as a modified rankin score 3 to 5) among stroke survivors from the joinville stroke registry was assessed using a validated telephone interview. incidence of fd after stroke in joinville in one year was 23.24 per 100,000 population. the overall proportion of fd among stroke survivors at discharge was 32.7%. of 303 patients with first-ever ischaemic stroke (is), one-third were fd at discharge, and 12%, 9% and 8%, respectively at 1, 2 and 3 years. among 37 patients with haemorrhagic stroke (hs), 38% were dependent at discharge, 16% after 1 and 2 years and 14% after 3. among 27 patients with subarachnoid haemorrhage (sah), 19% were dependent at discharge and 4% from 1 to 3 years. among is subtypes, cardioembolic ones had the worst risk of fd. (rr 19.8; 95% ci: 2.2 to 175.9). our results showed that one-third of stroke survivors have fd during the first year after stroke in brazil. therefore, a city with half a million people might expect 120 new stroke patients with fd each year."
        },
        {
            "id": "R161629",
            "label": "Highly Stretchy Black Gold E-Skin Nanopatches as Highly Sensitive Wearable Biomedical Sensors",
            "doi": "10.1002/aelm.201400063",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R161622",
                    "label": "Development of wearable sensors"
                }
            ],
            "abstract": "s. gong, b. su, k. j. si, z. ma, l. w. yap, p. guo, prof. w. cheng department of chemical engineering monash university clayton , victoria 3800 , australia e-mail: wenlong.cheng@monash.edu s. gong, dr. b. su, k. j. si, z. ma, l. w. yap, p. guo, prof. w. cheng the melbourne centre for nanofabrication clayton , victoria 3800 , australia dr. d. t. h. lai college of engineering and science victoria university victoria 8001 , australia"
        },
        {
            "id": "R146842",
            "label": "Push\u00e2\u0080\u0093Pull Type Non-Fullerene Acceptors for Polymer Solar Cells: Effect of the Donor Core",
            "doi": "10.1021/acsami.7b05417",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "there has been a growing interest in the design and synthesis of non-fullerene acceptors for organic solar cells that may overcome the drawbacks of the traditional fullerene-based acceptors. herein, two novel push-pull (acceptor-donor-acceptor) type small-molecule acceptors, that is, itdi and cdtdi, with indenothiophene and cyclopentadithiophene as the core units and 2-(3-oxo-2,3-dihydroinden-1-ylidene)malononitrile (incn) as the end-capping units, are designed and synthesized for non-fullerene polymer solar cells (pscs). after device optimization, pscs based on itdi exhibit good device performance with a power conversion efficiency (pce) as high as 8.00%, outperforming the cdtdi-based counterparts fabricated under identical condition (2.75% pce). we further discuss the performance of these non-fullerene pscs by correlating the energy level and carrier mobility with the core of non-fullerene acceptors. these results demonstrate that indenothiophene is a promising electron-donating core for high-performance non-fullerene small-molecule acceptors."
        },
        {
            "id": "R168717",
            "label": "LAILAPS-QSM: A RESTful API and JAVA library for semantic query suggestions",
            "doi": "10.1371/journal.pcbi.1006058",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in order to access and filter content of life-science databases, full text search is a widely applied query interface. but its high flexibility and intuitiveness is paid for with potentially imprecise and incomplete query results. to reduce this drawback, query assistance systems suggest those combinations of keywords with the highest potential to match most of the relevant data records. widespread approaches are syntactic query corrections that avoid misspelling and support expansion of words by suffixes and prefixes. synonym expansion approaches apply thesauri, ontologies, and query logs. all need laborious curation and maintenance. furthermore, access to query logs is in general restricted. approaches that infer related queries by their query profile like research field, geographic location, co-authorship, affiliation etc. require user\u2019s registration and its public accessibility that contradict privacy concerns. to overcome these drawbacks, we implemented lailaps-qsm, a machine learning approach that reconstruct possible linguistic contexts of a given keyword query. the context is referred from the text records that are stored in the databases that are going to be queried or extracted for a general purpose query suggestion from pubmed abstracts and uniprot data. the supplied tool suite enables the pre-processing of these text records and the further computation of customized distributed word vectors. the latter are used to suggest alternative keyword queries. an evaluated of the query suggestion quality was done for plant science use cases. locally present experts enable a cost-efficient quality assessment in the categories trait, biological entity, taxonomy, affiliation, and metabolic function which has been performed using ontology term similarities. lailaps-qsm mean information content similarity for 15 representative queries is 0.70, whereas 34% have a score above 0.80. in comparison, the information content similarity for human expert made query suggestions is 0.90. the software is either available as tool set to build and train dedicated query suggestion services or as already trained general purpose restful web service. the service uses open interfaces to be seamless embeddable into database frontends. the java implementation uses highly optimized data structures and streamlined code to provide fast and scalable response for web service calls. the source code of lailaps-qsm is available under gnu general public license version 2 in bitbucket git repository: https://bitbucket.org/ipk_bit_team/bioescorte-suggestion"
        },
        {
            "id": "R182418",
            "label": "SPECTER: Document-level Representation Learning using Citation-informed Transformers",
            "doi": "10.18653/v1/2020.acl-main.207",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R125056",
                    "label": "Representation Learning"
                },
                {
                    "id": "R182427",
                    "label": "Representation Learning of Scientific Literature"
                }
            ],
            "abstract": "representation learning is a critical ingredient for natural language processing systems. recent transformer language models like bert learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. for applications on scientific documents, such as classification and recommendation, accurate embeddings of documents are a necessity. we propose specter, a new method to generate document-level embedding of scientific papers based on pretraining a transformer language model on a powerful signal of document-level relatedness: the citation graph. unlike existing pretrained language models, specter can be easily applied to downstream applications without task-specific fine-tuning. additionally, to encourage further research on document-level models, we introduce scidocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. we show that specter outperforms a variety of competitive baselines on the benchmark."
        },
        {
            "id": "R4693",
            "label": "A Graph Based Tool for Modelling Planning Processes in Building Engineering",
            "doi": "10.1061/40794(179)112",
            "research_field": {
                "id": "R225",
                "label": "Civil Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the planning process of a building is very complex. many participants with different technical disciplines are involved and work on certain tasks. to manage the planning process the project leader has to organize participants, tasks and building data. for this purpose modern information and communication technologies can be used very effi ciently. but these technologies require a formal description of the planning process. within the research project \u201crelation based process modelling of co-operative building planning\u201d we have defined a consistent mathematical process model for planning processes and have developed a prototype implementation of an application for modelling these processes. our project is embedded in the priori ty program 1103 \u201cnetwork-based co-operative planning processes in structural engineering\u201d promoted by the german research foundation (dfg). in this paper we present the mathematical concept of our relational process model and the tool for building up the m odel and checking the structural consistency and correctness."
        },
        {
            "id": "R172842",
            "label": "A capability maturity model for scientific data management",
            "doi": "https://doi.org/10.1002/meet.14504701359",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R172845",
                    "label": "Develop a Capability Model for RDM practices"
                }
            ],
            "abstract": "in this poster, we propose a capability-maturity model (cmm) for scientific data management that includes a set of process areas required for data management, grouped at three levels of organizational capability maturity. the goal is to provide a framework for comparing and improving project and organizational data management practices."
        },
        {
            "id": "R169126",
            "label": "Combined Mitochondrial and Nuclear Markers Revealed a Deep Vicariant History for Leopoldamys neilli, a Cave-Dwelling Rodent of Thailand",
            "doi": "10.1371/journal.pone.0047670",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background historical biogeography and evolutionary processes of cave taxa have been widely studied in temperate regions. however, southeast asian cave ecosystems remain largely unexplored despite their high scientific interest. here we studied the phylogeography of leopoldamys neilli, a cave-dwelling murine rodent living in limestone karsts of thailand, and compared the molecular signature of mitochondrial and nuclear markers. methodology/principal findings we used a large sampling (n\\u200a=\\u200a225) from 28 localities in thailand and a combination of mitochondrial and nuclear markers with various evolutionary rates (two intronic regions and 12 microsatellites). the evolutionary history of l. neilli and the relative role of vicariance and dispersal were investigated using ancestral range reconstruction analysis and approximate bayesian computation (abc). both mitochondrial and nuclear markers support a large-scale population structure of four main groups (west, centre, north and northeast) and a strong finer structure within each of these groups. a deep genealogical divergence among geographically close lineages is observed and denotes a high population fragmentation. our findings suggest that the current phylogeographic pattern of this species results from the fragmentation of a widespread ancestral population and that vicariance has played a significant role in the evolutionary history of l. neilli. these deep vicariant events that occurred during plio-pleistocene are related to the formation of the central plain of thailand. consequently, the western, central, northern and northeastern groups of populations were historically isolated and should be considered as four distinct evolutionarily significant units (esus). conclusions/significance our study confirms the benefit of using several independent genetic markers to obtain a comprehensive and reliable picture of l. neilli evolutionary history at different levels of resolution. the complex genetic structure of leopoldamys neilli is supported by congruent mitochondrial and nuclear markers and has been influenced by the geological history of thailand during plio-pleistocene."
        },
        {
            "id": "R46603",
            "label": "Named entity recognition using a modified pegasos algorithm",
            "doi": "10.1145/2063576.2063960",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46594",
                    "label": "Learning-based Named Entity Recognition and Classification system"
                }
            ],
            "abstract": "in this paper, we describe a named entity recognition using a modified pegasos algorithm for structural svms. we show the modified pegasos algorithm significantly outperformed crfs and the training time for the modified pegasos algorithm is reduced 17-26 times compared to crfs."
        },
        {
            "id": "R110767",
            "label": "Abstractive Meeting Summarization Using Dependency Graph Fusion",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "automatic summarization techniques on meeting conversations developed so far have been primarily extractive, resulting in poor summaries. to improve this, we propose an approach to generate abstractive summaries by fusing important content from several utterances. any meeting is generally comprised of several discussion topic segments. for each topic segment within a meeting conversation, we aim to generate a one sentence summary from the most important utterances using an integer linear programming-based sentence fusion approach. experimental results show that our method can generate more informative summaries than the baselines."
        },
        {
            "id": "R144081",
            "label": "A soluble cryogenic thermometer with high sensitivity based on excited-state configuration transformations",
            "doi": "10.1039/c5cp04400f",
            "research_field": {
                "id": "R130",
                "label": "Physical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R144063",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "cryogenic temperature detection plays an irreplaceable role in exploring nature. developing high sensitivity, accurate, observable and convenient measurements of cryogenic temperature is not only a challenge but also an opportunity for the thermometer field. the small molecule 9-(9,9-dimethyl-9h-fluoren-3yl)-14-phenyl-9,14-dihydrodibenzo[a,c]phenazine (fipac) in 2-methyl-tetrahydrofuran (methf) solution is utilized for the detection of cryogenic temperature with a wide range from 138 k to 343 k. this system possesses significantly high sensitivity at low temperature, which reaches as high as 19.4% k(-1) at 138 k. the temperature-dependent ratio of the dual emission intensity can be fitted as a single-exponential curve as a function of temperature. this single-exponential curve can be explained by the mechanism that the dual emission feature of fipac results from the excited-state configuration transformations upon heating or cooling, which is very different from the previously reported mechanisms. here, our work gives an overall interpretation for this mechanism. therefore, application of fipac as a cryogenic thermometer is experimentally and theoretically feasible."
        },
        {
            "id": "R170704",
            "label": "Singing-Related Activity in Anterior Forebrain of Male Zebra Finches Reflects Courtship Motivation for Target Females",
            "doi": "10.1371/journal.pone.0081725",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"a critical function of singing by male songbirds is to attract a female mate. previous studies have suggested that the anterior forebrain system is involved in this courtship behavior. neural activity in this system, including the striatal area x, is strikingly dependent on the function of male singing. when males sing to attract a female bird rather than while alone, less variable neural activity results in less variable song spectral features, which may be attractive to the female. these characteristics of neural activity and singing thus may reflect a male's motivation for courtship. here, we compared the variability of neural activity and song features between courtship singing directed to a female with whom a male had previously formed a pair-bond or to other females. surprisingly, across all units, there was no clear tendency for a difference in variability of neural activity or song features between courtship of paired females, nonpaired females, or dummy females. however, across the population of recordings, there was a significant relationship between the relative variability of syllable frequency and neural activity: when syllable frequency was less variable to paired than nonpaired females, neural activity was also less variable (and vice-versa). these results show that the lower variability of neural activity and syllable frequency during directed singing is not a binary distinction from undirected singing, but can vary in intensity, possibly related to the relative preference of a male for his singing target.\""
        },
        {
            "id": "R201435",
            "label": "PKG: A Personal Knowledge Graph for Recommendation",
            "doi": "10.1145/3477495.3531671",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "mobile internet users generate personal data on the devices all the time in this era. in this paper, we demonstrate a novel system for integrating the data of a user from different sources into a personal knowledge graph, i.e., pkg. we show how a user's intention can be detected and how the personal data can be aligned and connected by the user behaviors. the constructed pkg allows the system makes reasonable and accurate recommendations for users by a \"neural + symbolic'' approach across different services. our system is shown in https://youtu.be/hwuo8kcdrto."
        },
        {
            "id": "R206387",
            "label": "TLDR: Extreme summarization of scientific documents",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R124827",
                    "label": "Scientific Document Summarization"
                }
            ],
            "abstract": "we introduce tldr generation, a new form of extreme summarization, for scientific papers. tldr generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. to facilitate study on this task, we introduce scitldr, a new multi-target dataset of 5.4k tldrs over 3.2k papers. scitldr contains both author-written and expert-derived tldrs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. we propose catts, a simple yet effective learning strategy for generating tldrs that exploits titles as an auxiliary training signal. catts improves upon strong baselines under both automated metrics and human evaluations. data and code are publicly available at https://github.com/allenai/scitldr."
        },
        {
            "id": "R170650",
            "label": "Multivoxel Patterns in Fusiform Face Area Differentiate Faces by Sex and Race",
            "doi": "10.1371/journal.pone.0069684",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "although prior research suggests that fusiform gyrus represents the sex and race of faces, it remains unclear whether fusiform face area (ffa)\u2013the portion of fusiform gyrus that is functionally-defined by its preferential response to faces\u2013contains such representations. here, we used functional magnetic resonance imaging to evaluate whether ffa represents faces by sex and race. participants were scanned while they categorized the sex and race of unfamiliar black men, black women, white men, and white women. multivariate pattern analysis revealed that multivoxel patterns in ffa\u2013but not other face-selective brain regions, other category-selective brain regions, or early visual cortex\u2013differentiated faces by sex and race. specifically, patterns of voxel-based responses were more similar between individuals of the same sex than between men and women, and between individuals of the same race than between black and white individuals. by showing that ffa represents the sex and race of faces, this research contributes to our emerging understanding of how the human brain perceives individuals from two fundamental social categories."
        },
        {
            "id": "R4432",
            "label": "Evaluating the Demand for Soft Skills in Software Development",
            "doi": "10.1109/mitp.2012.7",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4439",
                    "label": "Finding important Soft Skills in Software Development"
                }
            ],
            "abstract": "\"an analysis of 500 advertisements for it positions focuses on the soft skills mentioned in the ads, revealing which soft skills are in high demand for software development and which ones are neglected despite their importance. our survey indicates that soft skills are in demand in the software industry, but only to a limited extent. this highlights the lack of understanding of the role that soft skills play in an employee's professional ability and performance.\""
        },
        {
            "id": "R169626",
            "label": "Integrated Analysis and Visualization of Group Differences in Structural and Functional Brain Connectivity: Applications in Typical Ageing and Schizophrenia",
            "doi": "10.1371/journal.pone.0137484",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "structural and functional brain connectivity are increasingly used to identify and analyze group differences in studies of brain disease. this study presents methods to analyze uni- and bi-modal brain connectivity and evaluate their ability to identify differences. novel visualizations of significantly different connections comparing multiple metrics are presented. on the global level, \u201cbi-modal comparison plots\u201d show the distribution of uni- and bi-modal group differences and the relationship between structure and function. differences between brain lobes are visualized using \u201cworm plots\u201d. group differences in connections are examined with an existing visualization, the \u201cconnectogram\u201d. these visualizations were evaluated in two proof-of-concept studies: (1) middle-aged versus elderly subjects; and (2) patients with schizophrenia versus controls. each included two measures derived from diffusion weighted images and two from functional magnetic resonance images. the structural measures were minimum cost path between two anatomical regions according to the \u201cstatistical analysis of minimum cost path based structural connectivity\u201d method and the average fractional anisotropy along the fiber. the functional measures were pearson\u2019s correlation and partial correlation of mean regional time series. the relationship between structure and function was similar in both studies. uni-modal group differences varied greatly between connectivity types. group differences were identified in both studies globally, within brain lobes and between regions. in the aging study, minimum cost path was highly effective in identifying group differences on all levels; fractional anisotropy and mean correlation showed smaller differences on the brain lobe and regional levels. in the schizophrenia study, minimum cost path and fractional anisotropy showed differences on the global level and within brain lobes; mean correlation showed small differences on the lobe level. only fractional anisotropy and mean correlation showed regional differences. the presented visualizations were helpful in comparing and evaluating connectivity measures on multiple levels in both studies."
        },
        {
            "id": "R196433",
            "label": "Two-year-olds learn words for absent objects and actions",
            "doi": "10.1111/j.2044-835x.1996.tb00695.x",
            "research_field": {
                "id": "R324",
                "label": "First/Second Language Acquisition"
            },
            "research_problems": [
                {
                    "id": "R196444",
                    "label": "Perceptual pairing effects on word learning"
                }
            ],
            "abstract": "\"two studies of word learning in 24-month-old children are reported, one involving an object word (study 1) and one involving an action word (study 2). in both studies, non-verbal scripts of playing with novel objects/actions in particular ways were established before the child was exposed to any language models. following this pre-training, children heard an experimenter announce her intention to either find an object or perform an action. in the referent condition, children then saw the intended referent (object or action) immediately after hearing the language model. children in the absent referent condition experienced the same non-verbal scripts and language models, but never saw the referent object or action after hearing the language model: at the appropriate juncture in the script they were told that the toy barn in which the target object had been previously located was \u201clocked\u201d, or that the toy character who had previously performed the target action was missing. comparisons with two control conditions indicated that children were able to learn words for a novel object and a novel action in both the referent and absent referent conditions and, moreover, that learning was equivalent in these two conditions. these results show quite clearly that early lexical acquisition does not depend on temporal contiguity between word and referent\u2014or indeed any perceptual pairing between word and referent at all\u2014but rather it relies on children's active understandings of a speaker's referential intentions in particular discourse contexts.\""
        },
        {
            "id": "R74375",
            "label": "Linguistic Frames as Support for Entity Alignment in Knowledge Graphs",
            "doi": "10.1145/3282373.3282415",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R74011",
                    "label": "entity linking"
                }
            ],
            "abstract": "entity alignment is a research topic that has drawn a lot of attention from practitioners and researchers from many different areas in the last years. also referred to as entity resolution or instance matching, it involves aligning different entity representations that refer to the same real-world entity. however, it is still a challenging solution and existing works are based on iterative methods, blocking schemes and learning approaches. among these latter, recent works have been using embedding models, focusing only on structural information. in this paper, we present an approach for entity alignment that enrich entity embeddings with different literal information. to be able to express complex relationships between properties and involving multiple entities we employ framebase schema, which is based on linguistic frames to create complex mappings from external knowledge bases to a unique schema. preliminary experiments showed competitive results to the performance of entity alignment task."
        },
        {
            "id": "R4208",
            "label": "You will be\u00e2\u0080\u00a6: a study of job advertisements to determine employers' requirements for LIS professionals in the UK in 2007",
            "doi": "10.1108/00242530810899595",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4213",
                    "label": "required skills for library and information professionals"
                }
            ],
            "abstract": "purpose the purpose of this paper is to investigate what employers seek when recruiting library and information professionals in the uk and whether professional skills, generic skills or personal qualities are most in demand. design/methodology/approach a content analysis of a sample of 180 advertisements requiring a professional library or information qualification from chartered institute of library and information professional\\'s library\\u2009+\\u2009information gazette over the period may 2006\u20102007. findings the findings reveal that a multitude of skills and qualities are required in the profession. when the results were compared with information national training organisation and library and information management employability skills research, customer service, interpersonal and communication skills, and general computing skills emerged as the requirements most frequently sought by employers. overall, requirements from the generic skills area were most important to employers, but the research also demonstrates that professional skills are still valued. an unanticipated demand for profession related experience was found: this was the single most frequently sought requirement in the advertisements analysed. research limitations/implications although the gazette is the largest source of library and information jobs, it does not provide a complete picture of the employment market. originality/value the paper contributes to debates about the skillsbase of the profession, and raises awareness of the abilities professionals need to cultivate in order to progress through their careers."
        },
        {
            "id": "R138439",
            "label": "Lignin Conversion to Low-Molecular-Weight Aromatics via an Aerobic Oxidation-Hydrolysis Sequence: Comparison of Different Lignin Sources",
            "doi": "10.1021/acssuschemeng.7b03541",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R138426",
                    "label": "Lignin decomposition"
                }
            ],
            "abstract": "diverse lignin samples have been subjected to a catalytic aerobic oxidation process, followed by formic-acid-induced hydrolytic depolymerization. the yield of monomeric aromatic compounds varies depending on the lignin plant source and pretreatment method. the best results are obtained from poplar lignin isolated via a acidolysis pretreatment method, which gives 42 wt% yield of low-molecular-weight aromatics. use of other pretreatment methods and/or use of maple and maize lignins afford yields of aromatics ranging from 3 to 31 wt%. these results establish useful references for the development of improved oxidation/depolymerization protocols."
        },
        {
            "id": "R38841",
            "label": "A Survey of Scholarly Data Visualization",
            "doi": "10.1109/access.2018.2815030",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R69858",
                    "label": "Developing a framework of scholarly data visualization"
                }
            ],
            "abstract": "scholarly information usually contains millions of raw data, such as authors, papers, citations, as well as scholarly networks. with the rapid growth of the digital publishing and harvesting, how to visually present the data efficiently becomes challenging. nowadays, various visualization techniques can be easily applied on scholarly data visualization and visual analysis, which enables scientists to have a better way to represent the structure of scholarly data sets and reveal hidden patterns in the data. in this paper, we first introduce the basic concepts and the collection of scholarly data. then, we provide a comprehensive overview of related data visualization tools, existing techniques, as well as systems for the analyzing volumes of diverse scholarly data. finally, open issues are discussed to pursue new solutions for abundant and complicated scholarly data visualization, as well as techniques, that support a multitude of facets."
        },
        {
            "id": "R34846",
            "label": "A survey of RDF data management systems",
            "doi": "10.1007/s11704-016-5554-y",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "rdf is increasingly being used to encode data for the semantic web and for data exchange. there have been a large number of works that address rdf data management. in this paper we provide an overview of these works."
        },
        {
            "id": "R172777",
            "label": "Automatic acquisition of hyponyms from large text corpora",
            "doi": "",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R172780",
                    "label": "extraction of hyponyms from large text"
                }
            ],
            "abstract": "we describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text. two goals motivate the approach: (i) avoidance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text. we identify a set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest. we describe a method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way. a subset of the acquisition algorithm is implemented and the results are used to augment and critique the structure of a large hand-built thesaurus. extensions and applications to areas such as information retrieval are suggested."
        },
        {
            "id": "R138353",
            "label": "Why is the Bay of Bengal less productive during summer monsoon compared to the Arabian Sea?: THE BAY OF BENGAL LESS PRODUCTIVE DURING SUMMER MONSOON",
            "doi": "10.1029/2002GL016013",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R138352",
                    "label": "Primary production assessment in the Bay of Bengal"
                }
            ],
            "abstract": "the bay of bengal is traditionally considered to be a less productive basin compared to the arabian sea. we explore the reasons for this in the central bay during summer. copious rainfall and river water freshen the upper layers of the bay by 3\u20137 psu during summer, and sst was warmer by 1.5\u20132\u00b0c than in the central arabian sea. this leads to a strongly stratified surface layer. the weaker winds over the bay are unable to erode the strongly stratified surface layer, thereby restricting the turbulent wind\u2010driven vertical mixing to a shallow depth of <20 m. this inhibits introduction of nutrients from below, situated close to the mixed layer bottom, into the upper layers. while advection of nutrients rich water into the euphotic zone makes the arabian sea highly productive, this process is unlikely in the bay of bengal."
        },
        {
            "id": "R139810",
            "label": "Digital heritage interpretation: a conceptual framework",
            "doi": "10.1080/14626268.2018.1511602",
            "research_field": {
                "id": "R417",
                "label": "Cultural History"
            },
            "research_problems": [
                {
                    "id": "R139833",
                    "label": "How to define digital heritage interpretation?"
                }
            ],
            "abstract": "abstract \u2018heritage interpretation\u2019 has always been considered as an effective learning, communication and management tool that increases visitors\u2019 awareness of and empathy to heritage sites or artefacts. yet the definition of \u2018digital heritage interpretation\u2019 is still wide and so far, no significant method and objective are evident within the domain of \u2018digital heritage\u2019 theory and discourse. considering \u2018digital heritage interpretation\u2019 as a process rather than as a tool to present or communicate with end-users, this paper presents a critical application of a theoretical construct ascertained from multiple disciplines and explicates four objectives for a comprehensive interpretive process. a conceptual model is proposed and further developed into a conceptual framework with fifteen considerations. this framework is then implemented and tested on an online platform to assess its impact on end-users\u2019 interpretation level. we believe the presented interpretive framework (predic) will help heritage professionals and media designers to develop interpretive heritage project."
        },
        {
            "id": "R213086",
            "label": "NorNE: Annotating Named Entities for Norwegian",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "this paper presents norne, a manually annotated corpus of named entities which extends the annotation of the existing norwegian dependency treebank. comprising both of the official standards of written norwegian (bokm\u00e5l and nynorsk), the corpus contains around 600,000 tokens and annotates a rich set of entity types including persons, organizations, locations, geo-political entities, products, and events, in addition to a class corresponding to nominals derived from names. we here present details on the annotation effort, guidelines, inter-annotator agreement and an experimental analysis of the corpus using a neural sequence labeling architecture."
        },
        {
            "id": "R169119",
            "label": "Copy Number Variation in Subjects with Major Depressive Disorder Who Attempted Suicide",
            "doi": "10.1371/journal.pone.0046315",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background suicide is one of the top ten leading causes of death in north america and represents a major public health burden, partcularly for people with major depressive disorder (md). many studies have suggested that suicidal behavior runs in families, however, identification of genomic loci that drive this efffect remain to be identified. methodology/principal findings using subjects collected as part of star*d, we genotyped 189 subjects with md with history of a suicide attempt and 1073 subjects with major depressive disorder that had never attempted suicide. copy number variants (cnvs) were called in birdsuite and analyzed in plink. we found a set of cnvs present in the suicide attempter group that were not present in in the non-attempter group including in sntg2 and macrod2 \u2013 two brain expressed genes previously linked to psychopathology; however, these results failed to reach genome-wide signifigance. conclusions these data suggest potential cnvs to be investigated further in relation to suicide attempts in md using large sample sizes."
        },
        {
            "id": "R155157",
            "label": "Petrography, XRD Analysis and Identification of Talc Minerals near Chhabadiya Village of Jahajpur Region, Bhilwara, India through Hyperion Hyperspectral Remote Sensing Data",
            "doi": "10.1109/ICCT46177.2019.8969008",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R155156",
                    "label": "Identification of Talc Minerals using Hyperion Hyperspectral data"
                }
            ],
            "abstract": "the larger synoptic view and contiguous channels arrangement of hyperion hyperspectral remote sensing data enhance the minor spectral identification of earth\u2019s features such as minerals, atmospheric gasses, vegetation and so on. hydrothermal alteration minerals mostly associated with vicinity of geological structural features such as lineaments and fractures. in this study hyperion data is used for identification of hydrothermally altered minerals and alteration facies near chhabadiya village of jahajpur area, bhilwara, rajasthan. there are some minerals such as talc minerals identified through hyperion imagery. the identified talc minerals correlated and evaluated through petrographic analysis, xrd analysis and spectroscopic analysis. the validation of identified minerals completed by field survey, field sample spectra and usgs spectral library talc mineral spectra. the conclusion is that hyperion hyperspectral remote sensing data have capability to identify the minerals, mineral assemblage, alteration minerals and alteration facies."
        },
        {
            "id": "R78263",
            "label": "Evaluating the effect of visually represented geodata uncertainty on decision-making: systematic review, lessons learned, and recommendations",
            "doi": "10.1080/15230406.2015.1089792",
            "research_field": {
                "id": "R317",
                "label": "Geographic Information Sciences"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract for many years, uncertainty visualization has been a topic of research in several disparate fields, particularly in geographical visualization (geovisualization), information visualization, and scientific visualization. multiple techniques have been proposed and implemented to visually depict uncertainty, but their evaluation has received less attention by the research community. in order to understand how uncertainty visualization influences reasoning and decision-making using spatial information in visual displays, this paper presents a comprehensive review of uncertainty visualization assessments from geovisualization and related fields. we systematically analyze characteristics of the studies under review, i.e., number of participants, tasks, evaluation metrics, etc. an extensive summary of findings with respect to the effects measured or the impact of different visualization techniques helps to identify commonalities and differences in the outcome. based on this summary, we derive \u201clessons learned\u201d and provide recommendations for carrying out evaluation of uncertainty visualizations. as a basis for systematic evaluation, we present a categorization of research foci related to evaluating the effects of uncertainty visualization on decision-making. by assigning the studies to categories, we identify gaps in the literature and suggest key research questions for the future. this paper is the second of two reviews on uncertainty visualization. it follows the first that covers the communication of uncertainty, to investigate the effects of uncertainty visualization on reasoning and decision-making."
        },
        {
            "id": "R169830",
            "label": "The Influence of Seasonality and Community-Based Health Worker Provided Counselling on Exclusive Breastfeeding - Findings from a Cross-Sectional Survey in India",
            "doi": "10.1371/journal.pone.0161186",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background exclusive breastfeeding (ebf) during the first six months of life is considered a high impact but low-cost measure for reducing the morbidity and mortality among children. the current study investigated the association of seasonality and frontline worker(flw) provided counselling with practice of ebf in bihar, india. methods we used the \u2018lot quality assurance sampling\u2019 technique to conduct a multi-stage sampling survey in 8 districts of bihar. regarding ebf, mothers of 0\u20135 (completed) months old children were asked if they had given only breastmilk to their children during the previous day, while mothers of 6\u20138 (completed) months old children were inquired about the total duration of ebf. we tested for association between ebf during the previous day with season of interview and ebf for full 6 months with nursing season. we also assessed if receiving counselling on ebf and complementary feeding had any association with relevant ebf indicators. results among the under-6 month old children, 76% received ebf during the previous day, whereas 92% of 6\u20138 (completed) months old children reportedly received ebf for the recommended duration. proportion of 0\u20135 (completed) month old children receiving only breastmilk (during last 24 hours) decreased significantly with increasing age and with change of season from colder to warmer months. odds of receiving only breastmilk during the previous day was significantly higher during the winter months (adjusted odds ratio(aor) = 1.50; 95% ci = 1.37, 1.63) compared to summer. also, the children nursed primarily during the winter season had higher odds of receiving ebf for 6 months (aor = 1.90, 95% ci = 1.43, 2.52) than those with non-winter nursing. receiving flw-counselling was positively associated with breastfeeding exclusively, even after adjusting for seasonality and other covariates (aor = 1.82; 95% ci = 1.67, 1.98). conclusions seasonality is a significant but non-modifiable risk factor for ebf. however, flw-counselling was found to increase practice of ebf irrespective of season. scale-up of flw-counselling services, with emphasis on summer months and mothers of older infants, can potentially reduce the impact of seasonality on ebf."
        },
        {
            "id": "R171305",
            "label": "Medication-related factors associated with health-related quality of life in patients older than 65 years with polypharmacy",
            "doi": "10.1371/journal.pone.0171320",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the current public health framework, the importance of medication as a determinant of citizens\u2019 health has emerged as a factor warranting special attention. most studies investigating the relationship between medication and quality of life do so from the perspective of adherence. however, other medication-related factors identified at home visits may be associated with health-related quality of life. methods and design objective: to describe the relationship between medication-related factors and the health-related quality of life in patients older than 65 years who use multiple medications (polypharmacy). design: cross-sectional descriptive study. setting: primary care. participants: patients older than 65 years who use multiple medications (n = 375). measurements: the main outcome measure was health-related quality of life according to the euroqol-5d instrument. sociodemographic, clinical and medication-related variables were recorded during home interviews. results mean age was 74.72 \u00b1 5.59 years, and 65.5% of our participants were women. the global level of health-related quality of life according to the eq-5d visual analog scale was 59.25 \u00b1 20.92. of the five euroqol dimensions, anxiety/depression and pain were the most frequently reported, while mobility and self-care were the dimensions with the greatest impact on self-reported quality of life. multivariate analysis indicated that functional independence was the factor most strongly associated (\u03b2 = 14.27 p < 0.001) with better health-related quality of life, while illiteracy (\u03b2 = \u221213.58 p < 0.001), depression (\u03b2 = \u221210.13 p < 0.001), social risk (\u03b2 = \u22127.23 p = 0.004) and using more than 10 medicines (\u03b2 = \u22124.85 p = 0.009) were strongly associated with a poorer health-related quality of life. conclusions factors inherent within the patient such as functional incapacity, cognitive impairment and social and emotional problems were the main constraints to quality of life in our study population. the number of medicines taken was negatively related with quality of life."
        },
        {
            "id": "R169904",
            "label": "Stress Marker Signatures in Lesion Mimic Single and Double Mutants Identify a Crucial Leaf Age-Dependent Salicylic Acid Related Defense Signal",
            "doi": "10.1371/journal.pone.0170532",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "plants are exposed to abiotic and biotic stress conditions throughout their lifespans that activates various defense programs. programmed cell death (pcd) is an extreme defense strategy the plant uses to manage unfavorable environments as well as during developmentally induced senescence. here we investigated the role of leaf age on the regulation of defense gene expression in arabidopsis thaliana. two lesion mimic mutants with misregulated cell death, catalase2 (cat2) and defense no death1 (dnd1) were used together with several double mutants to dissect signaling pathways regulating defense gene expression associated with cell death and leaf age. pcd marker genes showed leaf age dependent expression, with the highest expression in old leaves. the salicylic acid (sa) biosynthesis mutant salicylic acid induction deficient2 (sid2) had reduced expression of pcd marker genes in the cat2 sid2 double mutant demonstrating the importance of sa biosynthesis in regulation of defense gene expression. while the auxin- and jasmonic acid (ja)- insensitive auxin resistant1 (axr1) double mutant cat2 axr1 also led to decreased expression of pcd markers; the expression of several marker genes for sa signaling (isochorismate synthase 1, pr1 and pr2) were additionally decreased in cat2 axr1 compared to cat2. the reduced expression of these sa markers genes in cat2 axr1 implicates axr1 as a regulator of sa signaling in addition to its known role in auxin and ja signaling. overall, the current study reinforces the important role of sa signaling in regulation of leaf age-related transcript signatures."
        },
        {
            "id": "R70278",
            "label": "Adaptive behaviour and learning in slime moulds: the role of oscillations",
            "doi": "10.1098/rstb.2019.0757",
            "research_field": {
                "id": "R16",
                "label": "Biophysics"
            },
            "research_problems": [
                {
                    "id": "R70286",
                    "label": "Information processing in Physarum polycephalum"
                }
            ],
            "abstract": "\" \\n the slime mould\\n physarum polycephalum \\n , an aneural organism, uses information from previous experiences to adjust its behaviour, but the mechanisms by which this is accomplished remain unknown. this article examines the possible role of oscillations in learning and memory in slime moulds. slime moulds share surprising similarities with the network of synaptic connections in animal brains. first, their topology derives from a network of interconnected, vein-like tubes in which signalling molecules are transported. second, network motility, which generates slime mould behaviour, is driven by distinct oscillations that organize into spatio-temporal wave patterns. likewise, neural activity in the brain is organized in a variety of oscillations characterized by different frequencies. interestingly, the oscillating networks of slime moulds are not precursors of nervous systems but, rather, an alternative architecture. here, we argue that comparable information-processing operations can be realized on different architectures sharing similar oscillatory properties. after describing learning abilities and oscillatory activities of\\n p. polycephalum \\n , we explore the relation between network oscillations and learning, and evaluate the organism's global architecture with respect to information-processing potential. we hypothesize that, as in the brain, modulation of spontaneous oscillations may sustain learning in slime mould.\\n \\n this article is part of the theme issue \u2018basal cognition: conceptual tools and the view from the single cell\u2019. \""
        },
        {
            "id": "R137470",
            "label": "Fabrication and characterization of Ga-doped ZnO / Si heterojunction nanodiodes",
            "doi": "10.1063/1.4976470",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R137358",
                    "label": "Effect of dopant type on the characteristics of ZnO-based heterojunction diodes"
                }
            ],
            "abstract": "in this study, temperature-dependent electrical properties of n-type ga-doped zno thin film / p-type si nanowire heterojunction diodes were reported. metal-assisted chemical etching (mace) process was performed to fabricate si nanowires. ga-doped zno films were then deposited onto nanowires through chemical bath deposition (cbd) technique to build three-dimensional nanowire-based heterojunction diodes. fabricated devices revealed significant diode characteristics in the temperature range of 220 - 360\\u2005k. electrical measurements shown that diodes had a well-defined rectifying behavior with a good rectification ratio of 103 \u00b13\\u2005v at room temperature. ideality factor (n) were changed from 2.2 to 1.2 with increasing temperature.in this study, temperature-dependent electrical properties of n-type ga-doped zno thin film / p-type si nanowire heterojunction diodes were reported. metal-assisted chemical etching (mace) process was performed to fabricate si nanowires. ga-doped zno films were then deposited onto nanowires through chemical bath deposition (cbd) technique to build three-dimensional nanowire-based heterojunction diodes. fabricated devices revealed significant diode characteristics in the temperature range of 220 - 360\\u2005k. electrical measurements shown that diodes had a well-defined rectifying behavior with a good rectification ratio of 103 \u00b13\\u2005v at room temperature. ideality factor (n) were changed from 2.2 to 1.2 with increasing temperature."
        },
        {
            "id": "R150063",
            "label": "Selected Attractiveness Factors of Academic Conferences as a Product on the International Tourism Market",
            "doi": "10.18778/0867-5856.30.1.13",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "R150068",
                    "label": "Identify selected determinants of attractiveness of international academic conferences"
                }
            ],
            "abstract": "the paper identifies selected determinants of attractiveness of international academic conferences as products on the contemporary international tourism market, especially on the business tourism market. to achieve this aim, methods of analysing the literature, reports, synthesis, along with passive and active observation were used. in addition, a direct survey using a research questionnaire via a website and addressed to participants on an erasmus international week in kaunas was made. some of the most important conditions of the attractiveness of the conference for participants, including transport and information accessibility as well as to the originality of the destination and the leisure program for participants, were indicated. contemporary international academic conferences lasting a few days epitomize multiple products on tourism market. the article is empirical, but it also presents ideas for the development of conferences as attractive products in the contemporary economy of the european union."
        },
        {
            "id": "R169518",
            "label": "Proportions of Staphylococcus aureus and Methicillin-Resistant Staphylococcus aureus in Patients with Surgical Site Infections in Mainland China: A Systematic Review and Meta-Analysis",
            "doi": "10.1371/journal.pone.0116079",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background sufficient details have not been specified for the epidemiological characteristics of staphylococcus aureus (s. aureus) and methicillin-resistant staphylococcus aureus (mrsa) among surgical site infections (ssis) in mainland china. this systematic review aimed to estimate proportions of s. aureus and mrsa in ssis through available published studies. methods pubmed, embase and four chinese electronic databases were searched to identify relevant primary studies published between 2007 and 2012. meta-analysis was conducted on the basis of logit-transformed metric for proportions of s. aureus and mrsa, followed by pre-defined subgroup meta-analysis. random-effects meta-regression was also conducted to explore the impact of possible factors on s. aureus proportions. results 106 studies were included, of which 38 studies involved mrsa. s. aureus accounted for 19.1% (95%ci 17.2-21.0%; i2 = 84.1%) of all isolates in ssis, which was roughly parallel to 18.5% in the united states (us) (p-value = 0.57) but significantly exceeded those calculated through the surveillance system in china (p-value<0.001). in subgroup analysis, s. aureus in patients with thoracic surgery (41.1%, 95%ci 26.3-57.7%; i2 = 74.4%) was more common than in those with gynecologic surgery (20.1%, 95%ci 15.6-25.6%; i2 = 33.0%) or abdominal surgery (13.8%, 95%ci 10.3-18.4%; i2 = 70.0%). similar results were found in meta-regression. mrsa accounted for 41.3% (95%ci 36.5-46.3%; i2 = 64.6%) of s. aureus, significantly lower than that in the us (p-value = 0.001). mrsa was sensitive to vancomycin (522/522) and linezolid (93/94), while 79.9% (95%ci 67.4-88.4%; i2 = 0%) and 92.0% (95%ci 80.2-97.0%; i2 = 0%) of mrsa was resistant to clindamycin and erythromycin respectively. conclusion the overall proportion of s. aureus among ssis in china was similar to that in the us but seemed higher than those reported through the chinese national surveillance system. proportions of s. aureus ssis may vary with different surgery types. commonly seen in ssis, mrsa tended to be highly sensitive to vancomycin and linezolid but mostly resistant to clindamycin and erythromycin."
        },
        {
            "id": "R169660",
            "label": "Learning to Produce Syllabic Speech Sounds via Reward-Modulated Neural Plasticity",
            "doi": "10.1371/journal.pone.0145096",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "at around 7 months of age, human infants begin to reliably produce well-formed syllables containing both consonants and vowels, a behavior called canonical babbling. over subsequent months, the frequency of canonical babbling continues to increase. how the infant\u2019s nervous system supports the acquisition of this ability is unknown. here we present a computational model that combines a spiking neural network, reinforcement-modulated spike-timing-dependent plasticity, and a human-like vocal tract to simulate the acquisition of canonical babbling. like human infants, the model\u2019s frequency of canonical babbling gradually increases. the model is rewarded when it produces a sound that is more auditorily salient than sounds it has previously produced. this is consistent with data from human infants indicating that contingent adult responses shape infant behavior and with data from deaf and tracheostomized infants indicating that hearing, including hearing one\u2019s own vocalizations, is critical for canonical babbling development. reward receipt increases the level of dopamine in the neural network. the neural network contains a reservoir with recurrent connections and two motor neuron groups, one agonist and one antagonist, which control the masseter and orbicularis oris muscles, promoting or inhibiting mouth closure. the model learns to increase the number of salient, syllabic sounds it produces by adjusting the base level of muscle activation and increasing their range of activity. our results support the possibility that through dopamine-modulated spike-timing-dependent plasticity, the motor cortex learns to harness its natural oscillations in activity in order to produce syllabic sounds. it thus suggests that learning to produce rhythmic mouth movements for speech production may be supported by general cortical learning mechanisms. the model makes several testable predictions and has implications for our understanding not only of how syllabic vocalizations develop in infancy but also for our understanding of how they may have evolved."
        },
        {
            "id": "R170104",
            "label": "Preventive behaviors adults report using to avoid catching or spreading influenza, United States, 2015-16 influenza season",
            "doi": "10.1371/journal.pone.0195085",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction influenza vaccination can prevent influenza and potentially serious influenza-related complications. although the single best way to prevent influenza is annual vaccination, everyday preventive actions, including good hygiene, health, dietary, and social habits, might help, too. several preventive measures are recommended, including: avoiding close contact with people who are sick; staying home when sick; covering your mouth and nose when coughing or sneezing; washing your hands often; avoiding touching your eyes, nose, and mouth; and practicing other good health habits like cleaning and disinfecting frequently touched surfaces, getting plenty of sleep, and drinking plenty of fluids. understanding public acceptance and current usage of these preventive behaviors can be useful for planning both seasonal and pandemic influenza prevention campaigns. this study estimated the percentage of adults in the united states who reported practicing preventive behaviors to avoid catching or spreading influenza, and explored associations of reported behaviors with sociodemographic factors. methods we analyzed data from 2015 national internet flu survey, a nationally representative probability-based internet panel survey of the non-institutionalized u.s. population \u226518 years. the self-reported behaviors used to avoid catching or spreading influenza were grouped into four and three non-mutually exclusive subgroups, respectively. weighted proportions were calculated. multivariable logistic regression models were used to calculate adjusted prevalence differences and to determine independent associations between sociodemographic characteristics and preventive behavior subgroups. results common preventive behaviors reported were: 83.2% wash hands often, 80.0% cover coughs and sneezes, 78.2% stay home if sick with a respiratory illness, 64.4% avoid people sick with a respiratory illness, 51.7% use hand sanitizers, 50.2% get treatment as soon as possible, and 49.8% report getting the influenza vaccination. race/ethnicity, gender, age, education, income, region, receipt of influenza vaccination, and household size were associated with use of preventive behaviors after controlling for other factors. conclusion many adults in the united states reported using preventive behaviors to avoid catching or spreading influenza. though vaccination is the most important tool available to prevent influenza, the addition of preventive behaviors might play an effective role in reducing or slowing transmission of influenza and complement prevention efforts."
        },
        {
            "id": "R110811",
            "label": "Anastasis: recovery from the brink of cell death",
            "doi": "",
            "research_field": {
                "id": "R106",
                "label": "Systems Biology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "anastasis is a natural cell recovery phenomenon that rescues cells from the brink of death. programmed cell death such as apoptosis has been traditionally assumed to be an intrinsically irreversible cascade that commits cells to a rapid and massive demolition. interestingly, recent studies have demonstrated recovery of dying cells even at the late stages generally considered immutable. here, we examine the evidence for anastasis in cultured cells and in animals, review findings illuminating the potential mechanisms of action, discuss the challenges of studying anastasis and explore new strategies to uncover the function and regulation of anastasis, the identification of which has wide-ranging physiological, pathological and therapeutic implications."
        },
        {
            "id": "R129595",
            "label": "A Frustratingly Easy Approach for Entity and Relation Extraction",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R116569",
                    "label": "Relation Extraction"
                },
                {
                    "id": "R116714",
                    "label": "Joint Entity and Relation Extraction"
                }
            ],
            "abstract": "end-to-end relation extraction aims to identify named entities and extract relations between them. most recent work models these two subtasks jointly, either by casting them in one structured prediction framework, or performing multi-task learning through shared representations. in this work, we present a simple pipelined approach for entity and relation extraction, and establish the new state-of-the-art on standard benchmarks (ace04, ace05 and scierc), obtaining a 1.7%-2.8% absolute improvement in relation f1 over previous joint models with the same pre-trained encoders. our approach essentially builds on two independent encoders and merely uses the entity model to construct the input for the relation model. through a series of careful examinations, we validate the importance of learning distinct contextual representations for entities and relations, fusing entity information early in the relation model, and incorporating global context. finally, we also present an efficient approximation to our approach which requires only one pass of both entity and relation encoders at inference time, achieving an 8-16\u00d7 speedup with a slight reduction in accuracy."
        },
        {
            "id": "R170091",
            "label": "Determining gestational age and preterm birth in rural Guatemala: A comparison of methods",
            "doi": "10.1371/journal.pone.0193666",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background preterm birth is the leading cause of death among children <5 years of age. accurate determination of prematurity is necessary to provide appropriate neonatal care and guide preventive measures. to estimate the most accurate method to identify infants at risk for adverse outcomes, we assessed the validity of two widely available methods\u2014last menstrual period (lmp) and the new ballard (nb) neonatal assessment\u2014against ultrasound in determining gestational age and preterm birth in highland guatemala. methods pregnant women (n = 188) were recruited with a gestational age <20 weeks and followed until delivery. ultrasound was performed by trained physicians and lmp was collected during recruitment. nb was performed on infants within 96 hours of birth by trained study nurses. lmp and nb accuracy at determining gestational age and identifying prematurity was assessed by comparing them to ultrasound. results by ultrasound, infant mean gestational age at birth was 38.3 weeks (sd = 1.6) with 16% born at less than 37 gestation. lmp was more accurate than nb (mean difference of +0.13 weeks for lmp and +0.61 weeks for nb). however, lmp and nb estimates had low agreement with ultrasound-determined gestational age (lin\u2019s concordance<0.48 for both methods) and preterm birth (\u03ba<0.29 for both methods). by lmp, 18% were judged premature compared with 6% by nb. lmp underestimated gestational age among women presenting later to prenatal care (0.18 weeks for each additional week). gestational age for preterm infants was overestimated by nearly one week using lmp and nearly two weeks using nb. new ballard neuromuscular measurements were more predictive of preterm birth than those measuring physical criteria. conclusion in an indigenous population in highland guatemala, lmp overestimated prematurity by 2% and nb underestimated prematurity by 10% compared with ultrasound estimates. new, simple and accurate methods are needed to identify preterm birth in resource-limited settings worldwide."
        },
        {
            "id": "R132604",
            "label": "Deep Reinforcement Learning with Double Q-learning",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "\\n \\n the popular q-learning algorithm is known to overestimate action values under certain conditions. it was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. in this paper, we answer all these questions affirmatively. in particular, we first show that the recent dqn algorithm, which combines q-learning with a deep neural network, suffers from substantial overestimations in some games in the atari 2600 domain. we then show that the idea behind the double q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. we propose a specific adaptation to the dqn algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.\\n \\n"
        },
        {
            "id": "R135842",
            "label": "Considerations for the Conduction and Interpretation of FAIRness Evaluations",
            "doi": "10.1162/dint_a_00051",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R128971",
                    "label": "Fairness"
                }
            ],
            "abstract": "the fair principles were received with broad acceptance in several scientific communities. however, there is still some degree of uncertainty on how they should be implemented. several self-report questionnaires have been proposed to assess the implementation of the fair principles. moreover, the fairmetrics group released 14, general-purpose maturity for representing fairness. initially, these metrics were conducted as open-answer questionnaires. recently, these metrics have been implemented into a software that can automatically harvest metadata from metadata providers and generate a principle-specific fairness evaluation. with so many different approaches for fairness evaluations, we believe that further clarification on their limitations and advantages, as well as on their interpretation and interplay should be considered."
        },
        {
            "id": "R171751",
            "label": "Trajectories of patients with severe mental illness in two-year contact with Flexible Assertive Community Treatment teams using Routine Outcome Monitoring data: An observational study",
            "doi": "10.1371/journal.pone.0207680",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective using outcome data collected routinely over a continuous two-year treatment period, we wished to distinguish homogeneous subgroups of patients with a severe mental illness whose psychosocial problems followed a similar pattern over time. by identifying the effectiveness of health services for different patient groups, this approach allowed us to identify patients at risk of deterioration and those recovering from their symptoms. methods in total we included 2,660 patients who were in two-year continuous contact with a flexible assertive community treatment team (fact). we collected outcome data on psychosocial functioning, needs for care and quality of life. we performed a latent class growth analysis (lcga). results the lcga identified six homogenous patient subgroups using trajectories of honos scores. on the basis of the patterns of patients\u2019 psychosocial problems over time, we labelled these as follows: 1) stable at a low problem-severity level (n = 709; 27%); 2) stable at a low medium problem-severity level (n = 1,208; 45%); 3) stable at a high medium problem-severity level (n = 528; 20%); 4) stable at a high problem-severity level (n = 116; 4%); 5) amelioration of problems (n = 42; 2%); and 6) deterioration of problems (n = 57; 2%). patients with stable and a high severity of psychosocial problems had more practical and somatic unmet needs than those in other subgroups, and also had the fewest decrease in the number of unmet needs. discussion after linking patient subgroups with clinical features such as the need for care, we found that, over two years, most patients remained relatively stable in terms of psychosocial functioning, but that their unmet needs decreased over time. however, in terms of needs for treatment during two years of contact with a fact team, patients in the subgroup with a stable and high problem-severity level tended to derive little or no benefit."
        },
        {
            "id": "R170318",
            "label": "Recognition Profile of Emotions in Natural and Virtual Faces",
            "doi": "10.1371/journal.pone.0003628",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background computer-generated virtual faces become increasingly realistic including the simulation of emotional expressions. these faces can be used as well-controlled, realistic and dynamic stimuli in emotion research. however, the validity of virtual facial expressions in comparison to natural emotion displays still needs to be shown for the different emotions and different age groups. methodology/principal findings thirty-two healthy volunteers between the age of 20 and 60 rated pictures of natural human faces and faces of virtual characters (avatars) with respect to the expressed emotions: happiness, sadness, anger, fear, disgust, and neutral. results indicate that virtual emotions were recognized comparable to natural ones. recognition differences in virtual and natural faces depended on specific emotions: whereas disgust was difficult to convey with the current avatar technology, virtual sadness and fear achieved better recognition results than natural faces. furthermore, emotion recognition rates decreased for virtual but not natural faces in participants over the age of 40. this specific age effect suggests that media exposure has an influence on emotion recognition. conclusions/significance virtual and natural facial displays of emotion may be equally effective. improved technology (e.g. better modelling of the naso-labial area) may lead to even better results as compared to trained actors. due to the ease with which virtual human faces can be animated and manipulated, validated artificial emotional expressions will be of major relevance in future research and therapeutic applications."
        },
        {
            "id": "R187608",
            "label": "Distinguishing affixoid formations from compounds",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R187615",
                    "label": "distinguishing affixoid formations from compounds"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we study german affixoids, a type of morpheme in between affixes and free stems. several properties have been associated with them \u2013 increased productivity; a bleached semantics, which is often evaluative and/or intensifying and thus of relevance to sentiment analysis; and the existence of a free morpheme counterpart \u2013 but not been validated empirically. in experiments on a new data set that we make available, we put these key assumptions from the morphological literature to the test and show that despite the fact that affixoids generate many low-frequency formations, we can classify these as affixoid or non-affixoid instances with a best f1-score of 74%."
        },
        {
            "id": "R169154",
            "label": "Inferring Predator Behavior from Attack Rates on Prey-Replicas That Differ in Conspicuousness",
            "doi": "10.1371/journal.pone.0048497",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "behavioral ecologists and evolutionary biologists have long studied how predators respond to prey items novel in color and pattern. because a predatory response is influenced by both the predator\u2019s ability to detect the prey and a post-detection behavioral response, variation among prey types in conspicuousness may confound inference about post-prey-detection predator behavior. that is, a relatively high attack rate on a given prey type may result primarily from enhanced conspicuousness and not predators\u2019 direct preference for that prey. few studies, however, account for such variation in conspicuousness. in a field experiment, we measured predation rates on clay replicas of two aposematic forms of the poison dart frog dendrobates pumilio, one novel and one familiar, and two cryptic controls. to ask whether predators prefer or avoid a novel aposematic prey form independently of conspicuousness differences among replicas, we first modeled the visual system of a typical avian predator. then, we used this model to estimate replica contrast against a leaf litter background to test whether variation in contrast alone could explain variation in predator attack rate. we found that absolute predation rates did not differ among color forms. predation rates relative to conspicuousness did, however, deviate significantly from expectation, suggesting that predators do make post-detection decisions to avoid or attack a given prey type. the direction of this deviation from expectation, though, depended on assumptions we made about how avian predators discriminate objects from the visual background. our results show that it is important to account for prey conspicuousness when investigating predator behavior and also that existing models of predator visual systems need to be refined."
        },
        {
            "id": "R170855",
            "label": "No Genetic Tradeoffs between Hygienic Behaviour and Individual Innate Immunity in the Honey Bee, Apis mellifera",
            "doi": "10.1371/journal.pone.0104214",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "many animals have individual and social mechanisms for combating pathogens. animals may exhibit short-term physiological tradeoffs between social and individual immunity because the latter is often energetically costly. genetic tradeoffs between these two traits can also occur if mutations that enhance social immunity diminish individual immunity, or vice versa. physiological tradeoffs between individual and social immunity have been previously documented in insects, but there has been no study of genetic tradeoffs involving these traits. there is strong evidence that some genes influence both innate immunity and behaviour in social insects \u2013 a prerequisite for genetic tradeoffs. quantifying genetic tradeoffs is critical for understanding the evolution of immunity in social insects and for devising effective strategies for breeding disease-resistant pollinator populations. we conducted two experiments to test the hypothesis of a genetic tradeoff between social and individual immunity in the honey bee, apis mellifera. first, we estimated the relative contribution of genetics to individual variation in innate immunity of honey bee workers, as only heritable traits can experience genetic tradeoffs. second, we examined if worker bees with hygienic sisters have reduced individual innate immune response. we genotyped several hundred workers from two colonies and found that patriline genotype does not significantly influence the antimicrobial activity of a worker\u2019s hemolymph. further, we did not find a negative correlation between hygienic behaviour and the average antimicrobial activity of a worker\u2019s hemolymph across 30 honey bee colonies. taken together, our work indicates no genetic tradeoffs between hygienic behaviour and innate immunity in honey bees. our work suggests that using artificial selection to increase hygienic behaviour of honey bee colonies is not expected to concurrently compromise individual innate immunity of worker bees."
        },
        {
            "id": "R135097",
            "label": "Sequential Random Network for Fine-grained Image Classification",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R38570",
                    "label": "Image Classification"
                }
            ],
            "abstract": "deep convolutional neural network (dcnn) and transformer have achieved remarkable successes in image recognition. however, their performance in fine-grained image recognition is still difficult to meet the requirements of actual needs. this paper proposes a sequence random network (srn) to enhance the performance of dcnn. the output of dcnn is one-dimensional features. this onedimensional feature abstractly represents image information, but it does not express well the detailed information of image. to address this issue, we use the proposed srn, which composed of bilstm and several tanh-dropout blocks (called bilstm-tdn), to further process dcnn one-dimensional features for highlighting the detail information of image. after the feature transform by bilstmtdn, the recognition performance has been greatly improved. we conducted the experiments on six fine-grained image datasets. except for fgvc-aircraft, the accuracy of the proposed methods on the other datasets exceeded 99%. experimental results show that bilstm-tdn is far superior to the existing state-of-the-art methods. in addition to dcnn, bilstm-tdn can also be extended to other models, such as transformer."
        },
        {
            "id": "R170441",
            "label": "Fluctuating Environments, Sexual Selection and the Evolution of Flexible Mate Choice in Birds",
            "doi": "10.1371/journal.pone.0032311",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "environmentally-induced fluctuation in the form and strength of natural selection can drive the evolution of morphology, physiology, and behavior. here we test the idea that fluctuating climatic conditions may also influence the process of sexual selection by inducing unexpected reversals in the relative quality or sexual attractiveness of potential breeding partners. although this phenomenon, known as \u2018ecological cross-over\u2019, has been documented in a variety of species, it remains unclear the extent to which it has driven the evolution of major interspecific differences in reproductive behavior. we show that after controlling for potentially influential life history and demographic variables, there are significant positive associations between the variability and predictability of annual climatic cycles and the prevalence of infidelity and divorce within populations of a taxonomically diverse array of socially monogamous birds. our results are consistent with the hypothesis that environmental factors have shaped the evolution of reproductive flexibility and suggest that in the absence of severe time constraints, secondary mate choice behaviors can help prevent, correct, or minimize the negative consequences of ecological cross-overs. our findings also illustrate how a basic evolutionary process like sexual selection is susceptible to the increasing variability and unpredictability of climatic conditions that is resulting from climate change."
        },
        {
            "id": "R110507",
            "label": "Improved Nephron Model for Pressure-Diuresis and Pressure-Natriuresis",
            "doi": "10.1109/BIBE.2016.59",
            "research_field": {
                "id": "R36",
                "label": "Computational Biology"
            },
            "research_problems": [
                {
                    "id": "R110506",
                    "label": "Analyzed the factors for Pressure Diuresis and Pressure Natriuresis"
                }
            ],
            "abstract": "the complexity of the kidney is that mathematical models of renal function depend on the experimental measurements from in-vivo and in-vitro. earlier models of the nephron use the simple mathematical model that was unable to clearly capture the pressure-diuresis and pressure-natriuresis functionality. in this paper, a mathematical model of nephron has been developed with isoporous glomerulus model for better understanding of the functionality of the nephron for salt-sensitive rat(high-salt and low-salt) and salt-resistant. renal blood flow, glomerular filtration, pressure-diuresis and pressure-natriuresis relationships have been explained clearly based on predicted modelling data from the mathematical model of the nephron. the predicted data is compared with the experimental data. the water and sodium excretion are well controlled within the normal limits in the improved isoporous glomerulus nephron model. the predicted data of regulated water and sodium excretion are well fitted with the data collected from experimental studies of the dahl salt sensitive (low salt and high salt) rat and dahl salt resistive rat based on calculation of the mean square error for glomerulur filtration, urine output and sodium excretion."
        },
        {
            "id": "R109222",
            "label": "Targeting key alteration minerals in epithermal deposits in Patagonia, Argentina, using ASTER imagery and principal component analysis",
            "doi": "10.1080/0143116031000152291",
            "research_field": {
                "id": "R146",
                "label": "Geology"
            },
            "research_problems": [
                {
                    "id": "R109221",
                    "label": "Feature extraction from the sensors with limited wavelength range was not accurate and sufficient."
                }
            ],
            "abstract": "\"principal component analysis (pca) is an image processing technique that has been commonly applied to landsat thematic mapper (tm) data to locate hydrothermal alteration zones related to metallic deposits. with the advent of the advanced spaceborne thermal emission and reflection radiometer (aster), a 14-band multispectral sensor operating onboard the earth observation system (eos)-terra satellite, the availability of spectral information in the shortwave infrared (swir) portion of the electromagnetic spectrum has been greatly increased. this allows detailed spectral characterization of surface targets, particularly of those belonging to the groups of minerals with diagnostic spectral features in this wavelength range, including phyllosilicates (\u2018clay\u2019 minerals), sulphates and carbonates, among others. in this study, pca was applied to aster bands covering the swir with the objective of mapping the occurrence of mineral endmembers related to an epithermal gold prospect in patagonia, argentina. the results illustrate aster's ability to provide information on alteration minerals which are valuable for mineral exploration activities and support the role of pca as a very effective and robust image processing technique for that purpose.\""
        },
        {
            "id": "R171019",
            "label": "The Prevalence and Characteristics of Fibromyalgia in the 2012 National Health Interview Survey",
            "doi": "10.1371/journal.pone.0138024",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background most knowledge of fibromyalgia comes from the clinical setting, where healthcare-seeking behavior and selection issues influence study results. the characteristics of fibromyalgia in the general population have not been studied in detail. methods we developed and tested surrogate study specific criteria for fibromyalgia in rheumatology practices using variables from the us national health interview survey (nhis) and the modification (for surveys) of the 2010 american college of rheumatology (acr) preliminary fibromyalgia criteria. the surrogate criteria were applied to the 2012 nhis and identified persons who satisfied criteria from symptom data. the nhis weighted sample of 8446 persons represents 225.7 million us adults. results fibromyalgia was identified in 1.75% (95% ci 1.42, 2.07), or 3.94 million persons. however, 73% of identified cases self-reported a physician\u2019s diagnosis other than fibromyalgia. identified cases had high levels of self-reported pain, non-pain symptoms, comorbidity, psychological distress, medical costs, social security and work disability. caseness was associated with gender, education, ethnicity, citizenship and unhealthy behaviors. demographics, behaviors, and comorbidity were predictive of case status. examination of the surrogate polysymptomatic distress scale (psd) of the 2010 acr criteria found fibromyalgia symptoms extending through the full length of the scale. conclusions persons identified with criteria-based fibromyalgia have severe symptoms, but most (73%) have not received a clinical diagnosis of fibromyalgia. the association of fibromyalgia-like symptoms over the full length of the psd scale with physiological as well as mental stressors suggests psd may be a universal response variable rather than one restricted to fibromyalgia."
        },
        {
            "id": "R164425",
            "label": "Research Data Management: A proposed framework to boost research in Higher Educational Institutes.",
            "doi": "10.29173/iq12",
            "research_field": {
                "id": "R112120",
                "label": "Digital Libraries"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper attempts to present a brief overview of several research data management (rdm) issues and a detailed literature review regarding the rdm aspects adopted in libraries globally. furthermore, it will describe several tendencies concerning the management of repository tools for research data, as well as the challenges in implementing the rdm. the proper planned training and skill development for all stakeholders by mentors to train both staff and users are some of the issues that need to be considered to enhance the rdm process. an effort will be also made to present the suitable policies and workflows along with the adoption of best practices in rdm, so as to boost the research process in an organisation. this study will showcase the implementation of rdm processes in the higher educational institute of india, referring particularly to the central library @ nit rourkela in odisha, india with a proposed framework. finally, this study will also propose an area of opportunities that can boost research activities in the institute."
        },
        {
            "id": "R170409",
            "label": "What Factors Influence Smoking Prevalence and Smoke Free Policy Enactment across the European Union Member States",
            "doi": "10.1371/journal.pone.0023889",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background smoking prevention should be a primary public health priority for all governments, and effective preventive policies have been identified for decades. the heterogeneity of smoking prevalence between european union (eu) member states therefore reflects, at least in part, a failure by governments to prioritise public health over tobacco industry or possibly other financial interests, and hence potentially government corruption. the aims of this study were to test the hypothesis that smoking prevalence is higher in countries with high levels of public sector corruption, and explore the ecological association between smoking prevalence and a range of other national characteristics in current eu member states. methods ecological data from 27 eu member states were used to estimate univariate and multivariate correlations between smoking prevalence and the transparency international corruption perceptions index, and a range of other national characteristics including economic development, social inclusion, quality of life and importance of religion. we also explored the association between the corruption perceptions index and measures of the extent to which smoke-free policies have been enacted and are enforced. results in univariate analysis, smoking prevalence was significantly higher in countries with higher scores for corruption, material deprivation, and gender inequality; and lower in countries with higher per capita gross domestic product, social spending, life satisfaction and human development scores. in multivariate analysis, only the corruption perception index was independently related to smoking prevalence. exposure to tobacco smoke in the workplace was also correlated with corruption, independently from smoking prevalence, but not with the measures of national smoke-free policy implementation. conclusions corruption appears to be an important risk factor for failure of national tobacco control activity in eu countries, and the extent to which key tobacco control policies have been implemented. further research is needed to assess the causal relationships involved."
        },
        {
            "id": "R211438",
            "label": "Tackling the requirements jigsaw puzzle",
            "doi": "10.1109/re.2014.6912265",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a key challenge during stakeholder meetings is that of presenting the requirements and conflicts to stakeholders in a way that fosters co-responsibility and co-ownership regarding the conflicts and their resolution. in this paper, we propose a jigsaw puzzle metaphor to make identified conflicts explicit as well as an associated method to utilise this metaphor during stakeholder meetings. the metaphor provides an easy to understand language for stakeholders from otherwise diverse backgrounds. it enables stakeholders to work with a well-understood concept - that of building a system from misshapen pieces. these characteristics foster communication and team work, which improve commitment of stakeholders in co-authoring of requirements and co-responsibility in conflict handling. the gamification of conflict resolution also promotes a relaxed environment, which in turn improves team cooperation and creativity. our experience in three user studies demonstrates that the jigsaw puzzle indeed improves such co-responsibility and co-ownership when compared with typical text-based representations of requirements."
        },
        {
            "id": "R211394",
            "label": "Managing security requirements patterns using feature diagram hierarchies",
            "doi": "10.1109/re.2014.6912261",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "security requirements patterns represent reusable security practices that software engineers can apply to improve security in their system. reusing best practices that others have employed could have a number of benefits, such as decreasing the time spent in the requirements elicitation process or improving the quality of the product by reducing product failure risk. pattern selection can be difficult due to the diversity of applicable patterns from which an analyst has to choose. the challenge is that identifying the most appropriate pattern for a situation can be cumbersome and time-consuming. we propose a new method that combines an inquiry-cycle based approach with the feature diagram notation to review only relevant patterns and quickly select the most appropriate patterns for the situation. similar to patterns themselves, our approach captures expert knowledge to relate patterns based on decisions made by the pattern user. the resulting pattern hierarchies allow users to be guided through these decisions by questions, which introduce related patterns in order to help the pattern user select the most appropriate patterns for their situation, thus resulting in better requirement generation. we evaluate our approach using access control patterns in a pattern user study."
        },
        {
            "id": "R194905",
            "label": "Arithmetic Semantics of Feature and Goal Models for Adaptive Cyber-Physical Systems",
            "doi": "10.1109/re.2019.00034",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "many cyber-physical systems (cpss) today are self-adaptive, in order to handle frequent changes in environmental conditions and requirements. in cpss, goal-based reasoning is often used to include stakeholder and social concerns in decision making during design and runtime adaptation activities. to better support some of these activities, arithmetic semantics for goal models were proposed to enable the generation of mathematical functions usable by systems. however, goal models often allow invalid combinations of alternatives, which can be prevented by companion feature models. in this paper, to enable the generation of valid and optimal configurations for adaptive cpss, we propose new arithmetic semantics for feature models that enable their transformations to mathematical functions (in several programming languages) further restricting the ones generated from goal models. the composition of feature and goal functions results in a smaller design space, leading to fewer but valid solutions that can be generated (e.g., through optimization) and used in simulations and running adaptive cpss with social concerns. finally, a simulation model in sysml is proposed in this paper to demonstrate the feasibility and usefulness of this composition."
        },
        {
            "id": "R169604",
            "label": "Psychosocial Care Needs of Melanoma Survivors: Are They Being Met?",
            "doi": "10.1371/journal.pone.0132754",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "patients who have survived malignant melanoma for more than five years may lack the opportunity to talk about their burden. as a consequence their psychosocial care needs remain undetected and available supportive interventions may not be utilised. therefore, the psychosocial burden of this patient group needs to be assessed using specific screening instruments. the aim of this study was to investigate the psychosocial burden of long-term melanoma survivors, their psychosocial care needs and the determinants of these needs. we wanted to find out if the use of professional support corresponds to the care needs defined by experts. using the cancer registry of rhineland-palatinate, melanoma patients diagnosed at least 5 years before the survey were contacted by physicians. n = 689 former patients completed the hornheide questionnaire (short form hq-s) to identify psychosocial support need (scale cut off \u2265 16 or item-based cut-off score) and the potential psychosocial determinants of these needs. additionally, they were asked about their utilisation of the professional support system. more than one third (36%) of them was in need for professional psychosocial support. the highest burden scores concerned worry about tumour progression. younger age (< 50), higher general fatigue, higher symptom burden, lower general health, negative social interactions and unfulfilled information needs were significant predictors of the need for psychosocial intervention. related to the percentage of survivors identified as \u2018in need\u2019, the professional support system was underused. further studies should investigate whether using the hq-s to routinely identify burdened melanoma patients could lead to better fulfilment of their intervention needs, ultimately enhancing health-related quality of life."
        },
        {
            "id": "R169075",
            "label": "Is Coarse-to-Fine Strategy Sensitive to Normal Aging?",
            "doi": "10.1371/journal.pone.0038493",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "theories on visual perception agree that visual recognition begins with global analysis and ends with detailed analysis. different results from neurophysiological, computational, and behavioral studies all indicate that the totality of visual information is not immediately conveyed, but that information analysis follows a predominantly coarse-to-fine processing sequence (low spatial frequencies are extracted first, followed by high spatial frequencies). we tested whether such processing continues to occur in normally aging subjects. young and aged participants performed a categorization task (indoor vs. outdoor scenes), using dynamic natural scene stimuli, in which they resorted to either a coarse-to-fine (ctf) sequence or a reverse fine-to-coarse sequence (ftc). the results show that young participants categorized ctf sequences more quickly than ftc sequences. however, sequence processing interacts with semantic category only for aged participants. the present data support the notion that ctf categorization is effective even in aged participants, but is constrained by the spatial features of the scenes, thus highlighting new perspectives in visual models."
        },
        {
            "id": "R46639",
            "label": "Named entity recognition in query",
            "doi": "10.1145/1571941.1571989",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46594",
                    "label": "Learning-based Named Entity Recognition and Classification system"
                }
            ],
            "abstract": "this paper addresses the problem of named entity recognition in query (nerq), which involves detection of the named entity in a given query and classification of the named entity into predefined classes. nerq is potentially useful in many applications in web search. the paper proposes taking a probabilistic approach to the task using query log data and latent dirichlet allocation. we consider contexts of a named entity (i.e., the remainders of the named entity in queries) as words of a document, and classes of the named entity as topics. the topic model is constructed by a novel and general learning method referred to as ws-lda (weakly supervised latent dirichlet allocation), which employs weakly supervised learning (rather than unsupervised learning) using partially labeled seed entities. experimental results show that the proposed method based on ws-lda can accurately perform nerq, and outperform the baseline methods."
        },
        {
            "id": "R169633",
            "label": "Individual Effect Modifiers of Dust Exposure Effect on Cardiovascular Morbidity",
            "doi": "10.1371/journal.pone.0137714",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"background high concentrations of particulate matter (pm) air pollution have been associated with death and hospital admissions due to cardiovascular morbidity. however, it is not clear a) whether high levels of non-anthropogenic pm from dust storms constitute a health risk; and b) whether these health risks are exacerbated in a particular demographic. methods this study comprised all patients above 18 years old admitted to soroka university medical center (1000 bed tertiary hospital, be\u2019er- sheva, israel, 2001\u20132010) with a primary diagnosis of acute coronary syndrome (acs). data on meteorological parameters and pm10 (particulate matter <10 \u03bcm in aerodiameter) were obtained from monitoring stations in the city of be'er-sheva. data were analyzed using a case crossover analysis to examine the effect of dust exposure on hospitalization due to acs and the interaction with co-morbidities and demographic factors. results there were 16,734 hospitalizations due to acs during the study period. the estimated odds of hospitalization due to acs was significantly associated with pm10 during non dust storm days at the same day of the exposure (lag0); or = 1.014 (95%ci 1.001\u20131.027) for a 10 \u03bcg/m3 increase, while a delayed response (lag1) was found during the dust storm days; or = 1.007 (95%ci 1.002\u20131.012). the effect size for the dust exposure association was larger for older (above the age of 65), female or bedouin patients. conclusions exposure to non-anthropogenic pm is associated with cardiovascular morbidity. health risk associated dust exposure is gender and age specific with older women and bedouin patients being the most vulnerable groups.\""
        },
        {
            "id": "R195551",
            "label": "Feedback Gathering from an Industrial Point of View",
            "doi": "10.1109/re.2017.9",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "feedback communication channels allow end-users to express their needs, which can be considered in software development and evolution. although feedback gathering and analysis have been identified as an important topic and several researchers have started their investigation, information is scarce on how software companies currently elicit end-user feedback. in this study, we explore the experiences of software companies with respect to feedback gathering. the results of a case study and online survey indicate two sides of the same coin: on the one hand, most software companies are aware of the relevance of end-user feedback for software evolution and provide feedback channels, which allow end-users to communicate their needs and problems. on the other hand, the quantity and quality of the feedback received varies. we conclude that software companies still do not fully exploit the potential of end-user feedback for software development and evolution."
        },
        {
            "id": "R4415",
            "label": "Changing patterns in IT skill sets 1988-2003",
            "doi": "10.1145/1017114.1017121",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4422",
                    "label": "finding trends in required job skills for IT jobs during 17 years"
                }
            ],
            "abstract": "this paper examines trends in required job skills for it professionals. through an empirical study of classified job advertising for it professionals over the past 17 years, we evaluate whether the observed trends support earlier predictions offered by researchers who sought to anticipate future job and skill demands (leitheiser 1992; trauth, farwell, &amp; lee 1993). many of the findings are consistent with previous studies and support the notion that employers are seeking an ever-increasing number and variety of skill sets from the new hires. in addition, we found ongoing evidence of a recruitment gap (todd, mckeen &amp; gallupe 1995) where, despite many firms\\' stated emphasis on well-rounded individuals with business knowledge and strong \"soft skills,\" the job advertising aspect of the recruiting process continues to focus on \"hard skills\". the changing demand patterns for it professionals necessitate life-long learning skills not only for it practitioners but also for the academics who teach them."
        },
        {
            "id": "R171688",
            "label": "Barriers and enablers to walking in individuals with intermittent claudication: A systematic review to conceptualize a relevant and patient-centered program",
            "doi": "10.1371/journal.pone.0201095",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background walking limitation in patients with peripheral arterial disease (pad) and intermittent claudication (ic) contributes to poorer disease outcomes. identifying and examining barriers to walking may be an important step in developing a comprehensive patient-centered self-management intervention to promote walking in this population. aim to systematically review the literature regarding barriers and enablers to walking exercise in individuals with ic. methods a systematic review was conducted utilizing integrative review methodology. five electronic databases and the reference lists of relevant studies were searched. findings were categorized into personal, walking activity related, and environmental barriers and enablers using a social cognitive framework. results eighteen studies including quantitative (n = 12), qualitative (n = 5), and mixed method (n = 1) designs, and reporting data from a total of 4376 patients with ic, were included in the review. the most frequently reported barriers to engaging in walking were comorbid health concerns, walking induced pain, lack of knowledge (e.g. about the disease pathology and walking recommendations), and poor walking capacity. the most frequently reported enablers were cognitive coping strategies, good support systems, and receiving specific instructions to walk. findings suggest additionally that wider behavioral and environmental obstacles should be addressed in a patient-centered self-management intervention. conclusions this review has identified multidimensional factors influencing walking in patients with ic. within the social cognitive framework, these factors fall within patient level factors (e.g. comorbid health concerns), walking related factors (e.g. claudication pain), and environmental factors (e.g. support systems). these factors are worth considering when developing self-management interventions to increase walking in patients with ic. systematic review registration crd42018070418."
        },
        {
            "id": "R171593",
            "label": "Factors associated with sexual and reproductive health stigma among adolescent girls in Ghana",
            "doi": "10.1371/journal.pone.0195163",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective using our previously developed and tested adolescent sexual and reproductive health (srh) stigma scale, we investigated factors associated with perceived srh stigma among adolescent girls in ghana. methods we drew upon data from our survey study of 1,063 females 15-24yrs recruited from community- and clinic-based sites in two ghanaian cities. our adolescent srh stigma scale comprised 20 items and 3 sub-scales (internalized, enacted, lay attitudes) to measure stigma occurring with sexual activity, contraceptive use, pregnancy, abortion and family planning service use. we assessed relationships between a comprehensive set of demographic, health and social factors and srh stigma with multi-level multivariable linear regression models. results in unadjusted bivariate analyses, compared to their counterparts, srh stigma scores were higher among girls who were younger, accra residents, muslim, still in/dropped out of secondary school, unemployed, reporting excellent/very good health, not in a relationship, not sexually experienced, never received family planning services, never used contraception, but had been pregnant (all p-values <0.05). in multivariable models, higher srh stigma scores were associated with history of pregnancy (\u03b2 = 1.53, ci = 0.51,2.56) and excellent/very good self-rated health (\u03b2 = 0.89, ci = 0.20,1.58), while lower stigma scores were associated with older age (\u03b2 = -0.17, 95%ci = -0.24,-0.09), higher educational attainment (\u03b2 = -1.22, ci = -1.82,-0.63), and sexual intercourse experience (\u03b2 = -1.32, ci = -2.10,-0.55). conclusions findings provide insight into factors contributing to srh stigma among this young ghanaian female sample. further research disentangling the complex interrelationships between srh stigma, health, and social context is needed to guide multi-level interventions to address srh stigma and its causes and consequences for adolescents worldwide."
        },
        {
            "id": "R171670",
            "label": "Can we monitor adaptation of juvenile goats to a new social environment through continuous qualitative behaviour assessment?",
            "doi": "10.1371/journal.pone.0200165",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we aimed to verify whether continuous qualitative behaviour assessment (10 observers used a list of six qualitative descriptors) paired with temporal dominant behavioural expression (the same observers were asked to select the dominant descriptor and to score its intensity level) was able to monitor fluctuations of animal behaviour expression over time. we applied these techniques to three groups of juvenile goats either weaned (group c), or un-weaned (groups wom and wm). each animal was separated from its group, moved to group c and tested for 30 min either while their mothers were at pasture, or while their mothers were in an adjacent pen (group wom and wm, respectively). animals from group c were separated from their group and immediately reintroduced to it. tdbe duration and score of each descriptor of behavioural expression were able to detect differences among groups but were unable to describe how the behaviour of the goats changed as the time progressed. tdbe curves described the evolution of each behavioural expression of each animal over time but were unable to detect differences among groups. the \u03c72 test conducted on peaks of dominance, albeit displaying the variations of the behavioural expression over time and allowing the assessment of differences among groups, focussed on occurrences of higher agreement between observers while neglecting most of the information concerning the descriptors above the level of significance. conversely, based on mixed analysis of variance with the fixed effects of group, test interval and group x test interval (animal nested into group and observer were considered to be random), most of the descriptors were able to discriminate the three experimental groups while preserving the information on the fluctuations of the behavioural expression of the animals during the test."
        },
        {
            "id": "R189382",
            "label": "Facts That Matter",
            "doi": "10.18653/v1/d18-1129",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R189400",
                    "label": "Triple Extraction"
                }
            ],
            "abstract": "this work introduces fact salience: the task of generating a machine-readable representation of the most prominent information in a text document as a set of facts. we also present salie, the first fact salience system. salie is unsupervised and knowledge agnostic, based on open information extraction to detect facts in natural language text, pagerank to determine their relevance, and clustering to promote diversity. we compare salie with several baselines (including positional, standard for saliency tasks), and in an extrinsic evaluation, with state-of-the-art automatic text summarizers. salie outperforms baselines and text summarizers showing that facts are an effective way to compress information."
        },
        {
            "id": "R186158",
            "label": "Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R186161",
                    "label": "Inference performance characterization of neuro-symbolic models"
                }
            ],
            "abstract": "neuro-symbolic artificial intelligence is a novel area of ai research which seeks to combine traditional rules-based ai approaches with modern deep learning techniques. neurosymbolic models have already demonstrated the capability to outperform state-of-the-art deep learning models in domains such as image and video reasoning. they have also been shown to obtain high accuracy with significantly less training data than traditional models. due to the recency of the field\u2019s emergence and relative sparsity of published results, the performance characteristics of these models are not well understood. in this paper, we describe and analyze the performance characteristics of three recent neuro-symbolic models. we find that symbolic models have less potential parallelism than traditional neural models due to complex control flow and low-operational-intensity operations, such as scalar multiplication and tensor addition. however, the neural aspect of computation dominates the symbolic part in cases where they are clearly separable. we also find that data movement poses a potential bottleneck, as it does in many ml workloads."
        },
        {
            "id": "R131136",
            "label": "Look, Listen and Learn",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R122330",
                    "label": "Audio Classification"
                }
            ],
            "abstract": "we consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? there is a valuable, but so far untapped, source of information contained in the video itself \u2013 the correspondence between the visual and the audio streams, and we introduce a novel \u201caudio-visual correspondence\u201d learning task that makes use of this. training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. these features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art selfsupervised approaches on imagenet classification. we also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks."
        },
        {
            "id": "R170258",
            "label": "Coronin 1 Regulates Cognition and Behavior through Modulation of cAMP/Protein Kinase A Signaling",
            "doi": "10.1371/journal.pbio.1001820",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the evolutionarily conserved protein coronin 1 is needed for activating the cyclic amp signaling pathway in the brain and is important for cognition and behavior."
        },
        {
            "id": "R192123",
            "label": "Tracking Urban Expansion Using Random Forests for the Classification of Landsat Imagery (1986\u00e2\u0080\u00932015) and Predicting Urban/Built-Up Areas for 2025: A Study of the Kumasi Metropolis, Ghana",
            "doi": "10.3390/land10010044",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R191805",
                    "label": "Land use and cover change (LUCC)\t\t\t\t\t"
                }
            ],
            "abstract": "kumasi is a nodal city and functions as the administrative and economic capital of the ashanti region in ghana. rapid urbanization has been experienced inducing the transformation of various land use land cover (lulc) types into urban/built-up areas in kumasi. this paper aims at tracking spatio-temporal lulc changes utilizing landsat imagery from 1986, 2013 and 2015 of kumasi. the unique contribution of this research is its focus on urban expansion analysis and the utilization of random forest (rf) classifier for satellite image classification. change detection, urban land modelling and urban expansion in the sub-metropolitan zones, buffers, density decay curve and correlation analysis were methodologies adopted for our study. the classifier yielded better accuracy compared to earlier works in ghana. the evaluation of lulc changes indicated that urban/built-up areas are continually increasing at the expense of agricultural and forestlands. the urban/built-up areas occupied 4622.49 hectares (ha) (23.78%), 13,447.50 ha (69.18%) and 14,004.60 ha (72.05%) in 1986, 2013 and 2015, respectively of the 19,438 ha area of kumasi. projection indicated that urban/built-up areas will occupy 15,490 ha (79.70%) in 2025. the urban expansion was statistically significant. the results revealed the importance of spatial modeling for environmental management and city planning."
        },
        {
            "id": "R170194",
            "label": "A quantile regression forest based method to predict drug response and assess prediction reliability",
            "doi": "10.1371/journal.pone.0205155",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "drug response prediction is a critical step for personalized treatment of cancer patients and ultimately leads to precision medicine. a lot of machine-learning based methods have been proposed to predict drug response from different types of genomic data. however, currently available methods could only give a \u201cpoint\u201d prediction of drug response value but fail to provide the reliability and distribution of the prediction, which are of equal interest in clinical practice. in this paper, we proposed a method based on quantile regression forest and applied it to the ccle dataset. through the out-of-bag validation, our method achieved much higher prediction accuracy of drug response than other available tools. the assessment of prediction reliability by prediction intervals and its significance in personalized medicine were illustrated by several examples. functional analysis of selected drug response associated genes showed that the proposed method achieves more biologically plausible results."
        },
        {
            "id": "R170780",
            "label": "A Meta-Analysis of Self-Reported Achievement Goals and Nonself-Report Performance across Three Achievement Domains (Work, Sports, and Education)",
            "doi": "10.1371/journal.pone.0093594",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "during the past three decades, the achievement goal approach to achievement motivation has emerged as an influential area of research, and is dedicated to understanding the reasons behind the individual\u2019s drive to achieve competence and performance. however, the current literature on achievement goals is segmented rather than integrated. that is, citations across the three major and distinct achievement domains (work, education, and sports) are more the exception than the rule and similarities and differences between findings for the different achievement domains have yet to be tested. the purpose of the present study was to examine the relationships between self-reported achievement goals and nonself-report performance through meta-analysis, and the moderating potential of achievement domain. identifying achievement domain as moderator improves our understanding to which contexts we can (not) generalize conclusions to, it helps to understand seemingly inconsistent findings, and opens avenues for future research on the underlying processes. because the achievement goal (ag) measure used in a study is partially confounded with achievement domain, we examined the moderating role of this variable as well. our findings suggest that \u2013 overall \u2013 approach goals (either mastery or performance) were associated positively with performance attainment, whereas avoidance goals (either mastery or performance) were associated negatively with performance attainment. these relationships were moderated by achievement domain. for example, relative to the education or work domain, in the sports domain, we did not observe negative correlations between avoidance goals and performance. the absence of statistical moderation due to ag measure suggests that the observed moderation of achievement domain cannot be explained by the ag measure utilized. we suggest further steps to integrate the achievement goal literature, and accordingly, to broaden and deepen understanding of performance attainment in competence-relevant settings, including the workplace, the sports field, and the classroom."
        },
        {
            "id": "R196713",
            "label": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "doi": "10.48550/arXiv.2203.00255",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R196694",
                    "label": "Temporal Question Answering"
                }
            ],
            "abstract": "question answering over temporal knowledge graphs (kgs) efficiently uses facts contained in a temporal kg, which records entity relations and when they occur in time, to answer natural language questions (e.g., \u201cwho was the president of the us before obama?\u201d). these questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., \u201cobama\u201d instead of 2000); 2) subtle lexical differences in time relations (e.g., \u201cbefore\u201d vs \u201cafter\u201d); 3) off-the-shelf temporal kg embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. in this paper, we propose a time-sensitive question answering (tsqa) framework to tackle these problems. tsqa features a timestamp estimation module to infer the unwritten timestamp from the question. we also employ a time-sensitive kg encoder to inject ordering information into the temporal kg embeddings that tsqa is based on. with the help of techniques to reduce the search space for potential answers, tsqa significantly outperforms the previous state of the art on a new benchmark for question answering over temporal kgs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal kg."
        },
        {
            "id": "R170279",
            "label": "Octopamine Neuromodulation Regulates Gr32a-Linked Aggression and Courtship Pathways in Drosophila Males",
            "doi": "10.1371/journal.pgen.1004356",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "chemosensory pheromonal information regulates aggression and reproduction in many species, but how pheromonal signals are transduced to reliably produce behavior is not well understood. here we demonstrate that the pheromonal signals detected by gr32a-expressing chemosensory neurons to enhance male aggression are filtered through octopamine (oa, invertebrate equivalent of norepinephrine) neurons. using behavioral assays, we find males lacking both octopamine and gr32a gustatory receptors exhibit parallel delays in the onset of aggression and reductions in aggression. physiological and anatomical experiments identify gr32a to octopamine neuron synaptic and functional connections in the suboesophageal ganglion. refining the gr32a-expressing population indicates that mouth gr32a neurons promote male aggression and form synaptic contacts with oa neurons. by restricting the monoamine neuron target population, we show that three previously identified oa-frum neurons involved in behavioral choice are among the gr32a-oa connections. our findings demonstrate that octopaminergic neuromodulatory neurons function as early as a second-order step in this chemosensory-driven male social behavior pathway."
        },
        {
            "id": "R171684",
            "label": "The impact of self-esteem on the preferential processing of self-related information: Electrophysiological correlates of explicit self vs. other evaluation",
            "doi": "10.1371/journal.pone.0200604",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "preferential processing of self-related information is a well-documented phenomenon on both the behavioral and neural levels. however, the impact of self-esteem on this self-preference has not been studied in a systematic way. here, the electrophysiological correlates of explicit self-reflection were investigated in individuals with low (lse) and high self-esteem (hse). participants evaluated trait adjectives in reference to the self or to an \u201cother\u201d person (close-other, famous) while eeg was recorded. the analysis of event-related potentials focused on the late positive component (lpc), which exhibits a fronto-central distribution and latency over 500 ms. in both lse and hse groups, the amplitudes of lpc were enhanced in the self condition when compared to control conditions (both close-other and famous). crucially, lpc amplitudes in the hse group were significantly higher than in the lse group. moreover, the self-preference effect, defined as the difference between amplitudes of lpc associated with the evaluation of words in relation to oneself vs. other people, was significantly higher in the hse group than in the lse group. overall, our findings indicate that people with high self-esteem tend to engage in self-referential processing to a higher extent."
        },
        {
            "id": "R171234",
            "label": "Proposed Diagnostic Criteria for Smartphone Addiction",
            "doi": "10.1371/journal.pone.0163010",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background global smartphone penetration has led to unprecedented addictive behaviors. the aims of this study are to develop diagnostic criteria of smartphone addiction and to examine the discriminative ability and the validity of the diagnostic criteria. methods we developed twelve candidate criteria for characteristic symptoms of smartphone addiction and four criteria for functional impairment caused by excessive smartphone use. the participants consisted of 281 college students. each participant was systematically assessed for smartphone-using behaviors by psychiatrist\u2019s structured diagnostic interview. the sensitivity, specificity, and diagnostic accuracy of the candidate symptom criteria were analyzed with reference to the psychiatrists\u2019 clinical global impression. the optimal model selection with its cutoff point of the diagnostic criteria differentiating the smartphone addicted subjects from non-addicted subjects was then determined by the best diagnostic accuracy. results six symptom criteria model with optimal cutoff point were determined based on the maximal diagnostic accuracy. the proposed smartphone addiction diagnostic criteria consisted of (1) six symptom criteria, (2) four functional impairment criteria and (3) exclusion criteria. setting three symptom criteria as the cutoff point resulted in the highest diagnostic accuracy (84.3%), while the sensitivity and specificity were 79.4% and 87.5%, respectively. we suggested determining the functional impairment by two or more of the four domains considering the high accessibility and penetration of smartphone use. conclusion the diagnostic criteria of smartphone addiction demonstrated the core symptoms \u201cimpaired control\u201d paralleled with substance related and addictive disorders. the functional impairment involved multiple domains provide a strict standard for clinical assessment."
        },
        {
            "id": "R169355",
            "label": "Windowed Correlation: A Suitable Tool for Providing Dynamic fMRI-Based Functional Connectivity Neurofeedback on Task Difficulty",
            "doi": "10.1371/journal.pone.0085929",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the goal of neurofeedback training is to provide participants with relevant information on their ongoing brain processes in order to enable them to change these processes in a meaningful way. under the assumption of an intrinsic brain-behavior link, neurofeedback can be a tool to guide a participant towards a desired behavioral state, such as a healthier state in the case of patients. current research in clinical neuroscience regarding the most robust indicators of pathological brain processes in psychiatric and neurological disorders indicates that fmri-based functional connectivity measures may be among the most important biomarkers of disease. the present study therefore investigated the general potential of providing fmri neurofeedback based on functional correlations, computed from short-window time course data at the level of single task periods. the ability to detect subtle changes in task performance with block-wise functional connectivity measures was evaluated based on imaging data from healthy participants performing a simple motor task, which was systematically varied along two task dimensions representing two different aspects of task difficulty. the results demonstrate that fmri-based functional connectivity measures may provide a better indicator for an increase in overall (motor) task difficulty than activation level-based measures. windowed functional correlations thus seem to provide relevant and unique information regarding ongoing brain processes, which is not captured equally well by standard activation level-based neurofeedback measures. functional connectivity markers, therefore, may indeed provide a valuable tool to enhance and monitor learning within an fmri neurofeedback setup."
        },
        {
            "id": "R197572",
            "label": "LassoBench: A High-Dimensional Hyperparameter Optimization Benchmark Suite for Lasso",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "R127350",
                    "label": "AutoML"
                }
            ],
            "abstract": "while weighted lasso sparse regression has appealing statistical guarantees that would entail a major real-world impact in nance, genomics, and brain imaging applications, it is typically scarcely adopted due to its complex high-dimensional space composed by thousands of hyperparameters. on the other hand, the latest progress with high-dimensional hyperparameter optimization (hd-hpo) methods for black-box functions demonstrates that high-dimensional applications can indeed be eciently optimized. despite this initial success, hd-hpo approaches are mostly applied to synthetic problems with a moderate number of dimensions, which limits its impact in scientic and engineering applications. we propose lassobench , the rst benchmark suite tailored for weighted lasso regression. lassobench consists of benchmarks for both well-controlled synthetic setups (number of samples, noise level, ambient and eective dimensionalities, and multiple delities) and real-world datasets, which enables the use of many avors of hpo algorithms to be studied and extended to the high-dimensional lasso setting. we evaluate 6 state-of-the-art hpo methods and 3 lasso baselines, and demonstrate that bayesian optimization and evolutionary strategies can improve over the methods commonly used for sparse regression while highlighting limitations of these frameworks in very high-dimensional and noisy settings."
        },
        {
            "id": "R131845",
            "label": "Global Encoding for Abstractive Summarization",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124682",
                    "label": "Text Summarization"
                }
            ],
            "abstract": "in neural abstractive summarization, the conventional sequence-to-sequence (seq2seq) model often suffers from repetition and semantic irrelevance. to tackle the problem, we propose a global encoding framework, which controls the information flow from the encoder to the decoder based on the global information of the source context. it consists of a convolutional gated unit to perform global encoding to improve the representations of the source-side information. evaluations on the lcsts and the english gigaword both demonstrate that our model outperforms the baseline models, and the analysis shows that our model is capable of reducing repetition."
        },
        {
            "id": "R149004",
            "label": "Multi-frequency radiation of dissipative solitons in optical fiber cavities",
            "doi": "10.1038/s41598-020-65426-x",
            "research_field": {
                "id": "R137635",
                "label": "Optics, Quantum Optics and Physics of Atoms, Molecules and Plasmas"
            },
            "research_problems": [
                {
                    "id": "R149006",
                    "label": "Resonant radiation of optical solitons in presence of high-order dispersion"
                }
            ],
            "abstract": "abstract new resonant emission of dispersive waves by oscillating solitary structures in optical fiber cavities is considered analytically and numerically. the pulse propagation is described in the framework of the lugiato-lefever equation when a hopf-bifurcation can result in the formation of oscillating dissipative solitons. the resonance condition for the radiation of the dissipative oscillating solitons is derived and it is demonstrated that the predicted resonances match the spectral lines observed in numerical simulations perfectly. the complex recoil of the radiation on the soliton dynamics is discussed. the reported effect can have importance for the generation of frequency combs in nonlinear microring resonators."
        },
        {
            "id": "R134345",
            "label": "Unifying Count-Based Exploration and Intrinsic Motivation",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "\"we consider an agent's uncertainty about its environment and the problem of generalizing this uncertainty across observations. specifically, we focus on the problem of exploration in non-tabular reinforcement learning. drawing inspiration from the intrinsic motivation literature, we use density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary density model. this technique enables us to generalize count-based exploration algorithms to the non-tabular case. we apply our ideas to atari 2600 games, providing sensible pseudo-counts from raw pixels. we transform these pseudo-counts into intrinsic rewards and obtain significantly improved exploration in a number of hard games, including the infamously difficult montezuma's revenge.\""
        },
        {
            "id": "R142214",
            "label": "Nanoscale thermometry via the fluorescence of YAG:Ce phosphor particles: measurements from 7 to 77\u00c2\u00a0C",
            "doi": "10.1088/0957-4484/14/8/304",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R142135",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "the laser-induced fluorescence lifetime of 30 nm particles of yag:ce was measured as a function of temperature from 7 to 77\u00b0c. the fluorescence decay lifetimes for the nanoparticles of this phosphor varied from \u224818 to 27 ns, i.e. \u224833% relative to the longest lifetime measured. this large variation in lifetime, coupled with the high signal strength that was observed, suggest that yag:ce nanoparticles will be useful thermographic phosphors. we describe the material and the apparatus used to characterize its fluorescence, present the results of measurements made over the range of temperatures tested and comment on some possible applications for this novel material."
        },
        {
            "id": "R170135",
            "label": "A biophysically constrained computational model of the action potential of mouse urinary bladder smooth muscle",
            "doi": "10.1371/journal.pone.0200712",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "urinary incontinence is associated with enhanced spontaneous phasic contractions of the detrusor smooth muscle (dsm). although a complete understanding of the etiology of these spontaneous contractions is not yet established, it is suggested that the spontaneously evoked action potentials (saps) in dsm cells initiate and modulate the contractions. in order to further our understanding of the ionic mechanisms underlying sap generation, we present here a biophysically detailed computational model of a single dsm cell. first, we constructed mathematical models for nine ion channels found in dsm cells based on published experimental data: two voltage gated ca2+ ion channels, an hyperpolarization-activated ion channel, two voltage-gated k+ ion channels, three ca2+-activated k+ ion channels and a non-specific background leak ion channel. the ion channels\u2019 kinetics were characterized in terms of maximal conductances and differential equations based on voltage or calcium-dependent activation and inactivation. all ion channel models were validated by comparing the simulated currents and current-voltage relations with those reported in experimental work. incorporating these channels, our dsm model is capable of reproducing experimentally recorded spike-type saps of varying configurations, ranging from saps displaying after-hyperpolarizations to saps displaying after-depolarizations. the contributions of the principal ion channels to spike generation and configuration were also investigated as a means of mimicking the effects of selected pharmacological agents on dsm cell excitability. additionally, the features of propagation of an ap along a length of electrically continuous smooth muscle tissue were investigated. to date, a biophysically detailed computational model does not exist for dsm cells. our model, constrained heavily by physiological data, provides a powerful tool to investigate the ionic mechanisms underlying the genesis of dsm electrical activity, which can further shed light on certain aspects of urinary bladder function and dysfunction."
        },
        {
            "id": "R75832",
            "label": "The Coordination\u00e2\u0080\u0090Information Bubble in Humanitarian Response: Theoretical Foundations and Empirical Investigations",
            "doi": "10.1111/poms.13236",
            "research_field": {
                "id": "R353",
                "label": "Social Psychology"
            },
            "research_problems": [
                {
                    "id": "R75838",
                    "label": "Describing adaptive decision-making in dynamic situations with volatile information, and emerging coordination structures"
                }
            ],
            "abstract": "humanitarian disasters are highly dynamic and uncertain. the shifting situation, volatility of information, and the emergence of decision processes and coordination structures require humanitarian organizations to continuously adapt their operations. in this study, we aim to make headway in understanding adaptive decision-making in a dynamic interplay between changing situation, volatile information, and emerging coordination structures. starting from theories of sensemaking, coordination, and decision-making, we present two case studies that represent the response to two different humanitarian disasters: typhoon haiyan in the philippines, and the syria crisis, one of the most prominent ongoing conflicts. for both, we highlight how volatile information and the urge to respond via sensemaking lead to fragmentation and misalignment of emergent coordination structures and decisions, which, in turn, slow down adaptation. based on the case studies, we derive propositions and the need to continuously align laterally between different regions and hierarchically between operational and strategic levels to avoid persistence of coordination-information bubbles. we discuss the implications of our findings for the development of methods and theory to ensure that humanitarian operations management captures the critical role of information as a driver of emergent coordination and adaptive decisions."
        },
        {
            "id": "R171325",
            "label": "Quality of reproductive healthcare for adolescents: A nationally representative survey of providers in Mexico",
            "doi": "10.1371/journal.pone.0173342",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective adolescents need sexual and reproductive health services but little is known about quality-of-care in lower- and middle-income countries where most of the world\u2019s adolescents reside. quality-of-care has important implications as lower quality may be linked to higher unplanned pregnancy and sexually transmitted infection rates. this study sought to generate evidence about quality-of-care in public sexual and reproductive health services for adolescents. methods this cross-sectional study had a complex, probabilistic, stratified sampling design, representative at the national, regional and rural/urban level in mexico, collecting provider questionnaires at 505 primary care units in 2012. a sexual and reproductive quality-of-healthcare index was defined and multinomial logistic regression was utilized in 2015. results at the national level 13.9% (95%ci: 6.9\u201326.0) of healthcare units provide low quality, 68.6% (95%ci: 58.4\u201377.3) medium quality and 17.5% (95%ci: 11.9\u201325.0) high quality reproductive healthcare services to adolescents. urban or metropolitan primary care units were at least 10 times more likely to provide high quality care than those in rural areas. units with a space specifically for counseling adolescents were at least 8 times more likely to provide high quality care. ministry of health clinics provided the lowest quality of service, while those from social security for the underserved provided the best. conclusions the study indicates higher quality sexual and reproductive healthcare services are needed. in mexico and other middle- to low-income countries where quality-of-care has been shown to be a problem, incorporating adolescent-friendly, gender-equity and rights-based perspectives could contribute to improvement. setting and disseminating standards for care in guidelines and providing tools such as algorithms could help healthcare personnel provide higher quality care."
        },
        {
            "id": "R169876",
            "label": "Global Potential Distribution of Bactrocera carambolae and the Risks for Fruit Production in Brazil",
            "doi": "10.1371/journal.pone.0166142",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the carambola fruit fly, bactrocera carambolae, is a tephritid native to asia that has invaded south america through small-scale trade of fruits from indonesia. the economic losses associated with biological invasions of other fruit flies around the world and the polyphagous behaviour of b. carambolae have prompted much concern among government agencies and farmers with the potential spread of this pest. here, ecological niche models were employed to identify suitable environments available to b. carambolae in a global scale and assess the extent of the fruit acreage that may be at risk of attack in brazil. overall, 30 maxent models built with different combinations of environmental predictors and settings were evaluated for predicting the potential distribution of the carambola fruit fly. the best model was selected based on threshold-independent and threshold-dependent metrics. climatically suitable areas were identified in tropical and subtropical regions of central and south america, sub-saharan africa, west and east coast of india and northern australia. the suitability map of b. carambola was intersected against maps of fruit acreage in brazil. the acreage under potential risk of attack varied widely among fruit species, which is expected because the production areas are concentrated in different regions of the country. the production of cashew is the one that is at higher risk, with almost 90% of its acreage within the suitable range of b. carambolae, followed by papaya (78%), tangerine (51%), guava (38%), lemon (30%), orange (29%), mango (24%) and avocado (20%). this study provides an important contribution to the knowledge of the ecology of b. carambolae, and the information generated here can be used by government agencies as a decision-making tool to prevent the carambola fruit fly spread across the world."
        },
        {
            "id": "R4372",
            "label": "Challenge: Processing web texts for classifying job offers",
            "doi": "10.1109/icosc.2015.7050852",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4384",
                    "label": "classifying online job offers against a standard classification system of occupations"
                }
            ],
            "abstract": "today the web represents a rich source of labour market data for both public and private operators, as a growing number of job offers are advertised through web portals and services. in this paper we apply and compare several techniques, namely explicit-rules, machine learning, and lda-based algorithms to classify a real dataset of web job offers collected from 12 heterogeneous sources against a standard classification system of occupations."
        },
        {
            "id": "R130909",
            "label": "Trellis Networks for Sequence Modeling",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "we present trellis networks, a new architecture for sequence modeling. on the one hand, a trellis network is a temporal convolutional network with special structure, characterized by weight tying across depth and direct injection of the input into deep layers. on the other hand, we show that truncated recurrent networks are equivalent to trellis networks with special sparsity structure in their weight matrices. thus trellis networks with general weight matrices generalize truncated recurrent networks. we leverage these connections to design high-performing trellis networks that absorb structural and algorithmic elements from both recurrent and convolutional models. experiments demonstrate that trellis networks outperform the current state of the art methods on a variety of challenging benchmarks, including word-level language modeling and character-level language modeling tasks, and stress tests designed to evaluate long-term memory retention. the code is available at this https url ."
        },
        {
            "id": "R191750",
            "label": "Effect of Data Scaling Methods on Machine Learning Algorithms and Model Performance",
            "doi": "10.3390/technologies9030052",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "heart disease, one of the main reasons behind the high mortality rate around the world, requires a sophisticated and expensive diagnosis process. in the recent past, much literature has demonstrated machine learning approaches as an opportunity to efficiently diagnose heart disease patients. however, challenges associated with datasets such as missing data, inconsistent data, and mixed data (containing inconsistent missing data both as numerical and categorical) are often obstacles in medical diagnosis. this inconsistency led to a higher probability of misprediction and a misled result. data preprocessing steps like feature reduction, data conversion, and data scaling are employed to form a standard dataset\u2014such measures play a crucial role in reducing inaccuracy in final prediction. this paper aims to evaluate eleven machine learning (ml) algorithms\u2014logistic regression (lr), linear discriminant analysis (lda), k-nearest neighbors (knn), classification and regression trees (cart), naive bayes (nb), support vector machine (svm), xgboost (xgb), random forest classifier (rf), gradient boost (gb), adaboost (ab), extra tree classifier (et)\u2014and six different data scaling methods\u2014normalization (nr), standscale (ss), minmax (mm), maxabs (ma), robust scaler (rs), and quantile transformer (qt) on a dataset comprising of information of patients with heart disease. the result shows that cart, along with rs or qt, outperforms all other ml algorithms with 100% accuracy, 100% precision, 99% recall, and 100% f1 score. the study outcomes demonstrate that the model\u2019s performance varies depending on the data scaling method."
        },
        {
            "id": "R74459",
            "label": "Meta-analysis of the TAEE project applying social network analysis",
            "doi": "10.1109/EDUCON.2010.5493061",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74406",
                    "label": "Open Education"
                },
                {
                    "id": "R109069",
                    "label": "Open Education"
                }
            ],
            "abstract": "the social network analysis (sna) is an approach that can be applied as a complement to other analysis (such as statistical) in order to obtain other valuable information. the social network analysis has been used in several initiatives showing that it is an approach that can contribute in building the semantic web. within the project technologies applied to electronics teaching (taee) there are biannual conferences (it has been organized since 1996) and have accumulated a significant amount of data resulting from the conferences held. all of this information constitutes a data source that should be exploited and that can provide meaningful information. in this document we describe, how to social network analysis has been used on data sources generated by user communities, in order to obtain some semantic artifacts, like ontologies. also describes how to was applied the social network analysis and its metrics on the information generated in the taee congresses to answer a set of questions (what are the relationships and the level of cohesion of the different organizations (at the level of spain and across continents) involved in taee? how have evolutioned the thematics covered in the conference?, what are the new ontological additions in technology over the years?, and how have evolutioned the thematics in the research and studies related to teaching electronics?) formulated by the organizers of the congresses and that through other approaches would have been a large task and complicated. the answers to the questions can provide us important information about the behavior and characteristics of the elements present in taee conferences, furthermore being an element for making decisions on future initiatives with the same style of taee."
        },
        {
            "id": "R171612",
            "label": "Informal social accountability in maternal health service delivery: A study in Northern Malawi",
            "doi": "10.1371/journal.pone.0195671",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "despite the expansion of literature on social accountability in low-and middle-income countries, little is known about how health providers experience daily social pressure and citizen feedback. this study used a narrative inquiry approach to explore the function of daily social accountability relations among maternal health care workers in rural malawi. through semi-structured interviews with 32 nurses and 19 clinicians, we collected 155 feedback cases allowing the identification of four main strategies social actors use to express their opinion and concerns about maternal health services. we found that women who used delivery care express their appreciation for successful deliveries directly to the health worker but complaints, such as on absenteeism and poor interpersonal behaviour, follow an indirect route via intermediaries such as the health workers\u2019 spouse, co-workers or the health committee who forward some cases of misbehaviour to district authorities. the findings suggest that citizen feedback is important for the socialization, motivation and retention of maternal healthcare workers in under resourced rural settings. practitioners and external development programmes should understand and recognize the value of already existing accountability mechanisms and foster social accountability approaches that allow communities as well as health workers to challenge the systemic obstacles to quality and respectful service delivery."
        },
        {
            "id": "R146568",
            "label": "Preliminary Assessment of an Automated Surveillance System for Infection Control",
            "doi": "10.1086/502400",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "abstract background and objective: rapid identification and investigation of potential outbreaks is key to limiting transmission in the healthcare setting. manual review of laboratory results remains a cumbersome, time-consuming task for infection control practitioners (icps). computer-automated techniques have shown promise for improving the efficiency and accuracy of surveillance. we examined the use of automated control charts, provided by an automated surveillance system, for detection of potential outbreaks. setting: a 656-bed academic medical center. methods: we retrospectively reviewed 13 months (november 2001 through november 2002) of laboratory-patient data, comparing an automated surveillance application with standard infection control practices. we evaluated positive predictive value, sensitivity, and time required to investigate the alerts. an icp created 75 control charts. a standardized case investigation form was developed to evaluate each alert for the likelihood of nosocomial transmission based on temporal and spatial overlap and culture results. results: the 75 control charts were created in 75 minutes and 18 alerts fired above the 3-sigma level. these were independently reviewed by an icp and associate hospital epidemiologist. the review process required an average of 20 minutes per alert and the kappa score between the reviewers was 0.82. eleven of the 18 alerts were determined to be potential outbreaks, yielding a positive predictive value of 0.61. routine surveillance identified 5 of these 11 alerts during this time period. conclusion: automated surveillance with user-definable control charts for cluster identification was more sensitive than routine methods and is capable of operating with high specificity and positive predictive value in a time-efficient manner."
        },
        {
            "id": "R149052",
            "label": "Local ontologies for semantic interoperability in supply chain networks",
            "doi": "10.5220/0003416500220031",
            "research_field": {
                "id": "R276",
                "label": "Systems Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"most of the issues of current supply chain management practices are related to the challenges of interoperability of relevant enterprise information systems (eis). in this paper, we present the ontological framework for semantic interoperability of eiss in supply chain networks, based on supply chain operations reference (scor) model, its semantic enrichment and mappings with relevant enterprise conceptualizations. in order to introduce the realities of the enterprises into this framework, namely their models, we define and implement the approach to generation of local ontologies, based on the databases of their eiss. also, we discuss on the translation between semantic and sql queries, a process in which implicit semantics of the eis's databases and explicit semantics of the local ontologies become inter-related.\""
        },
        {
            "id": "R171468",
            "label": "National substance use patterns on Twitter",
            "doi": "10.1371/journal.pone.0187691",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose we examined openly shared substance-related tweets to estimate prevalent sentiment around substance use and identify popular substance use activities. additionally, we investigated associations between substance-related tweets and business characteristics and demographics at the zip code level. methods a total of 79,848,992 tweets were collected from 48 states in the continental united states from april 2015-march 2016 through the twitter api, of which 688,757 were identified as being related to substance use. we implemented a machine learning algorithm (maximum entropy text classifier) to estimate sentiment score for each tweet. zip code level summaries of substance use tweets were created and merged with the 2013 zip code business patterns and 2010 us census data. results quality control analyses with a random subset of tweets yielded excellent agreement rates between computer generated and manually generated labels: 97%, 88%, 86%, 75% for underage engagement in substance use, alcohol, drug, and smoking tweets, respectively. overall, 34.1% of all substance-related tweets were classified as happy. alcohol was the most frequently tweeted substance, followed by marijuana. regression results suggested more convenience stores in a zip code were associated with higher percentages of tweets about alcohol. larger zip code population size and higher percentages of african americans and hispanics were associated with fewer tweets about substance use and underage engagement. zip code economic disadvantage was associated with fewer alcohol tweets but more drug tweets. conclusions the patterns in substance use mentions on twitter differ by zip code economic and demographic characteristics. online discussions have great potential to glorify and normalize risky behaviors. health promotion and underage substance prevention efforts may include interactive social media campaigns to counter the social modeling of risky behaviors."
        },
        {
            "id": "R131303",
            "label": "Neural Architecture Transfer",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R123710",
                    "label": "Neural Architecture Search"
                }
            ],
            "abstract": "neural architecture search (nas) has emerged as a promising avenue for automatically designing task-specific neural networks. existing nas approaches require one complete search for each deployment specification of hardware or objective. this is a computationally impractical endeavor given the potentially large number of application scenarios. in this paper, we propose neural architecture transfer (nat) to overcome this limitation. nat is designed to efficiently generate task-specific custom models that are competitive under multiple conflicting objectives. to realize this goal we learn task-specific supernets from which specialized subnets can be sampled without any additional training. the key to our approach is an integrated online transfer learning and many-objective evolutionary search procedure. a pre-trained supernet is iteratively adapted while simultaneously searching for task-specific subnets. we demonstrate the efficacy of nat on 11 benchmark image classification tasks ranging from large-scale multi-class to small-scale fine-grained datasets. in all cases, including imagenet, natnets improve upon the state-of-the-art under mobile settings ( $\\\\leq$ \u2264 600m multiply-adds). surprisingly, small-scale fine-grained datasets benefit the most from nat. at the same time, the architecture search and transfer is orders of magnitude more efficient than existing nas methods. overall, experimental evaluation indicates that, across diverse image classification tasks and computational objectives, nat is an appreciably more effective alternative to conventional transfer learning of fine-tuning weights of an existing network architecture learned on standard datasets. code is available at https://github.com/human-analysis/neural-architecture-transfer ."
        },
        {
            "id": "R194895",
            "label": "Scalable Analysis of Real-Time Requirements",
            "doi": "10.1109/re.2019.00033",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "detecting issues in real-time requirements is usually a trade-off between flexibility and cost: the effort expended depends on how expensive it is to fix a defect introduced by faulty, ambiguous or incomplete requirements. the most rigorous techniques for real-time requirement analysis depend on the formalisation of these requirements. completely formalised real-time requirements allow the detection of issues that are hard to find through other means, like real-time inconsistency (i.e., \"do the requirements lead to deadlocks and starvation of the system?\") or vacuity (i.e., \"are some requirements trivially satisfied\"). current analysis techniques for real-time requirements suffer from scalability issues \u2013 larger sets of such requirements are usually intractable. we present a new technique to analyse formalised real-time requirements for various properties. our technique leverages recent advances in software model checking and automatic theorem proving by converting the analysis problem for real-time requirements to a program analysis task. we also report preliminary results from an ongoing, large scale application of our technique in the automotive domain at bosch."
        },
        {
            "id": "R74698",
            "label": "Design, Setup, and Evaluation of a Compensation System for the Light Deflection Effect Occurring When Measuring Wrought-Hot Objects Using Optical Triangulation Methods",
            "doi": "10.3390/met10070908",
            "research_field": {
                "id": "R184",
                "label": "Optics"
            },
            "research_problems": [
                {
                    "id": "R142419",
                    "label": "Influence of light deflection during fringe projection measurements of hot objects"
                }
            ],
            "abstract": "in this paper, we present a system to compensate for the light deflection effect during the optical geometry measurement of a wrought-hot object. the acquired 3d data can be used to analyze the formed geometry of a component directly after a hot forging process without waiting for the needed cooling time to room temperature. this may be used to parameterize the process and to detect defect components early in the production process, among others. the light deflection as the deviation from the linear path of the light is caused by an inhomogeneous refractive index field surrounding the hot object. we present the design and setup for a nozzle-based forced air flow actuator, which suppresses the light deflection effect. the design process includes a simulation of the developing field, as well as of the interaction of the field with an external forced air flow. the cooling effect of the air flow is evaluated, and conclusions are drawn from the conflicting interests of good measurement conditions against the forced cooling of the hot object. the findings are then implemented in the physical setup of the suppression system. the system is evaluated using a previously established method based on optical triangulation and fringe projection. other occurring effects and their influence on the evaluation are considered and discussed."
        },
        {
            "id": "R171344",
            "label": "Socio-environmental exposures and health outcomes among persons with sickle cell disease",
            "doi": "10.1371/journal.pone.0175260",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "there is much variability in the expression of sickle cell disease (scd) and recent works suggest that environmental and social factors may also influence this variability. this paper aims to use geographic information systems technology to examine the association between socio-environmental exposures and health outcomes in all persons who have attended or currently attend the sickle cell unit in jamaica. rural patients presented for clinical care at older ages and had less annual visits to clinic. persons travelled relatively long distances to seek scd care and those travelling longer had less health maintenance visits. urban patients had a higher prevalence of significant pain crises (69.4% vs. 55.8%, p value<0.001) and respiratory events (21.2% vs. 14%, p value<0.001). prevalence of leg ulcers did not vary between rural and urban patients but was higher in males than in females. females also had lower odds of having respiratory events but there was no sex difference in history of painful crises. persons with more severe genotypes lived in higher poverty and travelled longer for healthcare services. persons in areas with higher annual rainfall, higher mean temperatures and living farther from factories had less painful crises and respiratory events. the paper highlights a need for better access to healthcare services for jamaicans with scd especially in rural areas of the island. it also reports interesting associations between environmental climatic exposures and health outcomes."
        },
        {
            "id": "R171348",
            "label": "Insufficiently studied factors related to burnout in nursing: Results from an e-Delphi study",
            "doi": "10.1371/journal.pone.0175352",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"objective this study aimed to identify potentially important factors in explaining burnout in nursing that have been insufficiently studied or ignored. methods a three-round delphi study via e-mail correspondence was conducted, with a group of 40 european experts. the e-delphi questionnaire consisted of 52 factors identified from a literature review. experts rated and scored the importance of factors in the occurrence of burnout and the degree of attention given by researchers to each of the variables listed, on a six-point likert scale. we used the agreement percentage (>80%) to measure the level of consensus between experts. furthermore, to confirm the level of consensus, we also calculated mean scores and modes. regardless of the degree of consensus reached by the experts, we have calculated the mean of the stability of the answers for each expert (individual's qualitative stability) and the mean of the stability percentages of the experts (qualitative group stability). results the response rate in the three rounds was 93.02% (n = 40). eight new factors were suggested in the first round. after modified, the e-delphi questionnaire in the second and third rounds had 60 factors. all the factors reached the third round with a consensus level above 80% in terms of the attention that researchers gave them in their studies. moreover, the data show a total mean qualitative group stability of 96.21%. in the third round 9 factors were classified by experts as \u2018studied very little\u2019, 17 as \u2018studied little\u2019 and 34 as 'well studied' conclusion findings show that not all the factors that may influence nursing burnout have received the same attention from researchers. the panel of experts has identified factors that, although important in explaining burnout, have been poorly studied or even forgotten. our results suggest that further study into factors such as a lack of recognition of part of the tasks that nurses perform, feminine stereotype or excessive bureaucracy is needed for a better understanding of this syndrome and improve the quality of life in nurses.\""
        },
        {
            "id": "R155287",
            "label": "Ultra-Sensitive Strain Sensor Based on Femtosecond Laser Inscribed In-Fiber Reflection Mirrors and Vernier Effect",
            "doi": "10.1109/jlt.2019.2926066",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R155279",
                    "label": " Performance of  fiber optic strain sensors"
                }
            ],
            "abstract": "\"one of the efficient techniques to enhance the sensitivity of optical fiber sensor is to utilize vernier effect. however, the complex system structure, precisely controlled device fabrication, or expensive materials required for implementing the technique creates the difficulties for practical applications. here, we propose a highly sensitive optical fiber strain sensor based on two cascaded fabry\u2013perot interferometers and vernier effect. of the two interferometers, one is for sensing and the other for referencing, and they are formed by two pairs of in-fiber reflection mirrors fabricated by femtosecond laser pulse illumination to induce refractive-index-modified area in the fiber core. a relatively large distance between the two fabry\u2013perot interferometers needs to be used to ensure the independent operation of the two interferometers. the fabrication of the device is simple, and the cavity's length can be precisely controlled by a computer-controlled three-dimensional micromachining platform. moreover, as the device is based on the inner structure inside the optical fiber, good robustness of the device can be guaranteed. the experimental results obtained show that the strain sensitivity of the device is \u223c28.11\\xa0pm/\u03bc\u03f5, while the temperature sensitivity achieved is \u223c278.48\\xa0pm/\u00b0c.\""
        },
        {
            "id": "R36097",
            "label": "Schema extraction for tabular data on the web",
            "doi": "https://doi.org/10.14778/2536336.2536343",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R36029",
                    "label": "Table extraction"
                }
            ],
            "abstract": "\" tabular data is an abundant source of information on the web, but remains mostly isolated from the latter's interconnections since tables lack links and computer-accessible descriptions of their structure. in other words, the schemas of these tables -- attribute names, values, data types, etc. -- are not explicitly stored as table metadata. consequently, the structure that these tables contain is not accessible to the crawlers that power search engines and thus not accessible to user search queries. we address this lack of structure with a new method for leveraging the principles of table construction in order to extract table schemas. discovering the schema by which a table is constructed is achieved by harnessing the similarities and differences of nearby table rows through the use of a novel set of features and a feature processing scheme. the schemas of these data tables are determined using a classification technique based on conditional random fields in combination with a novel feature encoding method called logarithmic binning, which is specifically designed for the data table extraction task. our method provides considerable improvement over the well-known webtables schema extraction method. in contrast with previous work that focuses on extracting individual relations, our method excels at correctly interpreting full tables, thereby being capable of handling general tables such as those found in spreadsheets, instead of being restricted to html tables as is the case with the webtables method. we also extract additional schema characteristics, such as row groupings, which are important for supporting information retrieval tasks on tabular data. \""
        },
        {
            "id": "R140760",
            "label": "Hydrogen gas sensor based on metal oxide nanoparticles decorated graphene transistor",
            "doi": "10.1039/c5nr01924a",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "in this work, in order to enhance the performance of graphene gas sensors, graphene and metal oxide nanoparticles (nps) are combined to be utilized for high selectivity and fast response gas detection. whether at the relatively optimal temperature or even room temperature, our gas sensors based on graphene transistors, decorated with sno2 nps, exhibit fast response and short recovery times (\u223c1 seconds) at 50 \u00b0c when the hydrogen concentration is 100 ppm. specifically, x-ray photoelectron spectroscopy and conductive atomic force microscopy are employed to explore the interface properties between graphene and sno2 nps. through the complimentary characterization, a mechanism based on charge transfer and band alignment is elucidated to explain the physical originality of these graphene gas sensors: high carrier mobility of graphene and small energy barrier between graphene and sno2 nps have ensured a fast response and a high sensitivity and selectivity of the devices. generally, these gas sensors will facilitate the rapid development of next-generation hydrogen gas detection."
        },
        {
            "id": "R135045",
            "label": "EfficientNetV2: Smaller Models and Faster Training",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R38570",
                    "label": "Image Classification"
                }
            ],
            "abstract": "this paper introduces efficientnetv2, a new family of convolutional networks that have faster training speed and better parameter efficiency than previous models. to develop this family of models, we use a combination of training-aware neural architecture search and scaling, to jointly optimize training speed and parameter efficiency. the models were searched from the search space enriched with new ops such as fused-mbconv. our experiments show that efficientnetv2 models train much faster than state-of-the-art models while being up to 6.8x smaller. our training can be further sped up by progressively increasing the image size during training, but it often causes a drop in accuracy. to compensate for this accuracy drop, we propose an improved method of progressive learning, which adaptively adjusts regularization (e.g., dropout and data augmentation) along with image size. with progressive learning, our efficientnetv2 significantly outperforms previous models on imagenet and cifar/cars/flowers datasets. by pretraining on the same imagenet21k, our efficientnetv2 achieves 87.3% top-1 accuracy on imagenet ilsvrc2012, outperforming the recent vit by 2.0% accuracy while training 5x-11x faster using the same computing resources. code will be available at https://github.com/ google/automl/efficientnetv2."
        },
        {
            "id": "R46427",
            "label": "Machine comprehension using match-lstm and answer pointer",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46405",
                    "label": "Machine comprehension"
                },
                {
                    "id": "R46439",
                    "label": "Machine comprehension of text"
                }
            ],
            "abstract": "machine comprehension of text is an important problem in natural language processing. a recently released dataset, the stanford question answering dataset (squad), offers a large number of real questions and their answers created by humans through crowdsourcing. squad provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in squad the answers do not come from a small set of candidate answers and they have variable lengths. we propose an end-to-end neural architecture for the task. the architecture is based on match-lstm, a model we proposed previously for textual entailment, and pointer net, a sequence-to-sequence model proposed by vinyals et al.(2015) to constrain the output tokens to be from the input sequences. we propose two ways of using pointer net for our task. our experiments show that both of our two models substantially outperform the best results obtained by rajpurkar et al.(2016) using logistic regression and manually crafted features."
        },
        {
            "id": "R170764",
            "label": "Clinical- and Cost-Effectiveness of a Nurse Led Self-Management Intervention to Reduce Emergency Visits by People with Epilepsy",
            "doi": "10.1371/journal.pone.0090789",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"people with chronic epilepsy (pwe) often make costly, and clinically unnecessary emergency department (ed) visits. some do it frequently. no studies have examined interventions to reduce them. an intervention delivered by an epilepsy nurse specialist (ens) might reduce visits. the rationale is it may optimize patients' self-management skills and knowledge of appropriate ed use. we examined such an intervention's clinical- and cost-effectiveness. eighty-five adults with epilepsy were recruited from three london eds with similar catchment populations. forty-one pwe recruited from two eds received treatment-as-usual (tau) and formed the comparison group. the remaining 44 pwe were recruited from the ed of a hospital that had implemented a new ens service for pwe attending ed. these participants formed the intervention group. they were offered 2 one-to-one sessions with an ens, plus tau. participants completed questionnaires on health service use and psychosocial well-being at baseline, 6- and 12-month follow-up. covariates were identified and adjustments made. sixty-nine (81%) participants were retained at follow-up. no significant effect of the intervention on ed visits at 12 months or on other outcomes was found. however, due to less time as inpatients, the average service cost for intervention participants over follow-up was less than for tau participants' (adjusted difference \u00a3558, 95% ci, \u2212\u00a32409, \u00a3648). covariates most predictive of subsequent ed visits were patients' baseline feelings of stigmatization due to epilepsy and low confidence in managing epilepsy. the intervention did not lead to a reduction in ed use, but did not cost more, partly because those receiving the intervention had shorter hospital admissions. our findings on long-term ed predictors clarifies what causes ed use, and suggests that future interventions might focus more on patients' perceptions of stigma and on their confidence in managing epilepsy. if addressed, ed visits might be reduced and efficiency-savings generated.\""
        },
        {
            "id": "R170551",
            "label": "Social Support, Socio-Economic Status, Health and Abuse among Older People in Seven European Countries",
            "doi": "10.1371/journal.pone.0054856",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background social support has a strong impact on individuals, not least on older individuals with health problems. a lack of support network and poor family or social relations may be crucial in later life, and represent risk factors for elder abuse. this study focused on the associations between social support, demographics/socio-economics, health variables and elder mistreatment. methods the cross-sectional data was collected by means of interviews or interviews/self-response during january-july 2009, among a sample of 4,467 not demented individuals aged 60\u201384 years living in seven european countries (germany, greece, italy, lithuania, portugal, spain, and sweden). results multivariate analyses showed that women and persons living in large households and with a spouse/partner or other persons were more likely to experience high levels of social support. moreover, frequent use of health care services and low scores on depression or discomfort due to physical complaints were indicators of high social support. low levels of social support were related to older age and abuse, particularly psychological abuse. conclusions high levels of social support may represent a protective factor in reducing both the vulnerability of older people and risk of elder mistreatment. on the basis of these results, policy makers, clinicians and researchers could act by developing intervention programmes that facilitate friendships and social activities in old age."
        },
        {
            "id": "R151319",
            "label": "S2ORC: The Semantic Scholar Open Research Corpus",
            "doi": "10.18653/v1/2020.acl-main.447",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R151322",
                    "label": "Open research corpus of scientific papers with metadata"
                }
            ],
            "abstract": "we introduce s2orc, a large corpus of 81.1m english-language academic papers spanning many academic disciplines. the corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1m open access papers. full text is annotated with automatically-detected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. in s2orc, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. we hope this resource will facilitate research and development of tools and tasks for text mining over academic text."
        },
        {
            "id": "R200154",
            "label": "Estimating Soil Organic Matter Content Using Sentinel-2 Imagery by Machine Learning in Shanghai",
            "doi": "10.1109/access.2021.3080689",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R200160",
                    "label": "Assessment of soil organic matter using remote sensing"
                }
            ],
            "abstract": "soil organic matter (som) plays an important role in the field of climate change and terrestrial ecosystems. som in large areas, especially in urban areas, is difficult to monitor and estimate by traditional methods. urban land structure is complex, and soil is a mixture of organic and inorganic constituents with different physical and chemical properties. previous studies showed that remote sensing techniques that provide diverse data in the visible-near-infrared (vnir)-shortwave infrared (swir) spectral range, are promising in the prediction of som content on a large scale. sentinel-2 covers the important spectral bands (vnir-swir) for som prediction with a short revisit time. thus, this article aimed to evaluate the capacity of sentinel-2 for som prediction in an urban area (i.e., shanghai). 103 bare soil samples filtrated from 398 soil samples at a depth of 20 cm were selected. three methods, partial least square regression (plsr), artificial neural network (ann), and support vector machine (svm), were applied. the root mean square error (rmse) of modelling (mrmse) and the coefficient of determination ( $r^{2}$ ) of modelling $(mr^{2})$ were used to reflect the accuracy of the model. the results show that plsr has the poorest performance. ann has the highest modelling accuracy (mrmse = 7.387 g kg $^{-1}$ , $mr^{2}=0.446$ ). the ann prediction accuracy of rmse (prmse) is 4.713 g kg $^{-1}$ and the prediction accuracy of $r^{2}~(pr^{2})$ is 0.723. for svr, the prmse is 4.638 g kg $^{-1}$ , and the $pr^{2}$ is 0.732. the prediction accuracy of svr is slightly higher than that of ann. the spatial distribution of som demonstrates that the value obtained by ann is the closest to the range of the bare soil samples, and ann performs better in vegetation-covered areas. therefore, sentinel-2 can be used to estimate som content in urban areas, and ann is a promising method for som estimation."
        },
        {
            "id": "R171117",
            "label": "Longitudinal Intergenerational Birth Cohort Designs: A Systematic Review of Australian and New Zealand Studies",
            "doi": "10.1371/journal.pone.0150491",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background the longitudinal birth cohort design has yielded a substantial contribution to knowledge of child health and development. the last full review in new zealand and australia in 2004 identified 13 studies. since then, birth cohort designs continue to be an important tool in understanding how intrauterine, infant and childhood development affect long-term health and well-being. this updated review in a defined geographical area was conducted to better understand the factors associated with successful quality and productivity, and greater scientific and policy contribution and scope. methods we adopted the preferred reporting items for systematic reviews and meta-analyses (prisma) approach, searching pubmed, scopus, cinahl, medline, science direct and proquest between 1963 and 2013. experts were consulted regarding further studies. five inclusion criteria were used: (1) have longitudinally tracked a birth cohort, (2) have collected data on the child and at least one parent or caregiver (3) be based in australia or new zealand, (4) be empirical in design, and (5) have been published in english. results 10665 records were initially retrieved from which 23 birth cohort studies met the selection criteria. together these studies recruited 91,196 participants, with 38,600 mothers, 14,206 fathers and 38,390 live births. seventeen studies were located in australia and six in new zealand. research questions initially focused on the perinatal period, but as studies matured, longer-term effects and outcomes were examined. conclusions this review demonstrates the significant yield from this effort both in terms of scientific discovery and social policy impact. further opportunities have been recognised with cross-study collaboration and pooling of data between established and newer studies and international studies to investigate global health determinants."
        },
        {
            "id": "R168853",
            "label": "Objectively Measured Physical Activity and Fat Mass in a Large Cohort of Children",
            "doi": "10.1371/journal.pmed.0040097",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background previous studies have been unable to characterise the association between physical activity and obesity, possibly because most relied on inaccurate measures of physical activity and obesity. methods and findings we carried out a cross sectional analysis on 5,500 12-year-old children enrolled in the avon longitudinal study of parents and children. total physical activity and minutes of moderate and vigorous physical activity (mvpa) were measured using the actigraph accelerometer. fat mass and obesity (defined as the top decile of fat mass) were measured using the lunar prodigy dual x-ray emission absorptiometry scanner. we found strong negative associations between mvpa and fat mass that were unaltered after adjustment for total physical activity. we found a strong negative dose-response association between mvpa and obesity. the odds ratio for obesity in adjusted models between top and the bottom quintiles of minutes of mvpa was 0.03 (95% confidence interval [ci] 0.01\u20130.13, p-value for trend <0.0001) in boys and 0.36 (95% ci 0.17\u20130.74, p-value for trend = 0.006) in girls. conclusions we demonstrated a strong graded inverse association between physical activity and obesity that was stronger in boys. our data suggest that higher intensity physical activity may be more important than total activity."
        },
        {
            "id": "R185392",
            "label": "In-Pero: Exploiting Deep Learning Embeddings of Protein Sequences to Predict the Localisation of Peroxisomal Proteins",
            "doi": "10.3390/ijms22126409",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "peroxisomes are ubiquitous membrane-bound organelles, and aberrant localisation of peroxisomal proteins contributes to the pathogenesis of several disorders. many computational methods focus on assigning protein sequences to subcellular compartments, but there are no specific tools tailored for the sub-localisation (matrix vs. membrane) of peroxisome proteins. we present here in-pero, a new method for predicting protein sub-peroxisomal cellular localisation. in-pero combines standard machine learning approaches with recently proposed multi-dimensional deep-learning representations of the protein amino-acid sequence. it showed a classification accuracy above 0.9 in predicting peroxisomal matrix and membrane proteins. the method is trained and tested using a double cross-validation approach on a curated data set comprising 160 peroxisomal proteins with experimental evidence for sub-peroxisomal localisation. we further show that the proposed approach can be easily adapted (in-mito) to the prediction of mitochondrial protein localisation obtaining performances for certain classes of proteins (matrix and inner-membrane) superior to existing tools."
        },
        {
            "id": "R46346",
            "label": "Robust lexical features for improved neural network named-entity recognition",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46369",
                    "label": "Neural Network Named-Entity Recognition"
                },
                {
                    "id": "R46370",
                    "label": "Neural network approaches to Named-Entity Recognition"
                },
                {
                    "id": "R46371",
                    "label": "Named-Entity Recognition"
                },
                {
                    "id": "R46372",
                    "label": "NER"
                }
            ],
            "abstract": "neural network approaches to named-entity recognition reduce the need for carefully hand-crafted features. while some features do remain in state-of-the-art systems, lexical features have been mostly discarded, with the exception of gazetteers. in this work, we show that this is unfair: lexical features are actually quite useful. we propose to embed words and entity types into a low-dimensional vector space we train from annotated data produced by distant supervision thanks to wikipedia. from this, we compute \u2014 offline \u2014 a feature vector representing each word. when used with a vanilla recurrent neural network model, this representation yields substantial improvements. we establish a new state-of-the-art f1 score of 87.95 on ontonotes 5.0, while matching state-of-the-art performance with a f1 score of 91.73 on the over-studied conll-2003 dataset."
        },
        {
            "id": "R71532",
            "label": "Regression Analysis of ICT Impact Factors on Early Adolescents\u00e2\u0080\u0099 Reading Proficiency in Five High-Performing Countries",
            "doi": "10.3389/fpsyg.2019.01646",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "R70668",
                    "label": "ICT attitudes in PISA"
                }
            ],
            "abstract": "the popularity of information and communication technology (ict) has had a significant influence on the reading proficiency of early adolescents. achieving excellent reading proficiency, which is related not only to a student\u2019s inherent talent but also to various impact factors, can greatly enhance the effectiveness of reading education. the program for international student assessment (pisa) 2015 provides an international view on the reading proficiency of 15-year-olds in a computer-based testing environment. in this study, a multiple linear regression model was constructed using the computing language r to investigate the association between student-level ict impact factors (the availability of ict, the use of ict and attitudes toward ict) and reading proficiency among early adolescents. the sample included 37,155 15-year-olds from five representative countries with extremely high reading proficiency. the results showed that the students\u2019 ict-related attitudinal factors concerning their interest in ict and perceived autonomy in using ict, rather than ict availability and ict use, were closely associated with high reading proficiency. in addition, ict devices should be integrated not only as instructional media but also as a cognitive tool for teaching reading with timely and appropriate scrutiny."
        },
        {
            "id": "R168958",
            "label": "Social Transmission of Avoidance Behavior under Situational Change in Learned and Unlearned Rats",
            "doi": "10.1371/journal.pone.0006794",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background rats receive information from other conspecifics by observation or other types of social interaction. such social interaction may contribute to the effective adaptation to changes of environment such as situational switching. learning to avoid dangerous places or objects rapidly occurs with even a single conditioning session, and the conditioned memory tends to be sustained over long periods. the avoidance is important for adaptation, but the details of the conditions under which the social transmission of avoidance is formed are unknown. we demonstrate that the previous experience of avoidance learning is important for the formation of behaviors for social transmission of avoidance and that the experienced rats adapt to a change of situation determined by the presence or absence of aversive stimuli. we systematically investigated social influence on avoidance behavior using a passive avoidance test in a light/dark two-compartment apparatus. methodology/principal findings rats were divided into two groups, one receiving foot shocks and another with no aversive experience in a dark compartment. experienced and inexperienced rats were further divided into subjects and partners. in experiment 1, each subject experienced (1) interaction with an experienced partner, (2) interaction with an inexperienced partner, or (3) no interaction. in experiment 2, each subject experienced interaction with a partner that received a shock. the entering latency to a light compartment was measured. the avoidance behavior of experienced rats was inhibited by interaction with inexperienced or experienced partners in a safely-changed situation. the avoidance of experienced rats was reinstated in a dangerously-changed situation by interaction with shocked rats. in contrast, the inexperienced rats were not affected by any social circumstances. conclusions/significance these results suggest that transmitted information among rats can be updated under a situational change and that the previous experience is crucial for social enhancement and inhibition of avoidance behavior in rats."
        },
        {
            "id": "R195243",
            "label": "Rhetorical structure annotation of Chinese news commentaries",
            "doi": "",
            "research_field": {
                "id": "R323",
                "label": "Discourse/Text Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper reports a rhetorical structure annotation project to a chinese news commentary corpus caijingpinglun(cjpl) for the purpose of natural language processing.the elementary discourse unit(edu) in this project is defined as a string between two selected punctuation marks.and altogether 47 chinese rhetorical relations are defined to mark the nuclarity according to the classic rhetorical structure theory(rst).a 60-page annotation manual with detailed rules of edu segmentation,edu combination,relation and scheme tagging protocols are composed.analysis on the first manually annotated set of 97 texts shows that the rst has good cross-language transferability to chinese,and the data obtained from this project may be further exploited in chinese discourse processing."
        },
        {
            "id": "R108275",
            "label": "Consequences of Connectivity: Characterizing Account Hijacking on Twitter",
            "doi": "10.1145/2660267.2660282",
            "research_field": {
                "id": "R277",
                "label": "Computational Engineering"
            },
            "research_problems": [
                {
                    "id": "R108279",
                    "label": "Clustering Twitter spam from fraudulent accounts"
                }
            ],
            "abstract": "\"in this study we expose the serious large-scale threat of criminal account hijacking and the resulting damage incurred by users and web services. we develop a system for detecting large-scale attacks on twitter that identifies 14 million victims of compromise. we examine these accounts to track how attacks spread within social networks and to determine how criminals ultimately realize a profit from hijacked credentials. we find that compromise is a systemic threat, with victims spanning nascent, casual, and core users. even brief compromises correlate with 21% of victims never returning to twitter after the service wrests control of a victim's account from criminals. infections are dominated by social contagions---phishing and malware campaigns that spread along the social graph. these contagions mirror information diffusion and biological diseases, growing in virulence with the number of neighboring infections. based on the severity of our findings, we argue that early outbreak detection that stems the spread of compromise in 24 hours can spare 70% of victims.\""
        },
        {
            "id": "R198917",
            "label": "Mining Requirements Knowledge from Collections of Domain Documents",
            "doi": "10.1109/re.2016.50",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"when organizations enter domains that are entirely new to them, they need to invest significant time and effort to acquire domain knowledge. this typically involves searching through a broad set of domain documents, retrieving relevant ones, and analyzing the textual content in order to discover and specify pertinent requirements. depending on the nature of the domain and the availability of documentation, this task can be extremely time-consuming and may require non-trivial human effort. furthermore, the task must often be performed repeatedly throughout early phases of the project. in this paper we first explore the effort needed to manually build a high-level domain model capturing the functional components. we then present mark (mining requirements knowledge), which identifies and retrieves the documents containing descriptions of functional components in the domain model. domain analysts can use this information to to specify requirements. we introduce and evaluate an algorithm which ranks domain documents according to their relevance to a component and then highlights sections of text which are likely to contain requirements-related information. we describe our process within the context of the positive train control (ptc) domain with a repository of of 523 documents, representing 852mb of data. we empirically evaluate the mark relevance algorithm and its ability to retrieve relevant requirements knowledge for requirements related to ptc's on-board unit.\""
        },
        {
            "id": "R44446",
            "label": "Pharmacokinetics and toxicity of zonisamide in cats",
            "doi": "10.1016/j.jfms.2008.01.006 ",
            "research_field": {
                "id": "R77",
                "label": "Animal Sciences"
            },
            "research_problems": [
                {
                    "id": "R44421",
                    "label": "Antiepileptic drugs' safety and effectiveness"
                }
            ],
            "abstract": "with the eventual goal of making zonisamide (zns), a relatively new antiepileptic drug, available for the treatment of epilepsy in cats, the pharmacokinetics after a single oral administration at 10 mg/kg and the toxicity after 9-week daily administration of 20 mg/kg/day of zns were studied in healthy cats. pharmacokinetic parameters obtained with a single administration of zns at 10 mg/day were as follows: c max =13.1 \u03bcg/ml; t max =4.0 h; t 1/2 =33.0 h; areas under the curves (aucs)=720.3 \u03bcg/mlh (values represent the medians). the study with daily administrations revealed that the toxicity of zns was comparatively low in cats, suggesting that it may be an available drug for cats. however, half of the cats that were administered 20 mg/kg/day daily showed adverse reactions such as anorexia, diarrhoea, vomiting, somnolence and locomotor ataxia."
        },
        {
            "id": "R170331",
            "label": "Induction of Empathy by the Smell of Anxiety",
            "doi": "10.1371/journal.pone.0005987",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the communication of stress/anxiety between conspecifics through chemosensory signals has been documented in many vertebrates and invertebrates. here, we investigate how chemosensory anxiety signals conveyed by the sweat of humans (n\\u200a=\\u200a49) awaiting an academic examination are processed by the human brain, as compared to chemosensory control signals obtained from the same sweat donors in a sport condition. the chemosensory stimuli were pooled according to the donation condition and administered to 28 participants (14 males) synchronously to breathing via an olfactometer. the stimuli were perceived with a low intensity and accordingly only about half of the odor presentations were detected by the participants. the fmri results (event-related design) show that chemosensory anxiety signals activate brain areas involved in the processing of social emotional stimuli (fusiform gyrus), and in the regulation of empathic feelings (insula, precuneus, cingulate cortex). in addition, neuronal activity within attentional (thalamus, dorsomedial prefrontal cortex) and emotional (cerebellum, vermis) control systems were observed. the chemosensory perception of human anxiety seems to automatically recruit empathy-related resources. even though the participants could not attentively differentiate the chemosensory stimuli, emotional contagion seems to be effectively mediated by the olfactory system."
        },
        {
            "id": "R46391",
            "label": "A parallel-hierarchical model for machine comprehension on sparse data",
            "doi": "10.18653/v1/p16-1041",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46401",
                    "label": "Machine Comprehension on Sparse Data"
                },
                {
                    "id": "R46402",
                    "label": "Understanding unstructured text"
                },
                {
                    "id": "R46403",
                    "label": "machine comprehension on the challenging MCTest benchmark"
                },
                {
                    "id": "R46404",
                    "label": "Comprehension of unstructured text by machines , at a near- human level"
                },
                {
                    "id": "R46405",
                    "label": "Machine comprehension"
                },
                {
                    "id": "R46406",
                    "label": "MC"
                }
            ],
            "abstract": "understanding unstructured text is a major goal within natural language processing. comprehension tests pose questions based on short text passages to evaluate such understanding. in this work, we investigate machine comprehension on the challenging {\\\\it mctest} benchmark. partly because of its limited size, prior work on {\\\\it mctest} has focused mainly on engineering better features. we tackle the dataset with a neural approach, harnessing simple neural networks arranged in a parallel hierarchy. the parallel hierarchy enables our model to compare the passage, question, and answer from a variety of trainable perspectives, as opposed to using a manually designed, rigid feature set. perspectives range from the word level to sentence fragments to sequences of sentences; the networks operate only on word-embedding representations of text. when trained with a methodology designed to help cope with limited training data, our parallel-hierarchical model sets a new state of the art for {\\\\it mctest}, outperforming previous feature-engineered approaches slightly and previous neural approaches by a significant margin (over 15\\\\% absolute)."
        },
        {
            "id": "R194884",
            "label": "Extraction of System States from Natural Language Requirements",
            "doi": "10.1109/re.2019.00031",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in recent years, simulations have proven to be an important means to verify the behavior of complex software systems. the different states of a system are monitored in the simulations and are compared against the requirements specification. so far, system states in natural language requirements cannot be automatically linked to signals from the simulation. however, the manual mapping between requirements and simulation is a time-consuming task. named-entity recognition is a sub-task from the field of automated information retrieval and is used to classify parts of natural language texts into categories. in this paper, we use a self-trained named-entity recognition model with bidirectional lstms and cnns to extract states from requirements specifications. we present an almost entirely automated approach and an iterative semi-automated approach to train our model. the automated and iterative approach are compared and discussed with respect to the usual manual extraction. we show that the manual extraction of states in 2,000 requirements takes nine hours. our automated approach achieves an f1-score of 0.51 with 15 minutes of manual work and the iterative approach achieves an f1-score of 0.62 with 100 minutes of work."
        },
        {
            "id": "R160584",
            "label": "Spectral angle mapper and object-based classification combined with hyperspectral remote sensing imagery for obtaining land use/cover mapping in a Mediterranean region",
            "doi": "10.1080/10106049.2012.668950",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R160545",
                    "label": "Spectral angle mapper for Land use Land cover mapping"
                }
            ],
            "abstract": "in this study, we test the potential of two different classification algorithms, namely the spectral angle mapper (sam) and object-based classifier for mapping the land use/cover characteristics using a hyperion imagery. we chose a study region that represents a typical mediterranean setting in terms of landscape structure, composition and heterogeneous land cover classes. accuracy assessment of the land cover classes was performed based on the error matrix statistics. validation points were derived from visual interpretation of multispectral high resolution quickbird-2 satellite imagery. results from both the classifiers yielded more than 70% classification accuracy. however, the object-based classification clearly outperformed the sam by 7.91% overall accuracy (oa) and a relatively high kappa coefficient. similar results were observed in the classification of the individual classes. our results highlight the potential of hyperspectral remote sensing data as well as object-based classification approach for mapping heterogeneous land use/cover in a typical mediterranean setting."
        },
        {
            "id": "R201004",
            "label": "Fusion of Multiple Lidars and Inertial Sensors for the Real-Time Pose Tracking of Human Motion",
            "doi": "10.3390/s20185342",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "today, enhancement in sensing technology enables the use of multiple sensors to track human motion/activity precisely. tracking human motion has various applications, such as fitness training, healthcare, rehabilitation, human-computer interaction, virtual reality, and activity recognition. therefore, the fusion of multiple sensors creates new opportunities to develop and improve an existing system. this paper proposes a pose-tracking system by fusing multiple three-dimensional (3d) light detection and ranging (lidar) and inertial measurement unit (imu) sensors. the initial step estimates the human skeletal parameters proportional to the target user\u2019s height by extracting the point cloud from lidars. next, imus are used to capture the orientation of each skeleton segment and estimate the respective joint positions. in the final stage, the displacement drift in the position is corrected by fusing the data from both sensors in real time. the installation setup is relatively effortless, flexible for sensor locations, and delivers results comparable to the state-of-the-art pose-tracking system. we evaluated the proposed system regarding its accuracy in the user\u2019s height estimation, full-body joint position estimation, and reconstruction of the 3d avatar. we used a publicly available dataset for the experimental evaluation wherever possible. the results reveal that the accuracy of height and the position estimation is well within an acceptable range of \u00b13\u20135 cm. the reconstruction of the motion based on the publicly available dataset and our data is precise and realistic."
        },
        {
            "id": "R200098",
            "label": "Detecting repurposing and over-collection in multi-party privacy requirements specifications",
            "doi": "10.1109/re.2015.7320419",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "mobile and web applications increasingly leverage service-oriented architectures in which developers integrate third-party services into end user applications. this includes identity management, mapping and navigation, cloud storage, and advertising services, among others. while service reuse reduces development time, it introduces new privacy and security risks due to data repurposing and over-collection as data is shared among multiple parties who lack transparency into third-party data practices. to address this challenge, we propose new techniques based on description logic (dl) for modeling multiparty data flow requirements and verifying the purpose specification and collection and use limitation principles, which are prominent privacy properties found in international standards and guidelines. we evaluate our techniques in an empirical case study that examines the data practices of the waze mobile application and three of their service providers: facebook login, amazon web services (a cloud storage provider), and flurry.com (a popular mobile analytics and advertising platform). the study results include detected conflicts and violations of the principles as well as two patterns for balancing privacy and data use flexibility in requirements specifications. analysis of automation reasoning over the dl models show that reasoning over complex compositions of multi-party systems is feasible within exponential asymptotic timeframes proportional to the policy size, the number of expressed data, and orthogonal to the number of conflicts found."
        },
        {
            "id": "R196436",
            "label": "The Interplay of Cross-Situational Word Learning and Sentence-Level Constraints",
            "doi": "10.1111/cogs.12178",
            "research_field": {
                "id": "R324",
                "label": "First/Second Language Acquisition"
            },
            "research_problems": [
                {
                    "id": "R196445",
                    "label": "CSWL and SLCL application in word learning processes"
                }
            ],
            "abstract": "\"a variety of mechanisms contribute to word learning. learners can track co-occurring words and referents across situations in a bottom-up manner (cross-situational word learning, cswl). equally, they can exploit sentential contexts, relying on top-down information such as verb-argument relations and world knowledge, offering immediate constraints on meaning (word learning based on sentence-level constraints, slcl). when combined, cswl and slcl potentially modulate each other's influence, revealing how word learners deal with multiple mechanisms simultaneously: do they use all mechanisms? prefer one? is their strategy context dependent? three experiments conducted with adult learners reveal that learners prioritize slcl over cswl. cswl is applied in addition to slcl only if slcl is not perfectly disambiguating, thereby complementing or competing with it. these studies demonstrate the importance of investigating word-learning mechanisms simultaneously, revealing important characteristics of their interaction in more naturalistic learning environments.\""
        },
        {
            "id": "R75311",
            "label": "Estimating Selectivity for Joined RDF Triple Patterns",
            "doi": "10.1145/2063576.2063784",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R75732",
                    "label": "SPARQL query optimization"
                }
            ],
            "abstract": "a fundamental problem related to rdf query processing is selectivity estimation, which is crucial to query optimization for determining a join order of rdf triple patterns. in this paper we focus research on selectivity estimation for sparql graph patterns. the previous work takes the join uniformity assumption when estimating the joined triple patterns. this assumption would lead to highly inaccurate estimations in the cases where properties in sparql graph patterns are correlated. we take into account the dependencies among properties in sparql graph patterns and propose a more accurate estimation model. since star and chain query patterns are common in sparql graph patterns, we first focus on these two basic patterns and propose to use bayesian network and chain histogram respectively for estimating the selectivity of them. then, for estimating the selectivity of an arbitrary sparql graph pattern, we design algorithms for maximally using the precomputed statistics of the star paths and chain paths. the experiments show that our method outperforms existing approaches in accuracy."
        },
        {
            "id": "R168999",
            "label": "A First- and Second-Order Motion Energy Analysis of Peripheral Motion Illusions Leads to Further Evidence of \u00e2\u0080\u009cFeature Blur\u00e2\u0080\u009d in Peripheral Vision",
            "doi": "10.1371/journal.pone.0018719",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background anatomical and physiological differences between the central and peripheral visual systems are well documented. recent findings have suggested that vision in the periphery is not just a scaled version of foveal vision, but rather is relatively poor at representing spatial and temporal phase and other visual features. shapiro, lu, huang, knight, and ennis (2010) have recently examined a motion stimulus (the \u201ccurveball illusion\u201d) in which the shift from foveal to peripheral viewing results in a dramatic spatial/temporal discontinuity. here, we apply a similar analysis to a range of other spatial/temporal configurations that create perceptual conflict between foveal and peripheral vision. methodology/principal findings to elucidate how the differences between foveal and peripheral vision affect super-threshold vision, we created a series of complex visual displays that contain opposing sources of motion information. the displays (referred to as the peripheral escalator illusion, peripheral acceleration and deceleration illusions, rotating reversals illusion, and disappearing squares illusion) create dramatically different perceptions when viewed foveally versus peripherally. we compute the first-order and second-order directional motion energy available in the displays using a three-dimensional fourier analysis in the (x, y, t) space. the peripheral escalator, acceleration and deceleration illusions and rotating reversals illusion all show a similar trend: in the fovea, the first-order motion energy and second-order motion energy can be perceptually separated from each other; in the periphery, the perception seems to correspond to a combination of the multiple sources of motion information. the disappearing squares illusion shows that the ability to assemble the features of kanisza squares becomes slower in the periphery. conclusions/significance the results lead us to hypothesize \u201cfeature blur\u201d in the periphery (i.e., the peripheral visual system combines features that the foveal visual system can separate). feature blur is of general importance because humans are frequently bringing the information in the periphery to the fovea and vice versa."
        },
        {
            "id": "R75689",
            "label": "Diet Quality of Malaysians across Lifespan: A Scoping Review of Evidence in a Multi-Ethnic Population",
            "doi": "10.3390/nu13041380",
            "research_field": {
                "id": "R96",
                "label": "Nutritional Epidemiology"
            },
            "research_problems": [
                {
                    "id": "R75694",
                    "label": "Dietary patterns and obesity"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "malaysia is a rapidly developing economy experiencing a nutrition transition. it suffers from a double burden of over- and undernutrition, making it essential to understand diet quality in the population. in this scoping review, we have collated the existing literature on malaysian diet quality, including factors that influence it, and the association between diet quality and health outcomes across the lifespan of malaysians. overall, diet quality was poor in all age groups studied. the healthy eating index (hei) and its iterations were predominantly used in urban and clinical settings to evaluate diet-chronic disease relationships. these indices were significantly associated with cardio-metabolic and disease risks in adults. the diet diversity score (dds) and food variety score (fvs) were used to gauge diet quality in maternal and child nutrition studies and were associated with appropriate growth and caloric intake. deficiencies were found in fruit, vegetable, legumes, and dairy intake. meat, salt, and sugar intake were found to be excessive in many studies. the findings can inform policies to improve diet quality in this population. the review also identified knowledge gaps that require further investigation."
        },
        {
            "id": "R129773",
            "label": "Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R117118",
                    "label": "Machine Translation"
                }
            ],
            "abstract": "we propose a conditional non-autoregressive neural sequence model based on iterative refinement. the proposed model is designed based on the principles of latent variable models and denoising autoencoders, and is generally applicable to any sequence generation task. we extensively evaluate the proposed model on machine translation (en-de and en-ro) and image caption generation, and observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart."
        },
        {
            "id": "R178362",
            "label": "Clay-Based Nanocomposite Coating for Flexible Optoelectronics Applying Commercial Polymers",
            "doi": "10.1021/nn400713e",
            "research_field": {
                "id": "R137665",
                "label": "Coating and Surface Technology"
            },
            "research_problems": [
                {
                    "id": "R178356",
                    "label": "Barrier properties of nanocomposite coating"
                }
            ],
            "abstract": "transparency, flexibility, and especially ultralow oxygen (otr) and water vapor (wvtr) transmission rates are the key issues to be addressed for packaging of flexible organic photovoltaics and organic light-emitting diodes. concomitant optimization of all essential features is still a big challenge. here we present a thin (1.5 \u03bcm), highly transparent, and at the same time flexible nanocomposite coating with an exceptionally low otr and wvtr (1.0 \u00d7 10(-2) cm(3) m(-2) day(-1) bar(-1) and <0.05 g m(-2) day(-1) at 50% rh, respectively). a commercially available polyurethane (desmodur n 3600 and desmophen 670 ba, bayer materialscience ag) was filled with a delaminated synthetic layered silicate exhibiting huge aspect ratios of about 25,000. functional films were prepared by simple doctor-blading a suspension of the matrix and the organophilized clay. this preparation procedure is technically benign, is easy to scale up, and may readily be applied for encapsulation of sensitive flexible electronics."
        },
        {
            "id": "R175051",
            "label": "The transition of\n            ARVO\n            journals to open access",
            "doi": "10.1002/leap.1338",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R175062",
                    "label": "Open access page view advantage"
                },
                {
                    "id": "R175040",
                    "label": "Open access download advantage"
                }
            ],
            "abstract": "in january 2016, the three journals of the association for research in vision and ophthalmology (arvo) transitioned to gold open access. increased author charges were introduced to partially offset the loss of subscription revenue. submissions to the two established journals initially dropped by almost 15% but have now stabilized. the transition has not impacted acceptance rates and impact factors, and article pageviews and downloads may have increased as a result of open access."
        },
        {
            "id": "R169943",
            "label": "Personality in the cockroach Diploptera punctata: Evidence for stability across developmental stages despite age effects on boldness",
            "doi": "10.1371/journal.pone.0176564",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "despite a recent surge in the popularity of animal personality studies and their wide-ranging associations with various aspects of behavioural ecology, our understanding of the development of personality over ontogeny remains poorly understood. stability over time is a central tenet of personality; ecological pressures experienced by an individual at different life stages may, however, vary considerably, which may have a significant effect on behavioural traits. invertebrates often go through numerous discrete developmental stages and therefore provide a useful model for such research. here we test for both differential consistency and age effects upon behavioural traits in the gregarious cockroach diploptera punctata by testing the same behavioural traits in both juveniles and adults. in our sample, we find consistency in boldness, exploration and sociality within adults whilst only boldness was consistent in juveniles. both boldness and exploration measures, representative of risk-taking behaviour, show significant consistency across discrete juvenile and adult stages. age effects are, however, apparent in our data; juveniles are significantly bolder than adults, most likely due to differences in the ecological requirements of these life stages. size also affects risk-taking behaviour since smaller adults are both bolder and more highly explorative. whilst a behavioural syndrome linking boldness and exploration is evident in nymphs, this disappears by the adult stage, where links between other behavioural traits become apparent. our results therefore indicate that differential consistency in personality can be maintained across life stages despite age effects on its magnitude, with links between some personality traits changing over ontogeny, demonstrating plasticity in behavioural syndromes."
        },
        {
            "id": "R209304",
            "label": "Regional Climate Sensitivity of Climate Extremes in CMIP6 Versus CMIP5 Multimodel Ensembles",
            "doi": "10.1029/2019ef001474",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we analyze projected changes in climate extremes (extreme temperatures and heavy precipitation) in the multimodel ensembles of the fifth and sixth coupled model intercomparison projects (cmip5 and cmip6). the results reveal close similarity between both ensembles in the regional climate sensitivity of the projected multimodel mean changes in climate extremes, that is, their projected changes as a function of global warming. this stands in contrast to widely reported divergences in global (transient and equilibrium) climate sensitivity in the two multimodel ensembles. some exceptions include higher warming in the south america monsoon region, lower warming in southern asia and central africa, and higher increases in heavy precipitation in western africa and the sahel region in the cmip6 ensemble. the multimodel spread in regional climate sensitivity is found to be large in both ensembles. in particular, it contributes more to intermodel spread in projected regional climate extremes compared with the intermodel spread in global climate sensitivity in cmip6. our results highlight the need to consider regional climate sensitivity as a distinct feature of earth system models and a key determinant of projected regional impacts, which is largely independent of the models' response in global climate sensitivity."
        },
        {
            "id": "R170311",
            "label": "Socioeconomic risk markers of leprosy in high-burden countries: A systematic review and meta-analysis",
            "doi": "10.1371/journal.pntd.0006622",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "over 200,000 new cases of leprosy are detected each year, of which approximately 7% are associated with grade-2 disabilities (g2ds). for achieving leprosy elimination, one of the main challenges will be targeting higher risk groups within endemic communities. nevertheless, the socioeconomic risk markers of leprosy remain poorly understood. to address this gap we systematically reviewed medline/pubmed, embase, lilacs and web of science for original articles investigating the social determinants of leprosy in countries with > 1000 cases/year in at least five years between 2006 and 2016. cohort, case-control, cross-sectional, and ecological studies were eligible for inclusion; qualitative studies, case reports, and reviews were excluded. out of 1,534 non-duplicate records, 96 full-text articles were reviewed, and 39 met inclusion criteria. 17 were included in random-effects meta-analyses for sex, occupation, food shortage, household contact, crowding, and lack of clean (i.e., treated) water. the majority of studies were conducted in brazil, india, or bangladesh while none were undertaken in low-income countries. descriptive synthesis indicated that increased age, poor sanitary and socioeconomic conditions, lower level of education, and food-insecurity are risk markers for leprosy. additionally, in pooled estimates, leprosy was associated with being male (rr = 1.33, 95% ci = 1.06\u20131.67), performing manual labor (rr = 2.15, 95% ci = 0.97\u20134.74), suffering from food shortage in the past (rr = 1.39, 95% ci = 1.05\u20131.85), being a household contact of a leprosy patient (rr = 3.40, 95% ci = 2.24\u20135.18), and living in a crowded household (\u22655 per household) (rr = 1.38, 95% ci = 1.14\u20131.67). lack of clean water did not appear to be a risk marker of leprosy (rr = 0.94, 95% ci = 0.65\u20131.35). additionally, ecological studies provided evidence that lower inequality, better human development, increased healthcare coverage, and cash transfer programs are linked with lower leprosy risks. these findings point to a consistent relationship between leprosy and unfavorable economic circumstances and, thereby, underscore the pressing need of leprosy control policies to target socially vulnerable groups in high-burden countries."
        },
        {
            "id": "R74414",
            "label": "Open educational practices and resources based on social software, UTPL experience",
            "doi": "10.1145/1551722.1551756",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74406",
                    "label": "Open Education"
                },
                {
                    "id": "R109069",
                    "label": "Open Education"
                }
            ],
            "abstract": "open educational resources (oer) are a direct reaction to knowledge privatization; they foment their exchange to the entire world with the aim of increase the human intellectual capacity.in this document, we describe the committment of universidad t\u00e9cnica particular de loja (utpl), ecuador, in the promotion of open educational practices and resources and their impact in society and knowledge economy through the use of social software."
        },
        {
            "id": "R161635",
            "label": "Extremely Stretchable Strain Sensors Based on Conductive Self-Healing Dynamic Cross-Links Hydrogels for Human-Motion Detection",
            "doi": "10.1002/advs.201600190",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R161622",
                    "label": "Development of wearable sensors"
                }
            ],
            "abstract": "extremely stretchable self\u2010healing strain sensors based on conductive hydrogels are successfully fabricated. the strain sensor can achieve autonomic self\u2010heal electrically and mechanically under ambient conditions, and can sustain extreme elastic strain (1000%) with high gauge factor of 1.51. furthermore, the strain sensors have good response, signal stability, and repeatability under various human motion detections."
        },
        {
            "id": "R49115",
            "label": "Extreme sea level implications of 1.5\u00e2\u0080\u0089\u00c2\u00b0C, 2.0\u00e2\u0080\u0089\u00c2\u00b0C, and 2.5\u00e2\u0080\u0089\u00c2\u00b0C temperature stabilization targets in the 21st and 22nd centuries",
            "doi": "10.1088/1748-9326/aaac87",
            "research_field": {
                "id": "R169",
                "label": "Climate"
            },
            "research_problems": [
                {
                    "id": "R48245",
                    "label": "Global Mean Sea Level Rise Projections"
                }
            ],
            "abstract": "sea-level rise (slr) is magnifying the frequency and severity of extreme sea levels (esls) that can cause coastal flooding. the rate and amount of global mean sea-level (gmsl) rise is a function of the trajectory of global mean surface temperature (gmst). therefore, temperature stabilization targets (e.g. 1.5\\u2009\u00b0c and 2.0\\u2009\u00b0c of warming above pre-industrial levels, as from the paris agreement) have important implications for coastal flood risk. here, we assess, in a global network of tide gauges, the differences in the expected frequencies of esls between scenarios that stabilize gmst warming at 1.5\\u2009\u00b0c, 2.0\\u2009\u00b0c, and 2.5\\u2009\u00b0c above pre-industrial levels. we employ probabilistic, localized slr projections and long-term hourly tide gauge records to estimate the expected frequencies of historical and future esls for the 21st and 22nd centuries. by 2100, under 1.5\\u2009\u00b0c, 2.0\\u2009\u00b0c, and 2.5\\u2009\u00b0c gmst stabilization, the median gmsl is projected to rise 48\\u2009cm (90% probability of 28\u201382\\u2009cm), 56\\u2009cm (28\u201396\\u2009cm), and 58\\u2009cm (37\u201393\\u2009cm), respectively. as an independent comparison, a semi-empirical sea level model calibrated to temperature and gmsl over the past two millennia estimates median gmsl rise within 7\u20138\\u2009cm of these projections. by 2150, relative to the 2.0\\u2009\u00b0c scenario and based on median sea level projections, gmst stabilization of 1.5\\u2009\u00b0c spares the inundation of lands currently home to about 5\\u2009million people, including 60\\u2009000 individuals currently residing in small island developing states. we quantify projected changes to the expected frequency of historical 10-, 100-, and 500-year esl events using frequency amplification factors that incorporate uncertainty in both local slr and historical return periods of esls. by 2150, relative to a 2.0\\u2009\u00b0c scenario, the reduction in the frequency amplification of the historical 100\\u2009year esl event arising from a 1.5\\u2009\u00b0c gmst stabilization is greatest in the eastern united states, with esl event frequency amplification being reduced by about half at most tide gauges. in general, smaller reductions are projected for small island developing states."
        },
        {
            "id": "R170498",
            "label": "Mental Health Problems among the Survivors in the Hard-Hit Areas of the Yushu Earthquake",
            "doi": "10.1371/journal.pone.0046449",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background on april 14, 2010, an earthquake registering 7.1 on the richter scale shook qinghai province in southwest china. the earthquake caused numerous casualties and much damage. the epicenter, yushu county, suffered the most severe damage. as a part of the psychological relief work, the present study evaluated the mental health statuses of the people affected and identified the mental disorder risk factors related to earthquakes. methods five hundred and five earthquake survivors living in yushu county were investigated 3\u20134 months after the earthquake. participant demographic data including gender, age, marital status, ethnicity, educational level, and religious beliefs were collected. the earthquake-specific trauma exposure indicators assessed the intensity of exposure to trauma during the earthquake. the ptsd checklist-civilian version (pcl-c) and the hopkins symptoms checklist-25 (hscl-25) assessed the symptoms and prevalence rates of probable posttraumatic stress disorder (ptsd) as well as anxiety and depression, respectively. the perceived social support scale (psss) evaluated subjective social support. results the prevalence rates of probable ptsd, anxiety, and depression were 33.7%, 43.8% and 38.6%, respectively. approximately one fifth of participants suffered from all three conditions. individuals who were female, felt initial fear during the earthquake, and had less social support were the most likely to have poor mental health. conclusions the present study revealed that there are serious mental problems among the hard\u2013hit survivors of the yushu earthquake. survivors at high risk for mental disorders should be specifically considered. the present study provides useful information for rebuilding and relief work."
        },
        {
            "id": "R145355",
            "label": "Monitoring Out-of-State Patients during a 2017 Hurricane Response using ESSENCE",
            "doi": "10.5210/ojphi.v10i1.8936",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "objective to demonstrate the use of essence in the biosense platform to monitor out-of-state patients seeking emergency healthcare in tennessee during hurricanes harvey and irma. introduction syndromic surveillance is the monitoring of symptom combinations (i.e., syndromes) or other indicators within a population to inform public health actions. the tennessee department of health (tdh) collects emergency department (ed) data from more than 70 hospitals across tennessee to support statewide syndromic surveillance activities. hospitals in tennessee typically provide data within 48 hours of a patient encounter. while syndromic surveillance often supplements disease- or condition-specific surveillance, it can also provide general situational awareness about emergency department patients during an event or response. during hurricanes harvey (continental us landfall on august 25, 2017) and irma (continental us landfall on september 10, 2017), tdh supported all hazards situational awareness using the electronic surveillance system for the early notification of community-based epidemics (essence) in the biosense platform supported by the national syndromic surveillance program (nssp). the volume of out-of-state patients in tennessee was monitored to assess the impact on the healthcare system and any geographic- or hospital-specific clustering of out-of-state patients within tennessee. results were included in daily state health operations center (shoc) situation reports and shared with agency response partners such as the tennessee emergency management agency (tema). methods data were monitored from august 18, 2017 through september 24, 2017. a simple query was established in essence using the patient location (full details) dataset. data were limited to hospital ed visits reported by tennessee (site = \u201ctennessee\u201d). to monitor ed visits among residents of texas before, during, and after major hurricane harvey, data were queried for a patient zip code within texas (state = \u201ctexas\u201d). ed visits among florida residents were monitored similarly (state = \u201cflorida\u201d) before, during, and after major hurricane irma. additionally, a free text chief complaint search was implemented for the terms \u201charvey\u201d, \u201cirma, \u201churricane\u201d, \u201cevacuee\u201d, \u201cevacuate\u201d, \u201cflorida\u201d, and \u201ctexas\u201d. chief complaint search results were then filtered to remove encounters with patient zip codes within tennessee. results from august 18, 2017 through september 24, 2017, tennessee hospital eds reported 277 patient encounters among texas residents and 1,041 patient encounters among florida residents. the number of encounters among patients from texas remained stable throughout the monitoring period. in contrast, the number of encounters among patients from florida exceeded the expected value on september 7, peaked september 10 at 116 patient encounters, and returned to expected levels on september 16 (figure 1). the increase in patients from florida was evenly distributed across most of tennessee, with some clustering around a popular tourism area in east tennessee. no concerning trends in reported syndromes or chief complaints were identified among texas or florida patients. the free text chief complaint query first exceeded the expected value on september 9, peaked on september 11 with 5 patient encounters, and returned to expected levels on september 14. from august 18 through september 24, 21 of 30 visits captured by the query were among florida residents. one tennessee hospital appeared to be intentionally using the term \u201cirma\u201d in their chief complaint field to indicate patients from florida impacted by the hurricane. conclusions the essence instance in the biosense platform provided tdh the opportunity to easily locate and monitor out-of-state patients seen in tennessee hospital eds. while tdh was unable to validate whether all patients identified as residents of florida were displaced because of major hurricane irma, the timing of the rise and fall of patient encounters was highly suggestive. likewise, seeing no substantial increase ed patients with residence in texas reassured tdh that the effects of hurricane harvey were not impacting hospital emergency departments in tennessee. tdh used information and charts from essence to support situational awareness in our shoc and at tema. use of patient zip code to identify out-of-state residents was more sensitive than chief complaint searches by keyword during this event. essence allowed tdh to see where out-of-state patients appeared to be concentrating in tennessee and monitor the need for targeting messaging and resources to heavily affected areas. additionally, close surveillance of chief complaints among out-of-state patients provided assurance that no unusual patterns in illness or injury were occurring. essence is the only tdh information source capable of rapidly collecting health information on out-of-state patients. essence allowed tdh to quickly identify a change within the patient population seen at tennessee emergency departments and monitor the situation until the patient population returned to baseline levels."
        },
        {
            "id": "R109211",
            "label": "Mining cardinalities from knowledge bases",
            "doi": "10.1007/978-3-319-64468-4_34",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R107644",
                    "label": "Data Quality"
                },
                {
                    "id": "R109210",
                    "label": "Constraint validation"
                }
            ],
            "abstract": ". cardinality is an important structural aspect of data that has not received enough attention in the context of rdf knowledge bases (kbs). information about cardinalities can be useful for data users and knowledge engineers when writing queries, reusing or engineering kbs. such cardinalities can be declared using owl and rdf constraint languages as constraints on the usage of properties over instance data. however, their declaration is optional and consistency with the instance data is not ensured. in this paper, we address the problem of mining cardinality bounds for properties to discover structural characteristics of kbs, and use these bounds to assess completeness. because kbs are incomplete and error-prone, we apply statistical methods for \ufb01ltering property usage and for \ufb01nding accurate and robust patterns. accuracy of the cardinality patterns is ensured by properly handling equality axioms (owl:sameas); and robustness by \ufb01ltering outliers. we report an implementation of our algorithm with two variants using sparql 1.1 and apache spark, and their evaluation on real-world and synthetic data."
        },
        {
            "id": "R170060",
            "label": "Nurses\u00e2\u0080\u0099 professional competency and organizational commitment: Is it important for human resource management?",
            "doi": "10.1371/journal.pone.0187863",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"background professional competency is a fundamental concept in nursing, which has a direct relationship with quality improvement of patient care and public health. organizational commitment as a kind of affective attachment or sense of loyalty to the organization is an effective factor for professional competency. objective this study was conducted to evaluate the nurses\u00b4 professional competency and their organizational commitment as well as the relationship between these two concepts. methods and materials this descriptive-analytic study was conducted at the hospitals affiliated with a university of medical sciences, in the southeast of iran in 2016. the sample included 230 nurses who were selected using stratified random sampling. data were gathered by three questionnaires including socio-demographic information, competency inventory for registered nurse (cirn) and allen meyer's organizational commitment. results results showed that professional competency (mean\u00b1sd: 2.82\u00b10.53, range: 1.56\u20134.00) and organizational commitment (mean\u00b1sd: 72.80\u00b14.95, range: 58\u201381) of the nurses were at moderate levels. there was no statistically significant correlation between professional competency and organizational commitment (\u03c1 = 0.02; p = 0.74). there were significant differences in professional competency based on marital status (p = 0.03) and work experience (p<0.001). conclusion the results highlighted that the nurses needed to be more competent and committed to their organizations. developing professional competency and organizational commitment is vital, but not easy. this study suggests that human resource managers should pursue appropriate strategies to enhance the professional competency and organizational commitment of their nursing staff. it is necessary to conduct more comprehensive studies for exploring the status and gaps in the human resource management of healthcare in different cultures and contexts.\""
        },
        {
            "id": "R186148",
            "label": "Learning Sequence Encoders for Temporal Knowledge Graph Completion",
            "doi": "10.18653/v1/d18-1516",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "research on link prediction in knowledge graphs has mainly focused on static multi-relational data. in this work we consider temporal knowledge graphs where relations between entities may only hold for a time interval or a specific point in time. in line with previous work on static knowledge graphs, we propose to address this problem by learning latent entity and relation type representations. to incorporate temporal information, we utilize recurrent neural networks to learn time-aware representations of relation types which can be used in conjunction with existing latent factorization methods. the proposed approach is shown to be robust to common challenges in real-world kgs: the sparsity and heterogeneity of temporal expressions. experiments show the benefits of our approach on four temporal kgs. the data sets are available under a permissive bsd-3 license."
        },
        {
            "id": "R170683",
            "label": "Feasibility of Recruiting a Diverse Sample of Men Who Have Sex with Men: Observation from Nanjing, China",
            "doi": "10.1371/journal.pone.0077645",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background respondent-driven-sampling (rds) has well been recognized as a method for sampling from most hard-to-reach populations like commercial sex workers, drug users and men who have sex with men. however the feasibility of this sampling strategy in terms of recruiting a diverse spectrum of these hidden populations has not been understood well yet in developing countries. methods in a cross sectional study in nanjing city of jiangsu province of china, 430 msm were recruited including 9 seeds in 14 weeks of study period using rds. information regarding socio-demographic characteristics and sexual risk behavior were collected and testing was done for hiv and syphilis. duration, completion, participant characteristics and the equilibrium of key factors were used for assessing feasibility of rds. homophily of key variables, socio-demographic distribution and social network size were used as the indicators of diversity. results in the study sample, adjusted hiv and syphilis prevalence were 6.6% and 14.6% respectively. majority (96.3%) of the participants were recruited by members of their own social network. although there was a tendency for recruitment within the same self-identified group (homosexuals recruited 60.0% homosexuals), considerable cross-group recruitment (bisexuals recruited 52.3% homosexuals) was also seen. homophily of the self-identified sexual orientations was 0.111 for homosexuals. upon completion of the recruitment process, participant characteristics and the equilibrium of key factors indicated that rds was feasible for sampling msm in nanjing. participants recruited by rds were found to be diverse after assessing the homophily of key variables in successive waves of recruitment, the proportion of characteristics after reaching equilibrium and the social network size. the observed design effects were nearly the same or even better than the theoretical design effect of 2. conclusion rds was found to be an efficient and feasible sampling method for recruiting a diverse sample of msm in a reasonable time."
        },
        {
            "id": "R171228",
            "label": "A Heat Vulnerability Index: Spatial Patterns of Exposure, Sensitivity and Adaptive Capacity for Santiago de Chile",
            "doi": "10.1371/journal.pone.0162464",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "climate change will worsen the high levels of urban vulnerability in latin american cities due to specific environmental stressors. some impacts of climate change, such as high temperatures in urban environments, have not yet been addressed through adaptation strategies, which are based on poorly supported data. these impacts remain outside the scope of urban planning. new spatially explicit approaches that identify highly vulnerable urban areas and include specific adaptation requirements are needed in current urban planning practices to cope with heat hazards. in this paper, a heat vulnerability index is proposed for santiago, chile. the index was created using a gis-based spatial information system and was constructed from spatially explicit indexes for exposure, sensitivity and adaptive capacity levels derived from remote sensing data and socio-economic information assessed via principal component analysis (pca). the objective of this study is to determine the levels of heat vulnerability at local scales by providing insights into these indexes at the intra city scale. the results reveal a spatial pattern of heat vulnerability with strong variations among individual spatial indexes. while exposure and adaptive capacities depict a clear spatial pattern, sensitivity follows a complex spatial distribution. these conditions change when examining pca results, showing that sensitivity is more robust than exposure and adaptive capacity. these indexes can be used both for urban planning purposes and for proposing specific policies and measures that can help minimize heat hazards in highly dynamic urban areas. the proposed methodology can be applied to other latin american cities to support policy making."
        },
        {
            "id": "R170352",
            "label": "Virtue or Pretense? Looking behind Self-Declared Innocence in Doping",
            "doi": "10.1371/journal.pone.0010457",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"background social science studies of doping practices in sport rely predominantly on self-reports. studies of psychoactive drug use indicate that self-reporting is characterised by under-reporting. likewise doping practice is likely to be equally under-reported, if not more so. this calls for more sophisticated methods for such reporting and for independent, objective validation of its results. the aims of this study were: i) to contrast self-reported doping use with objective results from chemical hair analysis and ii) to investigate the influence of the discrepancy on doping attitudes, social projection, descriptive norms and perceived pressure to use doping. methodology/principal findings a doping attitudes questionnaire was developed and combined with a response latency-based implicit association test and hair sample analysis for key doping substances in 14 athletes selected from a larger sample (n\\u200a=\\u200a82) to form contrast comparison groups. results indicate that patterns of group differences in social projection, explicit attitude about and perceived pressure to use doping, vary depending on whether the user and non-user groups are defined by self-report or objectively verified through hair analysis. thus, self-confessed users scored higher on social projection, explicit attitude to doping and perceived pressure. however, when a doping substance was detected in the hair of an athlete who denied doping use, their self-report evidenced extreme social desirability (negative attitude, low projection and low perceived pressure) and contrasted sharply with a more positive estimate of their implicit doping attitude. conclusions/significance hair analysis for performance enhancing substances has shown considerable potential in validating athletes' doping attitude estimations and admissions of use. results not only confirm the need for improved self-report methodology for future research in socially-sensitive domains but also indicate where the improvements are likely to come from: as chemical validation remains expensive, a more realistic promise for large scale studies and online data collection efforts is held by measures of implicit social cognition.\""
        },
        {
            "id": "R169108",
            "label": "A Quantitative Assay for the Juvenile Hormones and Their Precursors Using Fluorescent Tags",
            "doi": "10.1371/journal.pone.0043784",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background the juvenile hormones (jhs) are sesquiterpenoid compounds that play a central role in insect reproduction, development and behavior. the lipophilic nature of jhs and their precursors, in conjunction with their low concentration in tissues and susceptibility to degradation had made their quantification difficult. a variety of methods exist for jh quantification but few can quantify on the femtomole range. currently applied methods are expensive and time consuming. in the present study we sought to develop a novel method for accurate detection and quantification of jhs and their precursors. methods a sensitive and robust method was developed to quantify the precursor, farnesoic acid (fa) and juvenile hormone iii (jh iii) in biological samples. the assay is based on the derivatization of analytes with fluorescent tags, with subsequent analysis by reverse phase high performance liquid chromatography coupled to a fluorescent detector (hplc-fd). the carboxyl group of fa was derivatized with 4-acetamido-7-mercapto-2,1,3-benzoxadiazole (aabd-sh). tagging the epoxide group of jh iii required a two-step reaction: the opening of the epoxide ring with sodium sulfide and derivatization with the fluorescent tag 4-(n,n-dimethylaminosulfonyl)-7-(n-chloroformylmethyl-n-methylamino)-2,1,3-benzoxadiazole (dbd-cocl). conclusions the method developed in the present study showed high sensitivity, accuracy and reproducibility. linear responses were obtained over the range of 10\u201320 to 1000 fmols. recovery efficiencies were over 90% for jh iii and 98% for fa with excellent reproducibility. significance the proposed method is applicable when sensitive detection and accurate quantification of limited amount of sample is needed. examples include corpora allata, hemolymph and whole body of female adult aedes aegypti and whole body drosophila melanogaster. a variety of additional functional groups can be targeted to add fluorescent tags to the remaining jh iii precursors."
        },
        {
            "id": "R171113",
            "label": "BDNF Val66Met Polymorphism Is Associated with Self-Reported Empathy",
            "doi": "10.1371/journal.pone.0149911",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "empathy is an important driver of human social behaviors and presents genetic roots that have been studied in neuroimaging using the intermediate phenotype approach. notably, the val66met polymorphism of the brain-derived neurotrophic factor (bdnf) gene has been identified as a potential target in neuroimaging studies based on its influence on emotion perception and social cognition, but its impact on self-reported empathy has never been documented. using a neurogenetic approach, we investigated the association between the bdnf val66met polymorphism and self-reported empathy (davis\u2019 interpersonal reactivity index; iri) in a sample of 110 young adults. our results indicate that the bdnf genotype is significantly associated with the linear combination of the four facets of the iri, one of the most widely used self-reported empathy questionnaire. crucially, the effect of bdnf val66met goes beyond the variance explained by two polymorphisms of the oxytocin transporter gene previously associated with empathy and its neural underpinnings (oxtr rs53576 and rs2254298). these results represent the first evidence suggesting a link between the bdnf gene and self-reported empathy and warrant further studies of this polymorphism due to its potential clinical significance."
        },
        {
            "id": "R150258",
            "label": "Mobile technologies for disease surveillance in humans and animals",
            "doi": "10.4102/ojvr.v81i2.737",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "a paper-based disease reporting system has been associated with a number of challenges.\\xa0these include difficulties to submit hard copies of the disease surveillance forms because\\xa0of poor road infrastructure, weather conditions or challenging terrain, particularly in the\\xa0developing countries. the system demands re-entry of the data at data processing and\\xa0analysis points, thus making it prone to introduction of errors during this process. all these\\xa0challenges contribute to delayed acquisition, processing and response to disease events\\xa0occurring in remote hard to reach areas. our study piloted the use of mobile phones in\\xa0order to transmit near to real-time data from remote districts in tanzania (ngorongoro and\\xa0ngara), burundi (muyinga) and zambia (kazungula and sesheke). two technologies namely,\\xa0digital and short messaging services were used to capture and transmit disease event data\\xa0in the animal and human health sectors in the study areas based on a server\u2013client model.\\xa0smart phones running the android operating system (minimum required version: android\\xa01.6), and which supported open source application, epicollect, as well as the open data kit\\xa0application, were used in the study. these phones allowed collection of geo-tagged data, with\\xa0the opportunity of including static and moving images related to disease events. the project\\xa0supported routine disease surveillance systems in the ministries responsible for animal and\\xa0human health in burundi, tanzania and zambia, as well as data collection for researchers at\\xa0the sokoine university of agriculture, tanzania. during the project implementation period\\xa0between 2011 and 2013, a total number of 1651 diseases event-related forms were submitted,\\xa0which allowed reporters to include gps coordinates and photographs related to the events\\xa0captured. it was concluded that the new technology-based surveillance system is useful in\\xa0providing near to real-time data, with potential for enhancing timely response in rural remote\\xa0areas of africa. we recommended adoption of the proven technologies to improve disease\\xa0surveillance, particularly in the developing countries."
        },
        {
            "id": "R129390",
            "label": "Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R116569",
                    "label": "Relation Extraction"
                }
            ],
            "abstract": "a relation tuple consists of two entities and the relation between them, and often such tuples are found in unstructured text. there may be multiple relation tuples present in a text and they may share one or both entities among them. extracting such relation tuples from a sentence is a difficult task and sharing of entities or overlapping entities among the tuples makes it more challenging. most prior work adopted a pipeline approach where entities were identified first followed by finding the relations among them, thus missing the interaction among the relation tuples in a sentence. in this paper, we propose two approaches to use encoder-decoder architecture for jointly extracting entities and relations. in the first approach, we propose a representation scheme for relation tuples which enables the decoder to generate one word at a time like machine translation models and still finds all the tuples present in a sentence with full entity names of different length and with overlapping entities. next, we propose a pointer network-based decoding approach where an entire tuple is generated at every time step. experiments on the publicly available new york times corpus show that our proposed approaches outperform previous work and achieve significantly higher f1 scores."
        },
        {
            "id": "R130420",
            "label": "Simple and Effective Multi-Paragraph Reading Comprehension",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R2061",
                    "label": "Question Answering"
                }
            ],
            "abstract": "we introduce a method of adapting neural paragraph-level question answering models to the case where entire documents are given as input. most current question answering models cannot scale to document or multi-document input, and naively applying these models to each paragraph independently often results in them being distracted by irrelevant text. we show that it is possible to significantly improve performance by using a modified training scheme that teaches the model to ignore non-answer containing paragraphs. our method involves sampling multiple paragraphs from each document, and using an objective function that requires the model to produce globally correct output. we additionally identify and improve upon a number of other design decisions that arise when working with document-level data. experiments on triviaqa and squad shows our method advances the state of the art, including a 10 point gain on triviaqa."
        },
        {
            "id": "R78301",
            "label": "Petroleum Hydrocarbons Contamination of Surface Water and Groundwater in the Niger Delta Region of Nigeria",
            "doi": "10.12691/jephh-6-2-2",
            "research_field": {
                "id": "R125",
                "label": "Environmental Chemistry"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "petroleum hydrocarbons contamination of the environment associated with exploration, development and production operations is a common feature in oil producing nations around the world, especially in a developing country like nigeria where the incidence of facilities sabotage, operational failures, accidental discharges, pipeline vandalization and leakages, bunkering and artisanal refining is very common. apart from poor governance systems, poor corporate social responsibility (csr) of multinational oil companies (mocs), poor environmental regulation of the petroleum industry, the inability of the political elite to effectively manage petroleum hydrocarbon-derived revenue, loss of petroleum hydrocarbons resource revenue to corruption and theft, petroleum hydrocarbons contamination of the total environment (air, soil, water and biota) have impacted negatively on the human health and wellbeing of oil producing communities in the nigeria\u2019s niger delta region. findings from several studies have revealed variable negative impacts of petroleum hydrocarbons toxicity on the human health (including exposed populations), the natural environment and other ecological receptors. over the past fifty\u2013five years, the oil producing host communities in the nigeria\u2019s niger delta region have experienced a wide range of environmental pollution, degradation, human health risks, deterioration of our cultural heritage items and socio\u2013economic problems as a result of various activities associated with petroleum exploration, development and production. petroleum hydrocarbons contamination of surface water and groundwater is a notable environmental and human health problem in the oil producing communities and there are several water quality issues in the nigeria\u2019s niger delta region. this review examines some of the water quality issues and human health implications of petroleum hydrocarbons contamination of controlled water sources (surface-water and groundwater) in the oil producing host communities in the nigeria\u2019s niger delta region. it will further highlight some of the problems of petroleum hydrocarbons contamination and/or pollution of marine environments associated with unsustainable practices of petroleum industry in the region."
        },
        {
            "id": "R171524",
            "label": "Social determinants of pulmonary tuberculosis treatment non-adherence in Rio de Janeiro, Brazil",
            "doi": "10.1371/journal.pone.0190578",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "success in tuberculosis control depends on the implementation of steps that reduce social inequities, allowing the diagnosis and effective treatment of the disease. little is known about the conditions affecting antituberculosis treatment non-adherence in areas of great social and economic heterogeneity, such as the municipality of rio de janeiro. this study aimed to describe and identify the social determinants of antituberculosis treatment non-adherence in the municipality of rio de janeiro between 2008 and 2012. an ecological study was conducted with the districts of rio de janeiro as the units of analysis. analyzes using poisson regression models allowed us to identify the association between dropout from antituberculosis treatment and the human development index and social development index. the final model showed that economic conditions, infrastructure, and the tuberculosis control quality of surveillance were associated with treatment non-adherence. this study demonstrated that the scenarios of socio-environmental precariousness found in the districts of rio de janeiro were able to identify populations with an increased risk of default treatment from antituberculosis."
        },
        {
            "id": "R155375",
            "label": "Sensitive Electronic-Skin Strain Sensor Array Based on the Patterned Two-Dimensional \u00ce\u00b1-In2Se3",
            "doi": "10.1021/acs.chemmater.6b01073",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R155374",
                    "label": "Performance of strain sensors based on 2D materials "
                }
            ],
            "abstract": "two-dimensional (2d) layered semiconductors have emerged as a highly attractive class of materials for flexible and wearable strain sensor-centric devices such as electronic-skin (e-skin). this is primarily due to their dimensionality, excellent mechanical flexibility, and unique electronic properties. however, the lack of effective and low-cost methods for wafer-scale fabrication of these materials for strain sensor arrays limits their potential for such applications. here, we report growth of large-scale 2d in2se3 nanosheets by templated chemical vapor deposition (cvd) method, using in2o3 and se powders as precursors. the strain sensors fabricated from the as-grown 2d in2se3 films show 2 orders of magnitude higher sensitivity (gauge factor \u223c237 in \u22120.39% to 0.39% uniaxial strain range along the device channel length) than what has been demonstrated from conventional metal-based (gauge factor: \u223c1\u20135) and graphene-based strain sensors (gauge factor: \u223c2\u20134) in a similar uniaxial strain range. the integrated ..."
        },
        {
            "id": "R74127",
            "label": "ISO-Standardized Smart City Platform Architecture and Dashboard",
            "doi": "10.1109/mprv.2017.31",
            "research_field": {
                "id": "R342",
                "label": "Urban Studies"
            },
            "research_problems": [
                {
                    "id": "R74148",
                    "label": "Indicators for a smart city"
                },
                {
                    "id": "R74152",
                    "label": "Smart City's dashboards creation"
                },
                {
                    "id": "R74272",
                    "label": "City dashboards"
                },
                {
                    "id": "R74277",
                    "label": "Standard for city services"
                }
            ],
            "abstract": "a concept guided by the iso 37120 standard for city services and quality of life is suggested as unified framework for smart city dashboards. the slow (annual, quarterly, or monthly) iso 37120 indicators are enhanced and complemented with more detailed and person-centric indicators that can further accelerate the transition toward smart cities. the architecture supports three tasks: acquire and manage data from heterogeneous sensors; process data originated from heterogeneous sources (sensors, opendata, social data, blogs, news, and so on); and implement such collection and processing on the cloud. a prototype application based on the proposed architecture concept is developed for the city of skopje, macedonia. this article is part of a special issue on smart cities."
        },
        {
            "id": "R110142",
            "label": "Do Animals Engage Greater Social Attention in Autism? An Eye Tracking Analysis",
            "doi": "10.3389/fpsyg.2020.00727",
            "research_field": {
                "id": "R346",
                "label": "Cognition and Perception"
            },
            "research_problems": [
                {
                    "id": "R110153",
                    "label": "Gaze Duration"
                }
            ],
            "abstract": "background visual atypicalities in autism spectrum disorder (asd) are a well documented phenomenon, beginning as early as 2\u20136 months of age and manifesting in a significantly decreased attention to the eyes, direct gaze and socially salient information. early emerging neurobiological deficits in perceiving social stimuli as rewarding or its active avoidance due to the anxiety it entails have been widely purported as potential reasons for this atypicality. parallel research evidence also points to the significant benefits of animal presence for reducing social anxiety and enhancing social interaction in children with autism. while atypicality in social attention in asd has been widely substantiated, whether this atypicality persists equally across species types or is confined to humans has not been a key focus of research insofar. methods we attempted a comprehensive examination of the differences in visual attention to static images of human and animal faces (40 images; 20 human faces and 20 animal faces) among children with asd using an eye tracking paradigm. 44 children (asd n = 21; td n = 23) participated in the study (10,362 valid observations) across five regions of interest (left eye, right eye, eye region, face and screen). results results obtained revealed significantly greater social attention across human and animal stimuli in typical controls when compared to children with asd. however in children with asd, a significantly greater attention allocation was seen to animal faces and eye region and lesser attention to the animal mouth when compared to human faces, indicative of a clear attentional preference to socially salient regions of animal stimuli. the positive attentional bias toward animals was also seen in terms of a significantly greater visual attention to direct gaze in animal images. conclusion our results suggest the possibility that atypicalities in social attention in asd may not be uniform across species. it adds to the current neural and biomarker evidence base of the potentially greater social reward processing and lesser social anxiety underlying animal stimuli as compared to human stimuli in children with asd."
        },
        {
            "id": "R170985",
            "label": "The Majority of the Migrant Factory Workers of the Light Industry in Shenzhen, China May Be Physically Inactive",
            "doi": "10.1371/journal.pone.0131734",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "physical inactivity is a strong risk factor of non-communicable diseases (ncd). in china, there are 250 million migrant factory workers, who are susceptible to physical inactivity and hence ncd because of work nature and setting. with random stratified sampling, 807 such workers of the light industry were recruited in shenzhen, china and completed a self-administered questionnaire with informed consent. the prevalence of inadequate physical activity (defined according to the world health organization\u2019s recommendation on level of moderate/vigorous physical activity) was 95.4%. of all participants, 69.1% showed \u201ca very low level of physical activity\u201d (vllpa), defined as \u226430 minutes of weekly moderate/vigorous physical activity, which was significantly associated with female sex (odds ratio [or]=1.65), lower education level (or=0.10 to 0.33, primary education as the reference group) and married status (or=0.63, single status as the reference group). adjusted for these factors, perceived social support (adjusted or=0.87) was negatively associated with vllpa, while job stress due to workload, which was significant in the univariate analysis (or=0.98), became non-significant (p=0.184). significant interaction between perceived social support and perceived job stress onto vllpa was found (p=0.044), implying that the negative association between job stress and vllpa, which might reflect a potential response to cope with stress by performing exercises, was stronger among those with weaker social support. the extremely low level of physical activity rings an alarm, as it implies high risk of ncd, and as there are no existing programs promoting physical activity in this group. interventions need to take into account social support, potential coping to job stress, and structural factors of the factory setting, while involving factories\u2019 management."
        },
        {
            "id": "R170506",
            "label": "Hepatitis C Virus Phylogenetic Clustering Is Associated with the Social-Injecting Network in a Cohort of People Who Inject Drugs",
            "doi": "10.1371/journal.pone.0047335",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "it is hypothesized that social networks facilitate transmission of the hepatitis c virus (hcv). we tested for association between hcv phylogeny and reported injecting relationships using longitudinal data from a social network design study. people who inject drugs were recruited from street drug markets in melbourne, australia. interviews and blood tests took place three monthly (during 2005\u20132008), with participants asked to nominate up to five injecting partners at each interview. the hcv core region of individual isolates was then sequenced and phylogenetic trees were constructed. genetic clusters were identified using bootstrapping (cut-off: 70%). an adjusted jaccard similarity coefficient was used to measure the association between the reported injecting relationships and relationships defined by clustering in the phylogenetic analysis (statistical significance assessed using the quadratic assignment procedure). 402 participants consented to participate; 244 hcv infections were observed in 238 individuals. 26 genetic clusters were identified, with 2\u20137 infections per cluster. newly acquired infection (aor\\u200a=\\u200a2.03, 95% ci: 1.04\u20133.96, p\\u200a=\\u200a0.037, and hcv genotype 3 (vs. genotype 1, aor\\u200a=\\u200a2.72, 95% ci: 1.48\u20134.99) were independent predictors of being in a cluster. 54% of participants whose infections were part of a cluster in the phylogenetic analysis reported injecting with at least one other participant in that cluster during the study. overall, 16% of participants who were infected at study entry and 40% of participants with newly acquired infections had molecular evidence of related infections with at least one injecting partner. likely transmission clusters identified in phylogenetic analysis correlated with reported injecting relationships (adjusted jaccard coefficient: 0.300; p<0.001). this is the first study to show that hcv phylogeny is associated with the injecting network, highlighting the importance of the injecting network in hcv transmission."
        },
        {
            "id": "R171150",
            "label": "Influence of Socio-Economic Inequalities on Access to Renal Transplantation and Survival of Patients with End-Stage Renal Disease",
            "doi": "10.1371/journal.pone.0153431",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background public and scientific concerns about the social gradient of end-stage renal disease and access to renal replacement therapies are increasing. this study investigated the influence of social inequalities on the (i) access to renal transplant waiting list, (ii) access to renal transplantation and (iii) patients\u2019 survival. methods all incident adult patients with end-stage renal disease who lived in bretagne, a french region, and started dialysis during the 2004\u20132009 period were geocoded in census-blocks. to each census-block was assigned a level of neighborhood deprivation and a degree of urbanization. cox proportional hazards models were used to identify factors associated with each study outcome. results patients living in neighborhoods with low level of deprivation had more chance to be placed on the waiting list and less risk of death (hr = 1.40 95%ci: [1.1\u20131.7]; hr = 0.82 95%ci: [0.7\u20130.98]), but this association did not remain after adjustment for the patients\u2019 clinical features. the likelihood of receiving renal transplantation after being waitlisted was not associated with neighborhood deprivation in univariate and multivariate analyses. conclusions in a mixed rural and urban french region, patients living in deprived or advantaged neighborhoods had the same chance to be placed on the waiting list and to undergo renal transplantation. they also showed the same mortality risk, when their clinical features were taken into account."
        },
        {
            "id": "R171106",
            "label": "Tuberculosis Mortality and Living Conditions in Bern, Switzerland, 1856-1950",
            "doi": "10.1371/journal.pone.0149195",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background tuberculosis (tb) is a poverty-related disease that is associated with poor living conditions. we studied tb mortality and living conditions in bern between 1856 and 1950. methods we analysed cause-specific mortality based on mortality registers certified by autopsies, and public health reports 1856 to 1950 from the city council of bern. results tb mortality was higher in the black quarter (550 per 100,000) and in the city centre (327 per 100,000), compared to the outskirts (209 per 100,000 in 1911\u20131915). tb mortality correlated positively with the number of persons per room (r = 0.69, p = 0.026), the percentage of rooms without sunlight (r = 0.72, p = 0.020), and negatively with the number of windows per apartment (r = -0.79, p = 0.007). tb mortality decreased 10-fold from 330 per 100,000 in 1856 to 33 per 100,000 in 1950, as housing conditions improved, indoor crowding decreased, and open-air schools, sanatoria, systematic tuberculin skin testing of school children and chest radiography screening were introduced. conclusions improved living conditions and public health measures may have contributed to the massive decline of the tb epidemic in the city of bern even before effective antibiotic treatment became finally available in the 1950s."
        },
        {
            "id": "R109629",
            "label": "Hep-CORE: a cross-sectional study of the viral hepatitis policy environment reported by patient groups in 25 European countries in 2016 and 2017",
            "doi": "10.1002/jia2.25052",
            "research_field": {
                "id": "R31",
                "label": "Public Health"
            },
            "research_problems": [
                {
                    "id": "R109635",
                    "label": "National viral hepatitis response"
                },
                {
                    "id": "R109636",
                    "label": "hepatitis C health policies"
                }
            ],
            "abstract": "the first world health organization (who) global health sector strategy on hepatitis b and c viruses (hbv and hcv) has called for the elimination of viral hepatitis as a major public health threat by 2030. this study assesses policies and programmes in support of elimination efforts as reported by patient groups in europe."
        },
        {
            "id": "R171053",
            "label": "Human Social Behavior and Demography Drive Patterns of Fine-Scale Dengue Transmission in Endemic Areas of Colombia",
            "doi": "10.1371/journal.pone.0144451",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "dengue is known to transmit between humans and a. aegypti mosquitoes living in neighboring houses. although transmission is thought to be highly heterogeneous in both space and time, little is known about the patterns and drivers of transmission in groups of houses in endemic settings. we carried out surveys of pcr positivity in children residing in 2-block patches of highly endemic cities of colombia. we found high levels of heterogeneity in pcr positivity, varying from less than 30% in 8 of the 10 patches to 56 and 96%, with the latter patch containing 22 children simultaneously pcr positive (pcr22) for den2. we then used an agent-based model to assess the likely eco-epidemiological context of this observation. our model, simulating daily dengue dynamics over a 20 year period in a single two block patch, suggests that the observed heterogeneity most likely derived from variation in the density of susceptible people. two aspects of human adaptive behavior were critical to determining this density: external social relationships favoring viral introduction (by susceptible residents or infectious visitors) and immigration of households from non-endemic areas. external social relationships generating frequent viral introduction constituted a particularly strong constraint on susceptible densities, thereby limiting the potential for explosive outbreaks and dampening the impact of heightened vectorial capacity. dengue transmission can be highly explosive locally, even in neighborhoods with significant immunity in the human population. variation among neighborhoods in the density of local social networks and rural-to-urban migration is likely to produce significant fine-scale heterogeneity in dengue dynamics, constraining or amplifying the impacts of changes in mosquito populations and cross immunity between serotypes."
        },
        {
            "id": "R193165",
            "label": "Human motion synthesis from 3D video",
            "doi": "10.1109/CVPR.2009.5206626",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R128713",
                    "label": "motion synthesis"
                }
            ],
            "abstract": "multiple view 3d video reconstruction of actor performance captures a level-of-detail for body and clothing movement which is time-consuming to produce using existing animation tools. in this paper we present a framework for concatenative synthesis from multiple 3d video sequences according to user constraints on movement, position and timing. multiple 3d video sequences of an actor performing different movements are automatically constructed into a surface motion graph which represents the possible transitions with similar shape and motion between sequences without unnatural movement artifacts. shape similarity over an adaptive temporal window is used to identify transitions between 3d video sequences. novel 3d video sequences are synthesized by finding the optimal path in the surface motion graph between user specified key-frames for control of movement, location and timing. the optimal path which satisfies the user constraints whilst minimizing the total transition cost between 3d video sequences is found using integer linear programming. results demonstrate that this framework allows flexible production of novel 3d video sequences which preserve the detailed dynamics of the captured movement for an actress with loose clothing and long hair without visible artifacts."
        },
        {
            "id": "R140600",
            "label": "SemEval-2007 Task 12: Turkish Lexical Sample Task",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140603",
                    "label": "Turkish Lexical Sample Task"
                }
            ],
            "abstract": "this paper presents the task definition, resources, and the single participant system for task 12: turkish lexical sample task (tlst), which was organized in the semeval-2007 evaluation exercise. the methodology followed for developing the specific linguistic resources necessary for the task has been described in this context. a language-specific feature set was defined for turkish. tlst consists of three pieces of data: the dictionary, the training data, and the evaluation data. finally, a single system that utilizes a simple statistical method was submitted for the task and evaluated."
        },
        {
            "id": "R138166",
            "label": "Stratigraphy of the Von K\u00c3\u00a1rm\u00c3\u00a1n Crater Based on Chang'E\u00e2\u0080\u00904 Lunar Penetrating Radar Data",
            "doi": "10.1029/2020GL088680",
            "research_field": {
                "id": "R138056",
                "label": "Planetary Sciences"
            },
            "research_problems": [
                {
                    "id": "R138165",
                    "label": "Stratigraphy of the Von Karman Crater using Lunar Penetrating Radar Data"
                }
            ],
            "abstract": "\"the chang'e\u20104 (ce\u20104) achieved the first successful soft landing on the floor of the von k\u00e1rm\u00e1n crater located in the northeast of the south pole\u2010aitken (spa) basin on the moon. here, through analysis and processing of the dual\u2010channel lunar penetrating radar (lpr) data, the shallow regolith structure and deep geological strata below the landing site are exposed. the high\u2010frequency data (ch\u20102, 500 mhz) show that the von k\u00e1rm\u00e1n crater underwent remodeling because of ejecta from multiple craters within a thickness of 40 m. under the surface fine\u2010grained regolith, superpositions among these crater materials and mare basalt units establish shallow regolith stratigraphic sequences. the low\u2010frequency data (ch\u20101, 60 mhz) show a deep stratigraphic structure to the depth of 360 m that indicates the previous geological evolution history of the von k\u00e1rm\u00e1n crater. the lpr results provide an important scientific basis for understanding the geological history of the far side of the moon.\""
        },
        {
            "id": "R75825",
            "label": "Evidence-Based Decision-Making (Part II): Applications in Disaster Relief Operations",
            "doi": "10.1017/s1049023x0000738x",
            "research_field": {
                "id": "R31",
                "label": "Public Health"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract recognized limitations to data in disaster management have led to dozens of initiatives to strengthen data gathering and decision-making during disasters. these initiatives are complicated by fundamental problems of definitions of terms, ambiguity of concepts, lack of standardization in methods of data collection, and inadequate attempts to strengthen the analytic capability of field organizations. cross-cutting issues in needs assessment, coordination, and evaluation illustrate additional recurring challenges in dealing with evidence in humanitarian assistance. these challenges include lack of agency expertise, dyscoordination at the field level, inappropriate reliance on indicators that measure process rather than outcome, flawed scientific inference, and erosion of the concept of minimum standards. decision-making in disaster management currently places a premium on expert or eminence-based decisions. by contrast, scientific advances in disaster medicine call for evidence-based decisions whose strength of evidence is established by the methods of data acquisition. at present, disaster relief operations may be data driven, but that does not mean that they are soundly evidence-based. options for strengthening evidence-based activities include rigorously adhering to evidenced-based interventions, using evidence-based tools to identify new approaches to problems of concern, studying model programs as well as failed ones to identify approaches that deserve replication, and improving standards for evidence of effectiveness in disaster science and services."
        },
        {
            "id": "R171267",
            "label": "How Are Gender Equality and Human Rights Interventions Included in Sexual and Reproductive Health Programmes and Policies: A Systematic Review of Existing Research Foci and Gaps",
            "doi": "10.1371/journal.pone.0167542",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the importance of promoting gender equality and human rights in sexual and reproductive health (srh) programmes and policies has been affirmed in numerous international and regional agreements, most recently the 2030 agenda for sustainable development. given the critical role of research to determine what works, we aimed to identify research gaps as part of a broader priority setting exercise on integrating gender equality and human rights approaches in srh programmes and policies. a systematic literature review of reviews was conducted to examine the question: what do we know about how research in the context of srh programmes and policies has addressed gender equality and human rights and what are the current gaps in research. we searched three databases for reviews that addressed the research question, were published between 1994\u20132014, and met methodological standards for systematic reviews, qualitative meta-syntheses and other reviews of relevance to the research question. additional grey literature was identified based on expert input. articles were appraised by the primary author and examined by an expert panel. an abstraction and thematic analysis process was used to synthesize findings. of the 3,073 abstracts identified, 56 articles were reviewed in full and 23 were included along with 10 from the grey literature. the majority focused on interventions addressing gender inequalities; very few reviews explicitly included human rights based interventions. across both topics, weak study designs and use of intermediate outcome measures limited evidence quality. further, there was limited evidence on interventions that addressed marginalized groups. better quality studies, longer-term indicators, and measurement of unintended consequences are needed to better understand the impact of these types of interventions on srh outcomes. further efforts are needed to cover research on gender equality and human rights issues as they pertain to a broader set of srh topics and populations."
        },
        {
            "id": "R169174",
            "label": "Resting-State Connectivity of the Sustained Attention Network Correlates with Disease Duration in Idiopathic Generalized Epilepsy",
            "doi": "10.1371/journal.pone.0050359",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction in idiopathic generalized epilepsy (ige), a normal electroencephalogram between generalized spike and wave (gsw) discharges is believed to reflect normal brain function. however, some studies indicate that even excluding gsw-related errors, ige patients perform poorly on sustained attention task, the deficit being worse as a function of disease duration. we hypothesized that at least in a subset of structures which are normally involved in sustained attention, resting-state functional connectivity (fc) is different in ige patients compared to controls and that some of the changes are related to disease duration. method seeds were selected based on a sustained attention study in controls. resting-state functional magnetic resonance imaging (fmri) data was obtained from 14 ige patients and 14 matched controls. after physiological noise removal, the mean time-series of each seed was used as a regressor in a general linear model to detect regions that showed correlation with the seed. in patients, duration factor was defined based on epilepsy duration. between-group differences weighted by the duration factor were evaluated with mixed-effects model. correlation was then evaluated in ige patients between the fc, averaged over each significant cluster, and the duration factor. results eight of 18 seeds showed significant difference in fc across groups. however, only for seeds in the medial superior frontal and precentral gyri and in the medial prefrontal area, average fc taken over significant clusters showed high correlation with the duration factor. these 3 seeds showed changes in fc respectively with the premotor and superior frontal gyrus, the dorsal premotor, and the supplementary motor area plus precentral gyrus. conclusion alterations of fc in ige patients are not limited to the frontal areas. however, as indicated by specificity analysis, patients with long history of disease show changes in fc mainly within the frontal areas."
        },
        {
            "id": "R186740",
            "label": "Systematic Dissection of the Evolutionarily Conserved WetA Developmental Regulator across a Genus of Filamentous Fungi",
            "doi": "10.1128/mbio.01130-18",
            "research_field": {
                "id": "R106",
                "label": "Systems Biology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n \\n asexual sporulation is fundamental to the ecology and lifestyle of filamentous fungi and can facilitate both plant and human infection. in\\n aspergillus \\n , the production of asexual spores is primarily governed by the brla\u2192abaa\u2192weta regulatory cascade. the final step in this cascade is controlled by the weta protein and governs not only the morphological differentiation of spores but also the production and deposition of diverse metabolites into spores. while weta is conserved across the genus\\n aspergillus \\n , the structure and degree of conservation of the\\n weta \\n gene regulatory network (grn) remain largely unknown. we carried out comparative transcriptome analyses of comparisons between\\n weta \\n null mutant and wild-type asexual spores in three representative species spanning the diversity of the genus\\n aspergillus \\n :\\n a.\\xa0nidulans \\n ,\\n a.\\xa0flavus \\n , and\\n a.\\xa0fumigatus \\n . we discovered that weta regulates asexual sporulation in all three species via a negative-feedback loop that represses brla, the cascade\u2019s first step. furthermore, data from chromatin immunoprecipitation sequencing (chip-seq) experiments in\\n a.\\xa0nidulans \\n asexual spores suggest that weta is a dna-binding protein that interacts with a novel regulatory motif. several global regulators known to bridge spore production and the production of secondary metabolites show species-specific regulatory patterns in our data. these results suggest that the brla\u2192abaa\u2192weta cascade\u2019s regulatory role in cellular and chemical asexual spore development is functionally conserved but that the\\n weta \\n -associated grn has diverged during\\n aspergillus \\n evolution.\\n \\n \\n importance \\n the formation of resilient spores is a key factor contributing to the survival and fitness of many microorganisms, including fungi. in the fungal genus\\n aspergillus \\n , spore formation is controlled by a complex gene regulatory network that also impacts a variety of other processes, including secondary metabolism. to gain mechanistic insights into how fungal spore formation is controlled across\\n aspergillus \\n , we dissected the gene regulatory network downstream of a major regulator of spore maturation (weta) in three species that span the diversity of the genus: the genetic model\\n a.\\xa0nidulans \\n , the human pathogen\\n a.\\xa0fumigatus \\n , and the aflatoxin producer\\n a.\\xa0flavus \\n . our data show that weta regulates asexual sporulation in all three species via a negative-feedback loop and likely binds a novel regulatory element that we term the weta response element (wre). these results shed light on how gene regulatory networks in microorganisms control important biological processes and evolve across diverse species.\\n"
        },
        {
            "id": "R160158",
            "label": "Nitrous oxide emissions from the Arabian Sea: A synthesis",
            "doi": "10.5194/acp-1-61-2001",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R160135",
                    "label": "N2O gas emission estimation from the Indian Ocean"
                }
            ],
            "abstract": "abstract. we computed high-resolution (1\u00ba latitude x\\xa0 1\u00ba longitude) seasonal and annual nitrous oxide (n2o) concentration fields for the arabian sea surface layer using a database containing more than 2400 values measured between december 1977 and july 1997. n2o concentrations are highest during the southwest (sw) monsoon along the southern indian continental shelf. annual emissions range from 0.33 to 0.70 tg n2o and are dominated by fluxes from coastal regions during the sw and northeast monsoons. our revised estimate for the annual n2o flux from the arabian sea is much more tightly constrained than the previous consensus derived using averaged in-situ data from a smaller number of studies. however, the tendency to focus on measurements in locally restricted features in combination with insufficient seasonal data coverage leads to considerable uncertainties of the concentration fields and thus in the flux estimates, especially in the coastal zones of the northern and eastern arabian sea. the overall mean relative error of the annual n2o emissions from the arabian sea was estimated to be at least 65%.\\n"
        },
        {
            "id": "R170269",
            "label": "Crowd vocal learning induces vocal dialects in bats: Playback of conspecifics shapes fundamental frequency usage by pups",
            "doi": "10.1371/journal.pbio.2002556",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"vocal learning, the substrate of human language acquisition, has rarely been described in other mammals. often, group-specific vocal dialects in wild populations provide the main evidence for vocal learning. while social learning is often the most plausible explanation for these intergroup differences, it is usually impossible to exclude other driving factors, such as genetic or ecological backgrounds. here, we show the formation of dialects through social vocal learning in fruit bats under controlled conditions. we raised 3 groups of pups in conditions mimicking their natural roosts. namely, pups could hear their mothers' vocalizations but were also exposed to a manipulation playback. the vocalizations in the 3 playbacks mainly differed in their fundamental frequency. from the age of approximately 6 months and onwards, the pups demonstrated distinct dialects, where each group was biased towards its playback. we demonstrate the emergence of dialects through social learning in a mammalian model in a tightly controlled environment. unlike in the extensively studied case of songbirds where specific tutors are imitated, we demonstrate that bats do not only learn their vocalizations directly from their mothers, but that they are actually influenced by the sounds of the entire crowd. this process, which we term \u201ccrowd vocal learning,\u201d might be relevant to many other social animals such as cetaceans and pinnipeds.\""
        },
        {
            "id": "R171169",
            "label": "Perceptions of a Specific Family Communication Application among Grandparents and Grandchildren: An Extension of the Technology Acceptance Model",
            "doi": "10.1371/journal.pone.0156680",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "many studies have noted that the use of social networks sites (snss) can enhance social interaction among the elderly and that the motivation for the elderly to use snss is to keep in contact with remote friends and family or the younger generation. memotree is designed to promote intergenerational family communication. the system incorporates the family tree design concept and provides family communication mechanisms based on the family communication scale. in addition, the system optimizes hardware and interface use to conform to the specific needs of older and substantially younger individuals. regarding the impact of variables on sns with respect to the interaction of usability variables in the construction of a cross-generational communication platform, we adopted the tam model and chung et al.\u2019s suggestions to promote user acceptance of the proposed memotree system. a total of 39 grandchildren and 39 grandparents met the criteria and were included in the study. the elderly and young respondents revealed substantial willingness to use and/or satisfaction with using the memotree system. empirical results indicate that technology affordances and perceived ease of use have a positive impact on perceived usefulness, while perceived ease of use is affected by technology affordances. internet self-efficacy and perceived usefulness have a positive impact on the user\u2019s behavioral intention toward the system. in addition, this study investigated age as a moderating variable in the model. the results indicate that grandchildren have a larger significant effect on the path between perceived usefulness and behavioral intention than grandparents. this study proposes a more complete framework for investigating the user\u2019s behavioral intention and provides a more appropriate explanation of related services for cross-generational interaction with sns services."
        },
        {
            "id": "R193162",
            "label": "Motion synthesis from annotations",
            "doi": "10.1145/1201775.882284",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R128713",
                    "label": "motion synthesis"
                }
            ],
            "abstract": "\"this paper describes a framework that allows a user to synthesize human motion while retaining control of its qualitative properties. the user paints a timeline with annotations --- like walk, run or jump --- from a vocabulary which is freely chosen by the user. the system then assembles frames from a motion database so that the final motion performs the specified actions at specified times. the motion can also be forced to pass through particular configurations at particular times, and to go to a particular position and orientation. annotations can be painted positively (for example, must run), negatively (for example, may not run backwards) or as a don't-care. the system uses a novel search method, based around dynamic programming at several scales, to obtain a solution efficiently so that authoring is interactive. our results demonstrate that the method can generate smooth, natural-looking motion.the annotation vocabulary can be chosen to fit the application, and allows specification of composite motions (run and jump simultaneously, for example). the process requires a collection of motion data that has been annotated with the chosen vocabulary. this paper also describes an effective tool, based around repeated use of support vector machines, that allows a user to annotate a large collection of motions quickly and easily so that they may be used with the synthesis algorithm.\""
        },
        {
            "id": "R137065",
            "label": "Biaryl Construction via Ni-Catalyzed C\u00e2\u0088\u0092O Activation of Phenolic Carboxylates",
            "doi": "10.1021/ja8056503",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R137056",
                    "label": "Activation of C-O bond"
                }
            ],
            "abstract": "biaryl scaffolds were constructed via ni-catalyzed aryl c-o activation by avoiding cleavage of the more reactive acyl c-o bond of aryl carboxylates. now aryl esters, in general, can be successfully employed in cross-coupling reactions for the first time. the substrate scope and synthetic utility of the chemistry were demonstrated by the syntheses of more than 40 biaryls and by constructing complex organic molecules. water was observed to play an important role in facilitating this transformation."
        },
        {
            "id": "R170818",
            "label": "How Psychological and Behavioral Team States Change during Positive and Negative Momentum",
            "doi": "10.1371/journal.pone.0097887",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in business and sports, teams often experience periods of positive and negative momentum while pursuing their goals. however, researchers have not yet been able to provide insights into how psychological and behavioral states actually change during positive and negative team momentum. in the current study we aimed to provide these insights by introducing an experimental dynamical research design. rowing pairs had to compete against a virtual opponent on rowing ergometers, while a screen in front of the team broadcasted the ongoing race. the race was manipulated so that the team\u2019s rowing avatar gradually progressed (positive momentum) or regressed (negative momentum) in relation to the victory. the participants responded verbally to collective efficacy and task cohesion items appearing on the screen each minute. in addition, effort exertion and interpersonal coordination were continuously measured. our results showed negative psychological changes (perceptions of collective efficacy and task cohesion) during negative team momentum, which were stronger than the positive changes during positive team momentum. moreover, teams\u2019 exerted efforts rapidly decreased during negative momentum, whereas positive momentum accompanied a more variable and adaptive sequence of effort exertion. finally, the interpersonal coordination was worse during negative momentum than during positive momentum. these results provide the first empirical insights into actual team momentum dynamics, and demonstrate how a dynamical research approach significantly contributes to current knowledge on psychological and behavioral processes."
        },
        {
            "id": "R160558",
            "label": "Classification of Iowa wetlands using an airborne hyperspectral image: a comparison of the spectral angle mapper classifier and an object-oriented approach",
            "doi": "10.5589/m05-003",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R160529",
                    "label": "Comparison of Spectral angle mapper and object oriented approach for wetlands classification"
                }
            ],
            "abstract": "\"wetlands mapping using multispectral imagery from landsat multispectral scanner (mss) and thematic mapper (tm) and syst\u00e8me pour l'observation de la terre (spot) does not in general provide high classification accuracies because of poor spectral and spatial resolutions. this study tests the feasibility of using high-resolution hyperspectral imagery to map wetlands in iowa with two nontraditional classification techniques: the spectral angle mapper (sam) method and a new nonparametric object-oriented (oo) classification. the software programs used were envi and ecognition. accuracies of these classified images were assessed by using the information collected through a field survey with a global positioning system and high-resolution color infrared images. wetlands were identified more accurately with the oo method (overall accuracy 92.3%) than with sam (63.53%). this paper also discusses the limitations of these classification techniques for wetlands, as well as discussing future directions for study.\""
        },
        {
            "id": "R211914",
            "label": "WiFiMon app measuring Wi-Fi performance as experienced by end-users",
            "doi": "10.1109/ict.2017.7998257",
            "research_field": {
                "id": "R277",
                "label": "Computational Engineering"
            },
            "research_problems": [
                {
                    "id": "R211919",
                    "label": "Network Performance measurement"
                }
            ],
            "abstract": "the measurement of quality and efficiency of a wireless wi-fi network is particularly difficult, as there is not a single tool that can record measurements from all sides of the system, i.e. from both the access point and the end-user. existing tools are able to monitor the overall quality of the wireless network; although they cannot determine how end-users experience the quality of wi-fi in a particular part of the network at a given time. in this paper we present a novel tool, named wifimon, which enables measuring, recording and exporting statistics regarding the quality of a wi-fi network as experienced by the end-users. the measurements are triggered by the end-users when they visit wifimon-enabled websites and/or run wifimon-enabled mobile applications and are recorded without users' intervention. main goal of wifimon is to give network administrators a better overview on how the end-users experience the conditions of the wi-fi network."
        },
        {
            "id": "R4677",
            "label": "Fragmentation as an aggregation process",
            "doi": "",
            "research_field": {
                "id": "R107",
                "label": "Physical Sciences & Mathematics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "when severely impacted, a cohesive object deforms and eventually breaks into fragments. cohesion forces keeping the material together and momentum driving the fragmentation couple through a complicated process involving crack propagation on a deforming substrate, so that a comprehensive scenario for the build-up of the full fragment size distribution of broken objects is still lacking. we use necklaces of cohesive particles (magnetized spheres) as an experimental model of a one-dimensional material, which we expand radially in an impulsive way. exploring in real time the intermediate state where the particles are no longer in contact, but still in interaction as they separate, we demonstrate that the final fragments result from the self-assembly of individual particles and that their size distribution converges to a stable self-similar distribution whose parameters, interpreted from first principles, depend on the expansion and cohesion strengths."
        },
        {
            "id": "R170915",
            "label": "Is There an Association between Traumatic Dental Injury and Social Capital, Binge Drinking and Socioeconomic Indicators among Schoolchildren?",
            "doi": "10.1371/journal.pone.0118484",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives traumatic dental injury is defined as trauma caused by forces on a tooth with variable extent and severity. the aim of the present study was to investigate the prevalence of traumatic dental injury and its association with overjet, lip protection, sex, socioeconomic status, social capital and binge drinking among 12-year-old students. research design and method a cross-sectional study was conducted with a sample of 633 12-year-old students. data were collected through a clinical exam and self-administered questionnaires. socioeconomic status was determined based on mother\u2019s schooling and household income. the social capital questionnaire for adolescent students and alcohol use disorders identification test (audit-c) were used to measure social capital and binge drinking, respectively. results the prevalence of traumatic dental injury was 29.9% (176/588). traumatic dental injury was more prevalent among male adolescents (p = 0.010), those with overjet greater than 5 mm (p < 0.001) and those with inadequate lip protection (p < 0.001). in the multiple logistic regression analysis, overjet [or = 3.80 (95% ci: 2.235\u20136.466), p < 0.0001], inadequate lip protection [or = 5.585 (95% ci: 3.654\u20138.535), p < 0.0001] and binge drinking [or = 1.93 (95% ci: 1.21\u20133.06), p = 0.005] remained significantly associated with traumatic dental injury. conclusions the present findings suggest that a high level of total social capital and trust are not associated with tdi in adolescents, unlike binge drinking. the effects of social and behavioral factors on tdi are not well elucidated. therefore, further research involving other populations and a longitudinal design is recommended."
        },
        {
            "id": "R196476",
            "label": "Circumstance adverbials in registers of Indian English",
            "doi": "10.1111/j.1467-971x.2009.01608.x",
            "research_field": {
                "id": "R409",
                "label": "South and Southeast Asian Languages and Societies"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": ":\\u2002 this is a corpus-based investigation of\\u2002also\\u2002and\\u2002too\\u2002in 11 registers of indian english. the corpus used for this study is a combination of a corpus of contemporary indian english (ccie), and certain sections of ice-india. the study: (1) determines the proportions of\\u2002also\\u2002and\\u2002too\\u2002with respect to each other in the indian corpus; (2) compares the proportions of the adverbials in registers of indian english versus registers of british and american english; (3) compares the position preferences (medial, initial, final) of the adverbials in registers of indian english versus registers of british and american english; and (4) determines the position of\\u2002also\\u2002and its relationship to the element in semantic focus in the clause in different registers of indian english. the study shows that there are: (1) significant differences between indian english and british and american english in the patterns of occurrence of the circumstance adverbials studied; and (2) there are substantial differences in patterns of occurrence of the circumstance adverbials among the registers of indian english. this study makes a contribution to the study of indian english as it shows: (1) that indian english is different from british and american english with respect to a core grammatical characteristic; and (2) that registers of indian english are substantially different from each other."
        },
        {
            "id": "R53426",
            "label": "Big Earth data analytics: a survey",
            "doi": "10.1080/20964471.2019.1611175",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R68677",
                    "label": "Designing big Earth data system architecture"
                },
                {
                    "id": "R68678",
                    "label": "Developing big Earth data analytics"
                },
                {
                    "id": "R68679",
                    "label": "Advancing domains using big Earth data"
                },
                {
                    "id": "R68680",
                    "label": "Facilitating the collaboration of big Earth data stakeholders"
                }
            ],
            "abstract": "abstract big earth data are produced from satellite observations, internet-of-things, model simulations, and other sources. the data embed unprecedented insights and spatiotemporal stamps of relevant earth phenomena for improving our understanding, responding, and addressing challenges of earth sciences and applications. in the past years, new technologies (such as cloud computing, big data and artificial intelligence) have gained momentum in addressing the challenges of using big earth data for scientific studies and geospatial applications historically intractable. this paper reviews the big earth data analytics from several aspects to capture the latest advancements in this fast-growing domain. we first introduce the concepts of big earth data. the architecture, various functionalities, and supporting modules are then reviewed from a generic methodology aspect. analytical methods supporting the functionalities are surveyed and analyzed in the context of different tools. the driven questions are exemplified through cutting-edge earth science researches and applications. a list of challenges and opportunities are proposed for different stakeholders to collaboratively advance big earth data analytics in the near future."
        },
        {
            "id": "R171130",
            "label": "Cognitive Performance and Long-Term Social Functioning in Psychotic Disorder: A Three-Year Follow-Up Study",
            "doi": "10.1371/journal.pone.0151299",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective studies have linked cognitive functioning to everyday social functioning in psychotic disorders, but the nature of the relationships between cognition, social cognition, symptoms, and social functioning remains unestablished. modelling the contributions of non-social and social cognitive ability in the prediction of social functioning may help in more clearly defining therapeutic targets to improve functioning. method in a sample of 745 patients with a non-affective psychotic disorder, the associations between cognition and social cognition at baseline on the one hand, and self-reported social functioning three years later on the other, were analysed. first, case-control comparisons were conducted; associations were subsequently further explored in patients, investigating the potential mediating role of symptoms. analyses were repeated in a subsample of 233 patients with recent-onset psychosis. results information processing speed and immediate verbal memory were stronger associated with social functioning in patients than in healthy controls. most cognition variables significantly predicted social functioning at follow-up, whereas social cognition was not associated with social functioning. symptoms were robustly associated with follow-up social functioning, with negative symptoms fully mediating most associations between cognition and follow-up social functioning. illness duration did not moderate the strength of the association between cognitive functioning and follow-up social functioning. no associations were found between (social) cognition and follow-up social functioning in patients with recent-onset psychosis. conclusions although cognitive functioning is associated with later social functioning in psychotic disorder, its role in explaining social functioning outcome above negative symptoms appears only modest. in recent-onset psychosis, cognition may have a negligible role in predicting later social functioning. moreover, social cognition tasks may not predict self-reported social functioning."
        },
        {
            "id": "R212379",
            "label": "Surface Urban Heat Islands Dynamics in Response to LULC and Vegetation across South Asia (2000\u00e2\u0080\u00932019)",
            "doi": "10.3390/rs13163177",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R209329",
                    "label": "change detection of urban land use"
                }
            ],
            "abstract": "urbanization is an increasing phenomenon around the world, causing many adverse effects in urban areas. urban heat island is are of the most well-known phenomena. in the present study, surface urban heat islands (suhi) were studied for seven megacities of the south asian countries from 2000\u20132019. the urban thermal environment and relationship between land surface temperature (lst), land use landcover (lulc) and vegetation were examined. the connection was explored with remote-sensing indices such as urban thermal field variance (utfvi), surface urban heat island intensity (suhii) and normal difference vegetation index (ndvi). lulc maps are classified using a cart machine learning classifier, and an accuracy table was generated. the lulc change matrix shows that the vegetated areas of all the cities decreased with an increase in the urban areas during the 20 years. the average lst in the rural areas is increasing compared to the urban core, and the difference is in the range of 1\u20132 (\u00b0c). the suhii linear trend is increasing in delhi, karachi, kathmandu, and thimphu, while decreasing in colombo, dhaka, and kabul from 2000\u20132019. utfvi has shown the poor ecological conditions in all urban buffers due to high lst and urban infrastructures. in addition, a strong negative correlation between lst and ndvi can be seen in a range of \u22120.1 to \u22120.6."
        },
        {
            "id": "R171497",
            "label": "Engagement of vulnerable youths using internet platforms",
            "doi": "10.1371/journal.pone.0189023",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "aim the aim of this study was to explore the online distress and help-seeking behavior of youths in hong kong. methods a cross-sectional telephone-based survey was conducted among 1,010 young people in hong kong. logistic regression analysis was then performed to identify the factors associated with those who reported expressing emotional distress online and the differences in help-seeking behavior among four groups of youths: (1) the non-distressed (reference) group; (2) \u201cdid not seek help\u201d group; (3) \u201cseek informal help\u201d group; and (4) \u201cseek formal help\u201d group. results the seeking of help and expression of distress online were found to be associated with a higher lifetime prevalence of suicidal ideation. the \u201cseek formal help\u201d and \u201cdid not seek help\u201d groups had a similar risk profile, including a higher prevalence of suicidal ideation, non-suicidal self-injury, unsafe sex, and being bullied. the \u201cseek informal help\u201d group was more likely to express distress online, which indicates that this population of youths may be accessible to professional identification. approximately 20% of the distressed youths surveyed had not sought help despite expressing their distress online. implication the study\u2019s results indicate that helping professionals have opportunities to develop strategic engagement methods that make use of social media to help distressed youths."
        },
        {
            "id": "R171175",
            "label": "The Impact of Parental Personality on Birth Outcomes: A Prospective Cohort Study",
            "doi": "10.1371/journal.pone.0157080",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective to investigate the effect of parental personality on birth outcomes. design prospective cohort study. setting 727 pregnant women and 579 spouses receiving antenatal care at a single-center in rural tokyo, japan during 2010\u20132013. methods we measured the association between maternal effect of parental personality traits assessed by the cloninger\u2019s temperament and character inventory on birth outcomes, using multiple regression and adjusting for demographics. results maternal self-transcendence personality was inversely associated with gestational age [-0.26 (95% confidence interval (ci): -0.51 to -0.01) weeks per unit] and positively associated with preterm birth [odds ratio (or) 2.60 (95% ci: 1.00 to 6.75) per unit], while paternal self-transcendence personality was positively associated with gestational age [0.31 (95% ci: 0.07 to 0.55) weeks per unit]. maternal reward dependence was positively associated with fetal growth [0.30 (95% ci: 0.02 to 0.59) per unit]. other maternal and paternal personality traits associated with adverse maternal behavior, such as novelty seeking, harm avoidance and self-directedness, were not associated with birth outcomes. conclusion we found that specific parental personality traits can be associated with birth outcomes."
        },
        {
            "id": "R41454",
            "label": "Individual homogenization in large-scale systems: on the politics of computer and social architectures",
            "doi": "10.1057/s41599-020-0425-4",
            "research_field": {
                "id": "R445",
                "label": "Ethics and Political Philosophy"
            },
            "research_problems": [
                {
                    "id": "R41460",
                    "label": "System organization"
                },
                {
                    "id": "R41461",
                    "label": "Heterogeneity"
                },
                {
                    "id": "R41462",
                    "label": "Pluralism"
                },
                {
                    "id": "R41463",
                    "label": "Technological design"
                }
            ],
            "abstract": "abstract one determining characteristic of contemporary sociopolitical systems is their power over increasingly large and diverse populations. this raises questions about power relations between heterogeneous individuals and increasingly dominant and homogenizing system objectives. this article crosses epistemic boundaries by integrating computer engineering and a historicalphilosophical approach making the general organization of individuals within large-scale systems and corresponding individual homogenization intelligible. from a versatile archeological-genealogical perspective, an analysis of computer and social architectures is conducted that reinterprets foucault\u2019s disciplines and political anatomy to establish the notion of politics for a purely technical system. this permits an understanding of system organization as modern technology with application to technical and social systems alike. connecting to heidegger\u2019s notions of the enframing ( gestell ) and a more primal truth ( anf\u00e4nglicheren wahrheit) , the recognition of politics in differently developing systems then challenges the immutability of contemporary organization. following this critique of modernity and within the conceptualization of system organization, derrida\u2019s democracy to come (\u00e0 venir) is then reformulated more abstractly as organizations to come . through the integration of the discussed concepts, the framework of large-scale systems composed of homogeneous individuals (lsschi) is proposed, problematizing the relationships between individuals, structure, activity, and power within large-scale systems. the lsschi framework highlights the conflict of homogenizing system-level objectives and individual heterogeneity, and outlines power relations and mechanisms of control shared across different social and technical systems."
        },
        {
            "id": "R166570",
            "label": "Access and Usage of E-Journals by Research Scholars in National Institute of Technology (NIT) Rourkela, Odisha: A Case Study",
            "doi": "10.5281/ZENODO.2578882",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the purpose of this study is to investigate different aspects such as awareness, access and usage of e-journals among the research scholars at biju patnaik central library (bpcl) of national institute of technology (nit) rourkela, odisha. the scope of this paper limits to: (i) e-resources: only e-journal is considered among the various types of e-resources subscribed by library; (ii) respondents: only research scholars are taken into consideration; and (iii) questionnaires: 150 questionnaires collected from 700 research scholars. this paper also reveals the problems and suggests some solutions. the study shows that user education programmes (uep), stable high-speed internet supply and adequate number of computers should be provided to ensure constant access that can effectively enhance the usage of e-journals."
        },
        {
            "id": "R8624",
            "label": "Revisiting Style, a Key Concept in Literary Studies",
            "doi": "10.1515/jlt-2015-0003",
            "research_field": {
                "id": "R388",
                "label": "Comparative Literature"
            },
            "research_problems": [
                {
                    "id": "R8627",
                    "label": "Definition of style"
                }
            ],
            "abstract": "abstract language and literary studies have studied style for centuries, and even since the advent of \u203astylistics\u2039 as a discipline at the beginning of the twentieth century, definitions of \u203astyle\u2039 have varied heavily across time, space and fields. today, with increasingly large collections of literary texts being made available in digital form, computational approaches to literary style are proliferating. new methods from disciplines such as corpus linguistics and computer science are being adopted and adapted in interrelated fields such as computational stylistics and corpus stylistics, and are facilitating new approaches to literary style. the relation between definitions of style in established linguistic or literary stylistics, and definitions of style in computational or corpus stylistics has not, however, been systematically assessed. this contribution aims to respond to the need to redefine style in the light of this new situation and to establish a clearer perception of both the overlap and the boundaries between \u203amainstream\u2039 and \u203acomputational\u2039 and/or \u203aempirical\u2039 literary stylistics. while stylistic studies of non-literary texts are currently flourishing, our contribution deliberately centers on those approaches relevant to \u203aliterary stylistics\u2039. it concludes by proposing an operational definition of style that we hope can act as a common ground for diverse approaches to literary style, fostering transdisciplinary research. the focus of this contribution is on literary style in linguistics and literary studies (rather than in art history, musicology or fashion), on textual aspects of style (rather than production- or reception-oriented theories of style), and on a descriptive perspective (rather than a prescriptive or didactic one). even within these limits, however, it appears necessary to build on a broad understanding of the various perspectives on style that have been adopted at different times and in different traditions. for this reason, the contribution first traces the development of the notion of style in three different traditions, those of german, dutch and french language and literary studies. despite the numerous links between each other, and between each of them to the british and american traditions, these three traditions each have their proper dynamics, especially with regard to the convergence and/or confrontation between mainstream and computational stylistics. for reasons of space and coherence, the contribution is limited to theoretical developments occurring since 1945. the contribution begins by briefly outlining the range of definitions of style that can be encountered across traditions today: style as revealing a higher-order aesthetic value, as the holistic \u203agestalt\u2039 of single texts, as an expression of the individuality of an author, as an artifact presupposing choice among alternatives, as a deviation from a norm or reference, or as any formal property of a text. the contribution then traces the development of definitions of style in each of the three traditions mentioned, with the aim of giving a concise account of how, in each tradition, definitions of style have evolved over time, with special regard to the way such definitions relate to empirical, quantitative or otherwise computational approaches to style in literary texts. it will become apparent how, in each of the three traditions, foundational texts continue to influence current discussions on literary style, but also how stylistics has continuously reacted to broader developments in cultural and literary theory, and how empirical, quantitative or computational approaches have long \\xadexisted, usually in parallel to or at the margins of mainstream stylistics. the review will also reflect the lines of discussion around style as a property of literary texts \u2013 or of any textual entity in general. the perspective on three stylistic traditions is accompanied by a more systematic perspective. the rationale is to work towards a common ground for literary scholars and linguists when talking about (literary) style, across traditions of stylistics, with respect for established definitions of style, but also in light of the digital paradigm. here, we first show to what extent, at similar or different moments in time, the three traditions have developed comparable positions on style, and which definitions out of the range of possible definitions have been proposed or promoted by which authors in each of the three traditions. on the basis of this synthesis, we then conclude by proposing an operational definition of style that is an attempt to provide a common ground for both mainstream and computational literary stylistics. this definition is discussed in some detail in order to explain not only what is meant by each term in the definition, but also how it relates to computational analyses of style \u2013 and how this definition aims to avoid some of the pitfalls that can be perceived in earlier definitions of style. our definition, we hope, will be put to use by a new generation of computational, quantitative, and empirical studies of style in literary texts."
        },
        {
            "id": "R189394",
            "label": "A Hierarchical Multi-Task Approach for Learning Embeddings from Semantic Tasks",
            "doi": "10.1609/aaai.v33i01.33016949",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R124236",
                    "label": "Coreference Resolution"
                }
            ],
            "abstract": "much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various natural language processing (nlp) down-stream applications. however, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. in this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. the model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. this model achieves state-of-the-art results on a number of tasks, namely named entity recognition, entity mention detection and relation extraction without hand-engineered features or external nlp tools like syntactic parsers. the hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. we show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information."
        },
        {
            "id": "R193537",
            "label": "A Virtual Reality Dance Training System Using Motion Capture Technology",
            "doi": "10.1109/TLT.2010.27",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"in this paper, a new dance training system based on the motion capture and virtual reality (vr) technologies is proposed. our system is inspired by the traditional way to learn new movements-imitating the teacher's movements and listening to the teacher's feedback. a prototype of our proposed system is implemented, in which a student can imitate the motion demonstrated by a virtual teacher projected on the wall screen. meanwhile, the student's motions will be captured and analyzed by the system based on which feedback is given back to them. the result of user studies showed that our system can successfully guide students to improve their skills. the subjects agreed that the system is interesting and can motivate them to learn.\""
        },
        {
            "id": "R170217",
            "label": "The effect of the optical design of multifocal contact lenses on choroidal thickness",
            "doi": "10.1371/journal.pone.0207637",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "studies have found reduced myopia progression with multifocal contact lenses, albeit with an unclear mechanism behind their protective effect. it is hypothesized that the induced myopic defocus of the addition zones of the multifocal contact lenses leads to choroidal thickening and therefore inhibits eye growth. in the current study, the effect of the optical design of multifocal contact lenses on choroidal thickness was investigated. eighteen myopic participants wore four different contact lenses ((1) single-vision lenses corrected for distance, (2) single-vision lenses with +2.50 d full-field defocus, (3) multifocal center-distance design, (4) multifocal center-near design, both with addition power +2.50 d) for 30 min each on their right eye. automated analysis of the macular choroidal thickness and vitreous chamber depth were performed before and after the wear of each of the contact lenses. peripheral refraction profiles in primary gaze were obtained using eccentric photorefraction prior to contact lens wear. choroidal thickness and vitreous chamber depth showed no significant differences to baseline with any of the contact lenses (all p > 0.05). choroidal thickness increased by +2.1 \u00b1 11.1 \u03bcm with the multifocal center-distance design, by +2.0 \u00b1 11.1 \u03bcm with the full-field defocus lens, followed by the multifocal center-near design with +1.6 \u00b1 11.3 \u03bcm and the single-vision contact lens correcting for distance with +0.9 \u00b1 11.2 \u03bcm. multifocal contact lenses have no significant influence on choroidal thickness after short-term wear. therefore, changes in choroidal thickness might not be the main contributor to the protective effect of multifocal contact lenses in myopia control."
        },
        {
            "id": "R168995",
            "label": "Specific Activation of Estrogen Receptor Alpha and Beta Enhances Male Sexual Behavior and Neuroplasticity in Male Japanese Quail",
            "doi": "10.1371/journal.pone.0018627",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "two subtypes of estrogen receptors (er), er\u03b1 and er\u03b2, have been identified in humans and numerous vertebrates, including the japanese quail. we investigated in this species the specific role(s) of each receptor in the activation of male sexual behavior and the underlying estrogen-dependent neural plasticity. castrated male japanese quail received empty (cx) or testosterone-filled (t) implants or were daily injected with the er general agonist diethylstilbestrol (des), the er\u03b1-specific agonist ppt, the er\u03b2-specific agonist dpn or the vehicle, propylene glycol. three days after receiving the first treatment, subjects were alternatively tested for appetitive (rhythmic cloacal sphincter movements, rcsm) and consummatory aspects (copulatory behavior) of male sexual behavior. 24 hours after the last behavioral testing, brains were collected and analyzed for aromatase expression and vasotocinergic innervation in the medial preoptic nucleus. the expression of rcsm was activated by t and to a lesser extent by des and ppt but not by the er\u03b2agonist dpn. in parallel, t fully restored the complete sequence of copulation, des was partially active and the specific activation of er\u03b1 or er\u03b2 only resulted in a very low frequency of mount attempts in few subjects. t increased the volume of the medial preoptic nucleus as measured by the dense cluster of aromatase-immunoreactive cells and the density of the vasotocinergic innervation within this nucleus. des had only a weak action on vasotocinergic fibers and the two specific er agonists did not affect these neural responses. simultaneous activation of both receptors or treatments with higher doses may be required to fully activate sexual behavior and the associated neurochemical events."
        },
        {
            "id": "R130733",
            "label": "Multiplicative LSTM for sequence modelling",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "we introduce multiplicative lstm (mlstm), a recurrent neural network architecture for sequence modelling that combines the long short-term memory (lstm) and multiplicative recurrent neural network architectures. mlstm is characterised by its ability to have different recurrent transition functions for each possible input, which we argue makes it more expressive for autoregressive density estimation. we demonstrate empirically that mlstm outperforms standard lstm and its deep variants for a range of character level language modelling tasks. in this version of the paper, we regularise mlstm to achieve 1.27 bits/char on text8 and 1.24 bits/char on hutter prize. we also apply a purely byte-level mlstm on the wikitext-2 dataset to achieve a character level entropy of 1.26 bits/char, corresponding to a word level perplexity of 88.8, which is comparable to word level lstms regularised in similar ways on the same task."
        },
        {
            "id": "R171407",
            "label": "Older adults\u00e2\u0080\u0099 acceptance of a robot for partner dance-based exercise",
            "doi": "10.1371/journal.pone.0182736",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "partner dance has been shown to be beneficial for the health of older adults. robots could potentially facilitate healthy aging by engaging older adults in partner dance-based exercise. however, partner dance involves physical contact between the dancers, and older adults would need to be accepting of partner dancing with a robot. using methods from the technology acceptance literature, we conducted a study with 16 healthy older adults to investigate their acceptance of robots for partner dance-based exercise. participants successfully led a human-scale wheeled robot with arms (i.e., a mobile manipulator) in a simple, which we refer to as the partnered stepping task (pst). participants led the robot by maintaining physical contact and applying forces to the robot\u2019s end effectors. according to questionnaires, participants were generally accepting of the robot for partner dance-based exercise, tending to perceive it as useful, easy to use, and enjoyable. participants tended to perceive the robot as easier to use after performing the pst with it. through a qualitative data analysis of structured interview data, we also identified facilitators and barriers to acceptance of robots for partner dance-based exercise. throughout the study, our robot used admittance control to successfully dance with older adults, demonstrating the feasibility of this method. overall, our results suggest that robots could successfully engage older adults in partner dance-based exercise."
        },
        {
            "id": "R12033",
            "label": "Improved Lossless Image Compression Using Adaptive Image Rotation",
            "doi": "10.23919/eusipco.2019.8902580",
            "research_field": {
                "id": "R246",
                "label": "Signal Processing"
            },
            "research_problems": [
                {
                    "id": "R12036",
                    "label": "lossless image compression"
                },
                {
                    "id": "R12038",
                    "label": "screen content coding"
                }
            ],
            "abstract": "state-of-the-art compression schemes generally have the ability to adapt themselves to the properties of the data to be compressed. this is a kind of learning process and requires the modification of internal variables influencing the treatment of subsequent data segments. in other words: the order of processing has an impact on the compression performance. in image compression, the order can be changed, for example, by rotating the input image by $90^{\\\\circ}, 180^{\\\\circ}$, or 270\u00b0. in application to lossless screen content compression, investigations with different compression schemes (loco-i, hevc, fp8v3, and scf) have shown that the rotation has a considerable impact on the compression performance. the difficulty, however, is to predict the best rotation. for the scf (soft context formation) compression scheme, we have developed a method based on a tiny neural network that suggests a suitable rotation by evaluating basic colour properties of the image to be compressed. the compression can be improved by 0.7098% to 1.3817% depending on the image set tested."
        },
        {
            "id": "R169090",
            "label": "Improving Community Coverage of Oral Cholera Mass Vaccination Campaigns: Lessons Learned in Zanzibar",
            "doi": "10.1371/journal.pone.0041527",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background recent research in two cholera-endemic communities of zanzibar has shown that a majority (\u223c94%) of the adult population was willing to receive free oral cholera vaccines (ocvs). since ocv uptake in the 2009 campaign reached only \u223c50% in these communities, an evaluation of social and cultural factors and of barriers was conducted to understand this difference for future cholera control planning. methodology/principal findings a random sample of 367 adult peri-urban and rural community residents (46.6% immunized vs. 53.4% unimmunized) was studied with a semi-structured interview that inquired about social and cultural features of cholera depicted in a vignette and barriers to ocv uptake. symptoms (rectal pain, loose skin only in rural community) and perceived causes (uncovered food, contact with contaminated water) specific for severe diarrhea were associated with uptake. purchasing drugs from pharmacies to stop diarrhea and vomiting was negatively associated with uptake. increasing household size, age and previous enteric illness episode were positively related to uptake, the latter only at the rural site. the most prominent barrier to uptake was competing obligations or priorities (reported by 74.5%, identified as most important barrier by 49.5%). next most prominent barriers were lacking information about the campaign (29.6%, 12.2%), sickness (14.3%, 13.3%) and fear of possible vaccine side effects (15.3%, 5.6%). the majority of unvaccinated respondents requested repetition of the vaccination with free ocvs. conclusions/significance factors associated with uptake indicated a positive impact of the vaccination campaign and of sensitization activities on vaccine acceptance behavior. unlike communities opposed to cholera control or settings where public confidence in vaccines is lacking, identified barriers to uptake indicated a good campaign implementation and trust in the health system. despite prospects and demand for repeating the vaccination, local decision-makers should reconsider how careful logistical arrangements may improve community coverage and thus effectiveness of vaccination campaigns."
        },
        {
            "id": "R171252",
            "label": "A Markerless 3D Computerized Motion Capture System Incorporating a Skeleton Model for Monkeys",
            "doi": "10.1371/journal.pone.0166154",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this study, we propose a novel markerless motion capture system (mcs) for monkeys, in which 3d surface images of monkeys were reconstructed by integrating data from four depth cameras, and a skeleton model of the monkey was fitted onto 3d images of monkeys in each frame of the video. to validate the mcs, first, estimated 3d positions of body parts were compared between the 3d mcs-assisted estimation and manual estimation based on visual inspection when a monkey performed a shuttling behavior in which it had to avoid obstacles in various positions. the mean estimation error of the positions of body parts (3\u201314 cm) and of head rotation (35\u201343\u00b0) between the 3d mcs-assisted and manual estimation were comparable to the errors between two different experimenters performing manual estimation. furthermore, the mcs could identify specific monkey actions, and there was no false positive nor false negative detection of actions compared with those in manual estimation. second, to check the reproducibility of mcs-assisted estimation, the same analyses of the above experiments were repeated by a different user. the estimation errors of positions of most body parts between the two experimenters were significantly smaller in the mcs-assisted estimation than in the manual estimation. third, effects of methamphetamine (map) administration on the spontaneous behaviors of four monkeys were analyzed using the mcs. map significantly increased head movements, tended to decrease locomotion speed, and had no significant effect on total path length. the results were comparable to previous human clinical data. furthermore, estimated data following map injection (total path length, walking speed, and speed of head rotation) correlated significantly between the two experimenters in the mcs-assisted estimation (r = 0.863 to 0.999). the results suggest that the presented mcs in monkeys is useful in investigating neural mechanisms underlying various psychiatric disorders and developing pharmacological interventions."
        },
        {
            "id": "R171645",
            "label": "Effect of socioeconomic status on behavioral problems from preschool to early elementary school \u00e2\u0080\u0093 A Japanese longitudinal study",
            "doi": "10.1371/journal.pone.0197961",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose social inequalities are widely accepted to have a deleterious effect on children\u2019s mental health, and those with lower socioeconomic status generally experience more mental health issues. in this study, we examine the impact of socioeconomic situations of children\u2019s families during their early childhood on the children\u2019s social adaptation in japanese elementary school. methods the current investigation consisted of two sets of data relating to two separate years (with a one-year interval). the participants included preschoolers aged five years at time 1 (the first year) and first graders aged six years at time 2 (the second year); 1,712 met the inclusion criteria for both years. parents of the participants completed a self-reported questionnaire regarding their ses (i.e., family economy and mother\u2019s education) and their children\u2019s mental health. mental health was assessed using the child behavior checklist/4\u201318, parent report. results for each ses indicator, we found an inverse relationship across all the symptom dimensions. specifically, bivariate analyses revealed that lower family income, maternal education level, and paternal education level predict all three domains of behavioral problems (i.e., internalized problems, externalized problems, and total behavioral problems). further, multivariate analyses revealed that lower family income consistently predicts all domains of behavioral problems, lower maternal education level predicted externalized problems and total behavioral problems, and paternal education level did not predict any clinically significant behavioral problems. conclusion in this sample, we found that, for children, family income and parental education when entering preschool were significant predictors of mental health problems after elementary school enrollment; in particular, low income and low maternal educational achievement predicted a high probability of the development of a psychiatric disorder. a greater understanding of the mechanisms of these associations could contribute to improvements in interventions aimed at preventing child maladjustment."
        },
        {
            "id": "R197078",
            "label": "Dual Script E2E framework for Multilingual and Code-Switching ASR",
            "doi": "10.48550/ARXIV.2106.01400",
            "research_field": {
                "id": "R405",
                "label": "European Languages and Societies (not elsewhere classified)"
            },
            "research_problems": [
                {
                    "id": "R197246",
                    "label": "Multilingual and Code-switching ASR for Indian languages"
                }
            ],
            "abstract": "india is home to multiple languages, and training automatic speech recognition (asr) systems is challenging. over time, each language has adopted words from other languages, such as english, leading to code-mixing. most indian languages also have their own unique scripts, which poses a major limitation in training multilingual and code-switching asr systems. inspired by results in text-to-speech synthesis, in this paper, we use an in-house rule-based phoneme-level common label set (cls) representation to train multilingual and code-switching asr for indian languages. we propose two end-to-end (e2e) asr systems. in the first system, the e2e model is trained on the cls representation, and we use a novel data-driven backend to recover the native language script. in the second system, we propose a modification to the e2e model, wherein the cls representation and the native language characters are used simultaneously for training. we show our results on the multilingual and code-switching (mucs) asr challenge 2021. our best results achieve \u2248 6% and 5% improvement in word error rate over the baseline system for the multilingual and code-switching tasks, respectively, on the challenge development data."
        },
        {
            "id": "R171262",
            "label": "Cognitive Costs of Reappraisal Depend on Both Emotional Stimulus Intensity and Individual Differences in Habitual Reappraisal",
            "doi": "10.1371/journal.pone.0167253",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "recent models of emotion regulation suggest that the cognitive costs of reappraisal depend on stimulus intensity and habitual reappraisal. in the current experiment, we tested these hypotheses by manipulating the intensity of unpleasant and pleasant images, which participants reappraised, viewed, or suppressed their emotions to. to assess cognitive costs, we measured participants\u2019 performance on a concurrent simple reaction time task. participants also reported on their everyday use of reappraisal and suppression. higher intensity stimuli were associated with greater cognitive costs of reappraisal, for unpleasant, but not pleasant pictures. also, greater habitual reappraisal predicted lower cognitive costs of reappraisal and greater reductions in subjective feelings. results support the role of stimulus intensity and habitual use of reappraisal in predicting the cognitive costs of reappraisal."
        },
        {
            "id": "R142560",
            "label": "Products and Services Ontologies: A Methodology for Deriving OWL Ontologies from Industrial Categorization Standards",
            "doi": "10.4018/jswis.2006010103",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R142511",
                    "label": "Ontology learning from Thesauri"
                }
            ],
            "abstract": "using semantic web technologies for e-business tasks, like product search or content integration, requires ontologies for products and services. their manual creation is problematic due to (1) the high specificity, resulting in a large number of concepts, and (2) the need for timely ontology maintenance due to product innovation; and due to cost, since building such ontologies from scratch requires significant resources. at the same time, industrial categorization standards, like unspsc, ecl@ss, eotd, or the rosettanet technical dictionary, reflect some degree of consensus and contain a wealth of concept definitions plus a hierarchy. they can thus be valuable input for creating domain ontologies. however, the transformation of existing standards, originally developed for some purpose other than ontology engineering, into useful ontologies is not as straightforward as it appears. in this paper, (1) we argue that deriving products and services ontologies from industrial taxonomies is more feasible than manual ontology engineering; (2) show that the representation of the original semantics of the input standard, especially the taxonomic relationship, is an important modeling decision that determines the usefulness of the resulting ontology; (3) illustrate the problem by analyzing existing ontologies derived from unspcs and ecl@ss; (4) present a methodology for creating ontologies in owl based on the reuse of existing standards; and (5) demonstrate this approach by transforming ecl@ss 5.1 into a practically useful products and services ontology."
        },
        {
            "id": "R75719",
            "label": "Cucurbit[n]uril-Immobilized Sensor Arrays for Indicator-Displacement Assays of Small Bioactive Metabolites",
            "doi": "10.1021/acsanm.1c00293",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R78343",
                    "label": "Cucurbit[n]uril immobilization approach"
                }
            ],
            "abstract": "the patterned immobilization of chemosensors into nano/microarrays has often boosted utilization in diagnostics and environmental sensing applications. while this is a standard approach for biosens..."
        },
        {
            "id": "R169559",
            "label": "Molecular Subtypes in Stage II-III Colon Cancer Defined by Genomic Instability: Early Recurrence-Risk Associated with a High Copy-Number Variation and Loss of RUNX3 and CDKN2A",
            "doi": "10.1371/journal.pone.0122391",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective we sought to investigate various molecular subtypes defined by genomic instability that may be related to early death and recurrence in colon cancer. methods we sought to investigate various molecular subtypes defined by instability at microsatellites (msi), changes in methylation patterns (cpg island methylator phenotype, cimp) or copy number variation (cnv) in 8 genes. stage ii-iii colon cancers (n = 64) were investigated by methylation-specific multiplex ligated probe amplification (ms-mlpa). correlation of cnv, cimp and msi, with mutations in kras and brafv600e were assessed for overlap in molecular subtypes and early recurrence risk by uni- and multivariate regression. results the cimp phenotype occurred in 34% (22/64) and msi in 27% (16/60) of the tumors, with noted cimp/msi overlap. among the molecular subtypes, a high cnv phenotype had an associated odds ratio (or) for recurrence of 3.2 (95% ci 1.1-9.3; p = 0.026). losses of cacna1g (or of 2.9, 95% ci 1.4-6.0; p = 0.001), igf2 (or of 4.3, 95% ci 1.1-15.8; p = 0.007), cdkn2a (p16) (or of 2.0, 95% ci 1.1-3.6; p = 0.024), and runx3 (or of 3.4, 95% ci 1.3-8.7; p = 0.002) were associated with early recurrence, while msi, cimp, kras or braf v600e mutations were not. the cnv was significantly higher in deceased patients (cnv in 6 of 8) compared to survivors (cnv in 3 of 8). only stage and loss of runx3 and cdkn2a were significant in the multivariable risk-model for early recurrence. conclusions a high copy number variation phenotype is a strong predictor of early recurrence and death, and may indicate a dose-dependent relationship between genetic instability and outcome. loss of tumor suppressors runx3 and cdkn2a were related to recurrence-risk and warrants further investigation."
        },
        {
            "id": "R44454",
            "label": "Disposition and clinical use of bromide in cats",
            "doi": "10.2460/javma.2002.221.1131",
            "research_field": {
                "id": "R77",
                "label": "Animal Sciences"
            },
            "research_problems": [
                {
                    "id": "R44421",
                    "label": "Antiepileptic drugs' safety and effectiveness"
                }
            ],
            "abstract": "objective\\nto establish a dosing regimen for potassium bromide and evaluate use of bromide to treat spontaneous seizures in cats.\\n\\n\\ndesign\\nprospective and retrospective studies.\\n\\n\\nanimals\\n7 healthy adult male cats and records of 17 cats with seizures.\\n\\n\\nprocedure\\nseven healthy cats were administered potassium bromide (15 mg/kg [6.8 mg/lb], p.o., q 12 h) until steady-state concentrations were reached. serum samples for pharmacokinetic analysis were obtained weekly until bromide concentrations were not detectable. clinical data were obtained from records of 17 treated cats.\\n\\n\\nresults\\nin the prospective study, maximum serum bromide concentration was 1.1 +/- 0.2 mg/ml at 8 weeks. mean disappearance half-life was 1.6 +/- 0.2 weeks. steady state was achieved at a mean of 5.3 +/-1.1 weeks. no adverse effects were detected and bromide was well tolerated. in the retrospective study, administration of bromide (n = 4) or bromide and phenobarbital (3) was associated with eradication of seizures in 7 of 15 cats (serum bromide concentration range, 1.0 to 1.6 mg/ml); however, bromide administration was associated with adverse effects in 8 of 16 cats. coughing developed in 6 of these cats, leading to euthanasia in 1 cat and discontinuation of bromide administration in 2 cats.\\n\\n\\nconclusions and clinical relevance\\ntherapeutic concentrations of bromide are attained within 2 weeks in cats that receive 30 mg/kg/d (13.6 mg/lb/d) orally. although somewhat effective in seizure control, the incidence of adverse effects may not warrant routine use of bromide for control of seizures in cats."
        },
        {
            "id": "R171240",
            "label": "Interpersonal Conflicts and Development of Self-Esteem from Adolescence to Mid-Adulthood. A 26-Year Follow-Up",
            "doi": "10.1371/journal.pone.0164942",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this study investigated the association between interpersonal conflicts and the trajectory of self-esteem from adolescence to mid-adulthood. the directionality of effects between self-esteem and interpersonal conflicts was also studied. participants of a finnish cohort study in 1983 at age 16 (n = 2194) were followed up at ages 22 (n = 1656), 32 (n = 1471) and 42 (n = 1334) using postal questionnaires. measures covered self-esteem and interpersonal conflicts including, conflicts with parents, friends, colleagues, superiors, partners, break-ups with girl/boyfriends, and divorces. participants were grouped using latent profile analysis to those having \u201cconsistently low\u201d, \u201cdecreasing\u201d, or \u201cincreasing\u201d number of interpersonal conflicts from adolescence to adulthood. analyses were done using latent growth curve models and autoregressive cross-lagged models. among both females and males the self-esteem growth trajectory was most favorable in the group with a consistently low number of interpersonal conflicts. compared to the low group, the group with a decreasing number of interpersonal conflicts had a self-esteem trajectory that started and remained at a lower level throughout the study period. the group with an increasing number of interpersonal conflicts had a significantly slower self-esteem growth rate compared to the other groups, and also the lowest self-esteem level at the end of the study period. cross-lagged autoregressive models indicated small, but significant lagged effects from low self-esteem to later interpersonal conflicts, although only among males. there were no effects to the opposite direction among either gender. our results show that those reporting more and an increasing number of interpersonal conflicts have a lower and more slowly developing self-esteem trajectory from adolescence to mid-adulthood. while the result was expected, it does not seem to imply an effect from interpersonal conflicts to low self-esteem. rather, if anything, our results seem to suggest that those with low self-esteem are more prone to later interpersonal conflicts."
        },
        {
            "id": "R169051",
            "label": "Limited Awareness and Low Immediate Uptake of Pre-Exposure Prophylaxis among Men Who Have Sex with Men Using an Internet Social Networking Site",
            "doi": "10.1371/journal.pone.0033119",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background in 2010, the iprex trial demonstrated that oral antiretroviral pre-exposure prophylaxis (prep) reduced the risk of hiv acquisition among high-risk men who have sex with men (msm). the impact of iprex on prep knowledge and actual use among at-risk msm is unknown. online surveys were conducted to assess prep awareness, interest and experience among at-risk msm before and after iprex, and to determine demographic and behavioral factors associated with these measures. methods and findings cross-sectional, national, internet-based surveys were administered to u.s. based members of the most popular american msm social networking site 2 months before (n\\u200a=\\u200a398) and 1 month after (n\\u200a=\\u200a4 558) publication of iprex results. comparisons were made between these samples with regards to prep knowledge, interest, and experience. data were collected on demographics, sexual risk, and experience with post-exposure prophylaxis (pep). regression analyses were performed to identify factors associated with prep awareness, interest, and experience post-iprex. most participants were white, educated, and indicated high-risk sexual behaviors. awareness of prep was limited pre- and post-iprex (13% vs. 19%), whereas interest levels after being provided with a description of prep remained high (76% vs. 79%). prep use remained uncommon (0.7% vs. 0.9%). prep use was associated with pep awareness (or 7.46; ci 1.52\u201336.6) and pep experience (or 34.2; ci 13.3\u201388.4). prep interest was associated with older age (or 1.01; ci 1.00\u20131.02), unprotected anal intercourse with \u22651 male partner in the prior 3 months (or 1.40; ci 1.10\u20131.77), and perceiving oneself at increased risk for hiv acquisition (or 1.20; ci 1.13\u20131.27). conclusions among msm engaged in online networking, awareness of prep was limited 1 month after the iprex data were released. utilization was low, although some msm who reported high-risk behaviors were interested in using prep. studies are needed to understand barriers to prep utilization by at-risk msm."
        },
        {
            "id": "R70872",
            "label": "Data Curation in the OpenAIRE Scholarly Communication Infrastructure",
            "doi": "10.3789/isqv25no3.2013.03",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R70863",
                    "label": "Overview of several scholarly databases and their properties"
                }
            ],
            "abstract": "openaire is the european union initiative for an open access infrastructure for research in support of open scholarly communication and access to the research output of european funded projects and open access content from a network of institutional and disciplinary repositories. this article outlines the curation activities conducted in the openaire infrastructure, which employs a multi-level, multi-targeted approach: the publication and implementation of interoperability guidelines to assist in the local data curation processes, the data curation due to the integration of heterogeneous sources supporting different types of data, the inference of links to accomplish the publication research contextualization and data enrichment, and the end-user metadata curation that allows users to edit the attributes and provide links among the entities."
        },
        {
            "id": "R171205",
            "label": "Mass Gatherings and Respiratory Disease Outbreaks in the United States \u00e2\u0080\u0093 Should We Be Worried? Results from a Systematic Literature Review and Analysis of the National Outbreak Reporting System",
            "doi": "10.1371/journal.pone.0160378",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background because mass gatherings create environments conducive for infectious disease transmission, public health officials may recommend postponing or canceling large gatherings during a moderate or severe pandemic. despite these recommendations, limited empirical information exists on the frequency and characteristics of mass gathering-related respiratory disease outbreaks occurring in the united states. methods we conducted a systematic literature review to identify articles about mass gathering-related respiratory disease outbreaks occurring in the united states from 2005 to 2014. a standard form was used to abstract information from relevant articles identified from six medical, behavioral and social science literature databases. we also analyzed data from the national outbreaks reporting system (nors), maintained by the centers for disease control and prevention since 2009, to estimate the frequency of mass gathering-related respiratory disease outbreaks reported to the system. results we identified 21 published articles describing 72 mass gathering-related respiratory disease outbreaks. of these 72, 40 (56%) were associated with agriculture fairs and influenza a h3n2v following probable swine exposure, and 25 (35%) with youth summer camps and pandemic influenza a h1n1. outbreaks of measles (n = 1) and mumps (n = 2) were linked to the international importation of disease. between 2009 and 2013, 1,114 outbreaks were reported to nors, including 96 respiratory disease outbreaks due to legionella. none of these legionellosis outbreaks was linked to a mass gathering according to available data. conclusion mass gathering-related respiratory disease outbreaks may be uncommon in the united states, but have been reported from fairs (zoonotic transmission) as well as at camps where participants have close social contact in communal housing. international importation can also be a contributing factor. nors collects information on certain respiratory diseases and could serve as a platform to monitor mass gathering-related respiratory outbreaks in the future."
        },
        {
            "id": "R169549",
            "label": "Association between Childhood Strabismus and Refractive Error in Chinese Preschool Children",
            "doi": "10.1371/journal.pone.0120720",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose to investigate the association between concomitant esotropia or concomitant exotropia and refractive error in preschool children methods a population-based sample of 5831 children aged 3 to 6 years was selected from all kindergartens in a representative county (yuhuatai district, nanjing, jiangsu province) of nanjing, china. clinical examinations including ocular alignment, ocular motility, visual acuity, optometry, stereopsis screening, slit lamp examination and fundus examination were performed by trained ophthalmologists and optometrists. odd ratios (or) and 95% confidence intervals (95% ci) were calculated to evaluate the association of refractive error with concomitant esotropia and concomitant exotropia. results in multivariate logistic regression analysis, concomitant esotropia was associated independently with spherical equivalent anisometropia (or, 3.15 for 0.50 to = 1.00 d of anisometropia) and hyperopia. there was a severity-dependent association of hyperopia with the development of concomitant esotropia, with ors increasing from 9.3 for 2.00 to = 5.00 d of hyperopia. concomitant exotropia was associated with astigmatism (or, 3.56 for 0.50 to 1.00 d of astigmatism, and 1.9 for <0.00 d of astigmatism), myopia (or, 40.54 for -1.00 to <0.00 d of myopia, and 18.93 for <-1.00 d of myopia), and hyperopia (or, 67.78 for 1.00 to <2.00 d of hyperopia, 23.13 for 2.00 to <3.00 d of hyperopia, 25.57 for 3.00 to <4.00 d of hyperopia, and 8.36 for 4.00 to <5.00 d of hyperopia). conclusions this study highlights the close associations between refractive error and the prevalence of concomitant esotropia and concomitant exotropia, which should be considered when managing childhood refractive error."
        },
        {
            "id": "R169602",
            "label": "Anthropogenic Black Carbon Emission Increase during the Last 150 Years at Coastal Jiangsu, China",
            "doi": "10.1371/journal.pone.0129680",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "black carbon (bc) is one of the major drivers of climate change and a useful indicator of environmental pollution from industrialization, and thus it is essential to reconstruct the historical trend in bc flux to better understand its impact. the yancheng coastal wetland reserve in jiangsu province is an area sensitive to global sea level change and is also located in the most developed as well as most polluted region of china. we investigated the concentration and historical flux of bc over the past 150 years through geochemical analysis of two 210pb-dated sediment cores from yancheng coastal wetland. measured bc contents ranged from 0.24 mg g-1 to 1.41 mg g-1 with average values of 0.51mg g-1-0.69 mg g-1, and bc fluxes ranged from 0.69 g m-2 yr-1 to 11.80 g m-2 yr-1 with averages of 2.94g m-2 yr-1-3.79 g m-2 yr-1. these values are consistent with other records worldwide. both bc content and flux show a gradual and continuous increase over time and clearly reflect increased emissions from anthropogenic activities. the bc records have a significant peak in recent years (from 2000 to 2007), which is accompanied by the sharp increase of energy consumption and total carbon emission in the region. it is reasonable to conclude that changes in bc from increasing human activities have controlled bc fluxes during the last 150 years. industrial contamination, especially bc emission, in the coastal region of eastern china should be taken into account when developing management strategies for protecting the natural environment."
        },
        {
            "id": "R170503",
            "label": "Matter Over Mind: A Randomised-Controlled Trial of Single-Session Biofeedback Training on Performance Anxiety and Heart Rate Variability in Musicians",
            "doi": "10.1371/journal.pone.0046597",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background musical performance is a skilled activity performed under intense pressure, thus is often a profound source of anxiety. in other contexts, anxiety and its concomitant symptoms of sympathetic nervous system arousal have been successfully ameliorated with hrv biofeedback (hrv bf), a technique involving slow breathing which augments autonomic and emotional regulatory capacity. objective: this randomised-controlled study explored the impact of a single 30-minute session of hrv bf on anxiety in response to a highly stressful music performance. methods a total of 46 trained musicians participated in this study and were randomly allocated to a slow breathing with or without biofeedback or no-treatment control group. a 3 group\u00d72 time mixed experimental design was employed to compare the effect of group before and after intervention on performance anxiety (stai-s) and frequency domain measures of hrv. results slow breathing groups (n\\u200a=\\u200a30) showed significantly greater improvements in high frequency (hf) and lf/hf ratio measures of hrv relative to control (n\\u200a=\\u200a15) during 5 minute recordings of performance anticipation following the intervention (effect size: \u03b72\\u200a=\\u200a0.122 and \u03b72\\u200a=\\u200a0.116, respectively). the addition of biofeedback to a slow breathing protocol did not produce differential results. while intervention groups did not exhibit an overall reduction in self-reported anxiety, participants with high baseline anxiety who received the intervention (n\\u200a=\\u200a15) displayed greater reductions in self-reported state anxiety relative to those in the control condition (n\\u200a=\\u200a7) (r\\u200a=\\u200a0.379). conclusions these findings indicate that a single session of slow breathing, regardless of biofeedback, is sufficient for controlling physiological arousal in anticipation of psychosocial stress associated with music performance and that slow breathing is particularly helpful for musicians with high levels of anxiety. future research is needed to further examine the effects of hrv bf as a low-cost, non-pharmacological treatment for music performance anxiety."
        },
        {
            "id": "R186551",
            "label": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
            "doi": "",
            "research_field": {
                "id": "R112125",
                "label": "Machine Learning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we describe an open-source toolkit for neural machine translation (nmt). the toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting nmt research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. the toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques."
        },
        {
            "id": "R44458",
            "label": "Therapeutic serum phenobarbital concentrations obtained using chronic transdermal administration of phenobarbital in healthy cats",
            "doi": "10.1177/1098612X14545141",
            "research_field": {
                "id": "R77",
                "label": "Animal Sciences"
            },
            "research_problems": [
                {
                    "id": "R44421",
                    "label": "Antiepileptic drugs' safety and effectiveness"
                }
            ],
            "abstract": "seizures are a common cause of neurologic disease, and phenobarbital (pb) is the most commonly used antiepileptic drug. chronic oral dosing can be challenging for cat owners, leading to poor compliance. the purpose of this study was to determine if the transdermal administration of pb could achieve serum pb concentrations of between 15 and 45 \u03bcg/ml in healthy cats. nineteen healthy cats were enrolled in three groups. transdermal pb in pluronic lecithin organogel (plo) was applied to the pinnae for 14 days at a dosage of 3 mg/kg q12h in group 1 (n = 6 cats) and 9 mg/kg q12h in group 2 (n = 7 cats). transdermal pb in lipoderm activemax was similarly applied at 9 mg/kg q12h for 14 days in group 3 (n = 6 cats). steady-state serum pb concentrations were measured at trough, and at 2, 4 and 6 h after the morning dose on day 15. in group 1, median concentrations ranged from 6.0\u20137.5 \u03bcg/ml throughout the day (observed range 0\u201311 \u03bcg/ml). group 2 median concentrations were 26.0 \u03bcg/ml (observed range 18.0\u201337.0 \u03bcg/ml). for group 3, median concentrations ranged from 15.0\u201317.0 \u03bcg/ml throughout the day (range 5\u201329 \u03bcg/ml). side effects were mild. one cat was withdrawn from group 2 owing to ataxia and sedation. these results show therapeutic serum pb concentrations can be achieved in cats following chronic transdermal administration of pb in plo at a dosage of 9 mg/kg q12h. more individual variation was noted using lipoderm activemax. transdermal administration may be an alternative for cats that are difficult to medicate orally."
        },
        {
            "id": "R170144",
            "label": "Effect of age at initiation of antiretroviral therapy on treatment outcomes; A retrospective cohort study at a large HIV clinic in southwestern Uganda",
            "doi": "10.1371/journal.pone.0201898",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background the prevalence of hiv infection among older persons is increasing yet older age at initiation of antiretroviral therapy (art) may be associated with poorer treatment outcomes including mortality. however, majority of these studies have been done in the western world and there is limited data in resource limited settings. our study used routinely collected health facility data to assess trends in age at initiation of art, the effect of age at art initiation on mortality and immunological response at a large urban hospital in south western uganda. methods we conducted a retrospective records review of patients attending the hiv clinic at mbarara regional referral hospital in western uganda. we retrieved records for 8,533 patients who started art between january 2006 and december 2012. their data had been collected and stored as part of the larger international epidemiological database for the evaluation of aids (iedea). age was stratified into three categories namely; 18\u201334 (young adults), 35\u201349 (mid-age) and 50 years or older (older adults). survival analysis procedures with kaplan-meier\u2019s plots were used to calculate the survival probability with mortality as the endpoint and poisson regression analysis used to determine the adjusted relative risks (rr) of mortality. results the proportion of young adults and patients at who stage i initiating art increased steadily over the 7-year period. older age at art initiation (> = 50 years) was associated with a higher risk of mortality with adjusted relative risk (rr) at 1.63, (95% ci 1.26\u20132.11) compared to younger age. male gender, who stages iii and iv, lower cd4 count and lower body mass index were also all independently and significantly associated with higher risk for mortality. older adults also had a poorer immunological response rr = 1.79 (95% ci 0.89\u20133.58) but was not statistically significant. conclusions following art initiation, older adults compared to the young, have a higher risk of mortality. this age group should be targeted first for \u2018screen and treat\u2019 approach. optimization of art treatment regimens for this age group is also required to reduce mortality and improve immunological response."
        },
        {
            "id": "R36093",
            "label": "TableSeer: automatic table metadata extraction and searching in digital libraries",
            "doi": "https://doi.org/10.1145/1255175.1255193",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R36029",
                    "label": "Table extraction"
                }
            ],
            "abstract": "tables are ubiquitous in digital libraries. in scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. however, current search engines do not support table search. the difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. in this paper, we describe tableseer, a search engine for tables. tableseer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. we propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. in addition, we devise a novel page box-cutting method to improve the performance of the table detection. given a query, tableseer ranks the matched tables using an innovative ranking algorithm - tablerank. tablerank rates each \u20edquery, table\u2102 pair with a tailored vector space model and a specific term weighting scheme. overall, tableseer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. we demonstrate the value of tableseer with empirical studies on scientific documents."
        },
        {
            "id": "R140556",
            "label": "An image processing approach for converging ASTER-derived spectral maps for mapping Kolhan limestone, Jharkhand, India",
            "doi": "10.18520/CS/V106/I1/40-49",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R140555",
                    "label": "Delineation of limestone using ASTER data"
                }
            ],
            "abstract": "in the present study, we have attempted the delineation of limestone using different spectral mapping algorithms in aster data. each spectral mapping algorithm derives limestone exposure map independently. although these spectral maps are broadly similar to each other, they are also different at places in terms of spatial disposition of limestone pixels. therefore, an attempt is made to integrate the results of these spectral maps to derive an integrated map using minimum noise fraction (mnf) method. the first mnf image is the result of two cascaded principal component methods suitable for preserving complementary information derived from each spectral map. while implementing mnf, noise or non-coherent pixels occurring within a homogeneous patch of limestone are removed first using shift difference method, before attempting principal component analysis on input spectral maps for deriving composite spectral map of limestone exposures. the limestone exposure map is further validated based on spectral data and ancillary geological data."
        },
        {
            "id": "R171066",
            "label": "The Effect of Oxytocin on Social and Non-Social Behaviour and Striatal Protein Expression in C57BL/6N Mice",
            "doi": "10.1371/journal.pone.0145638",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "oxytocin has been suggested as a promising new treatment for neurodevelopmental disorders. however, important gaps remain in our understanding of its mode of action, in particular, to what extent oxytocin modulates social and non-social behaviours and whether its effects are generalizable across both sexes. here we investigated the effects of a range of oxytocin doses on social and non-social behaviours in c57bl/6n mice of both sexes. as the striatum modulates social and non-social behaviours, and is implicated in neurodevelopmental disorders, we also conducted a pilot exploration of changes in striatal protein expression elicited by oxytocin. oxytocin increased prepulse inhibition of startle but attenuated the recognition memory in male c57bl/6n mice. it increased social interaction time and suppressed the amphetamine locomotor response in both sexes. the striatum proteome following oxytocin exposure could be clearly discriminated from saline controls. with the caveat that these results are preliminary, oxytocin appeared to alter individual protein expression in directions similar to conventional anti-psychotics. the proteins affected by oxytocin could be broadly categorized as those that modulate glutamatergic, gabaergic or dopaminergic signalling and those that mediate cytoskeleton dynamics. our results here encourage further research into the clinical application of this peptide hormone, which may potentially extend treatment options across a spectrum of neurodevelopmental conditions."
        },
        {
            "id": "R169703",
            "label": "Biomarkers of Exposure to Polycyclic Aromatic Hydrocarbons and Cognitive Function among Elderly in the United States (National Health and Nutrition Examination Survey: 2001-2002)",
            "doi": "10.1371/journal.pone.0147632",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "recent studies report a link between common environmental exposures, such as particulate matter air pollution and tobacco smoke, and decline in cognitive function. the purpose of this study was to assess the association between exposure to polycyclic aromatic hydrocarbons (pahs), a selected group of chemicals present in particulate matter and tobacco smoke, and measures of cognitive performance among elderly in the general population. this cross-sectional analysis involved data from 454 individuals aged 60 years and older from the 2001\u20132002 national health and nutrition examination survey. the association between pah exposures (as measured by urinary biomarkers) and cognitive function (digit symbol substitution test (dsst)) was assessed using multiple linear regression analyses. after adjusting for age, socio-economic status and diabetes we observed a negative association between urinary 1-hydroxypyrene, the gold standard of pah exposure biomarkers, and dsst score. a one percent increase in urinary 1-hydroxypyrene resulted in approximately a 1.8 percent poorer performance on the digit symbol substitution test. our findings are consistent with previous publications and further suggest that pahs, at least in part may be responsible for the adverse cognitive effects linked to tobacco smoke and particulate matter air pollution."
        },
        {
            "id": "R171247",
            "label": "Open-Access Mega-Journals: A Bibliometric Profile",
            "doi": "10.1371/journal.pone.0165359",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper we present the first comprehensive bibliometric analysis of eleven open-access mega-journals (oamjs). oamjs are a relatively recent phenomenon, and have been characterised as having four key characteristics: large size; broad disciplinary scope; a gold-oa business model; and a peer-review policy that seeks to determine only the scientific soundness of the research rather than evaluate the novelty or significance of the work. our investigation focuses on four key modes of analysis: journal outputs (the number of articles published and changes in output over time); oamj author characteristics (nationalities and institutional affiliations); subject areas (the disciplinary scope of oamjs, and variations in sub-disciplinary output); and citation profiles (the citation distributions of each oamj, and the impact of citing journals). we found that while the total output of the eleven mega-journals grew by 14.9% between 2014 and 2015, this growth is largely attributable to the increased output of scientific reports and medicine. we also found substantial variation in the geographical distribution of authors. several journals have a relatively high proportion of chinese authors, and we suggest this may be linked to these journals\u2019 high journal impact factors (jifs). the mega-journals were also found to vary in subject scope, with several journals publishing disproportionately high numbers of articles in certain sub-disciplines. our citation analsysis offers support for bj\u00f6rk & catani\u2019s suggestion that oamjs\u2019s citation distributions can be similar to those of traditional journals, while noting considerable variation in citation rates across the eleven titles. we conclude that while the oamj term is useful as a means of grouping journals which share a set of key characteristics, there is no such thing as a \u201ctypical\u201d mega-journal, and we suggest several areas for additional research that might help us better understand the current and future role of oamjs in scholarly communication."
        },
        {
            "id": "R200119",
            "label": "Sketching and notation creation with FlexiSketch Team: Evaluating a new means for collaborative requirements elicitation",
            "doi": "10.1109/re.2015.7320421",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "whiteboards and paper allow for any kind of notations and are easy to use. requirements engineers love to use them in creative requirements elicitation and design sessions. however, the resulting diagram sketches cannot be interpreted by software modeling tools. we have developed flexisketch as an alternative to whiteboards in previous work. it is a mobile tool for model-based sketching of free-form diagrams that allows the definition and re-use of diagramming notations on the fly. the latest version of the tool, called flexisketch team, supports collaboration with multiple tablets and an electronic whiteboard, such that several users can work simultaneously on the same model sketch. in this paper we present an exploratory study about how novice and experienced engineers sketch and define ad-hoc notations collaboratively in early requirements elicitation sessions when supported by our tool. results show that participants incrementally build notations by defining language constructs the first time they use them. participants considered the option to re-use defined constructs to be a big motivational factor for providing type definitions. they found our approach useful for longer sketching sessions and situations where sketches are re-used later on."
        },
        {
            "id": "R154440",
            "label": "Anatase TiO2 Activated by Gold Nanoparticles for Selective Hydrodeoxygenation of Guaiacol to Phenolics",
            "doi": "10.1021/acscatal.6b02368",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "gold nanoparticles on a number of supporting materials, including anatase tio2 (tio2-a, in 40 nm and 45 \u03bcm), rutile tio2 (tio2-r), zro2, al2o3, sio2 , and activated carbon, were evaluated for hydrodeoxygenation of guaiacol in 6.5 mpa initial h2 pressure at 300 \u00b0c. the presence of gold nanoparticles on the supports did not show distinguishable performance compared to that of the supports alone in the conversion level and in the product distribution, except for that on a tio2-a-40 nm. the lack of marked catalytic activity on supports other than tio2-a-40 nm suggests that au nanoparticles are not catalytically active on these supports. most strikingly, the gold nanoparticles on the least-active tio2-a-40 nm support stood out as the best catalyst exhibiting high activity with excellent stability and remarkable selectivity to phenolics from guaiacol hydrodeoxygenation. the conversion of guaiacol (\u223c43.1%) over gold on the tio2-a-40 nm was about 33 times that (1.3%) over the tio2-a-40 nm alone. the selectivity o..."
        },
        {
            "id": "R171001",
            "label": "Domestic Cats (Felis silvestris catus) Do Not Show Signs of Secure Attachment to Their Owners",
            "doi": "10.1371/journal.pone.0135109",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the ainsworth strange situation test (sst) has been widely used to demonstrate that the bond between both children and dogs to their primary carer typically meets the requirements of a secure attachment (i.e. the carer being perceived as a focus of safety and security in otherwise threatening environments), and has been adapted for cats with a similar claim made. however methodological problems in this latter research make the claim that the cat-owner bond is typically a secure attachment, operationally definable by its behaviour in the sst, questionable. we therefore developed an adapted version of the sst with the necessary methodological controls which include a full counterbalance of the procedure. a cross-over design experiment with 20 cat-owner pairs (10 each undertaking one of the two versions of the sst first) and continuous focal sampling was used to record the duration of a range of behavioural states expressed by the cats that might be useful for assessing secure attachment. since data were not normally distributed, non-parametric analyses were used on those behaviours shown to be reliable across the two versions of the test (which excluded much cat behaviour). although cats vocalised more when the owner rather the stranger left the cat with the other individual, there was no other evidence consistent with the interpretation of the bond between a cat and its owner meeting the requirements of a secure attachment. these results are consistent with the view that adult cats are typically quite autonomous, even in their social relationships, and not necessarily dependent on others to provide a sense of security and safety. it is concluded that alternative methods need to be developed to characterise the normal psychological features of the cat-owner bond."
        },
        {
            "id": "R194816",
            "label": "What Will Summer Look Like? Summer Learning Loss and COVID-19 Learning Gaps",
            "doi": "10.5860/cal.19.2.3",
            "research_field": {
                "id": "R136096",
                "label": "Educational Research"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "summer 2021 will likely look much different than previous summers due to the impact of the now more than one-year-long pandemic.here we share research about summer learning loss and overlap that with emerging studies illustrating how covid-19 closures and remote learning have compounded learning loss, all of which disproportionately impacts black children, indigenous children, children of color, and all children who live in poverty."
        },
        {
            "id": "R46262",
            "label": "PROBABILISTIC ROBUST PARALLEL DESIGN OF THE SUBSYSTEMS CONSTITUTING A COMPLEX SYSTEM",
            "doi": "10.3182/20050703-6-cz-1902.01543",
            "research_field": {
                "id": "R276",
                "label": "Systems Engineering"
            },
            "research_problems": [
                {
                    "id": "R46265",
                    "label": "Robust Design Methods"
                },
                {
                    "id": "R46266",
                    "label": "Complex Systems Design"
                }
            ],
            "abstract": "abstract the design of complex systems, consisting of several subsystems and with performance specifications from multiple disciplines, in parallel was addressed in a previous publication using a robust parallel design (rpd) approach. in this paper, rpd is extended and a probabilistic robust parallel design (prpd) approach is proposed to handle cases where the statistical properties of uncertainties are known. monte carlo simulation is used to determine the value of a subsystem objective, given the known statistical distributions of uncertainties. random search techniques (e.g., simulated annealing) can then be used to minimize the subsystem objective. prpd is illustrated using a passive suspension design example of a half-car model."
        },
        {
            "id": "R193452",
            "label": "Online advertising fraud",
            "doi": "",
            "research_field": {
                "id": "R137556",
                "label": "Electrical Engineering and Information Technology"
            },
            "research_problems": [
                {
                    "id": "R193401",
                    "label": "Attacks, revenue model goal and primary component targets in online advertising system"
                }
            ],
            "abstract": "fraud is a trust issue. online fraud is a cybertrust issue. juniper research estimated that advertising frauds cost online advertisers us&dollar;19 billion worldwide in 2018. a recent survey found that 78% of respondents were concerned about ad fraud and bot traffic."
        },
        {
            "id": "R169917",
            "label": "Leisure-time physical activity, sedentary behaviors, sleep, and cardiometabolic risk factors at baseline in the PREDIMED-PLUS intervention trial: A cross-sectional analysis",
            "doi": "10.1371/journal.pone.0172253",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "limited data exists on the interrelationships between physical activity (pa), sedentary behaviors and sleep concerning cardiometabolic risk factors in aged adults at high cardiovascular disease risk. our aim was to examine independent and joint associations between time spent in leisure-time pa, sedentary behaviors and sleep on the prevalence of obesity, type 2 diabetes (t2d) and components of the metabolic syndrome (mets) in mediterranean individuals at high cardiovascular risk. cross-sectional analyses were performed on baseline data from 5776 spanish adults (aged 55-75y in men; 60-75y in women) with overweight/obesity and mets, from october 2013 to october 2016, in the predimed-plus trial. employing multivariable-adjusted cox regression with robust variance and constant time (given the cross-sectional design), higher prevalence of obesity, t2d and abdominal obesity as component of the mets were associated with greater time in tv-viewing (relative risk, rr: 1.02, 95%ci: 1.01, 1.03; rr:1.04, 95%ci: 1.02, 1.06 and rr: 1.01 95%ci: 1.00, 1.02; respectively, all p < .01). conversely, greater time in moderate-vigorous pa (mvpa) was associated with lower prevalence of obesity, t2d, abdominal obesity and low hdl-cholesterol (rr: 0.95, 95%ci: 0.93, 0.97; rr: 0.94, 95%ci: 0.89, 0.99; rr: 0.97, 95%ci: 0.96, 0.98; and rr: 0.95, 95%ci: 0.91, 0.99, respectively, all p < .05). for these outcomes, theoretically substituting 1-h/day of mvpa for 1-h/day tv-viewing was also significantly associated with lower prevalence (rr 0.91 to 0.97, all p < .05). similar lower rr in these outcomes was observed when substituting 1-h/day of mvpa for 1-h/day of sleeping. longer time watching tv and not meeting mvpa recommendations were jointly associated with higher rr of the prevalence of obesity and t2d. we concluded that, in senior individuals at high cardiovascular risk, greater time spent on mvpa and fewer on sedentary behaviors was inversely associated with prevalence of obesity, t2d, and some of the components of mets."
        },
        {
            "id": "R130126",
            "label": "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R2061",
                    "label": "Question Answering"
                },
                {
                    "id": "R119127",
                    "label": "Reading Comprehension"
                },
                {
                    "id": "R120724",
                    "label": "Natural Language Inference"
                },
                {
                    "id": "R122129",
                    "label": "Semantic Textual Similarity"
                },
                {
                    "id": "R122151",
                    "label": "Paraphrase Identification"
                },
                {
                    "id": "R127504",
                    "label": "Humor Detection"
                },
                {
                    "id": "R197043",
                    "label": "Semantic similarity computation performance at sentence- or document-level"
                }
            ],
            "abstract": "with the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like bert achieves better performance than pretraining approaches based on autoregressive language modeling. however, relying on corrupting the input with masks, bert neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. in light of these pros and cons, we propose xlnet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of bert thanks to its autoregressive formulation. furthermore, xlnet integrates ideas from transformer-xl, the state-of-the-art autoregressive model, into pretraining. empirically, under comparable experiment settings, xlnet outperforms bert on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking."
        },
        {
            "id": "R131636",
            "label": "Multilingual Models for Compositional Distributed Semantics",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124044",
                    "label": "Cross-Lingual Document Classification"
                }
            ],
            "abstract": "we present a novel technique for learning semantic representations, which extends the distributional hypothesis to multilingual data and joint-space embeddings. our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences, while maintaining sufficient distance between those of dissimilar sentences. the models do not rely on word alignments or any syntactic information and are successfully applied to a number of diverse languages. we extend our approach to learn semantic representations at the document level, too. we evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art. through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic relationships across languages without parallel data."
        },
        {
            "id": "R170404",
            "label": "Concealed Fertility and Extended Female Sexuality in a Non-Human Primate (Macaca assamensis)",
            "doi": "10.1371/journal.pone.0023105",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in numerous primates living in mixed-sex groups, females display probabilistic cues of fertility to simultaneously concentrate paternity to dominant males while diluting it amongst others as a means to reduce the risk of infanticide and to increase male care for offspring. a few species, however, lack these cues and potentially conceal fertility from males; yet, to date, little is known about mating patterns and their underlying proximate mechanisms in such species. here, we investigated mating activity and sexual consortships relative to female reproductive state in wild assamese macaques (macaca assamensis), a species where females lack prominent anogenital swellings and copulation calls. during two mating seasons (2837 contact hours) we recorded sexual and social behaviors, sexual consortships, and collected 1178 fecal samples (n\\u200a=\\u200a15 females) which were analyzed for progestogen concentrations to assess female reproductive state and to determine the timing of ovulation and conception. although mostly conceiving in their first ovarian cycle, females were sexually receptive throughout the entire 4-month mating season, and within-cycle mating frequencies were not increased during fertile phases. dominant males did not monopolize fertile matings, and consortships by high-ranking males lasted for long periods, which were not exclusively linked to female fertile phases. furthermore, females copulated promiscuously but not randomly, i.e. for almost every female, matings were concentrated to a certain male, irrespective of male rank. collectively, we demonstrate that fertility is undisclosed to males. the extreme extended female sexuality facilitated by concealed fertility may allow females to create differentiated mating relationships within a promiscuous mating system. our study provides important new insight into the plasticity of female sexuality in non-human primates."
        },
        {
            "id": "R207042",
            "label": "Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status",
            "doi": "10.1162/089120102762671936",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R207050",
                    "label": "Rhetorical Annotation"
                },
                {
                    "id": "R207051",
                    "label": "Relevance Selection"
                }
            ],
            "abstract": "in this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work. we provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. we present several experiments measuring our judges' agreement on these annotations. we also present an algorithm that, on the basis of the annotated training material, selects content from unseen articles and classifies it into a fixed set of seven rhetorical categories. the output of this extraction and classification system can be viewed as a single-document summary in its own right; alternatively, it provides starting material for the generation of task-oriented and user-tailored summaries designed to give users an overview of a scientific field."
        },
        {
            "id": "R49549",
            "label": "Induced Pluripotent Stem Cell-Derived Brain Endothelial Cells as a Cellular Model to Study Neisseria meningitidis Infection",
            "doi": "10.3389/fmicb.2019.01181",
            "research_field": {
                "id": "R56",
                "label": "Pathogenic Microbiology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "meningococcal meningitis is a severe central nervous system infection that occurs when neisseria meningitidis (nm) penetrates brain endothelial cells (becs) of the meningeal blood-cerebrospinal fluid barrier. as a human-specific pathogen, in vivo models are greatly limited and pose a significant challenge. in vitro cell models have been developed, however, most lack critical bec phenotypes limiting their usefulness. human becs generated from induced pluripotent stem cells (ipscs) retain bec properties and offer the prospect of modeling the human-specific nm interaction with becs. here, we exploit ipsc-becs as a novel cellular model to study nm host-pathogen interactions, and provide an overview of host responses to nm infection. using ipsc-becs, we first confirmed that multiple nm strains and mutants follow similar phenotypes to previously described models. the recruitment of the recently published pilus adhesin receptor cd147 underneath meningococcal microcolonies could be verified in ipsc-becs. nm was also observed to significantly increase the expression of pro-inflammatory and neutrophil-specific chemokines il6, cxcl1, cxcl2, cxcl8, and ccl20, and the secretion of ifn-\u03b3 and rantes. for the first time, we directly observe that nm disrupts the three tight junction proteins zo-1, occludin, and claudin-5, which become frayed and/or discontinuous in becs upon nm challenge. in accordance with tight junction loss, a sharp loss in trans-endothelial electrical resistance, and an increase in sodium fluorescein permeability and in bacterial transmigration, was observed. finally, we established rna-seq of sorted, infected ipsc-becs, providing expression data of nm-responsive host genes. altogether, this model provides novel insights into nm pathogenesis, including an impact of nm on barrier properties and tight junction complexes, and suggests that the paracellular route may contribute to nm traversal of becs."
        },
        {
            "id": "R196832",
            "label": "\u00ef\u00bb\u00bfFocus marking in Indian English",
            "doi": "10.1075/eww.28.1.05lan",
            "research_field": {
                "id": "R409",
                "label": "South and Southeast Asian Languages and Societies"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper investigates the use of only and itself in indian english, drawing on data from the indian subcorpus of the international corpus of english (ice-india). in all varieties of english, only is used as an exclusive focus particle and itself as a reflexive pronoun and intensifier. indian english has developed an additional use for only and itself as presentational, i.e. non-contrastive focus markers. the paper investigates the syntactic and semantic contexts of itself and only in order to capture the two lexical items\u2019 functional extension in current indian english. one interesting finding concerns the distribution of the two forms within the corpus: itself is mainly found in written texts, while only is restricted to the spoken language. the paper further considers the origin and the likely future of this innovation in indian english: whereas it is quite clear that substrate influence is directly responsible for the innovative usage, the question whether this usage will also become accepted as part of an emerging indian english standard remains to be settled."
        },
        {
            "id": "R170828",
            "label": "Chronic Treatment with Mood-Stabilizers Attenuates Abnormal Hyperlocomotion of GluA1-Subunit Deficient Mice",
            "doi": "10.1371/journal.pone.0100188",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abnormal excitatory glutamate neurotransmission and plasticity have been implicated in schizophrenia and affective disorders. gria1\u2212/\u2212 mice lacking glua1 subunit (encoded by gria1 gene) of ampa-type glutamate receptor show robust novelty-induced hyperactivity, social deficits and heightened approach features, suggesting that they could be used to test for anti-manic activity of drugs. here, we tested the efficacy of chronic treatment with established anti-manic drugs on behavioural properties of the gria1\u2212/\u2212 mice. the mice received standard mood stabilizers (lithium and valproate) and novel ones (topiramate and lamotrigine, used more as anticonvulsants) as supplements in rodent chow for at least 4 weeks. all drugs attenuated novelty-induced locomotor hyperactivity of the gria1\u2212/\u2212 mice, especially by promoting the habituation, while none of them attenuated 2-mg/kg amphetamine-induced hyperactivity as compared to control diet. treatment with lithium and valproate reversed the elevated exploratory activity of gria1\u2212/\u2212 mice. valproate treatment also reduced struggling behaviour in tail suspension test and restored reciprocally-initiated social contacts of gria1\u2212/\u2212 mice to the level shown by the wild-type gria1+/+ mice. gria1\u2212/\u2212 mice consumed slightly more sucrose during intermittent sucrose exposure than the wild-types, but ran similar distances on running wheels. these behaviours were not consistently affected by lithium and valproate in the gria1\u2212/\u2212 mice. the efficacy of various anti-manic drug treatments on novelty-induced hyperactivity suggests that the gria1\u2212/\u2212 mouse line can be utilized in screening for new therapeutics."
        },
        {
            "id": "R145104",
            "label": "Syndromic Surveillance: Adapting Innovations to Developing Settings",
            "doi": "10.1371/journal.pmed.0050072",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "the tools and strategies of syndromic surveillance, say the authors, hold promise for improving public health security in developing countries."
        },
        {
            "id": "R142295",
            "label": "Phase 1 Assessment of the Safety and Immunogenicity of an mRNA- Lipid Nanoparticle Vaccine Candidate Against SARS-CoV-2 in Human Volunteers",
            "doi": "10.1101/2020.11.09.20228551",
            "research_field": {
                "id": "R40",
                "label": "Immunology and Infectious Disease"
            },
            "research_problems": [
                {
                    "id": "R142250",
                    "label": "COVID-19 Vaccine"
                }
            ],
            "abstract": "abstract there is an urgent need for vaccines to counter the covid-19 pandemic due to infections with severe acute respiratory syndrome coronavirus (sars-cov-2). evidence from convalescent sera and preclinical studies has identified the viral spike (s) protein as a key antigenic target for protective immune responses. we have applied an mrna-based technology platform, rnactive \u00ae , to develop cvncov which contains sequence optimized mrna coding for a stabilized form of s protein encapsulated in lipid nanoparticles (lnp). following demonstration of protective immune responses against sars-cov-2 in animal models we performed a dose-escalation phase 1 study in healthy 18-60 year-old volunteers. this interim analysis shows that two doses of cvncov ranging from 2 \u03bcg to 12 \u03bcg per dose, administered 28 days apart were safe. no vaccine-related serious adverse events were reported. there were dose-dependent increases in frequency and severity of solicited systemic adverse events, and to a lesser extent of local reactions, but the majority were mild or moderate and transient in duration. immune responses when measured as igg antibodies against s protein or its receptor-binding domain (rbd) by elisa, and sars-cov-2-virus neutralizing antibodies measured by micro-neutralization, displayed dose-dependent increases. median titers measured in these assays two weeks after the second 12 \u03bcg dose were comparable to the median titers observed in convalescent sera from covid-19 patients. seroconversion (defined as a 4-fold increase over baseline titer) of virus neutralizing antibodies two weeks after the second vaccination occurred in all participants who received 12 \u03bcg doses. preliminary results in the subset of subjects who were enrolled with known sars-cov-2 seropositivity at baseline show that cvncov is also safe and well tolerated in this population, and is able to boost the pre-existing immune response even at low dose levels. based on these results, the 12 \u03bcg dose is selected for further clinical investigation, including a phase 2b/3 study that will investigate the efficacy, safety, and immunogenicity of the candidate vaccine cvncov."
        },
        {
            "id": "R169347",
            "label": "Integrated Assessment of Behavioral and Environmental Risk Factors for Lyme Disease Infection on Block Island, Rhode Island",
            "doi": "10.1371/journal.pone.0084758",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "peridomestic exposure to borrelia burgdorferi-infected ixodes scapularis nymphs is considered the dominant means of infection with black-legged tick-borne pathogens in the eastern united states. population level studies have detected a positive association between the density of infected nymphs and lyme disease incidence. at a finer spatial scale within endemic communities, studies have focused on individual level risk behaviors, without accounting for differences in peridomestic nymphal density. this study simultaneously assessed the influence of peridomestic tick exposure risk and human behavior risk factors for lyme disease infection on block island, rhode island. tick exposure risk on block island properties was estimated using remotely sensed landscape metrics that strongly correlated with tick density at the individual property level. behavioral risk factors and lyme disease serology were assessed using a longitudinal serosurvey study. significant factors associated with lyme disease positive serology included one or more self-reported previous lyme disease episodes, wearing protective clothing during outdoor activities, the average number of hours spent daily in tick habitat, the subject\u2019s age and the density of shrub edges on the subject\u2019s property. the best fit multivariate model included previous lyme diagnoses and age. the strength of this association with previous lyme disease suggests that the same sector of the population tends to be repeatedly infected. the second best multivariate model included a combination of environmental and behavioral factors, namely hours spent in vegetation, subject\u2019s age, shrub edge density (increase risk) and wearing protective clothing (decrease risk). our findings highlight the importance of concurrent evaluation of both environmental and behavioral factors to design interventions to reduce the risk of tick-borne infections."
        },
        {
            "id": "R161619",
            "label": "Sensitive, High-Strain, High-Rate Bodily Motion Sensors Based on Graphene\u00e2\u0080\u0093Rubber Composites",
            "doi": "10.1021/nn503454h",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R161622",
                    "label": "Development of wearable sensors"
                }
            ],
            "abstract": "monitoring of human bodily motion requires wearable sensors that can detect position, velocity and acceleration. they should be cheap, lightweight, mechanically compliant and display reasonable sensitivity at high strains and strain rates. no reported material has simultaneously demonstrated all the above requirements. here we describe a simple method to infuse liquid-exfoliated graphene into natural rubber to create conducting composites. these materials are excellent strain sensors displaying 10(4)-fold increases in resistance and working at strains exceeding 800%. the sensitivity is reasonably high, with gauge factors of up to 35 observed. more importantly, these sensors can effectively track dynamic strain, working well at vibration frequencies of at least 160 hz. at 60 hz, we could monitor strains of at least 6% at strain rates exceeding 6000%/s. we have used these composites as bodily motion sensors, effectively monitoring joint and muscle motion as well and breathing and pulse."
        },
        {
            "id": "R171473",
            "label": "Psychometric properties of the Resilience Scale for Adults (RSA) and its relationship with life-stress, anxiety and depression in a Hispanic Latin-American community sample",
            "doi": "10.1371/journal.pone.0187954",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "resilience is a multi-dimensional construct associated with health and well-being. at present, we do not yet have a valid, scientific instrument that is designed to evaluate adult resilience in spanish-speaking countries and that accounts for family, social and individual components. this study aimed at investigating the construct and cross-cultural validity of the resilience scale for adults (rsa) by combining confirmatory factor analysis (cfa), multidimensional scaling (mds) and hierarchical regression models in a hispanic latin-american group. a community sample of 805 adults answered the rsa, spanish language stressful life-events checklist (sl-sle), and the hopkins symptom checklist-25 (hscl-25). first-order cfa verified the six factors structure for the rsa (rmsea = .037, srmr = .047, cfi = .91, tli = .90). five rsa scales and total score have good internal consistency (scales \u03b1 > .70; total score \u03b1 = .90). two second-order cfa verified the intrapersonal and interpersonal dimensions of the protector factors of resilience, as well as their commonality and uniqueness with affective symptoms (anxiety and depression). an exploratory mds reproduced the relations of rsa items and factors at first and second-order levels against random simulated data, thereby providing initial evidence of its cross-cultural validity in a spanish-speaking group. the four-steps hierarchical model showed that the rsa scales are the strongest predictors of anxiety and depression\u2013greater than gender, age, education and stressful life-events. three rsa scales are significant unique predictors of affective symptoms. in addition, similar to findings in diverse cultural settings, resilience is positively associated with age but not with education. women report higher scores of social resources and social competence and lower scores of perception of the self. in conclusion, this study demonstrates the construct and criterion-related validity of the rsa in broad, diverse and spanish speaking sample."
        },
        {
            "id": "R146978",
            "label": "Data-Driven Model Predictive Control With Stability and Robustness Guarantees",
            "doi": "10.1109/tac.2020.3000182",
            "research_field": {
                "id": "R109",
                "label": "Control Theory"
            },
            "research_problems": [
                {
                    "id": "R146977",
                    "label": "data-driven predictive control using input-output data"
                }
            ],
            "abstract": "we propose a robust data-driven model predictive control (mpc) scheme to control linear time-invariant systems. the scheme uses an implicit model description based on behavioral systems theory and past measured trajectories. in particular, it does not require any prior identification step, but only an initially measured input\u2013output trajectory as well as an upper bound on the order of the unknown system. first, we prove exponential stability of a nominal data-driven mpc scheme with terminal equality constraints in the case of no measurement noise. for bounded additive output measurement noise, we propose a robust modification of the scheme, including a slack variable with regularization in the cost. we prove that the application of this robust mpc scheme in a multistep fashion leads to practical exponential stability of the closed loop w.r.t. the noise level. the presented results provide the first (theoretical) analysis of closed-loop properties, resulting from a simple, purely data-driven mpc scheme."
        },
        {
            "id": "R171579",
            "label": "Factors determining the social participation of older adults: A comparison between Japan and Korea using EASS 2012",
            "doi": "10.1371/journal.pone.0194703",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "aims japan and korea are the world\u2019s most aged and most rapidly aging nations. they both have low fertility rates, thereby intensifying the importance of social structures to aid a large, dependent population of older adults. common strategies involve improving their social participation, which enhances their physical and mental health, so they are supporting society rather than being supported. since the social participation rates in both countries are not as high as those of western countries, it is critical to shed light on the factors related to social participation of the elderly. methods a secondary analyses were performed using japanese and korean data from the 2012 east asia social survey (eass), which includes nationally representative samples through random sampling. the analyses only include data from those 65 and older (japan: n = 683, korea: n = 362). results social participation is classified into four types: 1) no affiliation; 2) inactive participation; 3) active recreational; and 4) active social. the japanese respondents had a higher participation rate than koreans, but more japanese were inactive. though the rates of active participations were similar in both countries. multinomial logistic regressions were conducted to examine the related factors among the four types of social participation. basic attributes (e.g., living alone) and other factors (e.g., network size) were included as independent variables. the results show that larger non-family networks were linked with increased social participation in both societies. men were more vulnerable to engaging in no social activities and at a higher risk of social isolation in both countries. one difference between the two nations is that among the japanese, people with higher social orientations engage in more active social type participation. conclusion this study reveals that non-kin social networks are important for social participation in japan and korea."
        },
        {
            "id": "R206169",
            "label": "Mining Software Entities in Scientific Literature: Document-level NER for an Extremely Imbalance and Large-scale Task",
            "doi": "10.1145/3459637.3481936",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present a comprehensive information extraction system dedicated to software entities in scientific literature. this task combines the complexity of automatic reading of scientific documents (pdf processing, document structuring, styled/rich text, scaling) with challenges specific to mining software entities: high heterogeneity and extreme sparsity of mentions, document-level cross-references, disambiguation of noisy software mentions and poor portability of machine learning approaches between highly specialized domains. while ner is a key component to recognize new and unseen software, considering this task as a simple ner application fails to address most of these issues. in this paper, we propose a multi-model machine learning approach where raw documents are ingested by a cascade of document structuring processes applied not to text, but to layout token elements. the cascading process further enriches the relevant structures of the document with a deep learning software mention recognizer adapted to the high sparsity of mentions. the machine learning cascade culminates with entity disambiguation to alleviate false positives and to provide software entity linking. a bibliographical reference resolution is integrated to the process for attaching references cited alongside the software mentions. based on the first gold-standard annotated dataset developed for software mentions, this work establishes a new reference end-to-end performance for this task. experiments with the cord-19 publications have further demonstrated that our system provides practically usable performance and is scalable to the whole scientific corpus, enabling novel applications for crediting research software and for better understanding the impact of software in science."
        },
        {
            "id": "R146808",
            "label": "Reduced voltage losses yield 10% efficient fullerene free organic solar cells with >1 V open circuit voltages",
            "doi": "10.1039/c6ee02598f",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "non-fullerene acceptors with optimized energy levels enable 10% efficient solar cells with reduced voltage losses <0.6 v."
        },
        {
            "id": "R171293",
            "label": "Life-Course Relationship between Socioeconomic Circumstances and Timing of First Birth in a Birth Cohort",
            "doi": "10.1371/journal.pone.0170170",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives this study examines the influence of socioeconomic circumstances in childhood (childhood ses) and adulthood (adult ses) on timing of first birth by age 37. methods a longitudinal study of a 1972\u20131973 new zealand birth cohort collected information on socioeconomic characteristics from age 3\u201332 and reproductive histories at 21, 26, 32 and 38; information on first birth was available from 978 of the original 1037. relative risks (rr) and 95% confidence intervals (ci) were calculated using poisson regression to examine first live birth prior to age 21, from 21\u201325, from 26\u201331, and from 32\u201337, by socioeconomic characteristics at different ages. results overall, 68.5% of men had fathered a child and 75.9% of women had given birth, by age 37; with overall differences in parenthood to age 31 for men, and 37 for women evident by childhood ses. while parenthood by age 20 was strongly associated with lower childhood ses for both sexes, first entry into motherhood from 32\u201337 was more likely with higher adult ses at age 32 (rr = 1.8, 95% ci 1.1\u20133.0 for medium and rr = 1.9, 95% ci 1.1\u20133.3 for high compared with low). education also differientated age at parenthood, with those with higher education more likely to defer fatherhood past age 31, and motherhood past age 25 followed by a period of increased likelihood of motherhood for women with higher levels of education from age 32\u201337 (rr = 1.4, 95% ci 0.87\u20132.2 and rr = 1.7, 95% ci 1.1\u20132.6 for medium and high respectively compared with low). conclusions ses varies across the lifecourse, and ses at the time has the strongest association with first births at that time. low childhood ses drives adolescent parenthood, with resulting cumulative differences in parenthood past age 30. those with more education and higher adult ses are deferring parenthood but attempt to catch up in the mid to late thirties."
        },
        {
            "id": "R171533",
            "label": "Increase in suicides the months after the death of Robin Williams in the US",
            "doi": "10.1371/journal.pone.0191405",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "investigating suicides following the death of robin williams, a beloved actor and comedian, on august 11th, 2014, we used time-series analysis to estimate the expected number of suicides during the months following williams\u2019 death. monthly suicide count data in the us (1999\u20132015) were from the centers for disease control and prevention wide-ranging online data for epidemiologic research (cdc wonder). expected suicides were calculated using a seasonal autoregressive integrated moving averages model to account for both the seasonal patterns and autoregression. time-series models indicated that we would expect 16,849 suicides from august to december 2014; however, we observed 18,690 suicides in that period, suggesting an excess of 1,841 cases (9.85% increase). although excess suicides were observed across gender and age groups, males and persons aged 30\u201344 had the greatest increase in excess suicide events. this study documents associations between robin williams\u2019 death and suicide deaths in the population thereafter."
        },
        {
            "id": "R168707",
            "label": "iDREM: Interactive visualization of dynamic regulatory networks",
            "doi": "10.1371/journal.pcbi.1006019",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the dynamic regulatory events miner (drem) software reconstructs dynamic regulatory networks by integrating static protein-dna interaction data with time series gene expression data. in recent years, several additional types of high-throughput time series data have been profiled when studying biological processes including time series mirna expression, proteomics, epigenomics and single cell rna-seq. combining all available time series and static datasets in a unified model remains an important challenge and goal. to address this challenge we have developed a new version of drem termed interactive drem (idrem). idrem provides support for all data types mentioned above and combines them with existing interaction data to reconstruct networks that can lead to novel hypotheses on the function and timing of regulators. users can interactively visualize and query the resulting model. we showcase the functionality of the new tool by applying it to microglia developmental data from multiple labs."
        },
        {
            "id": "R169332",
            "label": "Clinical Unity and Community Empowerment: The Use of Smartphone Technology to Empower Community Management of Chronic Venous Ulcers through the Support of a Tertiary Unit",
            "doi": "10.1371/journal.pone.0078786",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background chronic ulcers affect roughly 60,000 irish people, at a total cost of \u20ac600,000,000, or \u20ac10,000 per patient annually. by virtue of their chronicity, these ulcers also contribute a significant burden to tertiary outpatient vascular clinics. objective we propose utilizing mobile phone technology to decentralise care from tertiary centres to the community, improving efficiency and patient satisfaction, while maintaining patient safety. methods bespoke mobile software was developed for apples iphone 4 platform. this allowed for the remote collection of patient images prospectively and their transmission with clinical queries, from the primary healthcare team to the tertiary centre. training and iphones were provided to five public health nurses in geographically remote areas of the region. data were uploaded securely and user end software was developed allowing the review and manipulation of images, along with two way communication between the teams. establishing reliability, patients were reviewed clinically as well as remotely, and concordance analysed. qualitative data were collected through focus group discussion. results from october to december 2011 eight patients (61\u201383 yrs, mean 75.3 yrs) with chronic venous ulceration and their five public health nurses were recruited. data were transmitted using 3 g, edge, gprs and wifi, at a mean speed of 69.03 kps. concordance was 100% for wound bed assessment, 80% for skin integrity/colour and 60% for exudate assessment. focus group analysis explored the concept, practicalities and future applications of the system. conclusions with an evolving national data network, the secure transmission of clinical images is a safe alternative to regular clinic appointments for patients with chronic venous ulceration. with further development, and packaged as a freely downloadable application, this has the potential to support the community care of chronic wounds."
        },
        {
            "id": "R140624",
            "label": "SemEval-2012 Task 5: Chinese Semantic Dependency Parsing",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140627",
                    "label": "Chinese Semantic Dependency Parsing"
                }
            ],
            "abstract": "the paper presents the semeval-2012 shared task 5: chinese semantic dependency parsing. the goal of this task is to identify the dependency structure of chinese sentences from the semantic view. we firstly introduce the motivation of providing chinese semantic dependency parsing task, and then describe the task in detail including data preparation, data format, task evaluation, and so on. over ten thousand sentences were labeled for participants to train and evaluate their systems. at last, we briefly describe the submitted systems and analyze these results."
        },
        {
            "id": "R170904",
            "label": "Long-Term Sickness Absence Due to Mental Disorders Is Associated with Individual Features and Psychosocial Work Conditions",
            "doi": "10.1371/journal.pone.0115885",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"aims sickness absence is a socioeconomic global burden. in brazil, mental disorders are the third leading cause of social security benefits payments. the aim of the present study was to compare factors associated with long-term sickness absence between workers who claimed social benefits due to mental disorders or by other causes. we investigated individual features and occupational characteristics. in addition, we evaluated psychosocial factors at work assessed by the demand-control-support (dcs) and effort-reward imbalance (eri) models, and whether they were associated with long-term sickness absence due to mental disorders (ltsa-md). methods the present case-control study was conducted in s\u00e3o paulo, brazil. the sample (n\\u200a=\\u200a385) included workers on sick leave for more than 15 days. cases were the participants with disabling psychiatric illnesses, and controls were the ones with other disabling diseases. interviews were conducted to assess individual features (sociodemographic data, health habits/lifestyle, health conditions) and occupational characteristics. the participants' perception of exposure to dimensions of the dcs and eri models was also recorded. multiple logistic regressions were performed to evaluate the association between independent variables and ltsa-md. results all the regression analyses showed that ltsa-md was associated with female sex, self-reported white skin color, higher education level, high tobacco consumption, high alcohol intake, two or more comorbidities, exposure to violence at work, high job strain and low social support at work, effort-reward imbalance and high overcommitment to work. ltsa-md was associated with separate and combined dcs and eri stress models. conclusions individual features and work conditions were associated with ltsa-md. combined analysis of stress models showed that psychosocial factors at work were significantly associated with ltsa-md. resourceful use of this information may contribute to the implementation of preventive actions and strategies to facilitate return to work targeting the populations most susceptible to mental disorders.\""
        },
        {
            "id": "R76164",
            "label": "Patterns and Correlates for Bullying among Young Adolescents in Ghana",
            "doi": "10.3390/socsci3040827",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "R76151",
                    "label": "bullying"
                }
            ],
            "abstract": "bullying is relatively common and is considered to be a public health problem among adolescents worldwide. the present study examined the risk factors associated with bullying behavior among adolescents in a lower-middle-income country setting. data on 6235 adolescents aged 11\u201316 years, derived from the republic of ghana\u2019s contribution to the global school-based health survey, were analyzed using bivariate and multinomial logistic regression analysis. a high prevalence of bullying was found among ghanaian adolescents. alcohol-related health compromising behaviors (alcohol use, alcohol misuse and getting into trouble as a result of alcohol) increased the risk of being bullied. in addition, substance use, being physically attacked, being seriously injured, hunger and truancy were also found to increase the risk of being bullied. however, having understanding parents and having classmates who were kind and helpful reduced the likelihood of being bullied. these findings suggest that school-based intervention programs aimed at reducing rates of peer victimization should simultaneously target multiple risk behaviors. teachers can also reduce peer victimization by introducing programs that enhance adolescents\u2019 acceptance of each other in the classroom."
        },
        {
            "id": "R135960",
            "label": "Knowledge extraction from web-based application source code: An approach to database reverse engineering for ontology development",
            "doi": "10.1109/IRI.2008.4583022",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R135954",
                    "label": "Ontology learning from source code"
                }
            ],
            "abstract": "this paper presents a novel approach for extracting knowledge from web-based application source code in supplementing and assisting ontology development from database schemas. the structure of web-based application source code is defined in order to distinguish different kinds of knowledge within the source code for ontology development. the connections between the relevant parts of web application source code and the backend database schema with their various forms are explicitly specified in detail. a knowledge processing and integration model for extracting and integrating the knowledge embedded in the source code for ontology development is then proposed."
        },
        {
            "id": "R135836",
            "label": "Making FAIR Easy with FAIR Tools: From Creolization to Convergence",
            "doi": "https://doi.org/10.1162/dint_a_00031",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R128971",
                    "label": "Fairness"
                }
            ],
            "abstract": "since their publication in 2016 we have seen a rapid adoption of the fair principles in many scientific disciplines where the inherent value of research data and, therefore, the importance of good data management and data stewardship, is recognized. this has led to many communities asking \u201cwhat is fair?\u201d and \u201chow fair are we currently?\u201d, questions which were addressed respectively by a publication revisiting the principles and the emergence of fair metrics. however, early adopters of the fair principles have already run into the next question: \u201chow can we become (more) fair?\u201d this question is more difficult to answer, as the principles do not prescribe any specific standard or implementation. moreover, there does not yet exist a mature ecosystem of tools, platforms and standards to support human and machine agents to manage, produce, publish and consume fair data in a user-friendly and efficient (i.e., \u201ceasy\u201d) way. in this paper we will show, however, that there are already many emerging examples of fair tools under development. this paper puts forward the position that we are likely already in a creolization phase where fair tools and technologies are merging and combining, before converging in a subsequent phase to solutions that make fair feasible in daily practice."
        },
        {
            "id": "R139698",
            "label": "Accessibility, Natural User Interfaces and Interactions in Museums: The IntARSI Project",
            "doi": "10.3390/heritage4020034",
            "research_field": {
                "id": "R136112",
                "label": "General and Domain-Specific Teaching and Learning"
            },
            "research_problems": [
                {
                    "id": "R139712",
                    "label": "How to build a holistic approach for planning of multimedia, virtual, and mixed reality applications based on the concept of \u201caugmented\u201d and multisensory experience, innovative tangible user interfaces, and storytelling techniques?"
                }
            ],
            "abstract": "in a museum context, people have specific needs in terms of physical, cognitive, and social accessibility that cannot be ignored. therefore, we need to find a way to make art and culture accessible to them through the aid of universal design principles, advanced technologies, and suitable interfaces and contents. integration of such factors is a priority of the museums general direction of the italian ministry of cultural heritage, within the wider strategy of museum exploitation. in accordance with this issue, the intarsi project, publicly funded, consists of a pre-evaluation and a report of technical specifications for a new concept of museology applied to the new museum of civilization in rome (muciv). it relates to planning of multimedia, virtual, and mixed reality applications based on the concept of \u201caugmented\u201d and multisensory experience, innovative tangible user interfaces, and storytelling techniques. an inclusive approach is applied, taking into account the needs and attitudes of a wide audience with different ages, cultural interests, skills, and expectations, as well as cognitive and physical abilities."
        },
        {
            "id": "R170272",
            "label": "Vitellogenin-like A\u00e2\u0080\u0093associated shifts in social cue responsiveness regulate behavioral task specialization in an ant",
            "doi": "10.1371/journal.pbio.2005747",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "division of labor and task specialization explain the success of human and insect societies. social insect colonies are characterized by division of labor, with workers specializing in brood care early and foraging later in life. theory posits that this task switching requires shifts in responsiveness to task-related cues, yet experimental evidence is weak. here, we show that a vitellogenin (vg) ortholog identified in an rnaseq study on the ant t. longispinosus is involved in this process: using phylogenetic analyses of vg and vg-like genes, we firstly show that this candidate gene does not cluster with the intensively studied honey bee vg but falls into a separate vg-like a cluster. secondly, an experimental knockdown of vg-like a in the fat body caused a reduction in brood care and an increase in nestmate care in young ant workers. nestmate care is normally exhibited by older workers. we demonstrate experimentally that this task switch is at least partly based on vg-like a\u2013associated shifts in responsiveness from brood to worker cues. we thus reveal a novel mechanism leading to early behavioral maturation via changes in social cue responsiveness mediated by vg-like a and associated pathways, which proximately play a role in regulating division of labor."
        },
        {
            "id": "R171548",
            "label": "Social capital and Internet use in an age-comparative perspective with a focus on later life",
            "doi": "10.1371/journal.pone.0192119",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "older adults (aged 65+) are still less likely to adopt the internet when compared to other age groups, although their usage is increasing. to explore the societal effects of internet usage, scholars have been using social capital as an analytical tool. social capital pertains to the resources that are potentially available in one\u2019s social ties. as the internet becomes a prominent source of information, communication, and participation in industrialized countries, it is critical to study how it affects social resources from an age-comparative perspective. research has found a positive association between internet use and social capital, though limited attention has been paid to older adults. studies have also found a positive association between social capital and wellbeing, health, sociability, and social support amongst older adults. however, little is known about how internet usage or lack thereof relates to their social capital. to address this gap, we used a mixed-methods approach to examine the relationship between internet usage and social capital and whether and how it differs by age. for this, we surveyed a representative sample of 417 adults (18+) living in lisbon, portugal, of which 118 are older adults. social capital was measured through bonding, bridging, and specific resources, and analyzed with latent class modeling and logistic regressions. internet usage was measured through frequency and type of use. fourteen follow-up semi-structured interviews helped contextualize the survey data. our findings show that social capital decreased with age but varied for each type of internet user. older adults were less likely to have a high level of social capital; yet within this age group, frequent internet users had higher levels than other users and non-users. on the one hand, the internet seems to help maintain, accrue, and even mobilize social capital. on the other hand, it also seems to reinforce social inequality and accumulated advantage (known as the matthew effect)."
        },
        {
            "id": "R169032",
            "label": "Schizotypy and Behavioural Adjustment and the Role of Neuroticism",
            "doi": "10.1371/journal.pone.0030078",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective in the present study the relationship between behavioural adjustment following cognitive conflict and schizotypy was investigated using a stroop colour naming paradigm. previous research has found deficits with behavioural adjustment in schizophrenia patients. based on these findings, we hypothesized that individual differences in schizotypy, a personality trait reflecting the subclinical expression of the schizophrenia phenotype, would be associated with behavioural adjustment. additionally, we investigated whether such a relationship would be explained by individual differences in neuroticism, a non-specific measure of negative trait emotionality known to be correlated with schizotypy. methods 106 healthy volunteers (mean age: 25.1, 60% females) took part. post-conflict adjustment was measured in a computer-based version of the stroop paradigm. schizotypy was assessed using the schizotypal personality questionnaire (spq) and neuroticism using the neo-ffi. results we found a negative correlation between schizotypy and post-conflict adjustment (r\\u200a=\\u200a\u2212.30, p<.01); this relationship remained significant when controlling for effects of neuroticism. regression analysis revealed that particularly the subscale no close friends drove the effect. conclusion previous findings of deficits in cognitive control in schizophrenia patients were extended to the subclinical personality expression of the schizophrenia phenotype and found to be specific to schizotypal traits over and above the effects of negative emotionality."
        },
        {
            "id": "R197311",
            "label": "Annotated Speech Corpus for Low Resource Indian Languages: Awadhi, Bhojpuri, Braj and Magahi",
            "doi": "10.48550/ARXIV.2206.12931",
            "research_field": {
                "id": "R405",
                "label": "European Languages and Societies (not elsewhere classified)"
            },
            "research_problems": [
                {
                    "id": "R197340",
                    "label": "Speech Dataset for Low-resource Indian Languages"
                }
            ],
            "abstract": "in this paper we discuss an in-progress work on the development of a speech corpus for four low-resource indo-aryan languages - awadhi, bhojpuri, braj and magahi using the \ufb01eld methods of linguistic data collection. the total size of the corpus cur-rently stands at approximately 18 hours (approx. 4-5 hours each language) and it is transcribed and annotated with grammatical information such as part-of-speech tags, morphological features and universal dependency relationships. we discuss our methodology for data collection in these languages, most of which was done in the middle of the covid - 19 pandemic, with one of the aims being to generate some additional income for low-income groups speaking these languages. in the paper, we also discuss the results of the baseline experiments for automatic speech recognition system in these languages."
        },
        {
            "id": "R134920",
            "label": "The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R38570",
                    "label": "Image Classification"
                }
            ],
            "abstract": "although simple individually, artificial neurons provide state-of-the-art performance when interconnected in deep networks. arguably, the tsetlin automaton is an even simpler and more versatile learning mechanism, capable of solving the multi-armed bandit problem. merely by means of a single integer as memory, it learns the optimal action in stochastic environments through increment and decrement operations. in this paper, we introduce the tsetlin machine, which solves complex pattern recognition problems with propositional formulas, composed by a collective of tsetlin automata. to eliminate the longstanding problem of vanishing signal-to-noise ratio, the tsetlin machine orchestrates the automata using a novel game. further, both inputs, patterns, and outputs are expressed as bits, while recognition and learning rely on bit manipulation, simplifying computation. our theoretical analysis establishes that the nash equilibria of the game align with the propositional formulas that provide optimal pattern recognition accuracy. this translates to learning without local optima, only global ones. in five benchmarks, the tsetlin machine provides competitive accuracy compared with svms, decision trees, random forests, naive bayes classifier, logistic regression, and neural networks. we further demonstrate how the propositional formulas facilitate interpretation. we believe the combination of high accuracy, interpretability, and computational simplicity makes the tsetlin machine a promising tool for a wide range of domains."
        },
        {
            "id": "R197296",
            "label": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression",
            "doi": "",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper, we discuss the development of a multilingual annotated corpus of misogyny and aggression in indian english, hindi, and indian bangla as part of a project on studying and automatically identifying misogyny and communalism on social media (the comma project). the dataset is collected from comments on youtube videos and currently contains a total of over 20,000 comments. the comments are annotated at two levels - aggression (overtly aggressive, covertly aggressive, and non-aggressive) and misogyny (gendered and non-gendered). we describe the process of data collection, the tagset used for annotation, and issues and challenges faced during the process of annotation. finally, we discuss the results of the baseline experiments conducted to develop a classifier for misogyny in the three languages."
        },
        {
            "id": "R195237",
            "label": "Building Chinese Discourse Corpus with Connective-driven Dependency Tree Structure",
            "doi": "10.3115/v1/D14-1224",
            "research_field": {
                "id": "R323",
                "label": "Discourse/Text Linguistics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper, we propose a connectivedriven dependency tree (cdt) scheme to represent the discourse rhetorical structure in chinese language, with elementary discourse units as leaf nodes and connectives as non-leaf nodes, largely motivated by the penn discourse treebank and the rhetorical structure theory. in particular, connectives are employed to directly represent the hierarchy of the tree structure and the rhetorical relation of a discourse, while the nuclei of discourse units are globally determined with reference to the dependency theory. guided by the cdt scheme, we manually annotate a chinese discourse treebank (cdtb) of 500 documents. preliminary evaluation justifies the appropriateness of the cdt scheme to chinese discourse analysis and the usefulness of our manually annotated cdtb corpus."
        },
        {
            "id": "R131069",
            "label": "Improving Neural Language Models with a Continuous Cache",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "we propose an extension to neural network language models to adapt their prediction to the recent history. our model is a simplified version of memory augmented networks, which stores past hidden activations as memory and accesses them through a dot product with the current hidden activation. this mechanism is very efficient and scales to very large memory sizes. we also draw a link between the use of external memory in neural network and cache models used with count based language models. we demonstrate on several language model datasets that our approach performs significantly better than recent memory augmented networks."
        },
        {
            "id": "R147181",
            "label": "Contribution of picoplankton to the total particulate organic carbon (POC) concentration in the eastern South Pacific",
            "doi": "10.5194/bgd-4-1461-2007",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R147168",
                    "label": "Picophytoplankton abundance estimation in the Ocean"
                }
            ],
            "abstract": "abstract. prochlorococcus, synechococcus, picophytoeukaryotes and bacterioplankton abundances and contributions to the total particulate organic carbon concentration (poc), derived from the total particle beam attenuation coefficient (cp), were determined across the eastern south pacific between the marquesas islands and the coast of chile. all flow cytometrically derived abundances decreased towards the hyper-oligotrophic centre of the gyre and were highest at the coast, except for prochlorococcus, which is not detected under eutrophic conditions. temperature and nutrient availability appeared important in modulating picophytoplankton abundance, according to the prevailing trophic conditions. although the non-vegetal particles tended to dominate the cp signal everywhere along the transect (50 to 83%), this dominance seemed to weaken from oligo- to eutrophic conditions, the contributions by vegetal and non-vegetal particles being about equal under mature upwelling conditions. spatial variability in the vegetal compartment was more important than the non-vegetal one in shaping the water column particulate attenuation coefficient. spatial variability in picophytoplankton biomass could be traced by changes in both tchla and cp. finally, picophytoeukaryotes contributed with ~38% on average to the total integrated phytoplankton carbon biomass or vegetal attenuation signal along the transect, as determined by direct size measurements on cells sorted by flow cytometry and optical theory. the role of picophytoeukaryotes in carbon and energy flow would therefore be very important, even under hyper-oligotrophic conditions.\\n"
        },
        {
            "id": "R169705",
            "label": "Differences in Looking at Own- and Other-Race Faces Are Subtle and Analysis-Dependent: An Account of Discrepant Reports",
            "doi": "10.1371/journal.pone.0148253",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the other-race effect (ore) is the robust and well-established finding that people are generally poorer at facial recognition of individuals of another race than of their own race. over the past four decades, much research has focused on the ore because understanding this phenomenon is expected to elucidate fundamental face processing mechanisms and the influence of experience on such mechanisms. several recent studies of the ore in which the eye-movements of participants viewing own- and other-race faces were tracked have, however, reported highly conflicting results regarding the presence or absence of differential patterns of eye-movements to own- versus other-race faces. this discrepancy, of course, leads to conflicting theoretical interpretations of the perceptual basis for the ore. here we investigate fixation patterns to own- versus other-race (african and chinese) faces for caucasian participants using different analysis methods. while we detect statistically significant, though subtle, differences in fixation pattern using an area of interest (aoi) approach, we fail to detect significant differences when applying a spatial density map approach. though there were no significant differences in the spatial density maps, the qualitative patterns matched the results from the aoi analyses reflecting how, in certain contexts, area of interest (aoi) analyses can be more sensitive in detecting the differential fixation patterns than spatial density analyses, due to spatial pooling of data with aois. aoi analyses, however, also come with the limitation of requiring a priori specification. these findings provide evidence that the conflicting reports in the prior literature may be at least partially accounted for by the differences in the statistical sensitivity associated with the different analysis methods employed across studies. overall, our results suggest that detection of differences in eye-movement patterns can be analysis-dependent and rests on the assumptions inherent in the given analysis."
        },
        {
            "id": "R146588",
            "label": "The design and establishment of epidemiological surveillance systems for high-risks diseases in developed countries: -EN- Creaci\u00c3\u00b3n y aplicaci\u00c3\u00b3n de sistemas de vigilencia epidemiol\u00c3\u00b3gica de enfermedades de alto riesgo en los pa\u00c3\u00adses desarrollados -FR- \u00c3\u0089laboration et mise en place de syst\u00c3\u00a8mes de surveillance \u00c3\u00a9pid\u00c3\u00a9mioogique des maladies \u00c3\u00a0 haut risque dans les pays d\u00c3\u00a9velopp\u00c3\u00a9s -ES-",
            "doi": "10.20506/rst.25.1.1659",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "in animal pathology, epidemiological surveillance has, over the last two decades, gradually become a top priority in developed countries, due to progress made in fighting major animal diseases. the management of effective epidemiological surveillance networks for high-risk animal diseases in developed countries is based on general rules governing epidemiological surveillance networks, but involves certain specificities. this article first of all sets out the requirements for the optimal functioning of epidemiological surveillance networks. it then describes and analyses the qualities expected of high-risk animal disease surveillance networks: detection sensitivity and specificity, simplicity and adaptability, and good cost efficiency. finally, it illustrates these general concepts via four examples of animal disease epidemiological surveillance in developed countries: foot and mouth disease in europe, west nile virus in the united states of america and france, and bluetongue in france."
        },
        {
            "id": "R171643",
            "label": "Longitudinal impacts of pubertal timing and weight status on adolescent Internet use: Analysis from a cohort study of Taiwanese youths",
            "doi": "10.1371/journal.pone.0197860",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "aim to investigate the longitudinal impacts of pubertal timing and weight status on internet use in adolescents. methods three waves of data on a longitudinal cohort of 7th grade students (n = 2430) were retrieved from the taiwan youth project. univariate and multivariate regression models were applied using crude and adjusted odds ratios (or) with 95% confidence intervals (ci) to examine the concomitant impacts of pubertal timing and weight status on adolescent internet use. results the dataset identified 210 (8.7%) students using the internet for more than 20 hours/week, and 81 (3.3%) were viewing pornographic material online. early maturing and thin-weight adolescents were at 35% and 46% increased risks of spending long hours on internet use, respectively. while early puberty was associated with online pornography viewing among males (adjusted or 1.84, 95% ci 1.04\u20133.28), early puberty was contrarily a protective factor against online gaming in females (adjusted or 0.59, 95% ci 0.36\u20130.96). conclusion early puberty was found to be positively related to adolescent internet use. appropriate health education and guidance regarding internet use should be provided to those with different developing needs."
        },
        {
            "id": "R201855",
            "label": "Thymeflow, An Open-Source Personal Knowledge Base System",
            "doi": "",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the typical internet user has data spread over several devices and across several online systems. in this paper, we introduce a novel framework for integrating a user's data from different sources into a single knowledge base. our framework integrates data of different kinds into a coherent whole, starting with email messages, calendar, contacts, and location history. we show how event periods in the user's location data can be detected, how they can be aligned with events from the calendar, and how they can be linked to relevant emails. this allows users to query their personal information within and across different dimensions, and to perform analytics over their emails, events, and locations. to this end, our system extends the schema.org vocabulary and provides a sparql interface."
        },
        {
            "id": "R211091",
            "label": "Generating Wikipedia by Summarizing Long Sequences",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we show that generating english wikipedia articles can be approached as a multi- document summarization of source documents. we use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. for the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder- decoder architectures used in sequence transduction. we show that this model can generate fluent, coherent multi-sentence paragraphs and even whole wikipedia articles. when given reference documents, we show it can extract relevant factual information as reflected in perplexity, rouge scores and human evaluations."
        },
        {
            "id": "R169056",
            "label": "Distinctive Gut Microbiota of Honey Bees Assessed Using Deep Sampling from Individual Worker Bees",
            "doi": "10.1371/journal.pone.0036393",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "surveys of 16s rdna sequences from the honey bee, apis mellifera, have revealed the presence of eight distinctive bacterial phylotypes in intestinal tracts of adult worker bees. because previous studies have been limited to relatively few sequences from samples pooled from multiple hosts, the extent of variation in this microbiota among individuals within and between colonies and locations has been unclear. we surveyed the gut microbiota of 40 individual workers from two sites, arizona and maryland usa, sampling four colonies per site. universal primers were used to amplify regions of 16s ribosomal rna genes, and amplicons were sequenced using 454 pyrotag methods, enabling analysis of about 330,000 bacterial reads. over 99% of these sequences belonged to clusters for which the first blastn hits in genbank were members of the known bee phylotypes. four phylotypes, one within gammaproteobacteria (corresponding to \u201ccandidatus gilliamella apicola\u201d) one within betaproteobacteria (\u201ccandidatus snodgrassella alvi\u201d), and two within lactobacillus, were present in every bee, though their frequencies varied. the same typical bacterial phylotypes were present in all colonies and at both sites. community profiles differed significantly among colonies and between sites, mostly due to the presence in some arizona colonies of two species of enterobacteriaceae not retrieved previously from bees. analysis of sanger sequences of rrna of the snodgrassella and gilliamella phylotypes revealed that single bees contain numerous distinct strains of each phylotype. strains showed some differentiation between localities, especially for the snodgrassella phylotype."
        },
        {
            "id": "R209873",
            "label": "Improved cell composition deconvolution method of bulk gene expression profiles to quantify subsets of immune cells",
            "doi": "10.1186/s12920-019-0613-5",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract background to facilitate the investigation of the pathogenic roles played by various immune cells in complex tissues such as tumors, a few computational methods for deconvoluting bulk gene expression profiles to predict cell composition have been created. however, available methods were usually developed along with a set of reference gene expression profiles consisting of imbalanced replicates across different cell types. therefore, the objective of this study was to create a new deconvolution method equipped with a new set of reference gene expression profiles that incorporate more microarray replicates of the immune cells that have been frequently implicated in the poor prognosis of cancers, such as t helper cells, regulatory t cells and macrophage m1/m2 cells. methods our deconvolution method was developed by choosing \u03b5-support vector regression (\u03b5-svr) as the core algorithm assigned with a loss function subject to the l1 -norm penalty. to construct the reference gene expression signature matrix for regression, a subset of differentially expressed genes were chosen from 148 microarray-based gene expression profiles for 9 types of immune cells by using anova and minimizing condition number. agreement analyses including mean absolute percentage errors and bland-altman plots were carried out to compare the performances of our method and cibersort. results in silico cell mixtures, simulated bulk tissues, and real human samples with known immune-cell fractions were used as the test datasets for benchmarking. our method outperformed cibersort in the benchmarks using in silico breast tissue-immune cell mixtures in the proportions of 30:70 and 50:50, and in the benchmark using 164 human pbmc samples. our results suggest that the performance of our method was at least comparable to that of a state-of-the-art tool, cibersort. conclusions we developed a new cell composition deconvolution method and the implementation was entirely based on the publicly available r and python packages. in addition, we compiled a new set of reference gene expression profiles, which might allow for a more robust prediction of the immune cell fractions from the expression profiles of cell mixtures. the source code of our method could be downloaded from https://github.com/holiday01/deconvolution-to-estimate-immune-cell-subsets ."
        },
        {
            "id": "R171739",
            "label": "Agreement between mothers\u00e2\u0080\u0099, fathers\u00e2\u0080\u0099, and teachers\u00e2\u0080\u0099 ratings of behavioural and emotional problems in 3\u00e2\u0080\u00935-year-old children",
            "doi": "10.1371/journal.pone.0206752",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background the strengths and difficulties questionnaire (sdq), a valid and reliable instrument for measuring children\u2019s mental health, is available in parent- and teacher versions, making it an ideal tool for assessing behavioural and emotional problems in young children. however, few studies have evaluated inter-parent agreement on the sdq, and in most studies on sdq agreement, parent scores are either provided by only one parent or have been combined into one parent score. furthermore, studies on sdq inter-rater agreement usually only reflect degree of correlation, leaving the agreement between measurements unknown. the aim of the present study was therefore to examine both degree of correlation and agreement between parent and teacher sdq reports, in a community sample of preschool-aged children in sweden. methods data were obtained from the children and parents in focus trial. the sample comprised 4,469 children 3\u20135-years-old. mothers, fathers and preschool teachers completed the sdq as part of the routine health check-ups at child health centres. inter-rater agreement was measured using pearson correlation coefficient and intraclass correlation (icc). results results revealed poor/fair agreement between parent and teacher ratings (icc 0.25\u20130.54) and good/excellent agreement between mother and father ratings (icc 0.66\u20130.76). the highest level of agreement between parents and teachers was found for the hyperactivity and peer problem subscales, whereas the strongest agreement between parents was found for the hyperactivity and conduct subscales. conclusions low inter-rater agreement between parent and teacher ratings suggests that information from both teachers and parents is important when using the sdq as a method to identify mental health problems in preschool children. although mothers and fathers each provide unique information about their child\u2019s behaviour, good inter-parent agreement indicates that a single parent informant may be sufficient and simplify data collection."
        },
        {
            "id": "R199149",
            "label": "What you ask is what you get: Understanding architecturally significant functional requirements",
            "doi": "10.1109/re.2015.7320411",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"software architects are responsible for designing an architectural solution that satisfies the functional and non-functional requirements of the system to the fullest extent possible. however, the details they need to make informed architectural decisions are often missing from the requirements specification. an earlier study we conducted indicated that architects intuitively recognize architecturally significant requirements in a project, and often seek out relevant stakeholders in order to ask probing questions (pqs) that help them acquire the information they need. this paper presents results from a qualitative interview study aimed at identifying architecturally significant functional requirements' categories from various business domains, exploring relevant pqs for each category, and then grouping pqs by type. using interview data from 14 software architects in three countries, we identified 15 categories of architecturally significant functional requirements and 6 types of pqs. we found that the domain knowledge of the architect and her experience influence the choice of pqs significantly. a preliminary quantitative evaluation of the results against real-life software requirements specification documents indicated that software specifications in our sample largely do not contain the crucial architectural differentiators that may impact architectural choices and that pqs are a necessary mechanism to unearth them. further, our findings provide the initial list of pqs which could be used to prompt business analysts to elicit architecturally significant functional requirements that the architects need.\""
        },
        {
            "id": "R4491",
            "label": "Industry Requirements of Operations Research Skills Based on Statistical Content Analysis of Job Ads",
            "doi": "10.2139/ssrn.1011468",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4496",
                    "label": "Defining the required skills for Operations Research related jobs"
                }
            ],
            "abstract": "we analyzed the text of more than 1,000 advertisements of us-based o.r. jobs to empirically determine the skills industry employers seek in graduates with o.r. backgrounds at the bachelors, masters, phd, or mba degree level. we found that employers consistently require modeling, statistics, programming and general analytical skills in an operations management context as their top requirements regardless of sector, function within company, and even degree type as their top requirements. moreover, these requirements are significantly different for another database of job ads that we analyzed. this indicates that employers perceive o.r. to be unique in comprising a mix of modeling, statistics, programming and general analytical skills but in an operations context. our analysis also shows that similar to other operations (but non-o.r.) jobs, employers also require communication, leadership, project management, spreadsheet and database and team skills."
        },
        {
            "id": "R12048",
            "label": "Adaptive context formation for linear prediction of image data",
            "doi": "10.1109/icip.2014.7026139",
            "research_field": {
                "id": "R246",
                "label": "Signal Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "images are typically non-stationary signals. if prediction is applied in a linear fashion, it must be combined with a technique which takes this characteristic into account. in general, images can be either regarded as piecewise two-dimensional autoregressive processes or they are handled in a block-wise manner. this paper presents a novel prediction technique, which treats the image data as an interleaved sequence generated by multiple sources. the challenge is to de-interleave the sequence and to compute prediction weights for each sub-source separately. the proposed approach adaptively determines the sub-sources based on the textures within the images. the prediction method is incorporated in a framework for lossless image compression. it is based on least-mean-square filtering and achieves prediction-error entropies, which are comparable to those of least-squares approaches. in combination with a dedicated coding algorithm, the proposed approach shows a competitive compression performance for a wide range of different natural images."
        },
        {
            "id": "R209986",
            "label": "Social Network Extraction and Analysis Based on Multimodal Dyadic Interaction",
            "doi": "10.3390/s120201702",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "social interactions are a very important component in people\u2019s lives. social network analysis has become a common technique used to model and quantify the properties of social interactions. in this paper, we propose an integrated framework to explore the characteristics of a social network extracted from multimodal dyadic interactions. for our study, we used a set of videos belonging to new york times\u2019 blogging heads opinion blog. the social network is represented as an oriented graph, whose directed links are determined by the influence model. the links\u2019 weights are a measure of the \u201cinfluence\u201d a person has over the other. the states of the influence model encode automatically extracted audio/visual features from our videos using state-of-the art algorithms. our results are reported in terms of accuracy of audio/visual data fusion for speaker segmentation and centrality measures used to characterize the extracted social network."
        },
        {
            "id": "R134227",
            "label": "Rainbow: Combining Improvements in Deep Reinforcement Learning",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "\\n \\n the deep reinforcement learning community has made several independent improvements to the dqn algorithm. however, it is unclear which of these extensions are complementary and can be fruitfully combined. this paper examines six extensions to the dqn algorithm and empirically studies their combination. our experiments show that the combination provides state-of-the-art performance on the atari 2600 benchmark, both in terms of data efficiency and final performance. we also provide results from a detailed ablation study that shows the contribution of each component to overall performance.\\n \\n"
        },
        {
            "id": "R110665",
            "label": "Combination Effects of Antimicrobial Peptides",
            "doi": "10.1128/aac.02434-15",
            "research_field": {
                "id": "R56",
                "label": "Pathogenic Microbiology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n \\n antimicrobial peptides (amps) are ancient and conserved across the tree of life. their efficacy over evolutionary time has been largely attributed to their mechanisms of killing. yet, the understanding of their pharmacodynamics both\\n in vivo \\n and\\n in vitro \\n is very limited. this is, however, crucial for applications of amps as drugs and also informs the understanding of the action of amps in natural immune systems. here, we selected six different amps from different organisms to test their individual and combined effects\\n in vitro \\n . we analyzed their pharmacodynamics based on the hill function and evaluated the interaction of combinations of two and three amps. interactions of amps in our study were mostly synergistic, and three-amp combinations displayed stronger synergism than two-amp combinations. this suggests synergism to be a common phenomenon in amp interaction. additionally, amps displayed a sharp increase in killing within a narrow dose range, contrasting with those of antibiotics. we suggest that our results could lead a way toward better evaluation of amp application in practice and shed some light on the evolutionary consequences of antimicrobial peptide interactions within the immune system of organisms.\\n"
        },
        {
            "id": "R196692",
            "label": "Modeling Soil Organic Carbon at Regional Scale by Combining Multi-Spectral Images with Laboratory Spectra",
            "doi": "10.1371/journal.pone.0142295",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R196702",
                    "label": "Monitoring of soil organic carbon (SOC)"
                }
            ],
            "abstract": "there is a great challenge in combining soil proximal spectra and remote sensing spectra to improve the accuracy of soil organic carbon (soc) models. this is primarily because mixing of spectral data from different sources and technologies to improve soil models is still in its infancy. the first objective of this study was to integrate information of soc derived from visible near-infrared reflectance (vis-nir) spectra in the laboratory with remote sensing (rs) images to improve predictions of topsoil soc in the skjern river catchment, denmark. the second objective was to improve soc prediction results by separately modeling uplands and wetlands. a total of 328 topsoil samples were collected and analyzed for soc. satellite pour l\u2019observation de la terre (spot5), landsat data continuity mission (landsat 8) images, laboratory vis-nir and other ancillary environmental data including terrain parameters and soil maps were compiled to predict topsoil soc using cubist regression and bayesian kriging. the results showed that the model developed from rs data, ancillary environmental data and laboratory spectral data yielded a lower root mean square error (rmse) (2.8%) and higher r2 (0.59) than the model developed from only rs data and ancillary environmental data (rmse: 3.6%, r2: 0.46). plant-available water (paw) was the most important predictor for all the models because of its close relationship with soil organic matter content. moreover, vegetation indices, such as the normalized difference vegetation index (ndvi) and enhanced vegetation index (evi), were very important predictors in soc spatial models. furthermore, the \u2018upland model\u2019 was able to more accurately predict soc compared with the \u2018upland & wetland model\u2019. however, the separately calibrated \u2018upland and wetland model\u2019 did not improve the prediction accuracy for wetland sites, since it was not possible to adequately discriminate the vegetation in the rs summer images. we conclude that laboratory vis-nir spectroscopy adds critical information that significantly improves the prediction accuracy of soc compared to using rs data alone. we recommend the incorporation of laboratory spectra with rs data and other environmental data to improve soil spatial modeling and digital soil mapping (dsm)."
        },
        {
            "id": "R169419",
            "label": "The Association of 5-HT2A, 5-HTT, and LEPR Polymorphisms with Obstructive Sleep Apnea Syndrome: A Systematic Review and Meta-Analysis",
            "doi": "10.1371/journal.pone.0095856",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective a consensus has not been reached regarding the association of several different gene polymorphisms and susceptibility to obstructive sleep apnea syndrome (osas). we performed a meta-analysis to better evaluate the associations between 5-ht2a, 5-htt, and lepr polymorphisms, and osas. method 5-ht2a, 5-htt, and lepr polymorphisms and osas were identified in pubmed and embase. the pooled odd rates (ors) with 95%cis were estimated using a fixed-effect or random-effect models. the associations between these polymorphisms and osas risk were assessed using dominant, recessive and additive models. results twelve publications were included in this study. the -1438 \u201ca\u201d allele of 5-ht2a was identified as a candidate genetic risk factor for osas (or: 2.33, 95%ci 1.49\u20133.66). individuals carrying the -1438 \u201cg\u201d allele had a nearly 70% reduced risk of osas when compared with aa homozygotes (or: 0.30, 95%ci 0.23\u20130.40). there was no significant association between 5-ht2a 102c/t and osas risk, using any model. the \u201cs\u201d allele of 5-httlpr conferred protection against osas (or: 0.80, 95%ci 0.67\u20130.95), while the \u201c10\u201d allele of 5-httvntr contributed to the risk of osas (or: 2.08, 95%ci: 1.58\u20132.73). the \u201cgg\u201d genotype of lepr was associated with a reduced risk of osas (or: 0.39, 95%ci 0.17\u20130.88). conclusion the meta-analysis demonstrated that 5-htr-1438 \u201ca\u201d and 5-httvntr \u201c10\u201d alleles were significantly associated with osas. the \u201cs\u201d allele of 5-httlpr and the \u201cgg\u201d genotype of lepr conferred protection against osas. further studies, such as genome-wide association study (gwas), should be conducted in a large cohort of osas patients to confirm our findings."
        },
        {
            "id": "R111355",
            "label": "Distribution, phenology and demography of sympatric sexual and asexual dandelions (Taraxacum officinale s.l.): geographic parthenogenesis on a small scale: GEOGRAPHIC PARTHENOGENESIS IN DANDELIONS",
            "doi": "10.1111/j.1095-8312.2004.00325.x",
            "research_field": {
                "id": "R27",
                "label": "Botany"
            },
            "research_problems": [
                {
                    "id": "R111324",
                    "label": "ecological parthenogenesis"
                }
            ],
            "abstract": "\"in many plant and animal species, sexual and asexual forms have different geographical distributions ('geographic parthenogenesis'). the common dandelion taraxacum officinale s.l. provides a particularly clear example of differing distributions: diploid sexuals are restricted to southern and central europe, while triploid asexuals occur across europe. to get a better understanding of the factors underlying this pattern, we studied the distribution and demography of sexuals and asexuals in a mixed population that was located at the northern distribution limit of the sexuals. in this population three adjacent, contrasting microhabitats were found: a foreland and south and north slopes of a river dike. comparative analyses of the distribution, phenology and demography indicated that sexuals had a stronger preference for the south slope than did asexuals. we therefore propose that the large-scale geographic parthenogenesis in t. officinale is shaped by an environmental gradient which acts upon the sexuals. [keywords: agamospermy; apomixis; flowering; microhabitat; polyploidy; triploidy]\""
        },
        {
            "id": "R170184",
            "label": "Thought experiment: Decoding cognitive processes from the fMRI data of one individual",
            "doi": "10.1371/journal.pone.0204338",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cognitive processes, such as the generation of language, can be mapped onto the brain using fmri. these maps can in turn be used for decoding the respective processes from the brain activation patterns. given individual variations in brain anatomy and organization, analyzes on the level of the single person are important to improve our understanding of how cognitive processes correspond to patterns of brain activity. they also allow to advance clinical applications of fmri, because in the clinical setting making diagnoses for single cases is imperative. in the present study, we used mental imagery tasks to investigate language production, motor functions, visuo-spatial memory, face processing, and resting-state activity in a single person. analysis methods were based on similarity metrics, including correlations between training and test data, as well as correlations with maps from the neurosynth meta-analysis. the goal was to make accurate predictions regarding the cognitive domain (e.g. language) and the specific content (e.g. animal names) of single 30-second blocks. four teams used the dataset, each blinded regarding the true labels of the test data. results showed that the similarity metrics allowed to reach the highest degrees of accuracy when predicting the cognitive domain of a block. overall, 23 of the 25 test blocks could be correctly predicted by three of the four teams. excluding the unspecific rest condition, up to 10 out of 20 blocks could be successfully decoded regarding their specific content. the study shows how the information contained in a single fmri session and in each of its single blocks can allow to draw inferences about the cognitive processes an individual engaged in. simple methods like correlations between blocks of fmri data can serve as highly reliable approaches for cognitive decoding. we discuss the implications of our results in the context of clinical fmri applications, with a focus on how decoding can support functional localization."
        },
        {
            "id": "R169262",
            "label": "Independent and Combined Effects of Physical Activity and Sedentary Behavior on Blood Pressure in Adolescents: Gender Differences in Two Cross-Sectional Studies",
            "doi": "10.1371/journal.pone.0062006",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives to examine the independent and combined association of physical activity (pa) and sedentary behavior (sb) on both systolic (sbp) and diastolic blood pressure (dbp) in adolescents from two observational studies. methods participants from two cross-sectional studies, one conducted in europe (n\\u200a=\\u200a3,308; helena study) and the other in brazil (n\\u200a=\\u200a991; bracah study), were selected by complex sampling. systolic and diastolic blood pressure (outcomes), pa and sb, both independently and combined, and potential confounders were analyzed. associations were examined by multilevel linear regression. results performing the recommended amount of pa (\u226560 min/d) attenuated the effect of sb on dbp in bracah study girls and in boys from both studies. in contrast, pa did not attenuate the effects of sb on the sbp of girls in the helena study. the combination of less than recommended levels of pa with 2\u20134 h/d of sedentary behavior was found to be associated with increased sbp in boys from both studies. conclusions meeting current pa recommendations could mediate the association between sb and dbp in both sexes. in boys, the joint effect of low levels of pa and excessive sedentary activity increases sbp levels. longitudinal studies are required to confirm these findings."
        },
        {
            "id": "R212197",
            "label": "Designing a multi-echelon closed-loop supply chain with disruption in the distribution centers under uncertainty",
            "doi": "10.3934/jimo.2022057",
            "research_field": {
                "id": "R272",
                "label": "Operations Research, Systems Engineering and Industrial Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "&lt;p style='text-indent:20px;'&gt;according to the need for further cost reduction and improving the process of the organization in the direction of customer demand, the concept of the supply chain has become increasingly significant and the organizations seek to expand this concept within their organizational framework. in this regard, efficient planning of distribution of products in the supply chain by considering disruption has received more attention recently. in this study a multi-objective mixed-integer linear programming model is developed for a green multi-echelon closed-loop supply chain network design under uncertainty. moreover, a partial disruption is considered for distribution centers where has not been studied enough in previous works. the fuzzy credibility constraint approach is applied to cover uncertainty. in the following, the \u03b5-constraint method is presented to solve and validate the model in small-sized instances. moreover, a non-dominated sorting genetic algorithm is developed for solving the large-sized problems. results show that uncertainty has a crucial impact on objective functions where the increase of objective functions by increasing the level of uncertainty, which was observed in all categories. furthermore, the proposed nsga-\u2171 is the best tool to deal with large-size problems where the ec method lacks the necessary efficiency.&lt;/p&gt;"
        },
        {
            "id": "R129825",
            "label": "An Effective Approach to Unsupervised Machine Translation",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R117322",
                    "label": "Unsupervised Machine Translation"
                }
            ],
            "abstract": "while machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both neural machine translation (nmt) and statistical machine translation (smt) systems using monolingual corpora only. in this paper, we identify and address several deficiencies of existing unsupervised smt approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. moreover, we use our improved smt system to initialize a dual nmt model, which is further fine-tuned through on-the-fly back-translation. together, we obtain large improvements over the previous state-of-the-art in unsupervised machine translation. for instance, we get 22.5 bleu points in english-to-german wmt 2014, 5.5 points more than the previous best unsupervised system, and 0.5 points more than the (supervised) shared task winner back in 2014."
        },
        {
            "id": "R142576",
            "label": "A method for re-engineering a thesaurus into an ontology",
            "doi": "10.3233/978-1-61499-084-0-133",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the construction of complex ontologies can be faci lit ted by adapting existing vocabularies. there is little clarity and i fact little consensus as to what modifications of vocabularies are necessary in orde r to re-engineer them into ontologies. in this paper we present a method that provides clear steps to follow when re-engineering a thesaurus. the method makes u se of top-level ontologies and was derived from the structural differences bet we n thesauri and ontologies as well as from best practices in modeling, some of wh ich ave been advocated in the biomedical domain. we illustrate each step of our m ethod with examples from a re-engineering case study about agricultural fertil izers based on the agrovoc thesaurus. our method makes clear that re-engineeri ng thesauri requires far more than just a syntactic conversion into a formal lang uage or other easily automatable steps. the method can not only be used for re-engin ering thesauri, but does also summarize steps for building ontologies in general, and can hence be adapted for the re-engineering of other types of vocabularies o r terminologies."
        },
        {
            "id": "R169502",
            "label": "Implementing Direct Access to Low-Dose Computed Tomography in General Practice\u00e2\u0080\u0094Method, Adaption and Outcome",
            "doi": "10.1371/journal.pone.0112162",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background early detection of lung cancer is crucial as the prognosis depends on the disease stage. chest radiographs has been the principal diagnostic tool for general practitioners (gps), but implies a potential risk of false negative results, while computed tomography (ct) has a higher sensitivity. the aim of this study was to describe the implementation of direct access to low-dose ct (ldct) from general practice. methods we conducted a cohort study nested in a randomised study. a total of 119 general practices with 266 gps were randomised into two groups. intervention gps were offered direct access to chest ldct combined with a continuing medical education (cme) meeting on lung cancer diagnosis. results during a 19-month period, 648 patients were referred to ldct (0.18/1000 adults on gp list/month). half of the patients needed further diagnostic work-up, and 15 (2.3%, 95% ci: 1.3\u20133.8%) of the patients had lung cancer; 60% (95% ci: 32.3\u201383.7%) in a localised stage. the gp referral rate was 61% higher for cme participants compared to non-participants. conclusion of all patients referred to ldct, 2.3% were diagnosed with lung cancer with a favourable stage distribution. half of the referred patients needed additional diagnostic work-up. there was an association between participation in cme and use of ct scan. the proportion of cancers diagnosed through the usual fast-track evaluation was 2.2 times higher in the group of cme-participating gps. the question remains if primary care case-finding with ldct is a better option for patients having signs and symptoms indicating lung cancer than a screening program. whether open access to ldct may provide earlier diagnosis of lung cancer is yet unknown and a randomised trial is required to assess any effect on outcome. trial registration clinicaltrials.gov nct01527214"
        },
        {
            "id": "R146241",
            "label": "Surveillance of Antimicrobial Resistance: The WHONET Program",
            "doi": "10.1093/clinids/24.supplement_1.s157",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R146204",
                    "label": "Epidemiological surveillance"
                }
            ],
            "abstract": "\"genes expressing resistance to each antimicrobial agent emerged after each agent became widely used. more than a hundred such genes now spread selectively through global networks of populations of bacteria in humans or animals treated with those agents. information to monitor and manage this spread exists in the susceptibility test results of tens of thousands of laboratories around the world. the comparability of those results is uncertain, however, and their storage in paper files or in computer files with diverse codes and formats has made them inaccessible for analysis. the whonet program puts each laboratory's data into a common code and file format at that laboratory, either by serving as or by translating from its own computer reporting system. it then enables each medical center to analyze its files in ways that help it monitor and manage resistance locally and to merge them with files of other centers for collaborative national or global surveillance of resistance.\""
        },
        {
            "id": "R138423",
            "label": "Oxidative Depolymerization of Lignin in Ionic Liquids",
            "doi": "10.1002/cssc.200900242",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R138426",
                    "label": "Lignin decomposition"
                }
            ],
            "abstract": "beech lignin was oxidatively cleaved in ionic liquids to give phenols, unsaturated propylaromatics, and aromatic aldehydes. a multiparallel batch reactor system was used to screen different ionic liquids and metal catalysts. mn(no(3))(2) in 1-ethyl-3-methylimidazolium trifluoromethanesulfonate [emim][cf(3)so(3)] proved to be the most effective reaction system. a larger scale batch reaction with this system in a 300 ml autoclave (11 g lignin starting material) resulted in a maximum conversion of 66.3 % (24 h at 100 degrees c, 84x10(5) pa air). by adjusting the reaction conditions and catalyst loading, the selectivity of the process could be shifted from syringaldehyde as the predominant product to 2,6-dimethoxy-1,4-benzoquinone (dmbq). surprisingly, the latter could be isolated as a pure substance in 11.5 wt % overall yield by a simple extraction/crystallization process."
        },
        {
            "id": "R50150",
            "label": "Global survey of star clusters in the Milky Way: I. The pipeline and fundamental parameters in the second quadrant\u00e2\u008b\u0086\u00e2\u008b\u0086\u00e2\u008b\u0086",
            "doi": "10.1051/0004-6361/201118708",
            "research_field": {
                "id": "R119",
                "label": "Stars, Interstellar Medium and the Galaxy"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "aims. on the basis of the ppmxl star catalogue we performed a survey of star clusters in the second quadrant of the milky way. methods. from the ppmxl catalogue of positions and proper motions we took the subset of stars with near-infrared photometry from 2mass and added the remaining 2mass stars without proper motions (called 2mast, i.e. 2mass with astrometry). we developed a data-processing pipeline including interactive human control of a standardised set of multi-dimensional diagrams to determine kinematic and photometric membership probabilities for stars in a cluster region. the pipeline simultaneously produced the astrophysical parameters of a cluster. from literature we compiled a target list of presently known open and globular clusters, cluster candidates, associations, and moving groups. from established member stars we derived spatial parameters (coordinates of centres and radii of the main morphological parts of clusters) and cluster kinematics (average proper motions and sometimes radial velocities). for distance, reddening, and age determination we used specific sets of theoretical isochrones. tidal parameters were obtained by a fit of three-parameter king profiles to the observed density distributions of members. results. we investigated all 871 objects in the 2nd galactic quadrant, of which we successfully treated 642 open clusters, 2 globular clusters, and 8 stellar associations. the remaining 219 objects (24%) were recognised by us to be nonexistent clusters, duplicate entries, or clusters too faint for 2mast. we found that our sample is complete in the 2nd quadrant up to a distance of 2 kpc, where the average surface density is 94 clusters per kpc 2 . compared with literature values we found good agreement in spatial and kinematic data, as well as for optical distances and reddening. small, but systematic offsets were detected in the age determination."
        },
        {
            "id": "R149046",
            "label": "Semantic modeling for the knowledge framework of computational experiments and decision making for supply chain networks",
            "doi": "",
            "research_field": {
                "id": "R308",
                "label": "Industrial Organization"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the complexity of a supply chain network (scn) is rooted in its complex structures, multiple decision-making (dm) entities, adaptive behaviors, and open environments. due to its unique advantages, computational experiment (ce) has been increasingly adopted as one of the most important methods for scn complexity research. data that are generated by computational experiments must be analyzed using effective tools. depending on this analysis, dm acts as an important analysis and selection mechanism for the optimization and design of scns. this optimization and design rely on the combination of ce and dm. this combination inevitably involves multiple types of knowledge in the domains of scns, ce, and dm, which have been less comprehensively considered in recent studies. it remains a challenge for researchers and practitioners to clarify the knowledge system of scns and select the most suitable research perspectives, paradigms, and methods for ces and dm of scns. to confront this challenge, it is necessary to systematically model the semantics of the knowledge that is involved in ce and dm to realize the consistency and interoperability of models, methods, and processes. therefore, this paper uses a semantic network approach to construct a semantic model to clarify the knowledge framework of ces and dm of scns. this knowledge framework is composed of the important knowledge elements that are extracted from the domains of scns, ce, and dm. the application procedure of the semantic model is demonstrated on a four-echelon scn case. the semantic model\u2019s understandability, consistency, reusability, procedure, systematization, and linkage analysis capability are evaluated. the results demonstrate that the semantic model is effective in providing a consistent, procedural, and systematic perspective for scn complexity research and supporting linkage analysis among scn modeling, ce, and dm."
        },
        {
            "id": "R169342",
            "label": "The Neural Basis of Responsibility Attribution in Decision-Making",
            "doi": "10.1371/journal.pone.0080389",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "social responsibility links personal behavior with societal expectations and plays a key role in affecting an agent\u2019s emotional state following a decision. however, the neural basis of responsibility attribution remains unclear. in two previous event-related brain potential (erp) studies we found that personal responsibility modulated outcome evaluation in gambling tasks. here we conducted a functional magnetic resonance imaging (fmri) study to identify particular brain regions that mediate responsibility attribution. in a context involving team cooperation, participants completed a task with their teammates and on each trial received feedback about team success and individual success sequentially. we found that brain activity differed between conditions involving team success vs. team failure. further, different brain regions were associated with reinforcement of behavior by social praise vs. monetary reward. specifically, right temporoparietal junction (rtpj) was associated with social pride whereas dorsal striatum and dorsal anterior cingulate cortex (acc) were related to reinforcement of behaviors leading to personal gain. the present study provides evidence that the rtpj is an important region for determining whether self-generated behaviors are deserving of praise in a social context."
        },
        {
            "id": "R140996",
            "label": "Fine-grained Event Classification in News-like Text Snippets - Shared Task 2, CASE 2021",
            "doi": "10.18653/v1/2021.case-1.23",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140999",
                    "label": "Fine-grained Event Classification"
                }
            ],
            "abstract": "this paper describes the shared task on fine-grained event classification in news-like text snippets. the shared task is divided into three sub-tasks: (a) classification of text snippets reporting socio-political events (25 classes) for which vast amount of training data exists, although exhibiting different structure and style vis-a-vis test data, (b) enhancement to a generalized zero-shot learning problem, where 3 additional event types were introduced in advance, but without any training data (\u2018unseen\u2019 classes), and (c) further extension, which introduced 2 additional event types, announced shortly prior to the evaluation phase. the reported shared task focuses on classification of events in english texts and is organized as part of the workshop on challenges and applications of automated extraction of socio-political events from text (case 2021), co-located with the acl-ijcnlp 2021 conference. four teams participated in the task. best performing systems for the three aforementioned sub-tasks achieved 83.9%, 79.7% and 77.1% weighted f1 scores respectively."
        },
        {
            "id": "R171055",
            "label": "Genomic Ancestry, Self-Rated Health and Its Association with Mortality in an Admixed Population: 10 Year Follow-Up of the Bambui-Epigen (Brazil) Cohort Study of Ageing",
            "doi": "10.1371/journal.pone.0144456",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background self-rated health (srh) has strong predictive value for mortality in different contexts and cultures, but there is inconsistent evidence on ethnoracial disparities in srh in latin america, possibly due to the complexity surrounding ethnoracial self-classification. materials/methods we used 370,539 single nucleotide polymorphisms (snps) to examine the association between individual genomic proportions of african, european and native american ancestry, and ethnoracial self-classification, with baseline and 10-year srh trajectories in 1,311 community dwelling older brazilians. we also examined whether genomic ancestry and ethnoracial self-classification affect the predictive value of srh for subsequent mortality. results european ancestry predominated among participants, followed by african and native american (median = 84.0%, 9.6% and 5.3%, respectively); the prevalence of non-white (mixed and black) was 39.8%. persons at higher levels of african and native american genomic ancestry, and those self-identified as non-white, were more likely to report poor health than other groups, even after controlling for socioeconomic conditions and an array of self-reported and objective physical health measures. increased risks for mortality associated with worse srh trajectories were strong and remarkably similar (hazard ratio ~3) across all genomic ancestry and ethno-racial groups. conclusions our results demonstrated for the first time that higher levels of african and native american genomic ancestry\u2014and the inverse for european ancestry\u2014were strongly correlated with worse srh in a latin american admixed population. both genomic ancestry and ethnoracial self-classification did not modify the strong association between baseline srh or srh trajectory, and subsequent mortality."
        },
        {
            "id": "R170067",
            "label": "Rates, indications, and outcomes of caesarean section deliveries: A comparison of tribal and non-tribal women in Gujarat, India",
            "doi": "10.1371/journal.pone.0189260",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background even though the caesarean section is an essential component of comprehensive obstetric and newborn care for reducing maternal and neonatal mortality, there is a lack of data regarding caesarean section rates, its determinants and health outcomes among tribal communities in india. objective the aim of this study is to estimate and compare rates, determinants, indications and outcomes of caesarean section. the article provides an assessment on how the inequitable utilization can be addressed in a community-based hospital in tribal areas of gujarat, india. method prospectively collected data of deliveries (n = 19923) from april 2010 to march 2016 in kasturba maternity hospital was used. the odds ratio of caesarean section was estimated for tribal and non-tribal women. decomposition analysis was done to decompose the differences in the caesarean section rates between tribal and non-tribal women. results the caesarean section rate was significantly lower among tribal compared to the non-tribal women (9.4% vs 15.6%, p-value < 0.01) respectively. the 60% of the differences in the rates of caesarean section between tribal and non-tribal women were unexplained. within the explained variation, the previous caesarean accounted for 96% (p-value < 0.01) of the variation. age of the mother, parity, previous caesarean and distance from the hospital were some of the important determinants of caesarean section rates. the most common indications of caesarean section were foetal distress (31.2%), previous caesarean section (23.9%), breech (16%) and prolonged labour (11.2%). there was no difference in case fatality rate (1.3% vs 1.4%, p-value = 0.90) and incidence of birth asphyxia (0.3% vs 0.6%, p-value = 0.26) comparing the tribal and non-tribal women. conclusion similar to the prior evidences, we found higher caesarean rates among non-tribal compare to tribal women. however, the adverse outcomes were similar between tribal and non-tribal women for caesarean section deliveries."
        },
        {
            "id": "R171302",
            "label": "Effects of a social accountability approach, CARE\u00e2\u0080\u0099s Community Score Card, on reproductive health-related outcomes in Malawi: A cluster-randomized controlled evaluation",
            "doi": "10.1371/journal.pone.0171316",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background social accountability approaches, which emphasize mutual responsibility and accountability by community members, health care workers, and local health officials for improving health outcomes in the community, are increasingly being employed in low-resource settings. we evaluated the effects of a social accountability approach, care\u2019s community score card (csc), on reproductive health outcomes in ntcheu district, malawi using a cluster-randomized control design. methods we matched 10 pairs of communities, randomly assigning one from each pair to intervention and control arms. we conducted two independent cross-sectional surveys of women who had given birth in the last 12 months, at baseline and at two years post-baseline. using difference-in-difference (did) and local average treatment effect (late) estimates, we evaluated the effects on outcomes including modern contraceptive use, antenatal and postnatal care service utilization, and service satisfaction. we also evaluated changes in indicators developed by community members and service providers in the intervention areas. results did analyses showed significantly greater improvements in the proportion of women receiving a home visit during pregnancy (b = 0.20, p < .01), receiving a postnatal visit (b = 0.06, p = .01), and overall service satisfaction (b = 0.16, p < .001) in intervention compared to control areas. late analyses estimated significant effects of the csc intervention on home visits by health workers (114% higher in intervention compared to control) (b = 1.14, p < .001) and current use of modern contraceptives (57% higher) (b = 0.57, p < .01). all 13 community- and provider-developed indicators improved, with 6 of them showing significant improvements. conclusions by facilitating the relationship between community members, health service providers, and local government officials, the csc contributed to important improvements in reproductive health-related outcomes. further, the csc builds mutual accountability, and ensures that solutions to problems are locally-relevant, locally-supported and feasible to implement."
        },
        {
            "id": "R8615",
            "label": "Examination of electron stains as a substitute for uranyl acetate for the ultrathin sections of bacterial cells",
            "doi": "10.1093/jmicro/dfp045",
            "research_field": {
                "id": "R21",
                "label": "Cell Biology"
            },
            "research_problems": [
                {
                    "id": "R8841",
                    "label": "comparison of staining effect of Pt-blue + Pb on different structures"
                },
                {
                    "id": "R8842",
                    "label": "comparison of staining effect of 0.2% OTE in 1/15M potassium phosphate buffer on different structures"
                },
                {
                    "id": "R8843",
                    "label": "comparison of staining effect of 0.5% potassium permanganate in 1/15M phosphate buffer on different structures"
                },
                {
                    "id": "R8844",
                    "label": "comparison of staining effect of uranyl acetate on different structures"
                },
                {
                    "id": "R8846",
                    "label": "comparison of staining effect of distilled water with 5% phosphotungstic acid (PTA) on different structures"
                },
                {
                    "id": "R8848",
                    "label": "comparison of staining effect of PB on different structures"
                }
            ],
            "abstract": "electron staining reagents were examined to find a possible substitute for uranyl acetate (ua) in electron microscopy of bacterial ultrathin sections. four kinds of stains, platinum blue (pt-blue), oolong tea extract (ote), potassium permanganate (kmno(4)) and phosphotungstic acid (pta), were examined in comparison with ua either with or without post-staining with lead citrate (pb). electron microscopy was performed on sections from spurr-embedded cells of a gram-positive bacterium, bacillus cereus nbrc 13597, and a gram-negative bacterium, escherichia coli nbrc 3301. both pt-blue and ote showed staining similar to each other and to that of double staining with ua and pb in b. cereus, while in e. coli the cytoplasmic membrane appeared less dense when compared with ua and pb. kmno(4) stained excessively to some extent, but showed images of the best contrast in the cytoplasmic membrane comparable with ua and pb among the four reagents. pta could stain the peptidoglycan layer but gave images of low quality for both bacteria. this study demonstrated that none of the reagents examined showed staining results of the same quality or better than the conventional method with ua and pb. however, stains of pt-blue, ote and kmno(4) could possibly be an alternative candidate for the ua according to the structure in question."
        },
        {
            "id": "R109981",
            "label": "Assessment of Heavy Metal Pollution of Soil-water-vegetative Ecosystems Associated with Artisanal Gold Mining",
            "doi": "10.1080/15320383.2020.1777936",
            "research_field": {
                "id": "R153",
                "label": "Soil Science"
            },
            "research_problems": [
                {
                    "id": "R109984",
                    "label": "Heavy metal pollution of soil and water resources"
                }
            ],
            "abstract": "abstract worldwide demand for gold has accelerated unregulated, small-scale artisanal gold mining (agm) activities, which are responsible for widespread environmental pollution in ghana. this study was conducted to assess the impact of agm activities, namely the heavy metals pollution of soil-water-vegetative ecosystems in southern ghana. composite soil, stream sediments and water, well water, and plant samples were randomly collected in replicates from adjoining agm areas, analyzed for soluble and total fe, cu, zn, pb, cd, hg contents and other properties, and calculated for indices to evaluate the extent of environmental pollution and degradation. results indicated that both well and stream waters were contaminated with heavy metals and were unsuitable for drinking due to high levels of pb (0.36\u20130.03 mg/l), cd (0.01\u20130.02 mg/l), and hg (<0.01 mg/l). enrichment factor and geo-accumulation index showed that the soil and sediments were polluted with cd and hg. the soil, which could have acted as a source of the hg pollutant for natural vegetation and food crops grown near agm areas, was loaded with 2.3 times more hg than the sediments. the concentration of heavy metals in fern was significantly higher than in corn, which exceeded the maximum permissible limits of who/fao guidelines. biocontamination factor suggested that the contamination of plants with hg was high compared to other heavy metals. further studies are needed for extensive sampling and monitoring of soil-water-vegetative ecosystems to remediate and control heavy metals pollution in response to agm activities in ghana."
        },
        {
            "id": "R170080",
            "label": "Visualizing the intercity correlation of PM2.5 time series in the Beijing-Tianjin-Hebei region using ground-based air quality monitoring data",
            "doi": "10.1371/journal.pone.0192614",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the beijing-tianjin-hebei area faces a severe fine particulate matter (pm2.5) problem. to date, considerable progress has been made toward understanding the pm2.5 problem, including spatial-temporal characterization, driving factors, and health effects. however, little research has been done on the dynamic interactions and relationships between pm2.5 concentrations in different cities in this area. to address the research gap, this study discovered a phenomenon of time-lagged intercity correlations of pm2.5 time series and proposed a visualization framework based on this phenomenon to visualize the interaction in pm2.5 concentrations between cities. the visualizations produced using the framework show that there are significant time-lagged correlations between the pm2.5 time series in different cities in this area. the visualizations also show that the correlations are more significant in colder months and between cities that are closer, and that there are seasonal changes in the temporal order of the correlated pm2.5 time series. further analysis suggests that the time-lagged intercity correlations of pm2.5 time series are most likely due to synoptic meteorological variations. we argue that the visualizations demonstrate the interactions of air pollution between cities in the beijing-tianjin-hebei area and the significant effect of synoptic meteorological conditions on pm2.5 pollution. the visualization framework could help determine the pathway of regional transportation of air pollution and may also be useful in delineating the area of interaction of pm2.5 pollution for impact analysis."
        },
        {
            "id": "R146924",
            "label": "Nonfullerene Polymer Solar Cells Based on a Main-Chain Twisted Low-Bandgap Acceptor with Power Conversion Efficiency of 13.2%",
            "doi": "10.1021/acsenergylett.8b00627",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "a new acceptor\u2013donor\u2013acceptor-structured nonfullerene acceptor, 2,2\u2032-((2z,2\u2032z)-(((4,4,9,9-tetrakis(4-hexylphenyl)-4,9-dihydro-s-indaceno[1,2-b:5,6-b\u2032]dithiophene-2,7-diyl)bis(4-((2-ethylhexyl)oxy)thiophene-4,3-diyl))bis(methanylylidene))bis(5,6-difluoro-3-oxo-2,3-dihydro-1h-indene-2,1-diylidene))dimalononitrile (i-ieico-4f), is designed and synthesized via main-chain substituting position modification of 2-(5,6-difluoro-3-oxo-2,3-dihydro-1h-indene-2,1-diylidene)dimalononitrile. unlike its planar analogue ieico-4f with strong absorption in the near-infrared region, i-ieico-4f exhibits a twisted main-chain configuration, resulting in 164 nm blue shifts and leading to complementary absorption with the wide-bandgap polymer (j52). a high solution molar extinction coefficient of 2.41 \u00d7 105 m\u20131 cm\u20131, and sufficiently high energy of charge-transfer excitons of 1.15 ev in a j52:i-ieico-4f blend were observed, in comparison with those of 2.26 \u00d7 105 m\u20131 cm\u20131 and 1.08 ev for ieico-4f. a power conversion efficiency of..."
        },
        {
            "id": "R170244",
            "label": "Socioeconomic status and 30-day mortality after minor and major trauma: A retrospective analysis of the Trauma Audit and Research Network (TARN) dataset for England",
            "doi": "10.1371/journal.pone.0210226",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction socioeconomic status (ses) is associated with rate and severity of trauma. however, it is unclear whether there is an independent association between ses and mortality after injury. our aim was to assess the relationship between ses and mortality from trauma. materials and methods we conducted a secondary analysis of the trauma audit and research network dataset. participants were patients admitted to nhs hospitals for trauma between january 2015 and december 2015, and resident in england. analyses used multivariate logistic regression with thirty-day mortality as the main outcome. co-variates include ses derived from area-level deprivation, age, injury severity and comorbidity. all analyses were stratified into minor and major trauma. results there were 48,652 admissions (68% for minor injury, iss<15) included, and 3,792 deaths. thirty-day mortality was 10% for patients over 85 with minor trauma, which was higher than major trauma for all age groups under 65. deprivation was not significantly associated with major trauma mortality. for minor trauma, patients older than 40 had significantly higher aors than the 0\u201315 age group. both the most and second most deprived had significantly higher aors (1.35 and 1.28 respectively). conclusions this study provides evidence of an independent relationship between ses and mortality after minor trauma, but not for major trauma. our results identify that, for less severe trauma, older patients and patients with low ses with have an increased risk of 30-day mortality. policy makers and service providers should consider extending the provision of \u2018major trauma\u2019 healthcare delivery to this at-risk population."
        },
        {
            "id": "R130563",
            "label": "Improving Transformer Models by Reordering their Sublayers",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "multilayer transformer networks consist of interleaved self-attention and feedforward sublayers. could ordering the sublayers in a different pattern lead to better performance? we generate randomly ordered transformers and train them with the language modeling objective. we observe that some of these models are able to achieve better performance than the interleaved baseline, and that those successful variants tend to have more self-attention at the bottom and more feedforward sublayers at the top. we propose a new transformer pattern that adheres to this property, the sandwich transformer, and show that it improves perplexity on multiple word-level and character-level language modeling benchmarks, at no cost in parameters, memory, or training time. however, the sandwich reordering pattern does not guarantee performance gains across every task, as we demonstrate on machine translation models. instead, we suggest that further exploration of task-specific sublayer reorderings is needed in order to unlock additional gains."
        },
        {
            "id": "R169123",
            "label": "Central Projection of Pain Arising from Delayed Onset Muscle Soreness (DOMS) in Human Subjects",
            "doi": "10.1371/journal.pone.0047230",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "delayed onset muscle soreness (doms) is a subacute pain state arising 24\u201348 hours after a bout of unaccustomed eccentric muscle contractions. functional magnetic resonance imaging (fmri) was used to examine the patterns of cortical activation arising during doms-related pain in the quadriceps muscle of healthy volunteers evoked by either voluntary contraction or physical stimulation. the painful movement or physical stimulation of the doms-affected thigh disclosed widespread activation in the primary somatosensory and motor (s1, m1) cortices, stretching far beyond the corresponding areas somatotopically related to contraction or physical stimulation of the thigh; activation also included a large area within the cingulate cortex encompassing posteroanterior regions and the cingulate motor area. pain-related activations were also found in premotor (m2) areas, bilateral in the insular cortex and the thalamic nuclei. in contrast, movement of a doms-affected limb led also to activation in the ipsilateral anterior cerebellum, while doms-related pain evoked by physical stimulation devoid of limb movement did not."
        },
        {
            "id": "R170932",
            "label": "Health-Related Quality of Life of Latin-American Immigrants and Spanish-Born Attended in Spanish Primary Health Care: Socio-Demographic and Psychosocial Factors",
            "doi": "10.1371/journal.pone.0122318",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background this study compares the health-related quality of life of spanish-born and latin american-born individuals settled in spain. socio-demographic and psychosocial factors associated with health-related quality of life are analyzed. methods a cross-sectional primary health care multi center-based study of latin american-born (n = 691) and spanish-born (n = 903) outpatients from 15 primary health care centers (madrid, spain). the medical outcomes study 36-item short form health survey (sf-36) was used to assess health-related quality of life. socio-demographic, psychosocial, and specific migration data were also collected. results compared to spanish-born participants, latin american-born participants reported higher health-related quality of life in the physical functioning and vitality dimensions. across the entire sample, latin american-born participants, younger participants, men and those with high social support reported significantly higher levels of physical health. men with higher social support and a higher income reported significantly higher mental health. when stratified by gender, data show that for men physical health was only positively associated with younger age. for women, in addition to age, social support and marital status were significantly related. both men and women with higher social support and income had significantly better mental health. finally, for immigrants, the physical and mental health components of health-related quality of life were not found to be significantly associated with any of the pre-migration factors or conditions of migration. only the variable \u201cexposure to political violence\u201d was significantly associated with the mental health component (p = 0.014). conclusions the key factors to understanding hrqol among latin american-born immigrants settled in spain are age, sex and social support. therefore, strategies to maintain optimal health outcomes in these immigrant communities should include public policies on social inclusion in the host society and focus on improving social support networks in order to foster and maintain the health and hrqol of this group."
        },
        {
            "id": "R74422",
            "label": "Integrating OER in the design of educational material: Blended learning and linked-open-educational-resources-data approach",
            "doi": "10.1109/EDUCON.2016.7474706",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74397",
                    "label": "Linked Data Interoperability"
                },
                {
                    "id": "R109063",
                    "label": "Linked Data Interoperability"
                }
            ],
            "abstract": "teaching and learning takes place in (or in a combination of) different educational environments: classroom, online, or mobile. blended learning, or hybrid learning, is a formal educational program that integrates face-to-face learning with technology-based, digital instruction. on the other hand, open educational resources (oer) provides a strategic opportunity to improve the quality of education as well as facilitate policy dialog, knowledge sharing, and capacity building. oers are actual resources/tools that can help enrich any classroom environment and push student thinking and comprehension. one of the fundamental concepts of oer is \"the ability to freely adapt and reuse existing pieces of knowledge\", and therefore be a way to create more economic and personalized learning. the oer movement has challenged the traditional value chain by employing new methods to deliver high-quality educational content. the purpose of this work is to show a way to enhance the face-to-face classrooms with integration of oers, and thus create blended learning instruction. reuse of oers by both individuals and organizations may have significant creative and economic benefit for learning environments. the approach is based on linked data for describe and publish oer. in this new paradigm for educational content consumption and integration, oer are expected to play a decisive and productive role for blended learning. the approach presented can be used to support different blended-learning models."
        },
        {
            "id": "R155520",
            "label": "Measurements of nitrogen fixation in the oligotrophic North Pacific Subtropical Gyre using a free-drifting submersible incubation device",
            "doi": "10.1093/plankt/fbv049",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R147137",
                    "label": "Nitrogen fixation rates estimation in the Pacific Ocean"
                }
            ],
            "abstract": "one challenge in field-based marine microbial ecology is to achieve sufficient spatial resolution to obtain representative information about microbial distributions and biogeochemical processes. the challenges are exacerbated when conducting rate measurements of biological processes due to potential perturbations during sampling and incubation. here we present the first application of a robotic microlaboratory, the 4 l-submersible incubation device (sid), for conducting in situ measurements of the rates of biological nitrogen (n2) fixation (bnf). the free-drifting autonomous instrument obtains samples from the water column that are incubated in situ after the addition of 15n2 tracer. after each of up to four consecutive incubation experiments, the 4-l sample is filtered and chemically preserved. measured bnf rates from two deployments of the sid in the oligotrophic north pacific ranged from 0.8 to 2.8 nmol n l?1 day?1, values comparable with simultaneous rate measurements obtained using traditional conductivity\u2013temperature\u2013depth (ctd)\u2013rosette sampling followed by on-deck or in situ incubation. future deployments of the sid will help to better resolve spatial variability of oceanic bnf, particularly in areas where recovery of seawater samples by ctd compromises their integrity, e.g. anoxic habitats."
        },
        {
            "id": "R195153",
            "label": "Efficiency and Effectiveness of Requirements Elicitation Techniques for Children",
            "doi": "10.1109/re.2018.00028",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "[context] the market for software targeting children, both for education and entertainment, is growing. existing work, mainly from hci, has considered the effectiveness of elicitation techniques for eliciting requirements from children as part of a design process. [objective] however, we are lacking work which compares requirements elicitation techniques when used with children. [methods] this study compares five elicitation techniques, taking into consideration the effectiveness and efficiency of each technique. techniques were used with a total of 54 children aged 8-13, eliciting requirements for a museum flight simulator. we compare techniques by looking at the number and type of requirements discovered, perceived participant satisfaction, resources required, perceived usefulness, and requirements coverage of domain specific categories. [conclusions] we observed notable differences between the techniques, including the effectiveness of observations and relative ineffectiveness of questionnaires. we present a set of guidelines to aid industry in eliciting requirements for child-friendly software."
        },
        {
            "id": "R170002",
            "label": "The current status of syphilis prevention and control in Jiangsu province, China: A cross-sectional study",
            "doi": "10.1371/journal.pone.0183409",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective to analyze the midterm evaluation data from the national syphilis prevention and control plan (2010\u20132020) and evaluate the current status of syphilis prevention and control in jiangsu province, china. methods we collected data via (1) field surveys conducted in 2015 and (2) data recorded in existing syphilis surveillance systems. we conducted descriptive statistical analysis to evaluate the current landscape of syphilis control initiatives and their potential effect in syphilis control. results the incidence of all cases of syphilis decreased from 2010 (32.3 per 100,000) to 2015 (30.1 per 100,000), with an annual growth of -1.17% (x2trend = -7.52, p<0.001) in jiangsu province. the incidence of primary and secondary syphilis and congenital syphilis both decreased significantly from 2010 to 2015. the average awareness rate of syphilis knowledge among professional personnel was 95.4% (3781/3963). rural residents had the lowest awareness rate (83.5%, 1875/2245) and commercial sex workers had the highest awareness rate (92.1%, 7804/8474) in 2015. only 47.8% (33908/70894) of patients received provider-initiated syphilis counseling and testing (pistc) services in sexually transmitted disease (std) clinics, but 94.5% (87927/93020) of all syphilis patients received free testing for syphilis. overall, 97.2% (9378/9648) of syphilis reported cases of syphilis at medical institutions were confirmed to be accurate, and 92.2% (5850/6345) of patients diagnosed with syphilis at medical institutions received treatment with penicillin. conclusion the syphilis incidence rate in jiangsu has decreased in recent years, but remains at a high level. it is essential to promote pistc services to improve knowledge of syphilis and rates of testing and treatment in jiangsu province."
        },
        {
            "id": "R169835",
            "label": "Tumors Alter Inflammation and Impair Dermal Wound Healing in Female Mice",
            "doi": "10.1371/journal.pone.0161537",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "tissue repair is an integral component of cancer treatment (e.g., due to surgery, chemotherapy, radiation). previous work has emphasized the immunosuppressive effects of tumors on adaptive immunity and has shown that surgery incites cancer metastases. however, the extent to which and how tumors may alter the clinically-relevant innate immune process of wound healing remains an untapped potential area of improvement for treatment, quality of life, and ultimately, mortality of cancer patients. in this study, 3.5 mm full-thickness dermal excisional wounds were placed on the dorsum of immunocompetent female mice with and without non-malignant flank at-84 murine oral squamous cell carcinomas. wound closure rate, inflammatory cell number and inflammatory signaling in wounds, and circulating myeloid cell concentrations were compared between tumor-bearing and tumor-free mice. tumors delayed wound closure, suppressed inflammatory signaling, and altered myeloid cell trafficking in wounds. an in vitro scratch \u201cwounding\u201d assay of adult dermal fibroblasts treated with tumor cell-conditioned media supported the in vivo findings. this study demonstrates that tumors are sufficient to disrupt fundamental and clinically-relevant innate immune functions. the understanding of these underlying mechanisms provides potential for therapeutic interventions capable of improving the treatment of cancer while reducing morbidities and mortality."
        },
        {
            "id": "R196520",
            "label": "LIORI at SemEval-2021 Task 2: Span Prediction and Binary Classification approaches to Word-in-Context Disambiguation",
            "doi": "10.18653/v1/2021.semeval-1.103",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R120611",
                    "label": "Word Sense Disambiguation"
                }
            ],
            "abstract": "this paper presents our approaches to semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation task. the first approach attempted to reformulate the task as a question answering problem, while the second one framed it as a binary classification problem. our best system, which is an ensemble of xlm-r based binary classifiers trained with data augmentation, is among the 3 best-performing systems for russian, french and arabic in the multilingual subtask. in the post-evaluation period, we experimented with batch normalization, subword pooling and target word occurrence aggregation methods, resulting in further performance improvements."
        },
        {
            "id": "R207059",
            "label": "Identifying Sections in Scientific Abstracts using Conditional Random Fields",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R207008",
                    "label": "Concept classification"
                }
            ],
            "abstract": "objective: the prior knowledge about the rhetorical structure of scientific abstracts is useful for various text-mining tasks such as information extraction, information retrieval, and automatic summarization. this paper presents a novel approach to categorize sentences in scientific abstracts into four sections, objective, methods, results, and conclusions. method: formalizing the categorization task as a sequential labeling problem, we employ conditional random fields (crfs) to annotate section labels into abstract sentences. the training corpus is acquired automatically from medline abstracts. results: the proposed method outperformed the previous approaches, achieving 95.5% per-sentence accuracy and 68.8% per-abstract accuracy. conclusion: the experimental results showed that crfs could model the rhetorical structure of abstracts more suitably."
        },
        {
            "id": "R145340",
            "label": "Evaluation of Syndromic Surveillance Systems in 6 US State and Local Health Departments",
            "doi": "10.1097/phh.0000000000000679",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "\"objective: evaluating public health surveillance systems is critical to ensuring that conditions of public health importance are appropriately monitored. our objectives were to qualitatively evaluate 6 state and local health departments that were early adopters of syndromic surveillance in order to (1) understand the characteristics and current uses, (2) identify the most and least useful syndromes to monitor, (3) gauge the utility for early warning and outbreak detection, and (4) assess how syndromic surveillance impacted their daily decision making. design: we adapted evaluation guidelines from the centers for disease control and prevention and gathered input from the centers for disease control and prevention subject matter experts in public health surveillance to develop a questionnaire. participants: we interviewed staff members from a convenience sample of 6 local and state health departments with syndromic surveillance programs that had been in operation for more than 10 years. results: three of the 6 interviewees provided an example of using syndromic surveillance to identify an outbreak (ie, cluster of foodborne illness in 1 jurisdiction) or detect a surge in cases for seasonal conditions (eg, influenza in 2 jurisdictions) prior to traditional, disease-specific systems. although all interviewees noted that syndromic surveillance has not been routinely useful or efficient for early outbreak detection or case finding in their jurisdictions, all agreed that the information can be used to improve their understanding of dynamic disease control environments and conditions (eg, situational awareness) in their communities. conclusion: in the jurisdictions studied, syndromic surveillance may be useful for monitoring the spread and intensity of large outbreaks of disease, especially influenza; enhancing public health awareness of mass gatherings and natural disasters; and assessing new, otherwise unmonitored conditions when real-time alternatives are unavailable. future studies should explore opportunities to strengthen syndromic surveillance by including broader access to and enhanced analysis of text-related data from electronic health records. health departments may accelerate the development and use of syndromic surveillance systems, including the improvement of the predictive value and strengthening the early outbreak detection capability of these systems. these efforts support getting the right information to the right people at the right time, which is the overarching goal of cdc's surveillance strategy.\""
        },
        {
            "id": "R70291",
            "label": "Development of a low-cost, user-customizable, high-speed camera",
            "doi": "10.1371/journal.pone.0232788",
            "research_field": {
                "id": "R241",
                "label": "Electrical and Electronics"
            },
            "research_problems": [
                {
                    "id": "R70297",
                    "label": "open hardware development"
                },
                {
                    "id": "R70298",
                    "label": "high speed cameras"
                }
            ],
            "abstract": "high-speed imaging equipment can be an expensive investment, especially when certain applications require custom solutions. in this paper, we present a low-cost high-speed prototype camera built on a low-end zynq-7000 system-on-chip (soc) platform and off-the-shelf components with the aim of removing the entry barrier into various high-speed imaging applications. the camera is standalone (does not require a host computer) and can achieve 211 frames per second (fps) at its maximum resolution of 1280x1024, and up to 2329 fps at a 256x256 resolution. with a current cost of only several hundred dollars and resource utilization of ~5%, the open-source design\u2019s modularity and customizability allows users with sufficient hardware or programming experience to modify the camera to suit their needs, potentially driving the cost lower. this can be done by utilizing the large remaining programmable logic for custom image processing algorithms, creating user interface software on the cpu, attaching extensions through the peripheral module connections, or creating custom carrier or daughter boards. the development and design of the camera is described and a figure-of-merit is presented to provide a value assessment of some available commercial high-speed cameras against which our camera is competitive. finally, the camera was tested to record low frequency spatial vibration and was found to be useful in investigating phenotypes associated with aging in a leading animal model, the nematode (worm) caenorhabditis elegans."
        },
        {
            "id": "R209485",
            "label": "A semantic Requirement Ontology for the engineering of building automation systems by means of OWL",
            "doi": "10.1109/ETFA.2009.5346991",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the increasing complexity of modern building automation systems (bas) results in higher initial investment costs for bas compared to the costs for conventional building installation. this fact scares many potential customers off the application of bas, although these systems offer significant energy cost saving potential. to reduce investment costs for bas, automated design processes offer significant optimization potential. for such an automated design process, consistent requirements for the individual bas are mandatory. within this paper, the authors propose a solution for a requirement ontology which is based on the knowledge representation language owl (web ontology language) for the automated design process of bas."
        },
        {
            "id": "R129488",
            "label": "Span-based Joint Entity and Relation Extraction with Transformer Pre-training",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R116569",
                    "label": "Relation Extraction"
                }
            ],
            "abstract": "we introduce spert, an attention model for span-based joint entity and relation extraction. our key contribution is a light-weight reasoning on bert embeddings, which features entity recognition and filtering, as well as relation classification with a localized, marker-free context representation. the model is trained using strong within-sentence negative samples, which are efficiently extracted in a single bert pass. these aspects facilitate a search over all spans in the sentence. \\nin ablation studies, we demonstrate the benefits of pre-training, strong negative sampling and localized context. our model outperforms prior work by up to 2.6% f1 score on several datasets for joint entity and relation extraction."
        },
        {
            "id": "R211261",
            "label": "Efficient Content-Based Sparse Attention with Routing Transformers",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "self-attention has recently been adopted for a wide range of sequence modeling problems. despite its effectiveness, self-attention suffers from quadratic computation and memory requirements with respect to sequence length. successful approaches to reduce this complexity focused on attending to local sliding windows or a small set of locations independent of content. our work proposes to learn dynamic sparse attention patterns that avoid allocating computation and memory to attend to content unrelated to the query of interest. this work builds upon two lines of research: it combines the modeling flexibility of prior work on content-based sparse attention with the efficiency gains from approaches based on local, temporal sparse attention. our model, the routing transformer, endows self-attention with a sparse routing module based on online k-means while reducing the overall complexity of attention to o( n 1.5 d) from o( n 2 d) for sequence length n and hidden dimension d. we show that our model outperforms comparable sparse attention models on language modeling on wikitext-103 (15.8 vs 18.3 perplexity), as well as on image generation on imagenet-64 (3.43 vs 3.44 bits/dim) while using fewer self-attention layers. additionally, we set a new state-of-the-art on the newly released pg-19 data-set, obtaining a test perplexity of 33.2 with a 22 layer routing transformer model trained on sequences of length 8192. we open-source the code for routing transformer in tensorflow. 1"
        },
        {
            "id": "R131630",
            "label": "Leveraging Monolingual Data for Crosslingual Compositional Word Representations",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124044",
                    "label": "Cross-Lingual Document Classification"
                }
            ],
            "abstract": "in this work, we present a novel neural network based architecture for inducing compositional crosslingual word representations. unlike previously proposed methods, our method fulfills the following three criteria; it constrains the word-level representations to be compositional, it is capable of leveraging both bilingual and monolingual data, and it is scalable to large vocabularies and large quantities of data. the key component of our approach is what we refer to as a monolingual inclusion criterion, that exploits the observation that phrases are more closely semantically related to their sub-phrases than to other randomly sampled phrases. we evaluate our method on a well-established crosslingual document classification task and achieve results that are either comparable, or greatly improve upon previous state-of-the-art methods. concretely, our method reaches a level of 92.7% and 84.4% accuracy for the english to german and german to english sub-tasks respectively. the former advances the state of the art by 0.9% points of accuracy, the latter is an absolute improvement upon the previous state of the art by 7.7% points of accuracy and an improvement of 33.0% in error reduction."
        },
        {
            "id": "R133937",
            "label": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "we explore the use of evolution strategies (es), a class of black box optimization algorithms, as an alternative to popular mdp-based rl techniques such as q-learning and policy gradients. experiments on mujoco and atari show that es is a viable solution strategy that scales extremely well with the number of cpus available: by using a novel communication strategy based on common random numbers, our es implementation only needs to communicate scalars, making it possible to scale to over a thousand parallel workers. this allows us to solve 3d humanoid walking in 10 minutes and obtain competitive results on most atari games after one hour of training. in addition, we highlight several advantages of es as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation."
        },
        {
            "id": "R148630",
            "label": "Naphthodithiophene\u00e2\u0080\u0090Based Nonfullerene Acceptor for High\u00e2\u0080\u0090Performance Organic Photovoltaics: Effect of Extended Conjugation",
            "doi": "10.1002/adma.201704713",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "naphtho[1,2\u2010b:5,6\u2010b\u2032]dithiophene is extended to a fused octacyclic building block, which is end capped by strong electron\u2010withdrawing 2\u2010(5,6\u2010difluoro\u20103\u2010oxo\u20102,3\u2010dihydro\u20101h\u2010inden\u20101\u2010ylidene)malononitrile to yield a fused\u2010ring electron acceptor (ioic2) for organic solar cells (oscs). relative to naphthalene\u2010based ihic2, naphthodithiophene\u2010based ioic2 with a larger \u03c0\u2010conjugation and a stronger electron\u2010donating core shows a higher lowest unoccupied molecular orbital energy level (ioic2: \u22123.78 ev vs ihic2: \u22123.86 ev), broader absorption with a smaller optical bandgap (ioic2: 1.55 ev vs ihic2: 1.66 ev), and a higher electron mobility (ioic2: 1.0 \u00d7 10\u22123 cm2 v\u22121 s\u22121 vs ihic2: 5.0 \u00d7 10\u22124 cm2 v\u22121 s\u22121). thus, ioic2\u2010based oscs show higher values in open\u2010circuit voltage, short\u2010circuit current density, fill factor, and thereby much higher power conversion efficiency (pce) values than those of the ihic2\u2010based counterpart. in particular, as\u2010cast oscs based on ftaz: ioic2 yield pces of up to 11.2%, higher than that of the control devices based on ftaz: ihic2 (7.45%). furthermore, by using 0.2% 1,8\u2010diiodooctane as the processing additive, a pce of 12.3% is achieved from the ftaz:ioic2\u2010based devices, higher than that of the ftaz:ihic2\u2010based devices (7.31%). these results indicate that incorporating extended conjugation into the electron\u2010donating fused\u2010ring units in nonfullerene acceptors is a promising strategy for designing high\u2010performance electron acceptors."
        },
        {
            "id": "R205057",
            "label": "A Human-in-the-Loop Approach for Personal Knowledge Graph Construction from File Names",
            "doi": "",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R205001",
                    "label": "Exploring Personal Knowledge Graph Literature"
                }
            ],
            "abstract": "users\u2019 personal and work related concepts (e.g. persons, projects, topics) are usually not sufficiently covered by knowledge graphs. yet, already handmade classification schemes, prominently folder structures, naturally mention several of their concepts in file names. thus, such data could be a promising source for constructing personal knowledge graphs. however, this idea poses several challenges: file names are usually noisy non-grammatical text snippets, while folder structures do not clearly define how concepts relate to each other. to cope with this semantic gap, we include knowledge workers as humans-in-the-loop to guide the building process with their feedback. our semi-automatic personal knowledge graph construction approach consists of four major stages: domain term extraction, ontology population, taxonomic and non-taxonomic relation learning. we conduct a case study with four expert interviews from different domains in an industrial scenario. results indicate that file systems are promising sources and, combined with our approach, already yield useful personal knowledge graphs with moderate effort spent."
        },
        {
            "id": "R171513",
            "label": "The effect of relaxation techniques on edema, anxiety and depression in post-mastectomy lymphedema patients undergoing comprehensive decongestive therapy: A clinical trial",
            "doi": "10.1371/journal.pone.0190231",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives lymphedema is sometimes accompanied by high degrees of anxiety and depression. this study aimed to assess the effects of relaxation techniques on the level of edema, anxiety and depression in women undergoing comprehensive decongestive therapy (cdt). design this clinical trial compared two treatment methods in 31 women with post-mastectomy lymphedema, including 15 cases who received cdt and 16 who received rcdt (relaxation plus cdt). the edema volume, anxiety and depression scores were compared at the first and last sessions of the first phase of the treatment and six weeks afterwards. results the edema, anxiety and depression scores were 63.6%, 54.1% and 65.5% in the rcdt group and 60.7%, 31.4% and 35.2% in the cdt group. there were significant differences between the two groups in terms of the reduction in depression (p = 0.024) and anxiety (p = 0.011) scores throughout the study. this significant relationship was due to the differences in the depression score in the 3rd and 9th weeks of the study between the two groups. similarly, anxiety levels differed significantly between the two groups at the 9th week of the study (p = 0.013). conclusion relaxation techniques reduced the anxiety and depression scores and the volume of edema in the patients with lymphedema. the addition of this intervention to the therapeutic package for lymphedema patients requires further studies in terms of cost-effectiveness."
        },
        {
            "id": "R108304",
            "label": "CATS: Characterizing automation of Twitter spammers",
            "doi": "10.1109/COMSNETS.2013.6465541",
            "research_field": {
                "id": "R277",
                "label": "Computational Engineering"
            },
            "research_problems": [
                {
                    "id": "R108238",
                    "label": "Spam detection in Twitter"
                }
            ],
            "abstract": "twitter, with its rising popularity as a micro-blogging website, has inevitably attracted the attention of spammers. spammers use myriad of techniques to evade security mechanisms and post spam messages, which are either unwelcome advertisements for the victim or lure victims in to clicking malicious urls embedded in spam tweets. in this paper, we propose several novel features capable of distinguishing spam accounts from legitimate accounts. the features analyze the behavioral and content entropy, bait-techniques, and profile vectors characterizing spammers, which are then fed into supervised learning algorithms to generate models for our tool, cats. using our system on two real-world twitter data sets, we observe a 96% detection rate with about 0.8% false positive rate beating state of the art detection approach. our analysis reveals detection of more than 90% of spammers with less than five tweets and about half of the spammers detected with only a single tweet. our feature computation has low latency and resource requirement making fast detection feasible. additionally, we cluster the unknown spammers to identify and understand the prevalent spam campaigns on twitter."
        },
        {
            "id": "R169188",
            "label": "From Mind to Mouth: Event Related Potentials of Sentence Production in Classic Galactosemia",
            "doi": "10.1371/journal.pone.0052826",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "patients with classic galactosemia, an inborn error of metabolism, have speech and language production impairments. past research primarily focused on speech (motor) problems, but these cannot solely explain the language impairments. which specific deficits contribute to the impairments in language production is not yet known. deficits in semantic and syntactic planning are plausible and require further investigation. in the present study, we examined syntactic encoding while patients and matched controls overtly described scenes of moving objects using either separate words (minimal syntactic planning) or sentences (sentence-level syntactic planning). the design of the paradigm also allowed tapping into local noun phrase- and more global sentence-level syntactic planning. simultaneously, we recorded event-related potentials (erps). the patients needed more time to prepare and finish the utterances and made more errors. the patient erps had a very similar morphology to that of healthy controls, indicating overall comparable neural processing. most importantly, the erps diverged from those of controls in several functionally informative time windows, ranging from very early (90\u2013150 ms post scene onset) to relatively late (1820\u20132020 ms post scene onset). these time windows can be associated with different linguistic encoding stages. the erp results form the first neuroscientific evidence for language production impairments in patients with galactosemia in lexical and syntactic planning stages, i.e., prior to the linguistic output phase. these findings hence shed new light on the language impairments in this disease."
        },
        {
            "id": "R194281",
            "label": "Learning Requirements Elicitation Interviews with Role-Playing, Self-Assessment and Peer-Review",
            "doi": "10.1109/re.2019.00015",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "interviews are largely used in the practice of requirements elicitation. nevertheless, performing an effective interview often depends on soft-skills, and on knowledge acquired through experience. when it comes to requirements engineering education and training (reet), limited resources and few well-founded pedagogical approaches are available to allow students to acquire and improve their skills as interviewers. this paper presents a novel pedagogical approach that combines role-playing, peer-review and self-assessment to enable students to reflect on their mistakes, and improve their interview skills. we evaluate the approach through a controlled quasi-experiment. the study shows that the approach significantly reduces the amount of mistakes made by the students. feedback from the participants confirms the usefulness and easiness of the proposed training. this work contributes to the body of knowledge of reet with an empirically evaluated method for teaching inter-views. furthermore, we share the pedagogical material used, to enable other educators to apply and possibly tailor the approach."
        },
        {
            "id": "R109720",
            "label": "Violent Extremism and Grievance in Sub-Saharan Africa",
            "doi": "10.1080/10402659.2017.1308732",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the last few years, violent extremism has proliferated significantly across sub-saharan africa, causing serious concern for much of the continent\u2019s institutions. the main actors and recruits of violent extremism in this region are comprised mostly of youth. most of the countries where violent extremist movements exist do have large populations of youth, but large youth populations do not correlate with the emergence of violent extremism. much of the studies and reports on countries with large youth populations, such as in sub-saharan africa, reveal that youth have not been adequately included in the affairs of the state in their countries. a substantial majority of these youth live their lives without significant investments by the state in terms of education, employment, social protection, healthcare, water and sanitation, and food security. the report lions on the move: the progress and potential of african economies, by the mckinsey global institute (mgi) for the mckinsey company, asserts that these are major challenges for the continents economies. it is widely assumed that the high unemployment rate of these youth makes them available and susceptible to recruitment by violent extremist groups of various kinds in the region."
        },
        {
            "id": "R171441",
            "label": "Religiosity prevalence and its association with depression and anxiety symptoms among Hispanic/Latino adults",
            "doi": "10.1371/journal.pone.0185661",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives religion plays an important role in the lives of people in the united states. we examined the prevalence of religiosity among hispanic/latinos in four regions of the united states and looked at its correlation to depression and anxiety symptoms. design the population-based hispanic community health study/ study of latinos enrolled a cohort of hispanic/latino adults (n = 16,415) ages 18\u201374 in four us cities from june 2008 to june 2011. participants with complete data on religiosity (i.e., religious affiliation, frequency of attending religious activities and importance of religion), depression (assessed with the cesd-10), and trait anxiety (assessed with the stai-10) were included in the present study. distribution of religiosity is described by sociodemographic characteristics. associations between religiosity with depression and anxiety were examined with logistic regression models controlling for sex, age group, education, hispanic/latino background, clinical center, and nativity. results the majority of the population (89.5%) reported having a religious affiliation. weekly attendance at religious activities was reported by 41.6% of participants, while 20.6% did not attend any religious activities. religion was very important to 63.9% and not at all important to 6.7% of the population. the ces-d scores and trait anxiety scores were not significantly related in the overall group to frequency of attending religious activity or perceived importance of religion. however, in age-stratified analyses, among older individuals (65+ years old) reporting \u201cnever\u201d participating in religious activities compared to more than once per week was associated with an 80% higher likelihood of having high depressive symptomatology. similarly, in the older age group, no religious affiliation or reporting that religion is \u201cnot at all important\u201d was associated with greater anxiety symptomatology. conclusion religiosity varied by hispanic/latino background. lack of religiosity was associated with elevated depressive or anxiety symptomology in older adults but not in young or middle-aged adults."
        },
        {
            "id": "R194125",
            "label": "Data-driven Risk Management for Requirements Engineering: An Automated Approach based on Bayesian Networks",
            "doi": "10.1109/re48521.2020.00024",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "requirements engineering (re) is a means to reduce the risk of delivering a product that does not fulfill the stakeholders\u2019 needs. therefore, a major challenge in re is to decide how much re is needed and what re methods to apply. the quality of such decisions is strongly based on the re expert\u2019s experience and expertise in carefully analyzing the context and current state of a project. recent work, however, shows that lack of experience and qualification are common causes for problems in re. we trained a series of bayesian networks on data from the napire survey to model relationships between re problems, their causes, and effects in projects with different contextual characteristics. these models were used to conduct (1) a post-mortem (diagnostic) analysis, deriving probable causes of suboptimal re performance, and (2) to conduct a preventive analysis, predicting probable issues a young project might encounter. the method was subject to a rigorous cross-validation procedure for both use cases before assessing its applicability to real-world scenarios with a case study."
        },
        {
            "id": "R168667",
            "label": "FIMTrack: An open source tracking and locomotion analysis software for small animals",
            "doi": "10.1371/journal.pcbi.1005530",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "imaging and analyzing the locomotion behavior of small animals such as drosophila larvae or c. elegans worms has become an integral subject of biological research. in the past we have introduced fim, a novel imaging system feasible to extract high contrast images. this system in combination with the associated tracking software fimtrack is already used by many groups all over the world. however, so far there has not been an in-depth discussion of the technical aspects. here we elaborate on the implementation details of fimtrack and give an in-depth explanation of the used algorithms. among others, the software offers several tracking strategies to cover a wide range of different model organisms, locomotion types, and camera properties. furthermore, the software facilitates stimuli-based analysis in combination with built-in manual tracking and correction functionalities. all features are integrated in an easy-to-use graphical user interface. to demonstrate the potential of fimtrack we provide an evaluation of its accuracy using manually labeled data. the source code is available under the gnu gplv3 at https://github.com/i-git/fimtrack and pre-compiled binaries for windows and mac are available at http://fim.uni-muenster.de."
        },
        {
            "id": "R69693",
            "label": "1-Butanethiol. MAK Value Documentation, supplement \u00e2\u0080\u0093 Translation of the German version from 2019 ",
            "doi": "10.34865/mb10979e5_4ad",
            "research_field": {
                "id": "R69",
                "label": "Toxicology"
            },
            "research_problems": [
                {
                    "id": "R69692",
                    "label": "Reevaluation of  the maximum concentration at the workplace (MAK value) of 1\u2011butanethiol"
                }
            ],
            "abstract": "the german commission for the investigation of health hazards of chemical compounds in the work area has re-evaluated the maximum concentration at the work place (mak value) of ethanethiol [75-08-1]. no new studies are available for ethanethiol itself. therefore, the mak value is derived by read-across with the structurally similar methyl mercaptan for which the mak value of 0.5 ml/m3 is based on slight behavioural changes at 2 ml/m3 in a 90-day inhalation study in rats. the mak value of 0.5 ml/m3 for ethanethiol is supported by a limited inhalation study with 3 volunteers, showing irritation and other symptoms after repeated exposure to ethanethiol in a concentration of 3.9 ml/m3, but not after 0.39 ml/m3. the behavioural changes in rats exposed to methyl mercaptan are presumably not neurotoxic effects but a result of the odour nuisance or the local irritation. therefore, ethanethiol is classified in peak limitation category i with an excursion factor of 1 by analogy with methyl mercaptan. there are no developmental toxicity studies and ethanethiol remains assigned to pregnancy risk group d. according to skin absorption models, percutaneous absorption is expected to contribute significantly to systemic toxicity. therefore, ethanethiol is designated with an \u201ch\u201d. there are no data on sensitization. the mak collection for occupational health and safety 2020, vol 5, no 4 1 mak value documentations \u2013 ethanethiol mak value (1969) 0.5 ml/m3 (ppm) \u2259 1.3 mg/m3 peak limitation (2018) category i, excursion factor 1 absorption through the skin (2018) h sensitization \u2013 carcinogenicity \u2013 prenatal toxicity (2000) pregnancy risk group d germ cell mutagenicity \u2013"
        },
        {
            "id": "R212419",
            "label": "The impact of institutional repositories: a systematic review",
            "doi": "10.5195/jmla.2020.856",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R187758",
                    "label": "Open access citation advantage"
                }
            ],
            "abstract": "objective: institutional repositories are platforms for presenting and publicizing scholarly output that might not be suitable to publish in a peer-reviewed journal or that must meet open access requirements. however, there are many challenges associated with their launch and up-keep. the objective of this systematic review was to define the impacts of institutional repositories (irs) on an academic institution, thus justifying their implementation and/or maintenance.methods: a comprehensive literature search was performed in the following databases: ovid medline, ovid embase, the cochrane library (wiley), eric (proquest), web of science (core collection), scopus (elsevier), and library, information science &amp; technology abstracts (ebsco). a total of 6,593 citations were screened against predefined inclusion and exclusion criteria.results: thirteen included studies were divided into 3 areas of impact: citation count, exposure or presence, and administrative impact. those focusing on citation count (n=5) and exposure or presence (n=7) demonstrated positive impacts of irs on institutions and researchers. one study focusing on administrative benefit demonstrated the utility of irs in automated population of orcid profiles.conclusion: based on the available literature, irs appear to have a positive impact on citation count, exposure or presence, and administrative burden. to draw stronger conclusions, more and higher-quality studies are needed."
        },
        {
            "id": "R146812",
            "label": "\u00cf\u0080-Bridge-Independent 2-(Benzo[c][1,2,5]thiadiazol-4-ylmethylene)malononitrile-Substituted Nonfullerene Acceptors for Efficient Bulk Heterojunction Solar Cells",
            "doi": "10.1021/acs.chemmater.6b00131",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "molecular acceptors are promising alternatives to fullerenes (e.g., pc61/71bm) in the fabrication of high-efficiency bulk-heterojunction (bhj) solar cells. while solution-processed polymer\u2013fullerene bhj devices have recently met the 10% efficiency threshold, molecular acceptors have yet to prove comparably efficient with polymer donors. at this point in time, it is important to forge a better understanding of the design parameters that directly impact small-molecule (sm) acceptor performance in bhj solar cells. in this report, we show that 2-(benzo[c][1,2,5]thiadiazol-4-ylmethylene)malononitrile (bm)-terminated sm acceptors can achieve efficiencies as high as 5.3% in bhj solar cells with the polymer donor pce10. through systematic device optimization and characterization studies, we find that the nonfullerene analogues (fbm, cbm, and cdtbm) all perform comparably well, independent of the molecular structure and electronics of the \u03c0-bridge that links the two electron-deficient bm end groups. with estimated..."
        },
        {
            "id": "R171236",
            "label": "Development and Validation of the Motivations for Selection of Medical Study (MSMS) Questionnaire in India",
            "doi": "10.1371/journal.pone.0164581",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background and objective understanding medical students\u2019 motivation to select medical studies is particularly salient to inform practice and policymaking in countries\u2014such as india\u2014where shortage of medical personnel poses crucial and chronical challenges to healthcare systems. this study aims to develop and validate a questionnaire to assess the motivation of medical students to select medical studies. methods a motivation for selection of medical study (msms) questionnaire was developed using extensive literature review followed by delphi technique. the scale consisted of 12 items, 5 measuring intrinsic dimensions of motivations and 7 measuring extrinsic dimensions. exploratory factor analysis (efa), confirmatory factor analysis (cfa), validity, reliability and data quality checks were conducted on a sample of 636 medical students from six medical colleges of three north indian states. results the msms questionnaire consisted of 3 factors (subscales) and 8 items. the three principal factors that emerged after efa were the scientific factor (e.g. research opportunities and the ability to use new cutting edge technologies), the societal factor (e.g. job security) and the humanitarian factor (e.g. desire to help others). the cfa conducted showed goodness-of-fit indices supporting the 3-factor model. conclusion the three extracted factors cut across the traditional dichotomy between intrinsic and extrinsic motivation and uncover a novel three-faceted motivation construct based on scientific factors, societal expectations and humanitarian needs. this validated instrument can be used to evaluate the motivational factors of medical students to choose medical study in india and similar settings and constitutes a powerful tool for policymakers to design measures able to increase selection of medical curricula."
        },
        {
            "id": "R168966",
            "label": "Behaviourally Mediated Phenotypic Selection in a Disturbed Coral Reef Environment",
            "doi": "10.1371/journal.pone.0007096",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "natural and anthropogenic disturbances are leading to changes in the nature of many habitats globally, and the magnitude and frequency of these perturbations are predicted to increase under climate change. globally coral reefs are one of the most vulnerable ecosystems to climate change. fishes often show relatively rapid declines in abundance when corals become stressed and die, but the processes responsible are largely unknown. this study explored the mechanism by which coral bleaching may influence the levels and selective nature of mortality on a juvenile damselfish, pomacentrus amboinensis, which associates with hard coral. recently settled fish had a low propensity to migrate small distances (40 cm) between habitat patches, even when densities were elevated to their natural maximum. intraspecific interactions and space use differ among three habitats: live hard coral, bleached coral and dead algal-covered coral. large fish pushed smaller fish further from the shelter of bleached and dead coral thereby exposing smaller fish to higher mortality than experienced on healthy coral. small recruits suffered higher mortality than large recruits on bleached and dead coral. mortality was not size selective on live coral. survival was 3 times as high on live coral as on either bleached or dead coral. subtle behavioural interactions between fish and their habitats influence the fundamental link between life history stages, the distribution of phenotypic traits in the local population and potentially the evolution of life history strategies."
        },
        {
            "id": "R169314",
            "label": "Exaggerated Intergroup Bias in Economical Decision Making Games: Differential Effects of Primary and Secondary Psychopathic Traits",
            "doi": "10.1371/journal.pone.0069565",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "psychopathic personality traits are linked with selfish and non-cooperative responses during economical decision making games. however, the possibility that these responses may vary when responding to members of the in-group and the out-group has not yet been explored. we aimed to examine the effects of primary (selfish, uncaring) and secondary (impulsive, irresponsible) psychopathic personality traits on the responses of non-offending participants to the in-group and the out-group (defined in terms of affiliation to a uk university) across a series of economical decision making games. we asked a total of 60 participants to act as the proposer in both the dictator game and the ultimatum game. we found that across both tasks, those who scored highly for secondary psychopathic traits showed an elevated intergroup bias, making more generous offers toward members of the in-group relative to the out-group. an exaggerated intergroup bias may therefore represent a motivational factor for the antisocial behavior of those with elevated secondary psychopathic traits."
        },
        {
            "id": "R136499",
            "label": "Increased attention but more efficient disengagement: Neuroscientific evidence for defensive processing of threatening health information.",
            "doi": "10.1037/a0019372",
            "research_field": {
                "id": "R111778",
                "label": "Communication Neuroscience"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"objective\\nprevious studies indicate that people respond defensively to threatening health information, especially when the information challenges self-relevant goals. the authors investigated whether reduced acceptance of self-relevant health risk information is already visible in early attention processes, that is, attention disengagement processes.\\n\\n\\ndesign\\nin a randomized, controlled trial with 29 smoking and nonsmoking students, a variant of posner's cueing task was used in combination with the high-temporal resolution method of event-related brain potentials (erps).\\n\\n\\nmain outcome measures\\nreaction times and p300 erp.\\n\\n\\nresults\\nsmokers showed lower p300 amplitudes in response to high- as opposed to low-threat invalid trials when moving their attention to a target in the opposite visual field, indicating more efficient attention disengagement processes. furthermore, both smokers and nonsmokers showed increased p300 amplitudes in response to the presentation of high- as opposed to low-threat valid trials, indicating threat-induced attention-capturing processes. reaction time measures did not support the erp data, indicating that the erp measure can be extremely informative to measure low-level attention biases in health communication.\\n\\n\\nconclusion\\nthe findings provide the first neuroscientific support for the hypothesis that threatening health information causes more efficient disengagement among those for whom the health threat is self-relevant.\""
        },
        {
            "id": "R130803",
            "label": "Language Models with Transformers",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "the transformer architecture is superior to rnn-based models in computational efficiency. recently, gpt and bert demonstrate the efficacy of transformer models on various nlp tasks using pre-trained language models on large-scale corpora. surprisingly, these transformer architectures are suboptimal for language model itself. neither self-attention nor the positional encoding in the transformer is able to efficiently incorporate the word-level sequential context crucial to language modeling. \\nin this paper, we explore effective transformer architectures for language model, including adding additional lstm layers to better capture the sequential context while still keeping the computation efficient. we propose coordinate architecture search (cas) to find an effective architecture through iterative refinement of the model. experimental results on the ptb, wikitext-2, and wikitext-103 show that cas achieves perplexities between 20.42 and 34.11 on all problems, i.e. on average an improvement of 12.0 perplexity units compared to state-of-the-art lstms. the source code is publicly available."
        },
        {
            "id": "R209428",
            "label": "Method for Recognition of the Physical Activity of Human Being Using a Wearable Accelerometer",
            "doi": "10.5755/J01.EEE.20.5.7113",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "companies are interested in retaining workers healthy, productive, and satisfied while cutting health-care and insurance costs. using a computer at work can cause back, neck and shoulder pain, eyestrain, and overuse injuries of human hands and wrists. it is possible to reduce these risks with better posture and good habits, such as taking rest breaks. during these breaks computer users should be encouraged to stand, stretch, and move around. for people who forget about a break or truly are focused on their direct work need help from special equipment for evaluation of real physical activity of computer user. method for recording accelerometer data from moving human as he or she performs daily activities and for identification of type, duration and intensity of movements by using wearable wireless sensing system is presented in this paper. the extraction of orientation independent acceleration data has positive effect on recognition accuracy of k-nearest neighbour classification scheme used for classification task. the recognition accuracy of algorithm is 78.9% and these results are better than accuracy obtained from raw accelerometer data. the method presented is simple, exhibited good performance and does not require significant computational recourses. doi: http://dx.doi.org/10.5755/j01.eee.20.5.7113"
        },
        {
            "id": "R175056",
            "label": "Attracting new users or business as usual? A case study of converting academic subscription-based journals to open access",
            "doi": "10.1162/qss_a_00126",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R175062",
                    "label": "Open access page view advantage"
                },
                {
                    "id": "R175040",
                    "label": "Open access download advantage"
                },
                {
                    "id": "R188168",
                    "label": "Open access advantage concerning page views and downloads from outside higher education institutions"
                }
            ],
            "abstract": "abstract \\n this paper studies a selection of 11 norwegian journals in the humanities and social sciences and their conversion from subscription to open access, a move heavily incentivized by governmental mandates and open access policies. by investigating the journals\u2019 visiting logs in the period 2014\u20132019, the study finds that a conversion to open access induces higher visiting numbers; all journals in the study had a significant increase, which can be attributed to the conversion. converting a journal had no spillover in terms of increased visits to previously published articles still behind the paywall in the same journals. visits from previously subscribing norwegian higher education institutions did not account for the increase in visits, indicating that the increase must be accounted for by visitors from other sectors. the results could be relevant for policymakers concerning the effects of strict policies targeting economically vulnerable national journals, and could further inform journal owners and editors on the effects of converting to open access."
        },
        {
            "id": "R169316",
            "label": "Effect of Socioeconomic Status on Mortality after Bacteremia in Working-Age Patients. A Danish Population-Based Cohort Study",
            "doi": "10.1371/journal.pone.0070082",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives to examine the effect of socioeconomic status (ses) on mortality in patients with bacteremia and the underlying factors that may mediate differences in mortality. methods we conducted a population-based cohort study in two danish regions. all patients 30 to 65 years of age with first time bacteremia from 2000 through 2008 were identified in a population-based microbiological bacteremia database (n\\u200a=\\u200a8,653). individual-level data on patients\u2019 ses (educational level and personal income) and comorbid conditions were obtained from public and medical registries. we used cox regression to examine mortality within 30 days after bacteremia with and without cumulative adjustment for potential mediators. results bacteremia patients of low ses were more likely to live alone and be unmarried than patients of high ses. they also had more pre-existing comorbidity, more substance abuse, more staphylococcus aureus and nosocomial infections, and more admissions to small nonteaching hospitals. overall, 1,374 patients (15.9%) died within 30 days of follow-up. patients of low ses had consistently higher mortality after bacteremia than those of high ses crude hazard ratio for low vs. high education, 1.38 [95% confidence interval (ci), 1.18\u20131.61]; crude hazard ratio for low-income vs. high-income tertile, 1.58 [ci, 1.39\u20131.80]. adjustment for differences in social support, pre-existing comorbidity, substance abuse, place of acquisition of the infection, and microbial agent substantially attenuated the effect of ses on mortality (adjusted hazard ratio for low vs. high education, 1.15 [95% ci, 0.98\u20131.36]; adjusted hazard ratio for low-income vs. high-income tertile, 1.29 [ci, 1.12\u20131.49]). further adjustment for characteristics of the admitting hospital had minimal effect on observed mortality differences. conclusions low ses was strongly associated with increased 30-day mortality after bacteremia. less social support, more pre-existing comorbidity, more substance abuse, and differences in place of acquisition and agent of infection appeared to mediate much of the observed disparities in mortality."
        },
        {
            "id": "R203521",
            "label": "Ravinder Agarwal sEMG Interface Design for Locomotion Identification S",
            "doi": "",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "surface electromyographic (semg) signal has the potential to identify the human activities and intention. this potential is further exploited to control the artificial limbs using the semg signal from residual limbs of amputees. the paper deals with the development of multichannel cost efficient semg signal interface for research application, along with evaluation of proposed class dependent statistical approach of the feature selection method. the semg signal acquisition interface was developed using ads1298 of texas instruments, which is a front-end interface integrated circuit for ecg application. further, the semg signal is recorded from two lower limb muscles for three locomotions namely: plane walk (pw), stair ascending (sa), stair descending (sd). a class dependent statistical approach is proposed for feature selection and also its performance is compared with 12 preexisting feature vectors. to make the study more extensive, performance of five different types of classifiers are compared. the outcome of the current piece of work proves the suitability of the proposed feature selection algorithm for locomotion recognition, as compared to other existing feature vectors. the svm classifier is found as the outperformed classifier among compared classifiers with an average recognition accuracy of 97.40%. feature vector selection emerges as the most dominant factor affecting the classification performance as it holds 51.51% of the total variance in classification accuracy. the results demonstrate the potentials of the developed semg signal acquisition interface along with the proposed feature selection algorithm. keywords\u2014classifiers, feature selection, locomotion, semg."
        },
        {
            "id": "R71525",
            "label": "Catch crop diversity increases rhizosphere carbon input and soil microbial biomass",
            "doi": "10.1007/s00374-020-01475-8",
            "research_field": {
                "id": "R153",
                "label": "Soil Science"
            },
            "research_problems": [
                {
                    "id": "R71528",
                    "label": "Estimation of the statistical difference in NEE of C between catch crop treatments"
                }
            ],
            "abstract": "abstract catch crops increase plant species richness in crop rotations, but are most often grown as pure stands. here, we investigate the impacts of increasing plant diversity in catch crop rotations on rhizosphere c input and microbial utilization. mustard ( sinapis alba l.) planted as a single cultivar was compared to diversified catch crop mixtures of four (mix4) or 12 species (mix12). we traced the c transfer from shoots to roots towards the soil microbial community and the soil respiration in a 13 c pulse labelling field experiment. net co 2 -c uptake from the atmosphere increased by two times in mix 4 and more than three times in mix 12. higher net ecosystem c production was linked to increasing catch crop diversity and increased belowground transfer rates of recently fixed photoassimilates. the higher rhizosphere c input stimulated the growth and activity of the soil microbiome, which was investigated by phospholipid fatty acid (plfa) analyses. total microbial biomass increased from 14 to 22\\xa0g\\xa0m \u22122 as compared to the fallow and was 18 and 8% higher for mix 12 and mix 4 as compared to mustard. in particular, the fungal and actinobacterial communities profited the most from the higher belowground c input and their biomass increased by 3.4 and 1.3 times as compared to the fallow. the residence time of the 13 c pulse, traced in the co 2 flux from the soil environment, increased with plant diversity by up to 1.8 times. the results of this study suggest positive impacts of plant diversity on c cycling by higher atmospheric c uptake, higher transport rates towards the rhizosphere, higher microbial incorporation and prolonged residence time in the soil environment. we conclude that diversified catch crop mixtures improve the efficiency of c cycling in cropping systems and provide a promising tool for sustainable soil management."
        },
        {
            "id": "R110545",
            "label": " Musical Representation and Philosophy of Mind",
            "doi": "10.14394/filnau.2019.0014",
            "research_field": {
                "id": "R451",
                "label": "Philosophy of Mind"
            },
            "research_problems": [
                {
                    "id": "R110566",
                    "label": "Semantic Representation in Music"
                }
            ],
            "abstract": "representation is one of the key concepts in cognitive science and philosophy of mind. the philosophical problem of musical meaning, or rather its naturalistic reformulation, has only recently\\xa0become the topic of empirical investigation. it might seem obvious that an explication of the concept\\xa0of meaning would appeal to the concept of representation. it is not a popular approach in the\\xa0philosophy of the cognitive science of music, however. the aim of this paper is to provide an\\xa0overview of possible frames of analysis of musical representation within selected contemporary\\xa0paradigms in the broadly understood philosophy of mind and cognitive science."
        },
        {
            "id": "R194114",
            "label": "How developers believe Invisibility impacts NFRs related to User Interaction",
            "doi": "10.1109/re48521.2020.00022",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the advance of ubiquitous computing (ubicomp) and internet of things (iot) brought a new set of non-functional requirements (nfrs), especially related to human-computer interaction (hci). invisibility is one of these nfrs, and it refers to either the merging of technology in the user environment or the decrease of the interaction workload. this new nfr may impact traditional nfrs (e.g., usability), revealing positive correlations, when one nfr helps another, and negative correlations, when a procedure favors an nfr but creates difficulty for another one. software engineers need to know about these correlations, so they can select appropriate strategies to satisfy invisibility and traditional nfrs. correlations between nfrs are usually stored in catalogs, which is a well-defined body of knowledge gathered from previous experience. although invisibility has been recently cataloged with development strategies, the literature still lacks catalogs with correlations for this nfr. therefore, this work aims at capturing and cataloging invisibility correlations for ubicomp and iot systems. to do that, we also propose to systematize the definition of correlations using the following well-defined research methods: interview, content analysis and questionnaire. as a result, we defined a catalog with 110 positive and negative correlations with 9 nfrs. this well-defined body of knowledge is useful for supporting software engineers to select strategies to satisfy invisibility and other nfrs related to user interaction."
        },
        {
            "id": "R175090",
            "label": "CUBIC: a new TCP-friendly high-speed TCP variant",
            "doi": "10.1145/1400097.1400105",
            "research_field": {
                "id": "R234",
                "label": "Digital Communications and Networking"
            },
            "research_problems": [
                {
                    "id": "R175098",
                    "label": "Loss Recovery and Rate Control"
                }
            ],
            "abstract": "cubic is a congestion control protocol for tcp (transmission control protocol) and the current default tcp algorithm in linux. the protocol modifies the linear window growth function of existing tcp standards to be a cubic function in order to improve the scalability of tcp over fast and long distance networks. it also achieves more equitable bandwidth allocations among flows with different rtts (round trip times) by making the window growth to be independent of rtt -- thus those flows grow their congestion window at the same rate. during steady state, cubic increases the window size aggressively when the window is far from the saturation point, and the slowly when it is close to the saturation point. this feature allows cubic to be very scalable when the bandwidth and delay product of the network is large, and at the same time, be highly stable and also fair to standard tcp flows. the implementation of cubic in linux has gone through several upgrades. this paper documents its design, implementation, performance and evolution as the default tcp algorithm of linux."
        },
        {
            "id": "R136477",
            "label": "Communicating with Sensation Seekers: An fMRI Study of Neural Responses to Antidrug Public Service Announcements",
            "doi": "10.1080/10410236.2017.1331185",
            "research_field": {
                "id": "R111778",
                "label": "Communication Neuroscience"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract this study examined the neural basis of processing high- and low-message sensation value (msv) antidrug public service announcements (psas) in high (hss) and low sensation seekers (lss) using fmri. hss more strongly engaged the salience network when processing psas (versus lss), suggesting that high-msv psas attracted their attention. hss and lss participants who engaged higher level cognitive processing regions reported that the psas were more convincing and believable and recalled the psas better immediately after testing. in contrast, hss and lss participants who strongly engaged visual attention regions for viewing psas reported lower personal relevance. these findings provide neurobiological evidence that high-msv content is salient to hss, a primary target group for antidrug messages, and additional cognitive processing is associated with higher perceived message effectiveness."
        },
        {
            "id": "R194317",
            "label": "Optimizing for Recall in Automatic Requirements Classification: An Empirical Study",
            "doi": "10.1109/re.2019.00016",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "using machine learning to solve requirements engineering problems can be a tricky task. even though certain algorithms have exceptional performance, their recall is usually below 100%. one key aspect in the implementation of machine learning tools is the balance between recall and precision. tools that do not find all correct answers may be considered useless. however, some tasks are very complicated and even requirements engineers struggle to solve them perfectly. if a tool achieves performance comparable to a trained engineer while reducing her workload considerably, it is considered to be useful. one such task is the classification of specification content elements into requirements and non-requirements. in this paper, we analyze this specific requirements classification problem and assess the importance of recall by performing an empirical study. we compared two groups of students who performed this task with and without tool support, respectively. we use the results to compute an estimate of f for the ff score, allowing us to choose the optimal balance between precision and recall. furthermore, we use the results to assess the practical time savings realized by the approach. by using the tool, users may not be able to find all defects in a document, however, they will be able to find close to all of them in a fraction of the time necessary. this demonstrates the practical usefulness of our approach and machine learning tools in general."
        },
        {
            "id": "R169169",
            "label": "Yersinia pestis: New Evidence for an Old Infection",
            "doi": "10.1371/journal.pone.0049803",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the successful reconstruction of an ancient bacterial genome from archaeological material presents an important methodological advancement for infectious disease research. the reliability of evolutionary histories inferred by the incorporation of ancient data, however, are highly contingent upon the level of genetic diversity represented in modern genomic sequences that are publicly accessible, and the paucity of available complete genomes restricts the level of phylogenetic resolution that can be obtained. here we add to our original analysis of the yersinia pestis strain implicated in the black death by consolidating our dataset for 18 modern genomes with single nucleotide polymorphism (snp) data for an additional 289 strains at over 600 positions. the inclusion of this additional data reveals a cluster of y. pestis strains that diverge at a time significantly in advance of the black death, with divergence dates roughly coincident with the plague of justinian (6th to 8th century ad). in addition, the analysis reveals further clues regarding potential radiation events that occurred immediately preceding the black death, and the legacy it may have left in modern y. pestis populations. this work reiterates the need for more publicly available complete genomes, both modern and ancient, to achieve an accurate understanding of the history of this bacterium."
        },
        {
            "id": "R170389",
            "label": "ANS: Aberrant Neurodevelopment of the Social Cognition Network in Adolescents with Autism Spectrum Disorders",
            "doi": "10.1371/journal.pone.0018905",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background autism spectrum disorders (asd) are characterized by aberrant neurodevelopment. although the asd brain undergoes precocious growth followed by decelerated maturation during early postnatal period of childhood, the neuroimaging approach has not been empirically applied to investigate how the asd brain develops during adolescence. methodology/principal findings we enrolled 25 male adolescents with high functioning asd and 25 typically developing controls for voxel-based morphometric analysis of structural magnetic resonance image. results indicate that there is an imbalance of regional gray matter volumes and concentrations along with no global brain enlargement in adolescents with high functioning asd relative to controls. notably, the right inferior parietal lobule, a role in social cognition, have a significant interaction of age by groups as indicated by absence of an age-related gain of regional gray matter volume and concentration for neurodevelopmental maturation during adolescence. conclusions/significance the findings indicate the neural correlates of social cognition exhibits aberrant neurodevelopment during adolescence in asd, which may cast some light on the brain growth dysregulation hypothesis. the period of abnormal brain growth during adolescence may be characteristic of asd. age effects must be taken into account while measures of structural neuroimaging have been clinically put forward as potential phenotypes for asd."
        },
        {
            "id": "R74498",
            "label": "Linked open knowledge organization systems",
            "doi": "10.1145/3309772.3309804",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74497",
                    "label": "Knowledge Organization"
                },
                {
                    "id": "R109120",
                    "label": "Knowledge Organization"
                }
            ],
            "abstract": "\"the web is the most used internet's service to create and share information. in large information collections, knowledge organization plays a key role in order to classify and to find valuable information. likewise, linked open data is a powerful approach for linking different web datasets. today, several knowledge organization systems are published by using the design criteria of linked data, it facilitates the automatic processing of them. in this paper, we address the issue of traversing open knowledge organization systems, considering difficulties associated with their dynamics and size. to fill this issue, we propose a method to identify irrelevant nodes on an open graph, thus reducing the time and the scope of the graph path and maximizing the possibilities of finding more relevant results. the approach for graph reduction is independent of the domain or task for which the open system will be used. the preliminary results of the proof of concept lead us to think that the method can be effective when the coverage of the concept of interest increases.\""
        },
        {
            "id": "R110453",
            "label": "Social isolation and the speed of covid-19 cases: measures to prevent transmission",
            "doi": "10.1590/1983-1447.2021.20200238",
            "research_field": {
                "id": "R31",
                "label": "Public Health"
            },
            "research_problems": [
                {
                    "id": "R110446",
                    "label": "Social Distance Effects COVID-19 "
                }
            ],
            "abstract": "\" abstract objective: to evaluate the social isolation index and the speed of new cases of covid-19 in brazil. methods: quantitative ecological, documentary, descriptive study using secondary data, comparing the period from march 14 to may 1, 2020, carried out with the 27 brazilian federative units, characterizing the study population. the data were analyzed through descriptive statistics using the statistical package for the social sciences-spss\u00ae software, evaluating the correlation between the social isolation index and the number of new cases of covid-19, using pearson\u2019s correlation coefficient. results: the increase in covid-19 cases is exponential. there was a significant, negative correlation regarding the social isolation index and the speed of the number of new cases by pearson's coefficient, which means that as the first one increases, the second one decreases. conclusion: social isolation measures have significant effects on the rate of coronavirus infection in the population. \""
        },
        {
            "id": "R171021",
            "label": "Administration of Non-Absorbable Antibiotics to Pregnant Mice to Perturb the Maternal Gut Microbiota Is Associated with Alterations in Offspring Behavior",
            "doi": "10.1371/journal.pone.0138293",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "there is increasing evidence that the gut microbiota plays a major role in host health and disease. in this study, we examined whether perturbation of the maternal gut microbiota during pregnancy, induced by administration of non-absorbable antibiotics to pregnant dams, influences the behavior of offspring. terminal restriction fragment length polymorphism analyses of fecal bacterial composition showed that the relative abundance of the bacterial order lactobacillales was lower in offspring born from antibiotic-treated dams (20.7\u00b13.4%) than in control offspring (42.1\u00b16.2%) at p24, while the relative abundance of the bacterial family clostridium subcluster xiva was higher in offspring born from antibiotic-treated dams (34.2\u00b15.0%) than in control offspring (16.4\u00b13.3%). offspring born from antibiotic-treated dams exhibited low locomotor activity in both familiar and novel environments, and preferred to explore in the peripheral area of an unfamiliar field at postnatal week 4. at postnatal weeks 7\u20138, no difference was observed in the level of locomotor activity between control offspring and offspring from antibiotic-treated dams, while the tendency for the offspring from antibiotic-treated dams to be less engaged in exploring the inside area was still observed. the behavioral phenotypes of the offspring from antibiotic-treated dams at postnatal week 4 could be rescued to a considerable extent through fostering of these offspring by normal dams from postnatal day 1. although the detailed underlying mechanisms are not fully elucidated, the present results suggest that administration of non-absorbable antibiotics to pregnant dams to perturb the maternal gut microbiota during pregnancy leads to alterations in the behavior of their offspring."
        },
        {
            "id": "R169996",
            "label": "Taste preference changes throughout different life stages in male rats",
            "doi": "10.1371/journal.pone.0181650",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "taste preference, a key component of food choice, changes with aging. however, it remains unclear how this occurs. to determine differences in taste preference between rats in different life stages, we examined the consumption of taste solutions and water using a two-bottle test. male sprague-dawley rats of different ages were used: juvenile (3\u20136 weeks), young adult (8\u201311 weeks), adult (17\u201320 weeks), middle-aged (34\u201337 weeks), and old-aged (69\u201372 weeks). the intakes of the high and low concentration solutions presented simultaneously were measured. we observed that the old-aged group had lower preference ratios for 0.3 m sucrose and 0.1 m msg in comparison with other groups. the preference ratio for 0.03 mm qhcl was higher in the middle-aged group than in the three younger groups and higher in the old-aged group than the juvenile group. the taste preferences for hcl and nacl did not significantly differ among the age groups. the old-aged group tended to prefer high concentrations of sucrose, qhcl, nacl, and msg to low concentrations, indicating age-related decline in taste sensitivity. we also aimed to investigate differences between life stages in the electrophysiological responses of the chorda tympani nerve, one of the peripheral gustatory nerves, to taste stimuli. the electrophysiological recordings showed that aging did not alter the function of the chorda tympani nerve. this study showed that aging induced alterations in taste preference. it is likely that these alterations are a result of functional changes in other peripheral taste nerves, the gastrointestinal system, or the central nervous system."
        },
        {
            "id": "R189450",
            "label": "FNG-IE: an improved graph-based method for keyword extraction from scholarly big-data",
            "doi": "10.7717/peerj-cs.389",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R129244",
                    "label": "Key Information Extraction"
                }
            ],
            "abstract": "keyword extraction is essential in determining influenced keywords from huge documents as the research repositories are becoming massive in volume day by day. the research community is drowning in data and starving for information. the keywords are the words that describe the theme of the whole document in a precise way by consisting of just a few words. furthermore, many state-of-the-art approaches are available for keyword extraction from a huge collection of documents and are classified into three types, the statistical approaches, machine learning, and graph-based methods. the machine learning approaches require a large training dataset that needs to be developed manually by domain experts, which sometimes is difficult to produce while determining influenced keywords. however, this research focused on enhancing state-of-the-art graph-based methods to extract keywords when the training dataset is unavailable. this research first converted the handcrafted dataset, collected from impact factor journals into n -grams combinations, ranging from unigram to pentagram and also enhanced traditional graph-based approaches. the experiment was conducted on a handcrafted dataset, and all methods were applied on it. domain experts performed the user study to evaluate the results. the results were observed from every method and were evaluated with the user study using precision, recall and f-measure as evaluation matrices. the results showed that the proposed method (fng-ie) performed well and scored near the machine learning approaches score."
        },
        {
            "id": "R135710",
            "label": "Continuous Symmetry Breaking Induced by Ion Pairing Effect in Heptamethine Cyanine Dyes: Beyond the Cyanine Limit",
            "doi": "10.1021/ja9100886",
            "research_field": {
                "id": "R130",
                "label": "Physical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R135709",
                    "label": "Ion pairing effect in heptamethine cyanine dyes"
                }
            ],
            "abstract": "the association of heptamethine cyanine cation 1(+) with various counterions a (a = br(-), i(-), pf(6)(-), sbf(6)(-), b(c(6)f(5))(4)(-), trisphat) was realized. the six different ion pairs have been characterized by x-ray diffraction, and their absorption properties were studied in polar (dcm) and apolar (toluene) solvents. a small, hard anion (br(-)) is able to strongly polarize the polymethine chain, resulting in the stabilization of an asymmetric dipolar-like structure in the crystal and in nondissociating solvents. on the contrary, in more polar solvents or when it is associated with a bulky soft anion (trisphat or b(c(6)f(5))(4)(-)), the same cyanine dye adopts preferentially the ideal polymethine state. the solid-state and solution absorption properties of heptamethine dyes are therefore strongly correlated to the nature of the counterion."
        },
        {
            "id": "R49006",
            "label": "A conserved RNA seed\u00e2\u0080\u0090pairing domain directs small RNA\u00e2\u0080\u0090mediated stress resistance in enterobacteria",
            "doi": "10.15252/embj.2019101650",
            "research_field": {
                "id": "R55",
                "label": "Microbial Physiology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "small regulatory rnas (srnas) are crucial components of many stress response systems. the envelope stress response (esr) of gram\u2010negative bacteria is a paradigm for srna\u2010mediated stress management and involves, among other factors, the alternative sigma factor e (\u03c3e) and one or more srnas. in this study, we identified the micv srna as a new member of the \u03c3e regulon in vibrio cholerae. we show that micv acts redundantly with another srna, vrra, and that both srnas share a conserved seed\u2010pairing domain allowing them to regulate multiple target mrnas. v. cholerae lacking \u03c3e displayed increased sensitivity toward antimicrobials, and over\u2010expression of either of the srnas suppressed this phenotype. laboratory selection experiments using a library of synthetic srna regulators revealed that the seed\u2010pairing domain of \u03c3e\u2010dependent srnas is strongly enriched among srnas identified under membrane\u2010damaging conditions and that repression of ompa is crucial for srna\u2010mediated stress relief. together, our work shows that micv and vrra act as global regulators in the esr of v. cholerae and provides evidence that bacterial srnas can be functionally annotated by their seed\u2010pairing sequences."
        },
        {
            "id": "R74467",
            "label": "Ontological model for the semantic description of syllabuses",
            "doi": "10.1145/3357419.3357442",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74409",
                    "label": "Knowledge Representation"
                },
                {
                    "id": "R109071",
                    "label": "Knowledge Representation"
                }
            ],
            "abstract": "the syllabus is a relevant document to organize how the teaching-learning process will be carried out during an academic course in higher education institutions (hei). usually, this document is written in a human-readable format that do not enable automatic processing through intelligent services to support teaching and learning. therefore, we created ontosyllabus ontology for the representation of syllabuses applying the neon methodology. the semantic model of a syllabus will allow the comprehension for both: machines and humans, and it will facilitate the interchange of data between different services and applications. the ontology was created based on the results of our three previous studies, which helped us to determinate the terms and relations in the syllabus ontology. the documentation and the computable model are available on the internet for their reuse."
        },
        {
            "id": "R56064",
            "label": "Stochastic Behavior of Tropical Convection in Observations and a Multicloud Model",
            "doi": "10.1175/jas-d-13-031.1",
            "research_field": {
                "id": "R168",
                "label": "Atmospheric Sciences"
            },
            "research_problems": [
                {
                    "id": "R56060",
                    "label": "Simulation of tropical convection"
                },
                {
                    "id": "R56072",
                    "label": "Understanding the dependence of tropical convection on the large-scale environment"
                },
                {
                    "id": "R56073",
                    "label": "Using observations to inform model development"
                },
                {
                    "id": "R56074",
                    "label": "Improving the representation of atmospheric convection in general circulation models"
                }
            ],
            "abstract": "abstract the aim for a more accurate representation of tropical convection in global circulation models is a long-standing issue. here, the relationships between large and convective scales in observations and a stochastic multicloud model (smcm) to ultimately support the design of a novel convection parameterization with stochastic elements are investigated. observations of tropical convection obtained at darwin and kwajalein are used here. it is found that the variability of observed tropical convection generally decreases with increasing large-scale forcing, implying a transition from stochastic to more deterministic behavior with increasing forcing. convection shows a more systematic relationship with measures related to large-scale convergence compared to measures related to energetics (e.g., cape). using the observations, the parameters in the smcm are adjusted. then, the smcm is forced with the time series of the observed large-scale state and the simulated convective behavior is compared to that observed. it is found that the smcm cloud fields compare better with observations when using predictors related to convergence rather than energetics. furthermore, the underlying framework of the smcm is able to reproduce the observed functional dependencies of convective variability on the imposed large-scale state\u2014an encouraging result on the road toward a novel convection parameterization approach. however, establishing sound cause-and-effect relationships between tropical convection and the large-scale environment remains problematic and warrants further research."
        },
        {
            "id": "R41374",
            "label": "Attention Guided Graph Convolutional Networks for Relation Extraction",
            "doi": "10.18653/v1/p19-1024",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R41429",
                    "label": "how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees"
                }
            ],
            "abstract": "dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. however, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. in this work, we propose attention guided graph convolutional networks (aggcns), a novel model which directly takes full dependency trees as inputs. our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches."
        },
        {
            "id": "R70864",
            "label": "COVID-19 Knowledge Graph: a computable, multi-modal, cause-and-effect knowledge model of COVID-19 pathophysiology",
            "doi": "10.1101/2020.04.14.040667",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R70863",
                    "label": "Overview of several scholarly databases and their properties"
                }
            ],
            "abstract": "abstract summary the past few weeks have witnessed a worldwide mobilization of the research community in response to the novel coronavirus (covid-19). this global response has led to a burst of publications on the pathophysiology of the virus, yet without coordinated efforts to organize this knowledge, it can remain hidden away from individual research groups. by extracting and formalizing this knowledge in a structured and computable form, as in the form of a knowledge graph, researchers can readily reason and analyze this information on a much larger scale. here, we present the covid-19 knowledge graph, an expansive cause-and-effect network constructed from scientific literature on the new coronavirus that aims to provide a comprehensive view of its pathophysiology. to make this resource available to the research community and facilitate its exploration and analysis, we also implemented a web application and released the kg in multiple standard formats. availability the covid-19 knowledge graph is publicly available under cc-0 license at https://github.com/covid19kg and https://bikmi.covid19-knowledgespace.de . contact alpha.tom.kodamullil@scai.fraunhofer.de supplementary information supplementary data are available online."
        },
        {
            "id": "R193470",
            "label": "An Empirical Evaluation of Convolutional Networks for Malaria Diagnosis",
            "doi": "",
            "research_field": {
                "id": "R136138",
                "label": "Medical Informatics and Medical Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "malaria is a globally widespread disease caused by parasitic protozoa transmitted to humans by infected female mosquitoes of anopheles. it is caused in humans only by the parasite plasmodium, further classified into four different species. identifying malaria parasites is possible by analysing digital microscopic blood smears, which is tedious, time-consuming and error prone. so, automation of the process has assumed great importance as it helps the laborious manual process of review and diagnosis. this work focuses on deep learning-based models, by comparing off-the-shelf architectures for classifying healthy and parasite-affected cells, by investigating the four-class classification on the plasmodium falciparum stages of life and, finally, by evaluating the robustness of the models with cross-dataset experiments on two different datasets. the main contributions to the research in this field can be resumed as follows: (i) comparing off-the-shelf architectures in the task of classifying healthy and parasite-affected cells, (ii) investigating the four-class classification on the p. falciparum stages of life and (iii) evaluating the robustness of the models with cross-dataset experiments. eleven well-known convolutional neural networks on two public datasets have been exploited. the results show that the networks have great accuracy in binary classification, even though they lack few samples per class. moreover, the cross-dataset experiments exhibit the need for some further regulations. in particular, resnet-18 achieved up to 97.68% accuracy in the binary classification, while densenet-201 reached 99.40% accuracy on the multiclass classification. the cross-dataset experiments exhibit the limitations of deep learning approaches in such a scenario, even though combining the two datasets permitted densenet-201 to reach 97.45% accuracy. naturally, this needs further investigation to improve the robustness. in general, densenet-201 seems to offer the most stable and robust performance, offering as a crucial candidate to further developments and modifications. moreover, the mobile-oriented architectures showed promising and satisfactory performance in the classification of malaria parasites. the obtained results enable extensive improvements, specifically oriented to the application of object detectors for type and stage of life recognition, even in mobile environments."
        },
        {
            "id": "R133107",
            "label": "Massively Parallel Methods for Deep Reinforcement Learning",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "we present the first massively distributed architecture for deep reinforcement learning. this architecture uses four main components: parallel actors that generate new behaviour; parallel learners that are trained from stored experience; a distributed neural network to represent the value function or behaviour policy; and a distributed store of experience. we used our architecture to implement the deep q-network algorithm (dqn). our distributed algorithm was applied to 49 games from atari 2600 games from the arcade learning environment, using identical hyperparameters. our performance surpassed non-distributed dqn in 41 of the 49 games and also reduced the wall-time required to achieve these results by an order of magnitude on most games."
        },
        {
            "id": "R211370",
            "label": "Discovering affect-laden requirements to achieve system acceptance",
            "doi": "10.1109/re.2014.6912259",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "novel envisioned systems face the risk of rejection by their target user community and the requirements engineer must be sensitive to the factors that will determine acceptance or rejection. conventionally, technology acceptance is determined by perceived usefulness and ease-of-use, but in some domains other factors play an important role. in healthcare systems, particularly, ethical and emotional factors can be crucial. in this paper we describe an approach to requirements discovery that we developed for such systems. we describe how we have applied our approach to a novel system to passively monitor users for signs of cognitive decline consistent with the onset of dementia. a key challenge was eliciting users' reactions to emotionally charged events never before experienced by them at first hand. our goal was to understand the range of users' emotional responses and their values and motivations, and from these formulate requirements that would maximise the likelihood of acceptance of the system. the problem was heightened by the fact that the key stakeholders were elderly people who represent a poorly studied user constituency. we discuss the elicitation and analysis methodologies used, and our experience with tool support. we conclude by reflecting on the affect issues for re and for technology acceptance."
        },
        {
            "id": "R170413",
            "label": "Fluid Intelligence and Psychosocial Outcome: From Logical Problem Solving to Social Adaptation",
            "doi": "10.1371/journal.pone.0024858",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"background while fluid intelligence has proved to be central to executive functioning, logical reasoning and other frontal functions, the role of this ability in psychosocial adaptation has not been well characterized. methodology/principal findings a random-probabilistic sample of 2370 secondary school students completed measures of fluid intelligence (raven's progressive matrices, rpm) and several measures of psychological adaptation: bullying (delaware bullying questionnaire), domestic abuse of adolescents (conflict tactic scale), drug intake (onudd), self-esteem (rosenberg's self esteem scale) and the perceived mental health scale (spanish adaptation). lower fluid intelligence scores were associated with physical violence, both in the role of victim and victimizer. drug intake, especially cannabis, cocaine and inhalants and lower self-esteem were also associated with lower fluid intelligence. finally, scores on the perceived mental health assessment were better when fluid intelligence scores were higher. conclusions/significance our results show evidence of a strong association between psychosocial adaptation and fluid intelligence, suggesting that the latter is not only central to executive functioning but also forms part of a more general capacity for adaptation to social contexts.\""
        },
        {
            "id": "R4590",
            "label": "Ontology-based employer demand management",
            "doi": "10.1002/spe.2319",
            "research_field": {
                "id": "R141",
                "label": "Theory/Algorithms"
            },
            "research_problems": [
                {
                    "id": "R4596",
                    "label": "Providing an Ontology-based Information Extraction (OBIE) method for identifying and quantifying skill demands across industry"
                }
            ],
            "abstract": "skills shortages globally pose a real and urgent need for proper investigation and workforce development planning into the future. analysing workforce development and employer demand needs through electronic job market allows much deeper and wider research into skill shortages. current methods do not provide the level of depth required to address such important economic implications. in this paper, we present a system aiming to gather and analyse current employer demand information from online job advertisements. it identifies current employer demand needs analysed from electronic job market. copyright \u00a9 2015 john wiley & sons, ltd."
        },
        {
            "id": "R134889",
            "label": "Augmented Neural ODEs",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R38570",
                    "label": "Image Classification"
                }
            ],
            "abstract": "we show that neural ordinary differential equations (odes) learn representations that preserve the topology of the input space and prove that this implies the existence of functions neural odes cannot represent. to address these limitations, we introduce augmented neural odes which, in addition to being more expressive models, are empirically more stable, generalize better and have a lower computational cost than neural odes."
        },
        {
            "id": "R74440",
            "label": "EMadrid project: MOOCs and learning analytics",
            "doi": "10.1109/SIIE.2016.7751870",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74431",
                    "label": "Learning Analytics"
                },
                {
                    "id": "R109084",
                    "label": "Learning Analytics"
                }
            ],
            "abstract": "both, moocs and learning analytics, are two emergent topics in the field of educational technology. this paper shows the main contributions of the emadrid network in these two topics during the last years (2014-2016), as well as the planned future works in the network. the contributions in the field of the moocs include the design and authoring of materials, the improvement of the peer review process or experiences about teaching these courses and institutional adoption. the contributions in the field of learning analytics include the inference of higher level information, the development of dashboards, the evaluation of the learning process, or the prediction and clustering."
        },
        {
            "id": "R6649",
            "label": "ERSS 2005: Coreference-Based Summarization Reloaded",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6544",
                    "label": "Automatic text summarization"
                }
            ],
            "abstract": "we present erss 2005, our entry to this year\u2019s duc competition. with only slight modifications from last year\u2019s version to accommodate the more complex context information present in duc 2005, we achieved a similar performance to last year\u2019s entry, ranking roughly in the upper third when examining the rouge-1 and basic element score. we also participated in the additional manual evaluation based on the new pyramid method and performed further evaluations based on the basic elements method and the automatic generation of pyramids. interestingly, the ranking of our system differs greatly between the different measures; we attempt to analyse this effect based on correlations between the different results using the spearman coefficient."
        },
        {
            "id": "R171260",
            "label": "The Everyday Moral Judge \u00e2\u0080\u0093 Autobiographical Recollections of Moral Emotions",
            "doi": "10.1371/journal.pone.0167224",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "moral emotions are typically elicited in everyday social interactions and regulate social behavior. previous research in the field of attribution theory identified ought (the moral standard of a given situation or intended goal), goal-attainment (a goal can be attained vs. not attained) and effort (high vs. low effort expenditure) as cognitive antecedents of moral emotions. in contrast to earlier studies, mainly relying on thought experiments, we investigated autobiographical recollections of n = 312 participants by means of an online study. we analyzed a diverse range of moral emotions, i.e., admiration, anger, contempt, indignation, pride, respect, schadenfreude, and sympathy, by using a mixed-method approach. qualitative and quantitative methods clearly corroborate the important role of ought, goal-attainment, and effort as eliciting conditions of moral emotions. furthermore, we built categorical systems based on our participants\u2019 descriptions of real-life situations, allowing for more fine-grained distinctions between seemingly similar moral emotions. we thus identify additional prerequisites explaining more subtle differences between moral emotion clusters as they emerge from our analyses (i.e., cluster 1: admiration, pride, and respect; cluster 2: anger, contempt, and indignation; cluster 3: schadenfreude and sympathy). results are discussed in the light of attributional theories of moral emotions, and implications for future research are derived."
        },
        {
            "id": "R193422",
            "label": "Badvertisements: Stealthy click-fraud with unwitting accessories",
            "doi": "",
            "research_field": {
                "id": "R137556",
                "label": "Electrical Engineering and Information Technology"
            },
            "research_problems": [
                {
                    "id": "R193401",
                    "label": "Attacks, revenue model goal and primary component targets in online advertising system"
                }
            ],
            "abstract": "abstract we describe a new type of threat to the internet infrastructure, in the shape of a highly efficient but very well camouflaged click-fraud attack on the advertising infrastructure. the attack, which we refer to as a \u201cbadvertisement,\u201d is described and experimentally verified on several prominent advertisement schemes. this stealthy attack can be thought of as a threatening mutation of spam and phishing attacks, with which it has many commonalities, except for the fact that it is not the targeted individual who is the victim in the attack, but the unwitting advertiser."
        },
        {
            "id": "R109331",
            "label": "Potential inhibitors of coronavirus 3-chymotrypsin-like protease (3CLpro): an in silico screening of alkaloids and terpenoids from African medicinal plants",
            "doi": "10.1080/07391102.2020.1764868",
            "research_field": {
                "id": "R14",
                "label": "Biochemistry"
            },
            "research_problems": [
                {
                    "id": "R51405",
                    "label": "potential inhibitors of SARS-CoV-2 replication"
                }
            ],
            "abstract": "abstract the novel coronavirus disease 2019 (covid-19) caused by sars-cov-2 has raised myriad of global concerns. there is currently no fda approved antiviral strategy to alleviate the disease burden. the conserved 3-chymotrypsin-like protease (3clpro), which controls coronavirus replication is a promising drug target for combating the coronavirus infection. this study screens some african plants derived alkaloids and terpenoids as potential inhibitors of coronavirus 3clpro using in silico approach. bioactive alkaloids (62) and terpenoids (100) of plants native to africa were docked to the 3clpro of the novel sars-cov-2. the top twenty alkaloids and terpenoids with high binding affinities to the sars-cov-2 3clpro were further docked to the 3clpro of sars-cov and mers-cov. the docking scores were compared with 3clpro-referenced inhibitors (lopinavir and ritonavir). the top docked compounds were further subjected to adem/tox and lipinski filtering analyses for drug-likeness prediction analysis. this ligand-protein interaction study revealed that more than half of the top twenty alkaloids and terpenoids interacted favourably with the coronaviruses 3clpro, and had binding affinities that surpassed that of lopinavir and ritonavir. also, a highly defined hit-list of seven compounds (10-hydroxyusambarensine, cryptoquindoline, 6-oxoisoiguesterin, 22-hydroxyhopan-3-one, cryptospirolepine, isoiguesterin and 20-epibryonolic acid) were identified. furthermore, four non-toxic, druggable plant derived alkaloids (10-hydroxyusambarensine, and cryptoquindoline) and terpenoids (6-oxoisoiguesterin and 22-hydroxyhopan-3-one), that bind to the receptor-binding site and catalytic dyad of sars-cov-2 3clpro were identified from the predictive adme/tox and lipinski filter analysis. however, further experimental analyses are required for developing these possible leads into natural anti-covid-19 therapeutic agents for combating the pandemic. communicated by ramaswamy h. sarma"
        },
        {
            "id": "R169587",
            "label": "The Influence of Emotion on Keyboard Typing: An Experimental Study Using Auditory Stimuli",
            "doi": "10.1371/journal.pone.0129056",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in recent years, a novel approach for emotion recognition has been reported, which is by keystroke dynamics. the advantages of using this approach are that the data used is rather non-intrusive and easy to obtain. however, there were only limited investigations about the phenomenon itself in previous studies. hence, this study aimed to examine the source of variance in keyboard typing patterns caused by emotions. a controlled experiment to collect subjects\u2019 keystroke data in different emotional states induced by international affective digitized sounds (iads) was conducted. two-way valence (3) x arousal (3) anovas was used to examine the collected dataset. the results of the experiment indicate that the effect of arousal is significant in keystroke duration (p < .05), keystroke latency (p < .01), but not in the accuracy rate of keyboard typing. the size of the emotional effect is small, compared to the individual variability. our findings support the conclusion that the keystroke duration and latency are influenced by arousal. the finding about the size of the effect suggests that the accuracy rate of emotion recognition technology could be further improved if personalized models are utilized. notably, the experiment was conducted using standard instruments and hence is expected to be highly reproducible."
        },
        {
            "id": "R131118",
            "label": "A Structured Learning Approach to Temporal Relation Extraction",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R121389",
                    "label": "Temporal Information Extraction"
                }
            ],
            "abstract": "identifying temporal relations between events is an essential step towards natural language understanding. however, the temporal relation between two events in a story depends on, and is often dictated by, relations among other events. consequently, effectively identifying temporal relations between events is a challenging problem even for human annotators. this paper suggests that it is important to take these dependencies into account while learning to identify these relations and proposes a structured learning approach to address this challenge. as a byproduct, this provides a new perspective on handling missing relations, a known issue that hurts existing methods. as we show, the proposed approach results in significant improvements on the two commonly used data sets for this problem."
        },
        {
            "id": "R49152",
            "label": "REDI: Towards knowledge graph-powered scholarly information management and research networking",
            "doi": "10.1177/0165551520944351",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R38477",
                    "label": "Semantic annotation for scholarly publications"
                },
                {
                    "id": "R38532",
                    "label": "knowledge graph population"
                }
            ],
            "abstract": "academic data management has become an increasingly challenging task as research evolves over time. essential tasks such as information retrieval and research networking have turned into extremely difficult operations due to an ever-growing number of researchers and scientific articles. numerous initiatives have emerged in the it environments to address this issue, especially focused on web technologies. although those approaches have individually provided solutions for diverse problems, they still can not offer integrated knowledge bases nor flexibility to exploit adequately this information. in this article, we present redi, a linked data-powered framework for academic knowledge management and research networking, which introduces a new perspective of integration. redi combines information from multiple sources into a consolidated knowledge base through state-of-the-art procedures and leverages semantic web standards to represent the information. moreover, redi takes advantage of such knowledge for data visualisation and analysis, which ultimately improves and simplifies many activities including research networking."
        },
        {
            "id": "R44448",
            "label": "Effect of valproate sodium on generalized penicillin epilepsy in the cat",
            "doi": "10.1111/j.1528-1157.1978.tb04501.x",
            "research_field": {
                "id": "R77",
                "label": "Animal Sciences"
            },
            "research_problems": [
                {
                    "id": "R44421",
                    "label": "Antiepileptic drugs' safety and effectiveness"
                }
            ],
            "abstract": "the antiepileptic effect of valproate sodium (vpa) on generalized epileptic activity produced by large parenteral doses of penicillin was tested in 8 cats. the clinical and electrographic manifestations of this model esemble those of human generalized corticoreticular epilepsy."
        },
        {
            "id": "R171283",
            "label": "Highly Educated Men Establish Strong Emotional Links with Their Dogs: A Study with Monash Dog Owner Relationship Scale (MDORS) in Committed Spanish Dog Owners",
            "doi": "10.1371/journal.pone.0168748",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the characteristics of the human-animal bond may be influenced by both owner-related and dog-related factors. a study was designed to explore the existence of different dog ownership patterns and their related factors. we created an on line questionnaire that included demographic questions about the dog and the owner, a spanish version of the monash dog owner relationship scale (mdors) and a validated measure of satisfaction with life (cantril\u2019s ladder). we collected 1140 valid responses from adult dog owners, who were recruited using the client databases of spanish veterinary practices. we explored the presence of groups within the population using principal components analysis (pca) of the mdors variables combined with hierarchical cluster analysis (hca). two groups were found; group i having a higher level of emotional involvement with their dogs compared with group ii. binary logistic regression was used to explore demographic factors that influenced group membership. four variables were significantly associated with membership of group i (p<0.0001); male gender of the owner (or = 32.36), high school level of maximum educational attainment (or = 0.052), university level of maximum educational attainment (or = 8.652), and owner cantril\u2019s score (or = 0.807). the results obtained from this convenience sample demonstrate that different patterns of dog-ownership may be present within a population of owner-dog dyads, and that certain owner characteristics are associated with the type of owner-dog relationship. future research could apply a similar approach to different types of sample population in order to identify specific patterns of dog-ownership."
        },
        {
            "id": "R155514",
            "label": "Biogeographic drivers of diazotrophs in the western Pacific Ocean",
            "doi": "10.1002/lno.11123",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R147137",
                    "label": "Nitrogen fixation rates estimation in the Pacific Ocean"
                }
            ],
            "abstract": "the global budget of marine nitrogen (n) is not balanced, with n removal largely exceeding n fixation. one of the major causes of this imbalance is our inadequate understanding of the diversity and distribution of marine n2 fixers (diazotrophs) as well as their contribution to n2 fixation. here, we performed a large\u2010scale cross\u2010system study spanning the south china sea, luzon strait, philippine sea, and western tropical pacific ocean to compare the biogeography of seven major diazotrophic groups and n2 fixation rates in these ecosystems. distinct spatial niche differentiation was observed. trichodesmium was dominant in the south china sea and western equatorial pacific, whereas the unicellular cyanobacterium ucyn\u2010b dominated in the philippine sea. furthermore, contrasting diel patterns of trichodesmium nifh genes and ucyn\u2010b nifh gene transcript activity were observed. the heterotrophic diazotroph gamma a phylotype was widespread throughout the western pacific ocean and occupied an ecological niche that overlapped with that of ucyn\u2010b. moreover, gamma a (or other possible unknown/undetected diazotrophs) rather than trichodesmium and ucyn\u2010b may have been responsible for the high n2 fixation rates in some samples. regional biogeochemistry analyses revealed cross\u2010system variations in n2\u2010fixing community composition and activity constrained by sea surface temperature, aerosol optical thickness, current velocity, mixed\u2010layer depth, and chlorophyll a concentration. these factors except for temperature essentially control/reflected iron supply/bioavailability and thus drive diazotroph biogeography. this study highlights biogeographical controls on marine n2 fixers and increases our understanding of global diazotroph biogeography."
        },
        {
            "id": "R110002",
            "label": "Application of support vector regression analysis to estimate total organic carbon content of Cambay shale in Cambay basin, India \u00e2\u0080\u0093 a case study",
            "doi": "",
            "research_field": {
                "id": "R148",
                "label": "Geophysics and Seismology"
            },
            "research_problems": [
                {
                    "id": "R110013",
                    "label": "To estimate total organic carbon, an important source rock characterization parameter, using well logs."
                }
            ],
            "abstract": "abstract the objective of the present study is to estimate total organic carbon (toc) content over the entire thickness of cambay shale, in the boreholes of jambusar\u2013broach block of cambay basin, india. to achieve this objective, support vector regression (svr), a supervised data mining technique, has been utilized using five basic wireline logs as input variables. suitable svr model has been developed by selecting epsilon-svr algorithm and varying three different kernel functions and parameters like gamma and cost on a sample dataset. the best result is obtained when the radial-basis kernel function with gamma = 1 and cost = 1, are used. finally, the performance of developed svr model is compared with the \u03b4logr method. the toc computed by svr method is found to be more precise than the \u03b4logr method, as it has better agreement with the core-toc. thus, in the present study area, the svr method is found to be a powerful tool for estimating toc of cambay shale in a continuous and rapid manner."
        },
        {
            "id": "R194610",
            "label": "Requirements Classification with Interpretable Machine Learning and Dependency Parsing",
            "doi": "10.1109/re.2019.00025",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"requirements classification is a traditional application of machine learning (ml) to re that helps handle large requirements datasets. a prime example of an re classification problem is the distinction between functional and non-functional (quality) requirements. state-of-the-art classifiers build their effectiveness on a large set of word features like text n-grams or pos n-grams, which do not fully capture the essence of a requirement. as a result, it is arduous for human analysts to interpret the classification results by exploring the classifier's inner workings. we propose the use of more general linguistic features, such as dependency types, for the construction of interpretable ml classifiers for re. through a feature engineering effort, in which we are assisted by modern introspection tools that reveal the hidden inner workings of ml classifiers, we derive a set of 17 linguistic features. while classifiers that use our proposed features fit the training set slightly worse than those that use high-dimensional feature sets, our approach performs generally better on validation datasets and it is more interpretable.\""
        },
        {
            "id": "R206391",
            "label": "Explaining Relationships Between Scientific Documents",
            "doi": "10.18653/v1/2021.acl-long.166",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R161745",
                    "label": "Relationship extraction"
                },
                {
                    "id": "R206395",
                    "label": "Relationship explanation"
                }
            ],
            "abstract": "we address the task of explaining relationships between two scientific documents using natural language text. this task requires modeling the complex content of long technical documents, deducing a relationship between these documents, and expressing the details of that relationship in text. in addition to the theoretical interest of this task, successful solutions can help improve researcher efficiency in search and review. in this paper we establish a dataset of 622k examples from 154k documents. we pretrain a large language model to serve as the foundation for autoregressive approaches to the task. we explore the impact of taking different views on the two documents, including the use of dense representations extracted with scientific ie systems. we provide extensive automatic and human evaluations which show the promise of such models, but make clear challenges for future work."
        },
        {
            "id": "R138490",
            "label": "Heterotrophic bacteria as major nitrogen fixers in the euphotic zone of the Indian Ocean: NITROGEN FIXATION IN THE INDIAN OCEAN",
            "doi": "10.1002/2014GB004886",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R138489",
                    "label": "Primary production assessment in the euphotic zone of the Indian Ocean"
                }
            ],
            "abstract": "diazotrophy in the indian ocean is poorly understood compared to that in the atlantic and pacific oceans. we first examined the basin\u2010scale community structure of diazotrophs and their nitrogen fixation activity within the euphotic zone during the northeast monsoon period along about 69\u00b0e from 17\u00b0n to 20\u00b0s in the oligotrophic indian ocean, where a shallow nitracline (49\u201359\\u2009m) prevailed widely and the sea surface temperature (sst) was above 25\u00b0c. phosphate was detectable at the surface throughout the study area. the dissolved iron concentration and the ratio of iron to nitrate\\u2009+\\u2009nitrite at the surface were significantly higher in the arabian sea than in the equatorial and southern indian ocean. nitrogen fixation in the arabian sea (24.6\u201347.1 \u03bcmoln m\u22122 d\u22121) was also significantly greater than that in the equatorial and southern indian ocean (6.27\u201316.6 \u03bcmoln m\u22122 d\u22121), indicating that iron could control diazotrophy in the indian ocean. phylogenetic analysis of nifh showed that most diazotrophs belonged to the proteobacteria and that cyanobacterial diazotrophs were absent in the study area except in the arabian sea. furthermore, nitrogen fixation was not associated with light intensity throughout the study area. these results are consistent with nitrogen fixation in the indian ocean, being largely performed by heterotrophic bacteria and not by cyanobacteria. the low cyanobacterial diazotrophy was attributed to the shallow nitracline, which is rarely observed in the pacific and atlantic oligotrophic oceans. because the shallower nitracline favored enhanced upward nitrate flux, the competitive advantage of cyanobacterial diazotrophs over nondiazotrophic phytoplankton was not as significant as it is in other oligotrophic oceans."
        },
        {
            "id": "R109994",
            "label": "Corn Cob Biochar Improves Aggregate Characteristics of a Tropical Sandy Loam",
            "doi": "10.2136/sssaj2017.04.0112",
            "research_field": {
                "id": "R153",
                "label": "Soil Science"
            },
            "research_problems": [
                {
                    "id": "R109997",
                    "label": "Biochar impact on soil aggregate tesile strength and stability"
                }
            ],
            "abstract": "most tropical soils are highly weathered and are vulnerable to soil erosion due to their poor aggregate characteristics. soil aggregate characteristics are critical indicators of soil structural stability, and they have the propensity to influence soil physical behavior and functioning. in this study, we investigated the effect of corn cob biochar on the aggregate characteristics of a highly weathered tropical sandy loam. biochar significantly increased soil organic carbon by 22-40% relative to the untreated soil with a surprising trend of increasing water dispersible clay as biochar rate increased. amount of water stable aggregates was significantly improved by 15 \u2013 34% in biochar treatments compared to control. incorporation of biochar decreased the tensile strength of the large aggregates (4\u20138 mm and 8\u201316 mm), but increased same in the smaller aggregates (1\u20132 mm). soil friability and workability were significantly improved in the bc-20 and bc-20+p treatments. conclusions increasing the rate of corn cob biochar improved the water stability of the aggregates compared to the ct, despite the absence of a significant effect on the dispersible clay content. for smaller aggregates (1\u20132mm), tensile strength for bc-20 and bc-20+p treatments was significantly higher than the ct and bc-10, with an opposite trend observed for larger aggregates (4\u20138 mm and 8\u201316 mm). corn cob biochar significantly improved soil friability and the ease of tillage quantified with a workability index. reference dexter, a.r., and b. kroesbergen. 1985. methodology for determination of tensile strength of soil aggregates. journal of agric. engineering research 31:139-147. corn cob biochar improves aggregate characteristics of a tropical sandy loam ohio state university south centers college of food, agricultural, and environmental sciences cfaes provides research and related educational programs to clientele on a nondiscriminatory basis. for more information: go.osu.edu/cfaesdiversity. the ohio state university field layout and experimental design randomized complete block design 4 treatments with 4 replications"
        },
        {
            "id": "R57556",
            "label": "Ethylamin [MAK Value Documentation in German language, 2019]",
            "doi": "10.1002/3527600418.mb7504d0066",
            "research_field": {
                "id": "R69",
                "label": "Toxicology"
            },
            "research_problems": [
                {
                    "id": "R57555",
                    "label": "Neubewertung aller toxikologischen Werte f\u00fcr Ethylamine"
                }
            ],
            "abstract": "der mak-wert des stark ammoniakalisch riechenden ethylamins ist aufgrund fehlender humanund unzureichender tierexperimenteller daten als vorl\u00e4ufig zu betrachten. im vordergrund steht die starke reizwirkung, welche nach tierexperimentellen studien (rd50) \u00e4hnlich wie die anderer aliphatischer amine ist (gagnaire et al. 1993). untersuchungen zur reizwirkung beim menschen liegen nicht vor. ethylamin ist an haut und auge \u00e4tzend (begr\u00fcndung 1984). als geruchsschwellenwert wurden 0,027 ml/m (tkachev 1971, siehe begr\u00fcndung 1984) bzw. 0,27 ml/m (hellman und small 1974, siehe begr\u00fcndung 1984) angegeben. in analogie zu anderen aliphatischen aminen, deren reizschwelle bei etwa 10 ml/m liegt, wird ethylamin in die kurzzeitwert-kategorie i mit einem \u00fcberschreitungsfaktor von 2 eingestuft. da der mak-wert nahe an der reizschwelle liegt und ethylamin \u00e4tzend wirkt, werden 10 ml/m als momentanwert f\u00fcr die expositionsbegrenzung festgelegt, um auch k\u00fcrzere expositionsspitzen zu vermeiden, die zu deutlichen reizwirkungen f\u00fchren k\u00f6nnen."
        },
        {
            "id": "R171666",
            "label": "Personality and social support as determinants of entrepreneurial intention. Gender differences in Italy",
            "doi": "10.1371/journal.pone.0199924",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the interest in the promotion of entrepreneurship is significantly increasing, particularly in those countries, such as italy, that suffered during the recent great economic recession and subsequently needed to revitalize their economy. entrepreneurial intention (ei) is a crucial stage in the entrepreneurial process and represents the basis for consequential entrepreneurial actions. several research projects have sought to understand the antecedents of ei. this study, using a situational approach, has investigated the personal and contextual determinants of ei, exploring gender differences. in particular, the mediational role of general self-efficacy between internal locus of control (loc), self-regulation, and support from family and friends, on the one hand, and ei, on the other hand, has been investigated. the study involved a sample of 658 italian participants, of which 319 were male and 339 were female. data were collected with a self-report on-line questionnaire and analysed with spss 23 and mplus 7 to test a multi-group structural equation model. the results showed that self-efficacy totally mediated the relationship between internal loc, self-regulation and ei. moreover, it partially mediated the relationship between support from family and friends and ei. all the relations were significant for both men and women; however, our findings highlighted a stronger relationship between self-efficacy and ei for men, and between support from family and friends and both self-efficacy and ei for women. findings highlighted the role of contextual characteristics in addition to personal ones in influencing ei and confirmed the key mediational function of self-efficacy. as for gender, results suggested that differences between men and women in relation to the entrepreneur role still exist. practical implications for trainers and educators are discussed."
        },
        {
            "id": "R140694",
            "label": "Comparison of airborne hyperspectral data and eo-1 hyperion for mineral mapping",
            "doi": "10.1109/TGRS.2003.812908",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R140693",
                    "label": "Mineralogy of Cuprite hills in Nevada of Unitd states from airborne and spaceborne imageries"
                }
            ],
            "abstract": "\"airborne hyperspectral data have been available to researchers since the early 1980s and their use for geologic applications is well documented. the launch of the national aeronautics and space administration earth observing 1 hyperion sensor in november 2000 marked the establishment of a test bed for spaceborne hyperspectral capabilities. hyperion covers the 0.4-2.5-/spl mu/m range with 242 spectral bands at approximately 10-nm spectral resolution and 30-m spatial resolution. analytical imaging and geophysics llc and the commonwealth scientific and industrial research organisation have been involved in efforts to evaluate, validate, and demonstrate hyperions's utility for geologic mapping in a variety of sites in the united states and around the world. initial results over several sites with established ground truth and years of airborne hyperspectral data show that hyperion data from the shortwave infrared spectrometer can be used to produce useful geologic (mineralogic) information. minerals mapped include carbonates, chlorite, epidote, kaolinite, alunite, buddingtonite, muscovite, hydrothermal silica, and zeolite. hyperion data collected under optimum conditions (summer season, bright targets, well-exposed geology) indicate that hyperion data meet prelaunch specifications and allow subtle distinctions such as determining the difference between calcite and dolomite and mapping solid solution differences in micas caused by substitution in octahedral molecular sites. comparison of airborne hyperspectral data [from the airborne visible/infrared imaging spectrometer (aviris)] to the hyperion data establishes that hyperion provides similar basic mineralogic information, with the principal limitation being limited mapping of fine spectral detail under less-than-optimum acquisition conditions (winter season, dark targets) based on lower signal-to-noise ratios. case histories demonstrate the analysis methodologies and level of information available from the hyperion data. they also show the viability of hyperion as a means of extending hyperspectral mineral mapping to areas not accessible to aircraft sensors. the analysis results demonstrate that spaceborne hyperspectral sensors can produce useful mineralogic information, but also indicate that snr improvements are required for future spaceborne sensors to allow the same level of mapping that is currently possible from airborne sensors such as aviris.\""
        },
        {
            "id": "R193176",
            "label": "A Recurrent Variational Autoencoder for Human Motion Synthesis",
            "doi": "10.5244/C.31.119",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R128713",
                    "label": "motion synthesis"
                }
            ],
            "abstract": "we propose a novel generative model of human motion that can be trained using a large motion capture dataset, and allows users to produce animations from high-level control signals. as previous architectures struggle to predict motions far into the future due to the inherent ambiguity, we argue that a user-provided control signal is desirable for animators and greatly reduces the predictive error for long sequences. thus, we formulate a framework which explicitly introduces an encoding of control signals into a variational inference framework trained to learn the manifold of human motion. as part of this framework, we formulate a prior on the latent space, which allows us to generate high-quality motion without providing frames from an existing sequence. we further model the sequential nature of the task by combining samples from a variational approximation to the intractable posterior with the control signal through a recurrent neural network (rnn) that synthesizes the motion. we show that our system can predict the movements of the human body over long horizons more accurately than state-of-the-art methods. finally, the design of our system considers practical use cases and thus provides a competitive approach to motion synthesis. variable from the approximate posterior, while we resign to sampling from the prior p ( z ) when no initial frame is provided. method performs signi\ufb01cantly better in both cases."
        },
        {
            "id": "R140875",
            "label": "Overview of NLPTEA-2020 Shared Task for Chinese Grammatical Error Diagnosis",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R140878",
                    "label": "Chinese Grammatical Error Diagnosis"
                }
            ],
            "abstract": "this paper presents the nlptea 2020 shared task for chinese grammatical error diagnosis (cged) which seeks to identify grammatical error types, their range of occurrence and recommended corrections within sentences written by learners of chinese as a foreign language. we describe the task definition, data preparation, performance metrics, and evaluation results. of the 30 teams registered for this shared task, 17 teams developed the system and submitted a total of 43 runs. system performances achieved a significant progress, reaching f1 of 91% in detection level, 40% in position level and 28% in correction level. all data sets with gold standards and scoring scripts are made publicly available to researchers."
        },
        {
            "id": "R191643",
            "label": "Documentation Mocap Database HDM05",
            "doi": "",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "preface in the past two decades, motion capture (mocap) systems have been developed that allow to track and record human motions at high spatial and temporal resolutions. the resulting motion capture data is used to analyze human motions in fields such as sports sciences and biometrics (person identification), and to synthesize realistic motion sequences in data-driven computer animation. such applications require efficient methods and tools for the automatic analysis, synthesis and classification of motion capture data, which constitutes an active research area with many yet unsolved problems. even though there is a rapidly growing corpus of motion capture data, the academic research community still lacks publicly available motion data, as supplied by [4], that can be freely used for systematic research on motion analysis, synthesis, and classification. furthermore, a common dataset of annotated and well-documented motion capture data would be extremely valuable to the research community in view of an objective comparison and evaluation of the achieved research results. it is the objective of our motion capture database hdm05 1 to supply free motion capture data for research purposes. hdm05 contains more than tree hours of systematically recorded and well-documented motion capture data in the c3d as well as in the asf/amc data format. furthermore, hdm05 contains for each of roughly 70 motion classes 10 to 50 realizations executed by various actors amounting to roughly 1, 500 motion clips. in this documentation, we give a detailed description of our mocap database hdm05. in sect. 1, we provide some general information on motion capture data including references to various application fields. a detailed description of the database structure of hdm05 as well as of the content of each mocap file can be found in sect. 2. we also provide several matlab tools comprising a parser for asf/amc and c3d as well as visualization, renaming and cutting tools, which are described in sect. 3. finally, sect. 4 summarizes some facts on the mocap file formats asf/amc and c3d as used in our database. we appreciate any comments and suggestions for improvement. 1 the motion capture data has been recorded at the hochschule der medien (hdm) in the year 2005 under the supervision of bernhard eberhardt."
        },
        {
            "id": "R171627",
            "label": "A multi-level model of emerging technology: An empirical study of the evolution of biotechnology from 1976 to 2003",
            "doi": "10.1371/journal.pone.0197024",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper, we develop an ecological, multi-level model that can be used to study the evolution of emerging technology. more specifically, by defining technology as a system composed of a set of interacting components, we can build upon the argument of multi-level density dependence from organizational ecology to develop a distribution-independent model of technological evolution. this allows us to distinguish between different stages of component development, which provides more insight into the emergence of stable component configurations, or dominant designs. we validate our hypotheses in the biotechnology industry by using patent data from the uspto from 1976 to 2003."
        },
        {
            "id": "R172792",
            "label": "Fairness is intuitive",
            "doi": "10.1007/s10683-015-9463-y",
            "research_field": {
                "id": "R303",
                "label": "Behavioral Economics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this paper we provide new evidence showing that fair behavior is intuitive to most people. we find a strong association between a short response time and fair behavior in the dictator game. this association is robust to controls that take account of the fact that response time might be affected by the decision-maker\u2019s cognitive ability and swiftness. the experiment was conducted with a large and heterogeneous sample recruited from the general population in denmark. we find a striking similarity in the association between response time and fair behavior across groups in the society, which suggests that the predisposition to act fairly is a general human trait."
        },
        {
            "id": "R170165",
            "label": "The impact of the patient\u00e2\u0080\u0099s initial NACA score on subjective and physiological indicators of workload during pre-hospital emergency care",
            "doi": "10.1371/journal.pone.0202215",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background excessive workload may impair patient safety. however, little is known about emergency care providers\u2019 workload during the treatment of life-threatening cases including cardiopulmonary resuscitation (cpr). therefore, we tested the hypothesis that subjective and physiological indicators of workload are associated with the patient\u2019s initial naca score and that workload is particularly high during cpr. methods nasa task load index (nasa-tlx) and alarm codes were obtained for 216 sorties of pre-hospital emergency medical care. furthermore, initial naca scores of 140 patients were extracted from the physicians\u2019 protocols. the physiological workload indicators mean heart rate (hr) and permutation entropy (peen) were calculated for 51 sorties of primary care. general linear mixed models were used to analyze the association of naca scores with subjective (nasa-tlx) and physiological (mean hr, peen) measures of workload. results in contrast to the physiological variables peen (p = 0.10) and hr (p = 0.19), the mental (p<0.001) and temporal demands (p<0.001) as well as the effort (p<0.001) and frustration (p = 0.04) subscale of the nasa-tlx were significantly associated with initial naca scores. compared to naca = i, an initial naca score of vi (representing cpr) increased workload by a mean of 389.5% (p = 0.001) in the mental and 345.9% (p<0.001) in the temporal demands, effort by a mean of 446,8% (p = 0.002) and frustration by 190.0% (p = 0.03). in line with the increase in nasa-tlx, peen increased by 20.6% (p = 0.01) and hr by 6.4% (p = 0.57). conclusions patients\u2019 initial naca scores are associated with subjective workload. workload was highest during cpr."
        },
        {
            "id": "R155256",
            "label": "Dictator games: a meta study",
            "doi": "10.1007/s10683-011-9283-7",
            "research_field": {
                "id": "R303",
                "label": "Behavioral Economics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "over the last 25 years, more than a hundred dictator game experiments have been published. this meta study summarises the evidence. exploiting the fact that most experiments had to fix parameters they did not intend to test, in multiple regression the meta study is able to assess the effect of single manipulations, controlling for a host of alternative explanatory factors. the resulting rich dataset also provides a testbed for comparing alternative specifications of the statistical model for analysing dictator game data. it shows how tobit models (assuming that dictators would even want to take money) and hurdle models (assuming that the decision to give a positive amount is separate from the choice of amount, conditional on giving) provide additional insights."
        },
        {
            "id": "R169657",
            "label": "Optogenetics in Mice Performing a Visual Discrimination Task: Measurement and Suppression of Retinal Activation and the Resulting Behavioral Artifact",
            "doi": "10.1371/journal.pone.0144760",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "optogenetic techniques are used widely to perturb and interrogate neural circuits in behaving animals, but illumination can have additional effects, such as the activation of endogenous opsins in the retina. we found that illumination, delivered deep into the brain via an optical fiber, evoked a behavioral artifact in mice performing a visually guided discrimination task. compared with blue (473 nm) and yellow (589 nm) illumination, red (640 nm) illumination evoked a greater behavioral artifact and more activity in the retina, the latter measured with electrical recordings. in the mouse, the sensitivity of retinal opsins declines steeply with wavelength across the visible spectrum, but propagation of light through brain tissue increases with wavelength. our results suggest that poor retinal sensitivity to red light was overcome by relatively robust propagation of red light through brain tissue and stronger illumination of the retina by red than by blue or yellow light. light adaptation of the retina, via an external source of illumination, suppressed retinal activation and the behavioral artifact without otherwise impacting behavioral performance. in summary, long wavelength optogenetic stimuli are particularly prone to evoke behavioral artifacts via activation of retinal opsins in the mouse, but light adaptation of the retina can provide a simple and effective mitigation of the artifact."
        },
        {
            "id": "R185395",
            "label": "PeroxisomeDB: a database for the peroxisomal proteome, functional genomics and disease",
            "doi": "10.1093/nar/gkl935",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "peroxisomes are essential organelles of eukaryotic origin, ubiquitously distributed in cells and organisms, playing key roles in lipid and antioxidant metabolism. loss or malfunction of peroxisomes causes more than 20 fatal inherited conditions. we have created a peroxisomal database () that includes the complete peroxisomal proteome of homo sapiens and saccharomyces cerevisiae, by gathering, updating and integrating the available genetic and functional information on peroxisomal genes. peroxisomedb is structured in interrelated sections \u2018genes\u2019, \u2018functions\u2019, \u2018metabolic pathways\u2019 and \u2018diseases\u2019, that include hyperlinks to selected features of ncbi, ensembl and ucsc databases. we have designed graphical depictions of the main peroxisomal metabolic routes and have included updated flow charts for diagnosis. precomputed blast, psi-blast, multiple sequence alignment (muscle) and phylogenetic trees are provided to assist in direct multispecies comparison to study evolutionary conserved functions and pathways. highlights of the peroxisomedb include new tools developed for facilitating (i) identification of novel peroxisomal proteins, by means of identifying proteins carrying peroxisome targeting signal (pts) motifs, (ii) detection of peroxisomes in silico, particularly useful for screening the deluge of newly sequenced genomes. peroxisomedb should contribute to the systematic characterization of the peroxisomal proteome and facilitate system biology approaches on the organelle."
        },
        {
            "id": "R131297",
            "label": "Multi-task Deep Reinforcement Learning with PopArt",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R123486",
                    "label": "Visual Navigation"
                }
            ],
            "abstract": "the reinforcement learning (rl) community has made great strides in designing algorithms capable of exceeding human performance on specific tasks. these algorithms are mostly trained one task at the time, each new task requiring to train a brand new agent instance. this means the learning algorithm is general, but each solution is not; each agent can only solve the one task it was trained on. in this work, we study the problem of learning to master not one but multiple sequentialdecision tasks at once. a general issue in multi-task learning is that a balance must be found between the needs of multiple tasks competing for the limited resources of a single learning system. many learning algorithms can get distracted by certain tasks in the set of tasks to solve. such tasks appear more salient to the learning process, for instance because of the density or magnitude of the in-task rewards. this causes the algorithm to focus on those salient tasks at the expense of generality. we propose to automatically adapt the contribution of each task to the agent\u2019s updates, so that all tasks have a similar impact on the learning dynamics. this resulted in state of the art performance on learning to play all games in a set of 57 diverse atari games. excitingly, our method learned a single trained policy - with a single set of weights - that exceeds median human performance. to our knowledge, this was the first time a single agent surpassed human-level performance on this multi-task domain. the same approach also demonstrated state of the art performance on a set of 30 tasks in the 3d reinforcement learning platform deepmind lab."
        },
        {
            "id": "R110099",
            "label": "Bioinspired Three-Dimensional-Printed Helical Soft Pneumatic Actuators and Their Characterization",
            "doi": "10.1089/soro.2019.0015",
            "research_field": {
                "id": "R236",
                "label": "Robotics"
            },
            "research_problems": [
                {
                    "id": "R110105",
                    "label": "Actautors fabrication and charecterization, Soft Grippers"
                }
            ],
            "abstract": "soft pneumatic actuators (spas) are widely studied and applied in the field of soft robotics. to expand their applications, the spas should be purpose-built to generate application-specific complex motions with multiple degrees of freedom. this article describes a new spa consisting of a series of internal chambers with the same helix angle arranged in a row, which could generate bending and twisting motions simultaneously. the trajectory of the helical actuator was analyzed through the finite element method (fem) by changing the angle of the chambers and the actuator length. we employed a three-dimensional printing method to directly fabricate the thin-walled and airtight helical actuators without applying any postfabrication process. the recorded trajectory of the actuator and the measured blocking force on the tipping point were compared with the corresponding simulation results from the fem. the actuation behavior of the helical actuator has been compared with that of the actuator with zero chamber angle, but with the same size (i.e., a normal bending actuator generating a two-dimensional trajectory). it is found that the proposed helical actuator (with a maximum 2.10\\u2009n blocking force) had a higher mechanical output (or efficiency) than the normal bending actuator (with a maximum 1.19\\u2009n blocking force) under the same pressure input. we fabricated a soft helical actuator as the fingers of a four-finger gripper to grasp complex-shaped items. furthermore, another four-finger gripper made of a hybrid actuator consisting of a half of the angled chambers and a half of the nonangled chambers was constructed to demonstrate that the proposed design and fabrication technique could be employed to establish application- and function-specific soft robotic systems."
        },
        {
            "id": "R145371",
            "label": "Local Public Health Surveillance of Heroin-Related Morbidity and Mortality, Orange County, Florida, 2010-2014",
            "doi": "10.1177/0033354917709783",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "objectives: heroin-related deaths have increased substantially in the past 10 years in the united states, particularly in florida. our objectives were to measure heroin-related morbidity and mortality rates in orange county, florida, and to assess trends in those rates during 2010-2014. methods: we used 3 heroin surveillance methods, based on data from the florida medical examiner, the florida agency for health care administration (ahca), and the electronic surveillance system for the early notification of community-based epidemics\u2013florida (essence-fl). we conducted descriptive and geographic spatial analyses of all 3 data sets, determined heroin-related mortality and morbidity (emergency department [ed] visit) rates, and compared the timeliness of data availability from the 3 data sources. results: heroin-related deaths in orange county increased by 590%, from 10 in 2010 to 69 in 2014. heroin-related ed visits during the same period increased 12-fold (from 13 to 154) and 6-fold (from 49 to 307) when based on ahca and essence-fl data, respectively. essence-fl identified 140% more heroin-related visits than did ahca. spatial analysis found geographic clustering of heroin-related morbidity and mortality. hospitals facing the greatest burden of heroin-related ed visits were close to communities with the highest crude heroin-related ed visit rates. of the 3 data sources, essence-fl provided the timeliest data availability. conclusions: these 3 data sources can be considered acceptable surveillance systems for monitoring heroin-related events in orange county. the timely availability of data from essence-fl makes it the most useful source for obtaining near\u2013real-time data about the heroin epidemic, potentially leading to improved identification of populations most in need of interventions to reduce morbidity and mortality."
        },
        {
            "id": "R168924",
            "label": "Report of a series of 82 cases of Buruli ulcer from Nigeria treated in Benin, from 2006 to 2016",
            "doi": "10.1371/journal.pntd.0006358",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background nigeria is one of the countries endemic for buruli ulcer (bu) in west africa but did not have a control programme until recently. as a result, bu patients often access treatment services in neighbouring benin where dedicated health facilities have been established to provide treatment free of charge for bu patients. this study aimed to describe the epidemiological, clinical, biological and therapeutic characteristics of cases from nigeria treated in three of the four treatment centers in benin. methodology/principal findings a series of 82 bu cases from nigeria were treated in three centres in benin during 2006\u20132016 and are retrospectively described. the majority of these patients came from ogun and lagos states which border benin. most of the cases were diagnosed with ulcerative lesions (80.5%) and who category iii lesions (82.9%); 97.5% were healed after a median hospital stay of 46 days (interquartile range [iqr]: 32\u2013176 days). conclusions/significance this report adds to the epidemiological understanding of bu in nigeria in the hope that the programme will intensify efforts aimed at early case detection and treatment."
        },
        {
            "id": "R70742",
            "label": "A PISA-2015 Comparative Meta-Analysis between Singapore and Finland: Relations of Students\u00e2\u0080\u0099 Interest in Science, Perceived ICT Competence, and Environmental Awareness and Optimism",
            "doi": "10.3390/ijerph16245157",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "R70668",
                    "label": "ICT attitudes in PISA"
                }
            ],
            "abstract": "the aim of the present study is twofold: (1) to identify a factor structure between variables-interest in broad science topics, perceived information and communications technology (ict) competence, environmental awareness and optimism; and (2) to explore the relations between these variables at the country level. the first part of the aim is addressed using exploratory factor analysis with data from the program for international student assessment (pisa) for 15-year-old students from singapore and finland. the results show that a comparable structure with four factors was verified in both countries. correlation analyses and linear regression were used to address the second part of the aim. the results show that adolescents\u2019 interest in broad science topics can predict perceived ict competence. their interest in broad science topics and perceived ict competence can predict environmental awareness in both countries. however, there is difference in predicting environmental optimism. singaporean students\u2019 interest in broad science topics and their perceived ict competences are positive predictors, whereas environmental awareness is a negative predictor. finnish students\u2019 environmental awareness negatively predicted environmental optimism."
        },
        {
            "id": "R170572",
            "label": "Health-Related Quality of Life among Children with Recurrent Respiratory Tract Infections in Xi\u00e2\u0080\u0099an, China",
            "doi": "10.1371/journal.pone.0056945",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective the aim of this study was to investigate the health-related quality of life (hrqol) in 2\u22127-year-old children diagnosed with recurrent respiratory tract infections (rrtis) and the impact of rrtis on affected families. methods this was a cross-sectional case-control study evaluating 2\u22127-year-old children with rrtis (n\\u200a=\\u200a352), 2\u22127-year-old healthy children (n\\u200a=\\u200a376), and associated caregivers (parents and/or grandparents). a chinese version of the pedsql\u2122 4.0 generic core scale was used to assess childhood hrqol, and a chinese version of the family impact module (fim) was used to assess the impact of rrtis on family members. hrqol scores were compared between children with rrtis and healthy children. in addition, a multiple step-wise regression with demographic variables of children and their caregivers, family economic status, and caregiver\u2019s hrqol as independent variables determined factors that influenced hrqol in children with rrtis. results children with rrtis showed significantly lower physical, emotional, social, and school functioning scores than healthy children (p<0.05). caregivers for children with rrtis also scored significantly lower than caregivers for healthy children on physical, emotional, social, cognitive, and communication functioning (p<0.05). caregivers for rrtis affected children also reported significantly higher levels of worry. multivariate analyses showed that children\u2019s age, children\u2019s relation with caregivers, the frequency of respiratory tract infections in the preceding year, caregiver\u2019s educational level, and caregiver\u2019s own hrqol influenced hrqol in children with rrtis. conclusions the current data demonstrated that rrtis were associated with lower hrqol in both children and their caregivers and negatively influenced family functioning. in addition, caregivers\u2019 social characteristics also significantly affected hrqol in children with rrtis."
        },
        {
            "id": "R199123",
            "label": "Selecting creativity techniques for creative requirements: An evaluation of four techniques using creativity workshops",
            "doi": "10.1109/re.2015.7320409",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "requirements engineering is recognized as a creative process where stakeholders jointly discover new creative ideas for innovative and novel products that eventually are expressed as requirements. this paper evaluates four different creativity techniques, namely hall of fame, constraint removal, brainstorming, and idea box, using creativity workshops with students and industry practitioners. in total, 34 creativity workshops were conducted with 90 students from two universities, and 86 industrial practitioners from six companies. the results from this study indicate that brainstorming can generate by far the most ideas, while hall of fame generates most creative ideas. idea box generates the least number of ideas, and the least number of creative ideas. finally, hall of fame was the technique that led to the most number of requirements that was included in future releases of the products."
        },
        {
            "id": "R169777",
            "label": "Magnetoreception Regulates Male Courtship Activity in Drosophila",
            "doi": "10.1371/journal.pone.0155942",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the possible neurological and biophysical effects of magnetic fields on animals is an area of active study. here, we report that courtship activity of male drosophila increases in a magnetic field and that this effect is regulated by the blue light-dependent photoreceptor cryptochrome (cry). na\u00efve male flies exhibited significantly increased courtship activities when they were exposed to a \u2265 20-gauss static magnetic field, compared with their behavior in the natural environment (0 gauss). cry-deficient flies, cryb and crym, did not show an increased courtship index in a magnetic field. rnai-mediated knockdown of cry in cry-gal4-positive neurons disrupted the increased male courtship activity in a magnetic field. genetically expressing cry under the control of cry-gal4 in the cry-deficient flies restored the increase in male courtship index that occurred in a magnetic field. interestingly, artificially activating cry-gal4-expressing neurons, which include large ventral lateral neurons and small ventral lateral neurons, via expression of thermosensitive cation channel dtrpa1, also increased the male courtship index. this enhancement was abolished by the addition of the cry-gal80 transgene. our results highlight the phenomenon of increased male courtship activity caused by a magnetic field through cry-dependent magnetic sensation in cry expression neurons in drosophila."
        },
        {
            "id": "R171733",
            "label": "Regulatory focus, coping strategies and symptoms of anxiety and depression: A comparison between Syrian refugees in Turkey and Germany",
            "doi": "10.1371/journal.pone.0206522",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "civil war, flight, escape and expulsion are extremely stressful and assert a negative impact on refugees\u2019 mental health. however scientific research about resilience and coping of refugees is scarce. especially in the recent refugee crisis, calls have been made to consider factors contributing to coping and resilience in this vulnerable population. therefore, the current research sought to investigate individual differences that could serve as antecedents of coping and contextual factors that might moderate these effects. specifically, it took into account individual\u2019s self-regulatory differences in terms of regulatory focus (i.e., a promotion focus on nurturance needs, ideals and gains vs. a prevention focus on security needs, oughts and losses). it furthermore explored contextual influences by considering syrian refugees in turkey (sample 1, n = 273) and germany (sample 2, n = 169). compared to syrian refugees in turkey, those in germany had a stronger promotion focus. they also reported more problem-focused and less maladaptive coping, as well as less symptoms. both promotion and prevention focus were positively related to problem-focused coping. problem-focused coping, in turn, predicted more symptoms in turkey but not in germany. furthermore, a stronger promotion focus was associated with less symptoms and maladaptive coping was associated with more symptoms in both samples. these results contribute to the coping literature in demonstrating that under certain conditions problem-focused coping can be maladaptive and extend the scarce previous work on self-regulation and coping. most importantly, they highlight a promotion focus as a clear resilience factor and the role of maladaptive coping in increasing vulnerability. as such, they might inform the design of effective interventions among syrian refugees and beyond."
        },
        {
            "id": "R109313",
            "label": "KGen: a knowledge graph generator from biomedical scientific literature",
            "doi": "10.1186/s12911-020-01341-5",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n background \\n knowledge is often produced from data generated in scientific investigations. an ever-growing number of scientific studies in several domains result into a massive amount of data, from which obtaining new knowledge requires computational help. for example, alzheimer\u2019s disease, a life-threatening degenerative disease that is not yet curable. as the scientific community strives to better understand it and find a cure, great amounts of data have been generated, and new knowledge can be produced. a proper representation of such knowledge brings great benefits to researchers, to the scientific community, and consequently, to society. \\n \\n methods \\n in this article, we study and evaluate a semi-automatic method that generates knowledge graphs (kgs) from biomedical texts in the scientific literature. our solution explores natural language processing techniques with the aim of extracting and representing scientific literature knowledge encoded in kgs. our method links entities and relations represented in kgs to concepts from existing biomedical ontologies available on the web. we demonstrate the effectiveness of our method by generating kgs from unstructured texts obtained from a set of abstracts taken from scientific papers on the alzheimer\u2019s disease. we involve physicians to compare our extracted triples from their manual extraction via their analysis of the abstracts. the evaluation further concerned a qualitative analysis by the physicians of the generated kgs with our software tool. \\n \\n results \\n the experimental results indicate the quality of the generated kgs. the proposed method extracts a great amount of triples, showing the effectiveness of our rule-based method employed in the identification of relations in texts. in addition, ontology links are successfully obtained, which demonstrates the effectiveness of the ontology linking method proposed in this investigation. \\n \\n conclusions \\n we demonstrate that our proposal is effective on building ontology-linked kgs representing the knowledge obtained from biomedical scientific texts. such representation can add value to the research in various domains, enabling researchers to compare the occurrence of concepts from different studies. the kgs generated may pave the way to potential proposal of new theories based on data analysis to advance the state of the art in their research domains. \\n"
        },
        {
            "id": "R171103",
            "label": "Counterfactual Reasoning Deficits in Schizophrenia Patients",
            "doi": "10.1371/journal.pone.0148440",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background counterfactual thinking is a specific type of conditional reasoning that enables the generation of mental simulations of alternatives to past factual events. although it has been broadly studied in the general population, research on schizophrenia is still scarce. the aim of the current study was to further examine counterfactual reasoning in this illness. methods forty schizophrenia patients and 40 controls completed a series of tests that assessed the influence of the \u201ccausal order effect\u201d on counterfactual thinking, and the ability to generate counterfactual thoughts and counterfactually derive inferences from a hypothetical situation. socio-demographic and clinical characteristics, as well as neurocognitive variables, were also examined. results compared to controls, the schizophrenia patients generated fewer counterfactual thoughts when faced with a simulated scenario. the pattern of response when assessing the causality effect of the order was also different between the groups, with the patients being more frequently unable to attribute any ordering of events than the control subjects. additionally, the schizophrenia patients showed more difficulties when deriving normative counterfactual inferences from hypothetical social situations. none of the counterfactual reasoning measures was associated to any of the cognitive functions or clinical and socio-demographic variables assessed. conclusions a global impairment in counterfactual thinking characterizes schizophrenia patients. because of the potential impact of such deficits on psychosocial functioning, targeting counterfactual reasoning for improvement might be considered in future treatment approaches."
        },
        {
            "id": "R211922",
            "label": "Neural Modeling for Named Entities and Morphology (NEMO2)",
            "doi": "10.1162/tacl_a_00404",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "abstract named entity recognition (ner) is a fundamental nlp task, commonly formulated as classification over a sequence of tokens. morphologically rich languages (mrls) pose a challenge to this basic formulation, as the boundaries of named entities do not necessarily coincide with token boundaries, rather, they respect morphological boundaries. to address ner in mrls we then need to answer two fundamental questions, namely, what are the basic units to be labeled, and how can these units be detected and classified in realistic settings (i.e., where no gold morphology is available). we empirically investigate these questions on a novel ner benchmark, with parallel token- level and morpheme-level ner annotations, which we develop for modern hebrew, a morphologically rich-and-ambiguous language. our results show that explicitly modeling morphological boundaries leads to improved ner performance, and that a novel hybrid architecture, in which ner precedes and prunes morphological decomposition, greatly outperforms the standard pipeline, where morphological decomposition strictly precedes ner, setting a new performance bar for both hebrew ner and hebrew morphological decomposition tasks."
        },
        {
            "id": "R201385",
            "label": "2D Human Pose Estimation: New Benchmark and State of the Art Analysis",
            "doi": "10.1109/CVPR.2014.471",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "human pose estimation has made significant progress during the last years. however current datasets are limited in their coverage of the overall pose estimation challenges. still these serve as the common sources to evaluate, train and compare different models on. in this paper we introduce a novel benchmark \"mpii human pose\" that makes a significant advance in terms of diversity and difficulty, a contribution that we feel is required for future developments in human body models. this comprehensive dataset was collected using an established taxonomy of over 800 human activities [1]. the collected images cover a wider variety of human activities than previous datasets including various recreational, occupational and householding activities, and capture people from a wider range of viewpoints. we provide a rich set of labels including positions of body joints, full 3d torso and head orientation, occlusion labels for joints and body parts, and activity labels. for each image we provide adjacent video frames to facilitate the use of motion information. given these rich annotations we perform a detailed analysis of leading human pose estimation approaches and gaining insights for the success and failures of these methods."
        },
        {
            "id": "R211380",
            "label": "Hidden in plain sight: Automatically identifying security requirements from natural language artifacts",
            "doi": "10.1109/re.2014.6912260",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "natural language artifacts, such as requirements specifications, often explicitly state the security requirements for software systems. however, these artifacts may also imply additional security requirements that developers may overlook but should consider to strengthen the overall security of the system. the goal of this research is to aid requirements engineers in producing a more comprehensive and classified set of security requirements by (1) automatically identifying security-relevant sentences in natural language requirements artifacts, and (2) providing context-specific security requirements templates to help translate the security-relevant sentences into functional security requirements. using machine learning techniques, we have developed a tool-assisted process that takes as input a set of natural language artifacts. our process automatically identifies security-relevant sentences in the artifacts and classifies them according to the security objectives, either explicitly stated or implied by the sentences. we classified 10,963 sentences in six different documents from healthcare domain and extracted corresponding security objectives. our manual analysis showed that 46% of the sentences were security-relevant. of these, 28% explicitly mention security while 72% of the sentences are functional requirements with security implications. using our tool, we correctly predict and classify 82% of the security objectives for all the sentences (precision). we identify 79% of all security objectives implied by the sentences within the documents (recall). based on our analysis, we develop context-specific templates that can be instantiated into a set of functional security requirements by filling in key information from security-relevant sentences."
        },
        {
            "id": "R170784",
            "label": "Screening Primary-Care Patients Forgoing Health Care for Economic Reasons",
            "doi": "10.1371/journal.pone.0094006",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"background growing social inequities have made it important for general practitioners to verify if patients can afford treatment and procedures. incorporating social conditions into clinical decision-making allows general practitioners to address mismatches between patients' health-care needs and financial resources. objectives identify a screening question to, indirectly, rule out patients' social risk of forgoing health care for economic reasons, and estimate prevalence of forgoing health care and the influence of physicians' attitudes toward deprivation. design multicenter cross-sectional survey. participants forty-seven general practitioners working in the french\u2013speaking part of switzerland enrolled a random sample of patients attending their private practices. main measures patients who had forgone health care were defined as those reporting a household member (including themselves) having forgone treatment for economic reasons during the previous 12 months, through a self-administered questionnaire. patients were also asked about education and income levels, self-perceived social position, and deprivation levels. key results overall, 2,026 patients were included in the analysis; 10.7% (ci95% 9.4\u201312.1) reported a member of their household to have forgone health care during the 12 previous months. the question \u201cdid you have difficulties paying your household bills during the last 12 months\u201d performed better in identifying patients at risk of forgoing health care than a combination of four objective measures of socio-economic status (gender, age, education level, and income) (r2\\u200a=\\u200a0.184 vs. 0.083). this question effectively ruled out that patients had forgone health care, with a negative predictive value of 96%. furthermore, for physicians who felt powerless in the face of deprivation, we observed an increase in the odds of patients forgoing health care of 1.5 times. conclusion general practitioners should systematically evaluate the socio-economic status of their patients. asking patients whether they experience any difficulties in paying their bills is an effective means of identifying patients who might forgo health care.\""
        },
        {
            "id": "R74398",
            "label": "Guidelines to producing structured interoperable data from Open Access Repositories",
            "doi": "10.1109/FIE.2016.7757660",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74397",
                    "label": "Linked Data Interoperability"
                },
                {
                    "id": "R109063",
                    "label": "Linked Data Interoperability"
                }
            ],
            "abstract": "one of the fundamental concepts of open educational resources (oer) is \u201cthe ability to freely adapt and reuse existing pieces of knowledge.\u201d the application of semantic web approach and linked data technologies to open education seeks to turn data and metadata from open educational repositories into actionable interoperability for the improvement of discovering, using and reusing of oer. interoperability is not an end in itself. instead, optimizing the level of interoperability has societal and educational value as a means to others purposes. interoperability can have a positive impact on open innovation, user choice, ease to reuse and adapt educational materials, global discovery of open and diverse content, among other things. this paper reports on the implementation of linked open data for open access repositories in a new interoperable and global open educational ecosystem. the goal is to improve the metadata interoperability between various collections of open material, so as to facilitate the discoverability and subsequent combining, remixing, or adapting oer; that is, oer data should be easily accessible to any user: human being or a machine agent. this work addressed two challenges in the oer ecosystem: providing evidence of globally discoverability and reusability academic resources. although there is much further potential for teaching and learning to realize, linked open data is a critical enabler of global and interoperable oer ecosystem."
        },
        {
            "id": "R137466",
            "label": "Comparison of heterojunction device parameters for pure and doped ZnO thin films with IIIA (Al or In) elements grown on silicon at room ambient",
            "doi": "10.1117/12.2239341",
            "research_field": {
                "id": "R259",
                "label": "Semiconductor and Optical Materials"
            },
            "research_problems": [
                {
                    "id": "R137358",
                    "label": "Effect of dopant type on the characteristics of ZnO-based heterojunction diodes"
                }
            ],
            "abstract": "in this work, pure and iiia element doped zno thin films were grown on p type silicon (si) with (100) orientated surface by sol-gel method, and were characterized for comparing their electrical characteristics. the heterojunction parameters were obtained from the current-voltage (i-v) and capacitance-voltage (c-v) characteristics at room temperature. the ideality factor (n), saturation current (io) and junction resistance of zno/p-si heterojunction for both pure and doped (with al or in) cases were determined by using different methods at room ambient. other electrical parameters such as fermi energy level (ef), barrier height (\u03c6b), acceptor concentration (na), built-in potential (\u03c6i) and voltage dependence of surface states (nss) profile were obtained from the c-v measurements. the results reveal that doping zno with iiia (al or in) elements to fabricate n-zno/p-si heterojunction can result in high performance diode characteristics."
        },
        {
            "id": "R138430",
            "label": "Selective photocatalytic C\u00e2\u0080\u0093C bond cleavage under ambient conditions with earth abundant vanadium complexes",
            "doi": "10.1039/c5sc02923f",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R138426",
                    "label": "Lignin decomposition"
                }
            ],
            "abstract": "chemoselective aliphatic carbon\u2013carbon bond activation photocatalyzed by vanadium oxo complexes under ambient conditions and visible light."
        },
        {
            "id": "R171475",
            "label": "Health assessment of French university students and risk factors associated with mental health disorders",
            "doi": "10.1371/journal.pone.0188187",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective the first year of university is a particularly stressful period and can impact academic performance and students\u2019 health. the aim of this study was to evaluate the health and lifestyle of undergraduates and assess risk factors associated with psychiatric symptoms. materials and methods between september 2012 and june 2013, we included all undergraduate students who underwent compulsory a medical visit at the university medical service in nice (france) during which they were screened for potential diseases during a diagnostic interview. data were collected prospectively in the calcium database (consultations assist\u00e9s par logiciel pour les centres inter-universitaire de m\u00e9decine) and included information about the students\u2019 lifestyle (living conditions, dietary behavior, physical activity, use of recreational drugs). the prevalence of psychiatric symptoms related to depression, anxiety and panic attacks was assessed and risk factors for these symptoms were analyzed using logistic regression. results a total of 4,184 undergraduates were included. prevalence for depression, anxiety and panic attacks were 12.6%, 7.6% and 1.0%, respectively. during the 30 days preceding the evaluation, 0.6% of the students regularly drank alcohol, 6.3% were frequent-to-heavy tobacco smokers, and 10.0% smoked marijuana. dealing with financial difficulties and having learning disabilities were associated with psychiatric symptoms. students who were dissatisfied with their living conditions and those with poor dietary behavior were at risk of depression. being a woman and living alone were associated with anxiety. students who screened positively for any psychiatric disorder assessed were at a higher risk of having another psychiatric disorder concomitantly. conclusion the prevalence of psychiatric disorders in undergraduate students is low but the rate of students at risk of developing chronic disease is far from being negligible. understanding predictors for these symptoms may improve students\u2019 health by implementing targeted prevention campaigns. further research in other french universities is necessary to confirm our results."
        },
        {
            "id": "R169651",
            "label": "Transient Cerebral Ischemia Promotes Brain Mitochondrial Dysfunction and Exacerbates Cognitive Impairments in Young 5xFAD Mice",
            "doi": "10.1371/journal.pone.0144068",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"alzheimer's disease (ad) is heterogeneous and multifactorial neurological disorder; and the risk factors of ad still remain elusive. recent studies have highlighted the role of vascular factors in promoting the progression of ad and have suggested that ischemic events increase the incidence of ad. however, the detailed mechanisms linking ischemic insult to the progression of ad is still largely undetermined. in this study, we have established a transient cerebral ischemia model on young 5xfad mice and their non-transgenic (nontg) littermates by the transient occlusion of bilateral common carotid arteries. we have found that transient cerebral ischemia significantly exacerbates brain mitochondrial dysfunction including mitochondrial respiration deficits, oxidative stress as well as suppressed levels of mitochondrial fusion proteins including optic atrophy 1 (opa1) and mitofusin 2 (mfn2) in young 5xfad mice resulting in aggravated spatial learning and memory. intriguingly, transient cerebral ischemia did not induce elevation in the levels of cortical or mitochondrial amyloid beta (a\u03b2)1-40 or 1\u201342 levels in 5xfad mice. in addition, the glucose- and oxygen-deprivation-induced apoptotic neuronal death in a\u03b2-treated neurons was significantly mitigated by mitochondria-targeted antioxidant mitotempo which suppresses mitochondrial superoxide levels. therefore, the simplest interpretation of our results is that young 5xfad mice with pre-existing ad-like mitochondrial dysfunction are more susceptible to the effects of transient cerebral ischemia; and ischemic events may exacerbate dementia and worsen the outcome of ad patients by exacerbating mitochondrial dysfunction.\""
        },
        {
            "id": "R146591",
            "label": "Quality assurance applied to animal disease surveillance systems: -EN- -FR- -ES-",
            "doi": "10.20506/rst.22.2.1431",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "monitoring and surveillance systems (moss) are essential activities for official veterinary services. in addition, the increased trade in animals and animal products over recent years has increased the importance of international disease reporting. a reliable surveillance system is the key to early warning of a change in the health status of any animal population. such a system is also essential for providing evidence about the absence of diseases or in determining the extent of a disease which is known to be present. the authors discuss a set of methods and approaches for evaluating the quality of surveillance and survey systems. certain steps are required when assessing the quality of a service or product. various approaches for quality assessment are available and the suitability of each method depends on the objective of the evaluation. an essential basic requirement is, however, to use an objective, transparent and systematic approach. the evidence collected and the analyses used to reach conclusions must be of such high quality that the results are acceptable to both the management of the moss and the assessor. repeated discussions and negotiations may be necessary to reach consensus, particularly if the judgement affects activities between trading partners. well-documented moss with specified objectives and integrated quality assurance mechanisms are likely to be easier to evaluate."
        },
        {
            "id": "R170834",
            "label": "Cortical Thinning in Temporo-Parietal Junction (TPJ) in Non-Affective First-Episode of Psychosis Patients with Persistent Negative Symptoms",
            "doi": "10.1371/journal.pone.0101372",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background negative symptoms represent an unmet therapeutic need in many patients with schizophrenia. in an extension to our previous voxel-based morphometry findings, we employed a more specific, vertex-based approach to explore cortical thinning in relation to persistent negative symptoms (pns) in non-affective first-episode of psychosis (fep) patients to advance our understanding of the pathophysiology of primary negative symptoms. methods this study included 62 non-affective fep patients and 60 non-clinical controls; 16 patients were identified with pns (i.e., at least 1 primary negative symptom at moderate or greater severity sustained for at least 6 consecutive months). using cortical thickness analyses, we explored for differences between pns and non-pns patients as well as between each patient group and healthy controls; cut-off threshold was set at p<0.01, corrected for multiple comparisons. results a thinner cortex prominently in the right superior temporal gyrus extending into the temporo-parietal junction (tpj), right parahippocampal gyrus, and left orbital frontal gyrus was identified in pns patients vs. non-pns patients. compared with healthy controls, pns patients showed a thinner cortex prominently in the right superior temporal gyrus, right parahippocampal gyrus, and right cingulate; non-pns patients showed a thinner cortex prominently in the parahippocampal gyrus bi-laterally. conclusion cortical thinning in the early stages of non-affective psychosis is present in the frontal and temporo-parietal regions in patients with pns. with these brain regions strongly related to social cognitive functioning, our finding suggests a potential link between primary negative symptoms and social cognitive deficits through common brain etiologies."
        },
        {
            "id": "R147188",
            "label": "Phytoplankton Growth and Productivity in the Western North Atlantic: Observations of Regional Variability From the NAAMES Field Campaigns",
            "doi": "10.3389/fmars.2020.00024",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R147184",
                    "label": "Primary production estimation in the Atlantic Ocean"
                }
            ],
            "abstract": "the ability to quantify spatio-temporal variability in phytoplankton growth and productivity is essential to improving our understanding of global carbon dynamics and trophic energy flow. satellite-based observations offered the first opportunity to estimate depth-integrated net primary production (npp) at a global scale, but early modeling approaches could not effectively address variability in algal physiology, particularly the effects of photoacclimation on changes in cellular chlorophyll. here, a previously developed photoacclimation model was used to derive depth-resolved estimates of phytoplankton division rate (\u03bc) and npp. the new approach predicts npp values that closely match discrete measurements of 14 c-based npp and effectively captured both spatial and temporal variability observed during the four field campaigns of the north atlantic aerosols and marine ecosystems study (naames). we observed favorable growth conditions for phytoplankton throughout the annual cycle in the subtropical western north atlantic. as a result, high rates of \u03bc are sustained year-round resulting in a strong coupling between growth and loss processes and a more moderate spring bloom compared to the high-latitude subarctic region. considerable light limitation was observed in the subarctic province during the winter, which resulted in divergent growth dynamics, stronger decoupling from grazing pressure and a taxonomically distinct phytoplankton community. this study demonstrates how detailed knowledge of phytoplankton division rate furthers our understanding of global carbon cycling by providing insight into the resulting influence on phytoplankton taxonomy and the loss processes that dictate the fate of fixed carbon."
        },
        {
            "id": "R131833",
            "label": "Concept Pointer Network for Abstractive Summarization",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124682",
                    "label": "Text Summarization"
                }
            ],
            "abstract": "a quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. inspired by the popular pointer generator sequence-to-sequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. the network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. the model then points to the most appropriate choice using both the concept set and original source text. this joint approach generates abstractive summaries with higher-level semantic concepts. the training model is also optimized in a way that adapts to different data, which is based on a novel method of distant-supervised learning guided by reference summaries and testing set. overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the duc-2004 and gigaword datasets. a human evaluation of the model\u2019s abstractive abilities also supports the quality of the summaries produced within this framework."
        },
        {
            "id": "R131085",
            "label": "Discrete Flows: Invertible Generative Models of Discrete Data",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "while normalizing flows have led to significant advances in modeling high-dimensional continuous distributions, their applicability to discrete distributions remains unknown. in this paper, we show that flows can in fact be extended to discrete events---and under a simple change-of-variables formula not requiring log-determinant-jacobian computations. discrete flows have numerous applications. we consider two flow architectures: discrete autoregressive flows that enable bidirectionality, allowing, for example, tokens in text to depend on both left-to-right and right-to-left contexts in an exact language model; and discrete bipartite flows that enable efficient non-autoregressive generation as in realnvp. empirically, we find that discrete autoregressive flows outperform autoregressive baselines on synthetic discrete distributions, an addition task, and potts models; and bipartite flows can obtain competitive performance with autoregressive baselines on character-level language modeling for penn tree bank and text8."
        },
        {
            "id": "R170822",
            "label": "When Does Hardship Matter for Health? Neighborhood and Individual Disadvantages and Functional Somatic Symptoms from Adolescence to Mid-Life in the Northern Swedish Cohort",
            "doi": "10.1371/journal.pone.0099558",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a large body of research has shown that health is influenced by disadvantaged living conditions, including both personal and neighborhood conditions. little is however known to what degree the health impact of different forms of disadvantage differ along the life course. the present study aims to examine when, during the life course, neighborhood and individual disadvantages relate to functional somatic symptoms. participants (n\\u200a=\\u200a992) came from the northern swedish cohort and followed from age 16, 21, 30 until 42 years. functional somatic symptoms, socioeconomic disadvantage, and social and material adversity were measured through questionnaires and linked to register data on neighborhood disadvantage. data was analyzed with longitudinal and cross-sectional multilevel models. results showed that neighborhood disadvantage, social and material adversity and gender all contributed independently to overall levels of symptoms across the life course. cross-sectional analyses also suggested that the impact of disadvantage differed between life course periods; neighborhood disadvantage was most important in young adulthood, and the relative importance of material versus social adversity increased as participants grew older. in summary, the study suggests that disadvantages from different contextual sources may affect functional somatic health across the life course, but also through life course specific patterns."
        },
        {
            "id": "R171005",
            "label": "Coping with Self-Threat and the Evaluation of Self-Related Traits: An fMRI Study",
            "doi": "10.1371/journal.pone.0136027",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a positive view of oneself is important for a healthy lifestyle. self-protection mechanisms such as suppressing negative self-related information help us to maintain a positive view of ourselves. this is of special relevance when, for instance, a negative test result threatens our positive self-view. to date, it is not clear which brain areas support self-protective mechanisms under self-threat. in the present functional magnetic resonance imaging (fmri) study the participants (n = 46) received a (negative vs. positive) performance test feedback before entering the scanner. in the scanner, the participants were instructed to ascribe personality traits either to themselves or to a famous other. our results showed that participants responded slower to negative self-related traits compared to positive self-related traits. high self-esteem individuals responded slower to negative traits compared to low self-esteem individuals following a self-threat. this indicates that high self-esteem individuals engage more in self-enhancing strategies after a threat by inhibiting negative self-related information more successfully than low self-esteem individuals. this behavioral pattern was mirrored in the fmri data as dacc correlated positively with trait self-esteem. generally, acc activation was attenuated under threat when participants evaluated self-relevant traits and even more for negative self-related traits. we also found that activation in the acc was negatively correlated with response times, indicating that greater activation of the acc is linked to better access (faster response) to positive self-related traits and to impaired access (slower response) to negative self-related traits. these results confirm the acc function as important in managing threatened self-worth but indicate differences in trait self-esteem levels. the fmri analyses also revealed a decrease in activation within the left hippocampus and the right thalamus under threat. this indicates that a down-regulation of activation in these regions might also serve as coping mechanism in dealing with self-threat."
        },
        {
            "id": "R170847",
            "label": "Resilience amongst Australian Aboriginal Youth: An Ecological Analysis of Factors Associated with Psychosocial Functioning in High and Low Family Risk Contexts",
            "doi": "10.1371/journal.pone.0102820",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we investigate whether the profile of factors protecting psychosocial functioning of high risk exposed australian aboriginal youth are the same as those promoting psychosocial functioning in low risk exposed youth. data on 1,021 youth aged 12\u201317 years were drawn from the western australian aboriginal child health survey (waachs 2000\u20132002), a population representative survey of the health and well-being of aboriginal children, their families and community contexts. a person-centered approach was used to define four groups of youth cross-classified according to level of risk exposure (high/low) and psychosocial functioning (good/poor). multivariate logistic regression was used to model the influence of individual, family, cultural and community factors on psychosocial outcomes separately for youth in high and low family-risk contexts. results showed that in high family risk contexts, prosocial friendship and low area-level socioeconomic status uniquely protected psychosocial functioning. however, in low family risk contexts the perception of racism increased the likelihood of poor psychosocial functioning. for youth in both high and low risk contexts, higher self-esteem and self-regulation were associated with good psychosocial functioning although the relationship was non-linear. these findings demonstrate that an empirical resilience framework of analysis can identify potent protective processes operating uniquely in contexts of high risk and is the first to describe distinct profiles of risk, protective and promotive factors within high and low risk exposed australian aboriginal youth."
        },
        {
            "id": "R147944",
            "label": "A near-infrared non-fullerene electron acceptor for high performance polymer solar cells",
            "doi": "10.1039/c7ee00844a",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "low-bandgap polymers/molecules are an interesting family of semiconductor materials, and have enabled many recent exciting breakthroughs in the field of organic electronics, especially for organic photovoltaics (opvs)."
        },
        {
            "id": "R109037",
            "label": "Drug\u00e2\u0080\u0093drug interaction prediction with Wasserstein Adversarial Autoencoder-based knowledge graph embeddings",
            "doi": "10.1093/bib/bbaa256",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R108870",
                    "label": "Comparison of drug-drug interaction prediction"
                },
                {
                    "id": "R109036",
                    "label": "DDI prediction"
                }
            ],
            "abstract": "abstract \\n an interaction between pharmacological agents can trigger unexpected adverse events. capturing richer and more comprehensive information about drug\u2013drug interactions (ddis) is one of the key tasks in public health and drug development. recently, several knowledge graph (kg) embedding approaches have received increasing attention in the ddi domain due to their capability of projecting drugs and interactions into a low-dimensional feature space for predicting links and classifying triplets. however, existing methods only apply a uniformly random mode to construct negative samples. as a consequence, these samples are often too simplistic to train an effective model. in this paper, we propose a new kg embedding framework by introducing adversarial autoencoders (aaes) based on wasserstein distances and gumbel-softmax relaxation for ddi tasks. in our framework, the autoencoder is employed to generate high-quality negative samples and the hidden vector of the autoencoder is regarded as a plausible drug candidate. afterwards, the discriminator learns the embeddings of drugs and interactions based on both positive and negative triplets. meanwhile, in order to solve vanishing gradient problems on the discrete representation\u2014an inherent flaw in traditional generative models\u2014we utilize the gumbel-softmax relaxation and the wasserstein distance to train the embedding model steadily. we empirically evaluate our method on two tasks: link prediction and ddi classification. the experimental results show that our framework can attain significant improvements and noticeably outperform competitive baselines. supplementary information: supplementary data and code are available at https://github.com/dyf0631/aae_for_kg."
        },
        {
            "id": "R129585",
            "label": "Entity, Relation, and Event Extraction with Contextualized Span Representations",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R116569",
                    "label": "Relation Extraction"
                },
                {
                    "id": "R116714",
                    "label": "Joint Entity and Relation Extraction"
                }
            ],
            "abstract": "we examine the capabilities of a unified, multi-task framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction. our framework (called dygie++) accomplishes all tasks by enumerating, refining, and scoring text spans designed to capture local (within-sentence) and global (cross-sentence) context. our framework achieves state-of-the-art results across all tasks, on four datasets from a variety of domains. we perform experiments comparing different techniques to construct span representations. contextualized embeddings like bert perform well at capturing relationships among entities in the same or adjacent sentences, while dynamic span graph updates model long-range cross-sentence relationships. for instance, propagating span representations via predicted coreference links can enable the model to disambiguate challenging entity mentions. our code is publicly available at https://github.com/dwadden/dygiepp and can be easily adapted for new tasks or datasets."
        },
        {
            "id": "R170959",
            "label": "Disruption of Parenting Behaviors in California Mice, a Monogamous Rodent Species, by Endocrine Disrupting Chemicals",
            "doi": "10.1371/journal.pone.0126284",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the nature and extent of care received by an infant can affect social, emotional and cognitive development, features that endure into adulthood. here we employed the monogamous, california mouse (peromyscus californicus), a species, like the human, where both parents invest in offspring care, to determine whether early exposure to endocrine disrupting chemicals (edc: bisphenol a, bpa; ethinyl estradiol, ee) of one or both parents altered their behaviors towards their pups. females exposed to either compound spent less time nursing, grooming and being associated with their pups than controls, although there was little consequence on their weight gain. care of pups by males was less affected by exposure to bpa and ee, but control, non-exposed females appeared able to \u201csense\u201d a male partner previously exposed to either compound and, as a consequence, reduced their own parental investment in offspring from such pairings. the data emphasize the potential vulnerability of pups born to parents that had been exposed during their own early development to edc, and that effects on the male, although subtle, also have consequences on overall parental care due to lack of full acceptance of the male by the female partner."
        },
        {
            "id": "R171559",
            "label": "Docosahexaenoic acid for reading, working memory and behavior in UK children aged 7-9: A randomized controlled trial for replication (the DOLAB II study)",
            "doi": "10.1371/journal.pone.0192909",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background omega-3 fatty acids are central to brain-development of children. evidence from clinical trials and systematic reviews demonstrates the potential of long-chain omega-3 supplementation for learning and behavior. however, findings are inconclusive and in need of robust replication studies since such work is lacking. objectives replication of the 2012 dolab 1 study findings that a dietary supplementation with the long-chain omega-3 docosahexaenoic acid (dha) had beneficial effects on the reading, working memory, and behavior of healthy schoolchildren. design parallel group, fixed-dose, randomized (minimization, 30% random element), double-blind, placebo-controlled trial (rct). setting mainstream primary schools (n = 84) from five counties in the uk in 2012\u20132015. participants healthy children aged 7\u20139 underperforming in reading (<20th centile). 1230 invited, 376 met study criteria. intervention 600 mg/day dha (from algal oil), placebo: taste/color matched corn/soybean oil; for 16 weeks. main outcome measures age-standardized measures of reading, working memory, and behavior, parent-rated and as secondary outcome teacher-rated. results 376 children were randomized. reading, working memory, and behavior change scores showed no consistent differences between intervention and placebo group. some behavioral subscales showed minor group differences. conclusions this rct did not replicate results of the earlier dolab 1 study on the effectiveness of nutritional supplementation with dha for learning and behavior. possible reasons are discussed, particularly regarding the replication of complex interventions. trial registration and protocol www.controlled-trials.com (isrctn48803273) and protocols.io (https://dx.doi.org/10.17504/protocols.io.k8kczuw)"
        },
        {
            "id": "R197609",
            "label": "Requirements Engineering Challenges in Large-Scale Agile System Development",
            "doi": "10.1109/re.2017.60",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "motivated by their success in software development, companies implement agile methods and their practices increasingly for software-intense, large products, such as cars, telecommunication infrastructure, and embedded systems. such systems are usually subject to safety and regulative concerns as well as different development cycles of hardware and software. consequently, requirements engineering involves upfront and detailed analysis, which can be at odds with agile (software) development. in this paper, we present results from a multiple case study with two car manufacturers, a telecommunications company, and a technology company that are on the journey to introduce organization wide continuous integration and continuous delivery to customers. based on 20 qualitative interviews, 5 focus groups, and 2 cross-company workshops, we discuss possible scopes of agile methods within system development, the consequences this has on the role of requirements, and the challenges that arise from the interplay of requirements engineering and agile methods in large-scale system development. these relate in particular to communicating and managing knowledge about a) customer value and b) the system under development. we conclude that better alignment of a holistic requirements model with agile development practices promises rich gains in development speed, flexibility, and overall quality of software and systems."
        },
        {
            "id": "R169723",
            "label": "Short-Term Effects of Traditional and Alternative Community Interventions to Address Food Insecurity",
            "doi": "10.1371/journal.pone.0150250",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background despite the effects of food insecurity on health are well documented, clear governmental policies to face food insecurity do not exist in western countries. in canada, interventions to face food insecurity are developed at the community level and can be categorized into two basic strategies: those providing an immediate response to the need for food, defined \u201ctraditional\u201d and those targeting the improvement of participants\u2019 social cohesion, capabilities and management of their own nutrition, defined \u201calternative\u201d. objective the objective of this study was to evaluate the effects of food insecurity interventions on food security status and perceived health of participants. design this was a longitudinal multilevel study implemented in montreal, quebec, canada. participants were recruited in a two-stage cluster sampling frame. clustering units were community organizations working on food insecurity; units of analysis were participants in community food security interventions. a total of 450 participants were interviewed at the beginning and after 9 months of participation in traditional or alternative food security interventions. food security and perceived health were investigated as dependent variables. differences overtime were assessed through multilevel regression models. results participants in traditional interventions lowered their food insecurity at follow-up. decreases among participants in alternative interventions were not statistically significant. participants in traditional interventions also improved physical (b coefficient 3.00, ci 95% 0.42\u20135.59) and mental health (b coefficient 6.25, ci 95% 4.15\u20138.35). conclusions our results challenge the widely held view suggesting the ineffectiveness of traditional interventions in the short term. although effects may be intervention-dependent, food banks decreased food insecurity and, in so doing, positively affected perceived health. although study findings demonstrate that food banks offer short term reprise from the effects of food insecurity, the question as to whether food banks are the most appropriate solution to food insecurity still needs to be addressed."
        },
        {
            "id": "R134502",
            "label": "BilBOWA: Fast Bilingual Distributed Representations without Word Alignments",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R125963",
                    "label": "Document Classification"
                }
            ],
            "abstract": "we introduce bilbowa (bilingual bag-of-words without alignments), a simple and computationally-efficient model for learning bilingual distributed representations of words which can scale to large monolingual datasets and does not require word-aligned parallel training data. instead it trains directly on monolingual data and extracts a bilingual signal from a smaller set of raw-text sentence-aligned data. this is achieved using a novel sampled bag-of-words cross-lingual objective, which is used to regularize two noise-contrastive language models for efficient cross-lingual feature learning. we show that bilingual embeddings learned using the proposed model outperform state-of-the-art methods on a cross-lingual document classification task as well as a lexical translation task on wmt11 data."
        },
        {
            "id": "R171614",
            "label": "Memory deficits for facial identity in patients with amnestic mild cognitive impairment (MCI)",
            "doi": "10.1371/journal.pone.0195693",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "faces are among the most relevant social stimuli revealing an encounter\u2019s identity and actual emotional state. deficits in facial recognition may be an early sign of cognitive decline leading to social deficits. the main objective of the present study is to investigate if individuals with amnestic mild cognitive impairment show recognition deficits in facial identity. thirty-seven individuals with amnestic mild cognitive impairment, multiple-domain (15 female; age: 75\u00b18 yrs.) and forty-one healthy volunteers (24 female; age 71\u00b16 yrs.) participated. all participants completed a human portrait memory test presenting unfamiliar faces with happy and angry emotional expressions. five and thirty minutes later, old and new neutral faces were presented, and discrimination sensitivity (d\u2019) and response bias (c) were assessed as signal detection parameters of cued facial identity recognition. memory performance was lower in amnestic mild cognitive impairment as compared to control subjects, mainly because of an altered response bias towards an increased false alarm rate (favoring false old ascription of new items). in both groups, memory performance declined between the early and later testing session, and was always better for acquired happy than angry faces. facial identity memory is impaired in patients with amnestic mild cognitive impairment. liberalization of the response bias may reflect a socially motivated compensatory mechanism maintaining an almost identical recognition hit rate of old faces in individuals with amnestic mild cognitive impairment."
        },
        {
            "id": "R170972",
            "label": "The Effect of a Mutation in the Thyroid Stimulating Hormone Receptor (TSHR) on Development, Behaviour and TH Levels in Domesticated Chickens",
            "doi": "10.1371/journal.pone.0129040",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the thyroid stimulating hormone receptor (tshr) has been suggested to be a \u201cdomestication locus\u201d in the chicken, due to a strong selective sweep over the gene found in domesticated chickens, differentiating them from their wild ancestor the red junglefowl (rjf). we investigated the effect of the mutation on development (incubation time), behaviour and thyroid hormone levels in intercross chickens homozygous for the mutation (d/d), wild type homozygotes (w/w) or heterozygotes (d/w). this allowed an assessment of the effect of genotype at this locus against a random mix of rjf and wl genotypes throughout the rest of the genome, controlling for family effects. the d/d genotype showed a longer incubation time, less fearful behaviours, lower number of aggressive behaviours and decreased levels of the thyroid hormone t4, in comparison to the w/w genotype. the difference between tshr genotypes (d/d vs. w/w) in these respects mirrors the differences in development and behaviour between pure domesticated white leghorns and pure rjf chickens. higher individual t3 and t4 levels were associated with more aggression. our study indicates that the tshr mutation affects typical domestication traits, possibly through modifying plasma levels of thyroid hormones, and may therefore have been important during the evolution of the domestic chicken."
        },
        {
            "id": "R74999",
            "label": "The Economic Lives of the Poor",
            "doi": "10.1257/jep.21.1.141",
            "research_field": {
                "id": "R303",
                "label": "Behavioral Economics"
            },
            "research_problems": [
                {
                    "id": "R75002",
                    "label": "poverty computation"
                }
            ],
            "abstract": "\" the 1990 world development report from the world bank defined the \u201cextremely poor\u201d people of the world as those who are currently living on no more than $1 per day per person. but how actually does one live on less than $1 per day? this essay is about the economic lives of the extremely poor: the choices they face, the constraints they grapple with, and the challenges they meet. a number of recent data sets and a body of new research allow us to start building an image of the way the extremely poor live their lives. our discussion builds on household surveys conducted in 13 countries: cote d'ivoire, guatemala, india, indonesia, mexico, nicaragua, pakistan, panama, papua new guinea, peru, south africa, tanzania, and timor leste (east timor). these surveys provide detailed information on extremely poor households around the world, from asia to africa to latin america, including information on what they consume, where they work, and how they save and borrow. we consider the extremely poor\u2014those living in households where the consumption per capita is less than $1.08 per person per day\u2014as well as the merely \u201cpoor\u201d\u2014defined as those who live under $2.16 a day\u2014using 1993 purchasing power parity as benchmark. in keeping with convention, we call these the $1 and $2 dollar poverty lines, respectively. \""
        },
        {
            "id": "R196677",
            "label": "Using Sentinel-2 Images for Soil Organic Carbon Content Mapping in Croplands of Southwestern France. The Usefulness of Sentinel-1/2 Derived Moisture Maps and Mismatches between Sentinel Images and Sampling Dates",
            "doi": "10.3390/rs13245115",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R196702",
                    "label": "Monitoring of soil organic carbon (SOC)"
                }
            ],
            "abstract": "in agronomy, soil organic carbon (soc) content is important for the development and growth of crops. from an environmental monitoring viewpoint, soc sequestration is essential for mitigating the emission of greenhouse gases into the atmosphere. soc dynamics in cropland soils should be further studied through various approaches including remote sensing. in order to predict soc content over croplands in southwestern france (area of 22,177 km\u00b2), this study addresses (i) the influence of the dates on which sentinel-2 (s2) images were acquired in the springs of 2017\u20132018 as well as the influence of the soil sampling period of a set of samples collected between 2005 and 2018, (ii) the use of soil moisture products (smps) derived from sentinel-1/2 satellites to analyze the influence of surface soil moisture on model performance when included as a covariate, and (iii) whether the spatial distribution of soc as mapped using s2 is related to terrain-derived attributes. the influences of s2 image dates and soil sampling periods were analyzed for bare topsoil. the dates of the s2 images with the best performance (rpd \u2265 1.7) were 6 april and 26 may 2017, using soil samples collected between 2016 and 2018. the soil sampling dates were also analyzed using smp values. soil moisture values were extracted for each sample and integrated into partial least squares regression (plsr) models. the use of soil moisture as a covariate had no effect on the prediction performance of the models; however, smp values were used to select the driest dates, effectively mapping topsoil organic carbon. s2 was able to predict high soc contents in the specific soil types located on the old terraces (mesas) shaped by rivers flowing from the southwestern pyr\u00e9n\u00e9es."
        },
        {
            "id": "R35080",
            "label": "On Research Challenges in Hybrid Medium-Access Control Protocols for IEEE 802.15.6 WBANs",
            "doi": "10.1109/jsen.2018.2883786",
            "research_field": {
                "id": "R241",
                "label": "Electrical and Electronics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "ieee 802.15.6 is a wireless body area network (wban) standard proposed to facilitate the exponentially growing interest in the field of health monitoring. this standard is flexible and outlines multiple basic medium-access control (mac) protocols that are contention based and collision free to meet the wban quality-of-service (qos) challenges. typically, current research trends in wban mac focus on designing a hybrid mac that is a combination of basic mac protocols. in this paper, we provide a first detailed survey of existing hybrid mac protocols based on the ieee 802.15.6, which would be useful for the related research community. first, this paper lists the design challenges of a wban mac. second, it highlights the significance of hybrid mac protocols in meeting the design challenges while comparing them to standard mac protocols. third, a critical and thorough comparison of existing hybrid mac protocols is presented in terms of network qos and wban specific parameters. finally, we identify key open research areas that are often neglected in hybrid mac design and further propose some possible directions for future research."
        },
        {
            "id": "R198979",
            "label": "What is the Impact of Bad Layout in the Understandability of Social Goal Models?",
            "doi": "10.1109/re.2016.51",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the i* community has published guidelines, including model layout guidelines, for the construction of models. our goal is to evaluate the effect of the layout guidelines on the i* novice stakeholders' ability to understand and review i* models. we performed a quasi-experiment where participants were given two understanding and two reviewing tasks. both tasks involved a model with a bad layout and another model following the i* layout guidelines. we evaluated the impact of layouts by combining the success level in those tasks and the required effort to accomplish them. effort was assessed using time, perceived complexity (with nasa tlx), and eye-tracking data. participants were more successful in understanding than in reviewing tasks. however, we found no statistically significant difference in the success, time taken, or perceived complexity, between tasks conducted with models with a bad layout and models with a good layout. most participants had little to no prior knowledge in i*, making them more representative of stakeholders with no requirements engineering expertise. they were able to understand the models fairly well after a short tutorial, but struggled when reviewing models. in the end, adherence to the existing i* layout guidelines did not significantly impact i* model understanding and reviewing performance.\""
        },
        {
            "id": "R12016",
            "label": "Solving Mixed Model Workplace Time-dependent Assembly Line Balancing Problem with FSS Algorithm",
            "doi": "",
            "research_field": {
                "id": "R112",
                "label": "Numerical Analysis and Computation"
            },
            "research_problems": [
                {
                    "id": "R12023",
                    "label": "Assembly line balancing problem (ALBP)"
                },
                {
                    "id": "R12024",
                    "label": "Optimisation problem"
                },
                {
                    "id": "R12026",
                    "label": "Mixed model workplace assembly line balancing problem (MMWALBP)"
                },
                {
                    "id": "R12066",
                    "label": "Optimization problem"
                }
            ],
            "abstract": "balancing assembly lines, a family of optimization problems commonly known as assembly line balancing problem, is notoriously np-hard. they comprise a set of problems of enormous practical interest to manufacturing industry due to the relevant frequency of this type of production paradigm. for this reason, many researchers on computational intelligence and industrial engineering have been conceiving algorithms for tackling different versions of assembly line balancing problems utilizing different methodologies. in this article, it was proposed a problem version referred as mixed model workplace time-dependent assembly line balancing problem with the intention of including pressing issues of real assembly lines in the optimization problem, to which four versions were conceived. heuristic search procedures were used, namely two swarm intelligence algorithms from the fish school search family: the original version, named \"vanilla\", and a special variation including a stagnation avoidance routine. either approaches solved the newly posed problem achieving good results when compared to particle swarm optimization algorithm."
        },
        {
            "id": "R199162",
            "label": "Handling knowledge uncertainty in risk-based requirements engineering",
            "doi": "10.1109/re.2015.7320413",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"requirements engineers are faced with multiple sources of uncertainty. in particular, the extent to which the identified software requirements and environment assumptions are adequate and sufficiently complete is uncertain; the extent to which they will be satisfied in the system-to-be is uncertain; and the extent to which obstacles to their satisfaction will occur is uncertain. the resolution of such domain-level uncertainty requires estimations of the likelihood that those different types of situations may or may not occur. however, the extent to which the resulting estimates are accurate is uncertain as well. this meta-level uncertainty limits current risk-based methods for requirements engineering. the paper introduces a quantitative approach for managing it. an earlier formal framework for probabilistic goals and obstacles is extended to explicitly cope with uncertainties about estimates of likelihoods of fine-grained obstacles to goal satisfaction. such estimates are elicited from multiple sources and combined in order to reduce their uncertainty margins. the combined estimates and their uncertainties are up-propagated through obstacle refinement trees and then through the system's goal model. two metrics are introduced for measuring problematic uncertainties. when applied to the probability distributions obtained by up-propagation to the top-level goals, the metrics allow critical leaf obstacles with most problematic uncertainty margins to be highlighted. the proposed approach is evaluated on excerpts from a real ambulance dispatching system.\""
        },
        {
            "id": "R170215",
            "label": "Risk of adverse treatment outcomes among new pulmonary TB patients co-infected with diabetes in Pakistan: A prospective cohort study",
            "doi": "10.1371/journal.pone.0207148",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose the escalating burden of diabetes in countries tackling high burden of tuberculosis (tb) has adverse implications for co-infected individuals and national tb control efforts. we aimed to study whether there was a difference in treatment outcome among diabetic and non-diabetic pulmonary tb patients and identify the determinants of treatment outcome among the two groups. materials and methods this prospective cohort study recruited new patients of pulmonary tuberculosis (ptb) aged 15 years and above who were diagnosed at and registered with gulab devi chest hospital, lahore, pakistan for anti-tuberculosis treatment (att). ptb patients were screened for diabetes using random and fasting blood glucose tests. diabetic and non-diabetic ptb patients were followed up at second, fifth and sixth month of att and 6 months after att completion to determine treatment outcome. multivariate logistic regression analysis was conducted to assess association between various factors and treatment outcome. results of 614 ptb patients, (n = 113 [18%]) were diabetic and (n = 501 [82%]) non-diabetic. final model showed that diabetics were more likely to experience an unfavorable outcome as compared to non-diabetics (adjusted odds ratio [aor] = 2.70, 95% confidence interval [ci] = 1.30 to 5.59). other predictors of unfavorable outcome included rural residence (aor = 1.98, 95% ci = 1.14 to 3.47), body mass index less than 18.50 (aor = 1.89, 95% ci = 1.03 to 3.47) and being a smoker (aor = 2.03, 95%ci = 1.04 to 3.94). conclusion our study shows unfavorable treatment outcome among diabetic ptb patients. integrated models of care with screening/testing and management for diabetes and tb could improve tb treatment outcomes."
        },
        {
            "id": "R44487",
            "label": "Hyperactivity and alopecia associated with ingestion of valproic acid in a cat",
            "doi": "10.2460/javma.2001.218.1587",
            "research_field": {
                "id": "R77",
                "label": "Animal Sciences"
            },
            "research_problems": [
                {
                    "id": "R44421",
                    "label": "Antiepileptic drugs' safety and effectiveness"
                }
            ],
            "abstract": "\"a 1-year-old castrated male cat was evaluated because of alopecia of approximately 4 to 5 months' duration as well as hyperactive behavior. it was later determined that the cat was ingesting valproic acid by eating food to which it had been added for daily administration to a child in the household who had cerebral palsy. the clinical signs slowly resolved after the source of valproic acid was removed. this emphasizes the sensitivity of cats to drugs that are commonly used in humans. it was not determined whether the clinical signs that developed in this cat were caused by an adverse reaction or from toxicosis as a result of prolonged hepatic elimination of valproic acid, which requires glucuronide metabolism for disposition. however, the cat recovered completely following removal of the drug and prevention of further exposure. this report emphasizes the importance of obtaining a careful and complete history from the owner regarding an animal and its environment. in the cat of this report, the owner had not considered the impact of the presence of the drug in the child's food.\""
        },
        {
            "id": "R169110",
            "label": "Environmental Enrichment Alters Nicotine-Mediated Locomotor Sensitization and Phosphorylation of DARPP-32 and CREB in Rat Prefrontal Cortex",
            "doi": "10.1371/journal.pone.0044149",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "exposure within an environmental enrichment paradigm results in neurobiological adaptations and decreases the baseline of locomotor activity. the current study determined activation of darpp-32 (dopamine- and camp-regulated phosphoprotein-32) and creb (camp response element binding protein), and locomotor activity in rats raised in enriched (ec), impoverished (ic), and standard (sc) conditions following repeated administration of nicotine or saline. in the saline-control group, the basal phosphorylation state of darpp-32 at threonine-34 site (pdarpp-32 thr34) in the prefrontal cortex (pfc) was lower in ec compared to ic and sc rats, which was positively correlated with their respective baseline activities. while nicotine (0.35 mg/kg, freebase) produced locomotor sensitization across all housing conditions when the nicotine-mediated locomotor activity was expressed as a percent change from their respective saline control, ec rats displayed greater sensitization to nicotine than ic and sc rats. consistent with the behavioral findings, repeated nicotine injection increased pdarpp-32 thr34 in pfc of ec and ic rats and in nucleus accumbens of ec rats; however, the magnitude of change from saline control in nicotine-induced enhancement of pdarpp-32 thr34 in pfc was strikingly increased in ec rats relative to ic rats. moreover, ec rats had lower basal phosphorylation levels of creb at serine 133 in pfc and nucleus accumbens compared to ic and sc rats, whereas the nicotine-induced increase in phosphorylated creb-ser133 was more pronounced in pfc of ec rats relative to ic and sc rats. collectively, these findings suggest innovative insights into advancing our understanding of the molecular mechanisms of enrichment-induced changes in the motivational effects of nicotine, and aiding in the identification of new therapeutic strategies for tobacco smokers."
        },
        {
            "id": "R74395",
            "label": "Framework for the integration of digital resources based-on a Semantic Web approach [Marco de Trabajo para la Integraci\u00c3\u00b3n de Recursos Digitales Basado en un Enfoque de Web Sem\u00c3\u00a1ntica]",
            "doi": "10.17013/risti.e3.55-70",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74394",
                    "label": "Linked Data Integration"
                },
                {
                    "id": "R109061",
                    "label": "Linked Data Integration"
                }
            ],
            "abstract": "espanolen un entorno abierto como la web, no es posible estandarizar los procesos de descripcion y publicacion de metadatos, cada institucion puede manejar diferentes formatos o modelos de datos. para mejorar la interoperabilidad semantica entre repositorios heterogeneos, se estan adoptando enfoques basados en tecnologias de la web semantica; de esta manera, cada libreria digital puede conservar sus cualidades locales especificas y no requerira resignarlas para poder normalizar el intercambio, reuso o la cosecha de recursos digitales. en este trabajo, se presenta un ciclo que cubre los procesos de: extraccion de metadatos desde repositorios oai-pmh, y la generacion y publicacion de datos enlazados, con el proposito de mejorar la integracion e interoperabilidad de recursos almacenados en librerias digitales. la propuesta descrita facilita la existencia de diversidad de metodos y estandares en los procesos de cada proveedor de recursos digitales. englishfrom the point of view of access to metadata from distributed repositories, the open archives initiative (oai) proposed a protocol for the interchange and harvesting of metadata called oai-pmh. this protocol provide a low degree of interoperability, however, with an approach based on semantic technologies, the interoperability of data can reach a higher level; thus, each digital library can retain their specific local qualities and will not require reassign them in order to standardize the exchange, re-use or harvesting of digital resources. in this paper, the process for the extraction of metadata, generation and publishing linked data in order to improve integration and interoperability between resources stored on digital libraries is presented. the proposal facilitates the existence of diversity of methods and standards in the processes of each supplier of digital resources"
        },
        {
            "id": "R170849",
            "label": "Invasive Cane Toads: Social Facilitation Depends upon an Individual\u00e2\u0080\u0099s Personality",
            "doi": "10.1371/journal.pone.0102880",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "individual variation in behavioural traits (including responses to social cues) may influence the success of invasive populations. we studied the relationship between sociality and personality in invasive cane toads (rhinella marina) from a recently established population in tropical australia. in our field experiments, we manipulated social cues (the presence of a feeding conspecific) near a food source. we captured and compared toads that only approached feeding sites where another toad was already present, with conspecifics that approached unoccupied feeding sites. subsequent laboratory trials showed correlated personality differences (behavioural syndromes) between these two groups of toads. for example, toads that approached already-occupied rather than unoccupied feeding sites in the field, took longer to emerge from a shelter-site in standardized trials, suggesting these individuals are \u2018shy\u2019 (whereas toads that approached unoccupied feeding stations tended to be \u2018bold\u2019). manipulating hunger levels did not abolish this difference. in feeding trials, a bold toad typically outcompeted a shy toad under conditions of low prey availability, but the outcome was reversed when multiple prey items were present. thus, both personality types may be favored under different circumstances. this invasive population of toads contains individuals that exhibit a range of personalities, hinting at the existence of a wide range of social dynamics in taxa traditionally considered to be asocial."
        },
        {
            "id": "R171134",
            "label": "Controversies Regarding the Psychometric Properties of the Brief COPE: The Case of the Brazilian-Portuguese Version \u00e2\u0080\u009cCOPE Breve\u00e2\u0080\u009d",
            "doi": "10.1371/journal.pone.0152233",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the brief coping orientation to problems experienced (cope) inventory investigates the different ways in which people respond to stressful situations. knowledge is lacking regarding the coping strategies and styles of people in developing countries, including brazil. this study aimed to adapt and validate the brief cope to brazilian portuguese (named cope breve) by focusing on dispositional coping. for the cross-cultural adaptation, the original brief cope in english (28 items grouped into 14 subscales) was adapted according to a universalistic approach, following these steps: translation, synthesis, back-translation, analysis by an expert panel, and pretest with 30 participants. then, 237 adults from the community health service responded to the cope breve. psychometric analyses included reliability and exploratory factor analysis. most of the 14 subscales from the original brief cope exhibited problems related to internal consistency. a velicer's minimum average partial test (map) was performed and pointed out 3 factors. exploratory factor analysis produced a revised 20-item version with a 3-factor solution: religion and positive reframing, distraction and external support. the psychometric properties of the cope breve with three factors were appropriate. limitations of this study as well as suggestions for future studies are presented. the cope breve should be used in brazilian clinics and investigations, but divergences in its psychometrics should be further explored in other contexts.\""
        },
        {
            "id": "R169405",
            "label": "Treatment Default amongst Patients with Tuberculosis in Urban Morocco: Predicting and Explaining Default and Post-Default Sputum Smear and Drug Susceptibility Results",
            "doi": "10.1371/journal.pone.0093574",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "setting public tuberculosis (tb) clinics in urban morocco. objective explore risk factors for tb treatment default and develop a prediction tool. assess consequences of default, specifically risk for transmission or development of drug resistance. design case-control study comparing patients who defaulted from tb treatment and patients who completed it using quantitative methods and open-ended questions. results were interpreted in light of health professionals\u2019 perspectives from a parallel study. a predictive model and simple tool to identify patients at high risk of default were developed. sputum from cases with pulmonary tb was collected for smear and drug susceptibility testing. results 91 cases and 186 controls enrolled. independent risk factors for default included current smoking, retreatment, work interference with adherence, daily directly observed therapy, side effects, quick symptom resolution, and not knowing one\u2019s treatment duration. age >50 years, never smoking, and having friends who knew one\u2019s diagnosis were protective. a simple scoring tool incorporating these factors was 82.4% sensitive and 87.6% specific for predicting default in this population. clinicians and patients described additional contributors to default and suggested locally-relevant intervention targets. among 89 cases with pulmonary tb, 71% had sputum that was smear positive for tb. drug resistance was rare. conclusion the causes of default from tb treatment were explored through synthesis of qualitative and quantitative data from patients and health professionals. a scoring tool with high sensitivity and specificity to predict default was developed. prospective evaluation of this tool coupled with targeted interventions based on our findings is warranted. of note, the risk of tb transmission from patients who default treatment to others is likely to be high. the commonly-feared risk of drug resistance, though, may be low; a larger study is required to confirm these findings."
        },
        {
            "id": "R110659",
            "label": "Faster computation of successive bounds on the group betweenness centrality",
            "doi": "10.1002/net.21817",
            "research_field": {
                "id": "R141",
                "label": "Theory/Algorithms"
            },
            "research_problems": [
                {
                    "id": "R110663",
                    "label": "Time complexity of group betweenness centrality (GBC) computations"
                }
            ],
            "abstract": "we propose a method that computes bounds on the group betweenness centrality (gbc) of groups of vertices of a network. once certain quantities related to the network are computed in the preprocessing step that takes o ( n 3 ) time, where n is the number of vertices in the network, our method can compute bounds on the gbc of any number of groups of vertices successively, for each group requiring a running time proportional to the square of its size. our method is an improvement of the method of kolaczyk et al. [social networks, 31, 3 (2009)], which has to be restarted for each group making it less efficient for the successive gbc computations. in addition, the bounds used in our method are stronger and/or faster to compute. our computational experiments show that in the search for a group of a certain size with the highest gbc value, our method reduces the number of candidate groups substantially and in some cases the optimal group can be found without exactly computing the gbc values which is computationally more demanding."
        },
        {
            "id": "R170275",
            "label": "Parental neural responsivity to infants\u00e2\u0080\u0099 visual attention: How mature brains influence immature brains during social interaction",
            "doi": "10.1371/journal.pbio.2006328",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "almost all attention and learning\u2014in particular, most early learning\u2014take place in social settings. but little is known of how our brains support dynamic social interactions. we recorded dual electroencephalography (eeg) from 12-month-old infants and parents during solo play and joint play. during solo play, fluctuations in infants\u2019 theta power significantly forward-predicted their subsequent attentional behaviours. however, this forward-predictiveness was lower during joint play than solo play, suggesting that infants\u2019 endogenous neural control over attention is greater during solo play. overall, however, infants were more attentive to the objects during joint play. to understand why, we examined how adult brain activity related to infant attention. we found that parents\u2019 theta power closely tracked and responded to changes in their infants\u2019 attention. further, instances in which parents showed greater neural responsivity were associated with longer sustained attention by infants. our results offer new insights into how one partner influences another during social interaction."
        },
        {
            "id": "R171776",
            "label": "Association of excessive smartphone use with psychological well-being among university students in Chiang Mai, Thailand",
            "doi": "10.1371/journal.pone.0210294",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background despite the pervasive use of smartphones among university students, there is still a dearth of research examining the association between smartphone use and psychological well-being among this population. the current study addresses this research gap by investigating the relationship between smartphone use and psychological well-being among university students in thailand. methods this cross-sectional study was conducted from january to march 2018 among university students aged 18\u201324 years from the largest university in chiang mai, thailand. the primary outcome was psychological well-being, and was assessed using the flourishing scale. smartphone use, the primary independent variable, was measured by five items which had been adapted from the eight-item young diagnostic questionnaire for internet addiction. all scores above the median value were defined as being indicative of excessive smartphone use. results out of the 800 respondents, 405 (50.6%) were women. in all, 366 (45.8%) students were categorized as being excessive users of smartphones. students with excessive use of smartphones had lower scores the psychological well-being than those who did not use smartphone excessively (b = -1.60; p < 0.001). female students had scores for psychological well-being that were, on average, 1.24 points higher than the scores of male students (p < 0.001). conclusion this study provides some of the first insights into the negative association between excessive smartphone use and the psychological well-being of university students. strategies designed to promote healthy smartphone use could positively impact the psychological well-being of students."
        },
        {
            "id": "R199039",
            "label": "From requirements elicitation to variability analysis using repertory grid: A cognitive approach",
            "doi": "10.1109/re.2015.7320407",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the growing complexity and dynamics of the execution environment have been major motivation for designing self-adaptive systems. although significant work can be found in the field of formalizing or modeling the requirements of adaptive system, not enough attention has been paid towards the requirements elicitation techniques for the same. it is still an open challenge to elicit the users' requirements in the light of various contexts and introduce the required flexibility in the system's behavior at an early phase of requirements engineering. we explore the idea of using a cognitive technique, repertory grid, to acquire the knowledge of various stakeholders along multiple dimensions of problem space and design space. we aim at discovering the scope of variations in the features of the system by capturing the intentional and technical variability in the problem space and design space respectively. a stepwise methodology for finding the right set of features in the changing context has also been provided in this work. we evaluate the proposed idea by a preliminary case study using smart home system domain.\""
        },
        {
            "id": "R195986",
            "label": "Do Words Make a Difference? An Empirical Study on the Impact of Taxonomies on the Classification of Requirements",
            "doi": "10.1109/re.2017.57",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"requirements taxonomies help to classify and channel the requirements in a project. a very simple taxonomy is the distinction between functional and non-functional requirements. furthermore, a taxonomy helps to decide if a statement is a requirement at all or just something else (e.g., 'information'). the quality of a taxonomy is important as we do not want to put a statement in the wrong category.in this paper, we argue that we need to take cognitive psychology into account in this task of requirements classification. cognitive psychology focuses on the abilities and limitations of the human mind. we present a controlled experiment and a replication in which we compare three requirements taxonomies.the participants had to evaluate a set of requirements based on the given taxonomies. the results of these experiments show that there are differences between the taxonomies: interestingly, the question whether a statement is identified as a requirement or not depends on the taxonomy. these experiments present initial results, we assume that these results are related to phenomena of cognitive psychology.we conclude that the wording should be carefully taken into account in the definition of the categories of a high quality requirements taxonomy.\""
        },
        {
            "id": "R168827",
            "label": "Genes regulated by SATB2 during neurodevelopment contribute to schizophrenia and educational attainment",
            "doi": "10.1371/journal.pgen.1007515",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "satb2 is associated with schizophrenia and is an important transcription factor regulating neocortical organization and circuitry. rare mutations in satb2 cause a syndrome that includes developmental delay, and mouse studies identify an important role for satb2 in learning and memory. interacting partners bcl11b and gatad2a are also schizophrenia risk genes indicating that other genes interacting with or are regulated by satb2 are making a contribution to schizophrenia and cognition. we used data from satb2 mouse models to generate three gene-sets that contain genes either functionally related to satb2 or targeted by satb2 at different stages of development. each was tested for enrichment using the largest available genome-wide association studies (gwas) datasets for schizophrenia and educational attainment (ea) and enrichment analysis was also performed for schizophrenia and other neurodevelopmental disorders using data from rare variant sequencing studies. these satb2 gene-sets were enriched for genes containing common variants associated with schizophrenia and ea, and were enriched for genes containing rare variants reported in studies of schizophrenia, autism and intellectual disability. in the developing cortex, genes targeted by satb2 based on chip-seq data, and functionally affected when satb2 is not expressed based on differential expression analysis using rna-seq data, show strong enrichment for genes associated with ea. for genes expressed in the hippocampus or at the synapse, those targeted by satb2 are more strongly enriched for genes associated ea than gene-sets not targeted by satb2. this study demonstrates that single gene findings from gwas can provide important insights to pathobiological processes. in this case we find evidence that genes influenced by satb2 and involved in synaptic transmission, axon guidance and formation of the corpus callosum are contributing to schizophrenia and cognition."
        },
        {
            "id": "R147402",
            "label": "Pegmatite spectral behavior considering ASTER and Landsat 8 OLI data in Naipa and Muiane mines (Alto Ligonha, Mozambique)",
            "doi": "10.1117/12.2325555",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R147397",
                    "label": "Understanding the pegmatites spectral behavior using Landsat 8 OLI"
                }
            ],
            "abstract": "the naipa and muiane mines are located on the nampula complex, a stratigraphic tectonic subdivision of the mozambique belt, in the alto ligonha region. the pegmatites are of the li-cs-ta type, intrude a chlorite phyllite and gneisses with amphibole and biotite. the mines are still active. the main objective of this work was to analyze the pegmatite\u2019s spectral behavior considering aster and landsat 8 oli data. an aster image from 27/05/2005, and an image landsat oli image from 02/02/2018 were considered. the data were radiometric calibrated and after atmospheric corrected considered the dark object subtraction algorithm available in the semi-automatic classification plugin accessible in qgis software. in the field, samples were collected from lepidolite waste pile in naipa and muaine mines. a spectroadiometer was used in order to analyze the spectral behavior of several pegmatite\u2019s samples collected in the field in alto ligonha (naipa and muiane mines). in addition, qgis software was also used for the spectral mapping of the hypothetical hydrothermal alterations associated with occurrences of basic metals, beryl gemstones, tourmalines, columbite-tantalites, and lithium minerals. a supervised classification algorithm was employed - spectral angle mapper for the data processing, and the overall accuracy achieved was 80%. the integration of aster and landsat 8 oli data have proved very useful for pegmatite\u2019s mapping. from the results obtained, we can conclude that: (i) the combination of aster and landsat 8 oli data allows us to obtain more information about mineral composition than just one sensor, i.e., these two sensors are complementary; (ii) the alteration spots identified in the mines area are composed of clay minerals. in the future, more data and others image processing algorithms can be applied in order to identify the different lithium minerals, as spodumene, petalite, amblygonite and lepidolite."
        },
        {
            "id": "R169492",
            "label": "The Local Effects of Ovarian Diathermy in an Ovine Model of Polycystic Ovary Syndrome",
            "doi": "10.1371/journal.pone.0111280",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in order to develop a medical alternative to surgical ovarian diathermy (od) in polycystic ovary syndrome (pcos) more mechanistic information is required about od. we therefore studied the cellular, molecular and vascular effects of diathermy on the ovary using an established ovine model of pcos. pregnant sheep were treated twice weekly with testosterone propionate (100 mg) from day 30\u2013100 gestation. their female offspring (n\\u200a=\\u200a12) were studied during their second breeding season when the pcos-like phenotype, with anovulation, is fully manifest. in one group (n\\u200a=\\u200a4) one ovary underwent diathermy and it was collected and compared to the contralateral ovary after 24 hours. in another group a treatment pcos cohort underwent diathermy (n\\u200a=\\u200a4) and the ovaries were collected and compared to the control pcos cohort (n\\u200a=\\u200a4) after 5 weeks. ovarian vascular indices were measured using contrast-enhanced ultrasound and colour doppler before, immediately after, 24 hours and five weeks after diathermy. antral follicles were assessed by immunohistochemistry and ovarian stromal gene expression by quantitative rt-pcr 24 hours and 5 weeks after diathermy. diathermy increased follicular atresia (p<0.05) and reduced antral follicle numbers after 5 weeks (p<0.05). there was an increase in stromal ccl2 expression 24 hours after diathermy (p<0.01) but no alteration in inflammatory indices at 5 weeks. immediately after diathermy there was increased microbubble transit time in the ovarian microvasculature (p\\u200a=\\u200a0.05) but this was not seen at 24 hours. however 24 hours after diathermy there was a reduction in the stromal doppler blood flow signal (p<0.05) and an increased ovarian resistance index (p<0.05) both of which persisted at 5 weeks (p<0.01; p<0.05). in the ovine model of pcos, od causes a sustained reduction in ovarian stromal blood flow with an increased ovarian artery resistance index associated with atresia of antral follicles."
        },
        {
            "id": "R25018",
            "label": "A survey of current Link Discovery frameworks",
            "doi": "10.3233/SW-150210",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R25025",
                    "label": "Link Discovery"
                }
            ],
            "abstract": "links build the backbone of the linked data cloud. with the steady growth in size of datasets comes an increased need for end users to know which frameworks to use for deriving links between datasets. in this survey, we comparatively evaluate current link discovery tools and frameworks. for this purpose, we outline general requirements and derive a generic architecture of link discovery frameworks. based on this generic architecture, we study and compare the features of state-ofthe-art linking frameworks. we also analyze reported performance evaluations for the different frameworks. finally, we derive insights pertaining to possible future developments in the domain of link discovery."
        },
        {
            "id": "R171028",
            "label": "Expectant Mothers Maximizing Opportunities: Maternal Characteristics Moderate Multifactorial Prenatal Stress in the Prediction of Birth Weight in a Sample of Children Adopted at Birth",
            "doi": "10.1371/journal.pone.0141881",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background mothers\u2019 stress in pregnancy is considered an environmental risk factor in child development. multiple stressors may combine to increase risk, and maternal personal characteristics may offset the effects of stress. this study aimed to test the effect of 1) multifactorial prenatal stress, integrating objective \u201cstressors\u201d and subjective \u201cdistress\u201d and 2) the moderating effects of maternal characteristics (perceived social support, self-esteem and specific personality traits) on infant birthweight. method hierarchical regression modeling was used to examine cross-sectional data on 403 birth mothers and their newborns from an adoption study. results distress during pregnancy showed a statistically significant association with birthweight (r2 = 0.032, f (2, 398) = 6.782, p = .001). the hierarchical regression model revealed an almost two-fold increase in variance of birthweight predicted by stressors as compared with distress measures (r2 \u03b4 = 0.049, f (4, 394) = 5.339, p < .001). further, maternal characteristics moderated this association (r2 \u03b4 = 0.031, f (4, 389) = 3.413, p = .009). specifically, the expected benefit to birthweight as a function of higher ses was observed only for mothers with lower levels of harm-avoidance and higher levels of perceived social support. importantly, the results were not better explained by prematurity, pregnancy complications, exposure to drugs, alcohol or environmental toxins. conclusions the findings support multidimensional theoretical models of prenatal stress. although both objective stressors and subjectively measured distress predict birthweight, they should be considered distinct and cumulative components of stress. this study further highlights that jointly considering risk factors and protective factors in pregnancy improves the ability to predict birthweight."
        },
        {
            "id": "R170295",
            "label": "Impacts on Breastfeeding Practices of At-Scale Strategies That Combine Intensive Interpersonal Counseling, Mass Media, and Community Mobilization: Results of Cluster-Randomized Program Evaluations in Bangladesh and Viet Nam",
            "doi": "10.1371/journal.pmed.1002159",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background despite recommendations supporting optimal breastfeeding, the number of women practicing exclusive breastfeeding (ebf) remains low, and few interventions have demonstrated implementation and impact at scale. alive & thrive was implemented over a period of 6 y (2009\u20132014) and aimed to improve breastfeeding practices through intensified interpersonal counseling (ipc), mass media (mm), and community mobilization (cm) intervention components delivered at scale in the context of policy advocacy (pa) in bangladesh and viet nam. in bangladesh, ipc was delivered through a large non-governmental health program; in viet nam, it was integrated into government health facilities. this study evaluated the population-level impact of intensified ipc, mm, cm, and pa (intensive) compared to standard nutrition counseling and less intensive mm, cm, and pa (non-intensive) on breastfeeding practices in these two countries. methods and findings a cluster-randomized evaluation design was employed in each country. for the evaluation sample, 20 sub-districts in bangladesh and 40 communes in viet nam were randomized to either the intensive or the non-intensive group. cross-sectional surveys (n ~ 500 children 0\u20135.9 mo old per group per country) were implemented at baseline (june 7\u2013august 29, 2010, in viet nam; april 28\u2013june 26, 2010, in bangladesh) and endline (june 16\u2013august 30, 2014, in viet nam; april 20\u2013june 23, 2014, in bangladesh). difference-in-differences estimates (ddes) of impact were calculated, adjusting for clustering. in bangladesh, improvements were significantly greater in the intensive compared to the non-intensive group for the proportion of women who reported practicing ebf in the previous 24 h (dde 36.2 percentage points [pp], 95% ci 21.0\u201351.5, p < 0.001; prevalence in intensive group rose from 48.5% to 87.6%) and engaging in early initiation of breastfeeding (eibf) (16.7 pp, 95% ci 2.8\u201330.6, p = 0.021; 63.7% to 94.2%). in viet nam, ebf increases were greater in the intensive group (27.9 pp, 95% ci 17.7\u201338.1, p < 0.001; 18.9% to 57.8%); eibf declined (60.0% to 53.2%) in the intensive group, but less than in the non-intensive group (57.4% to 40.6%; dde 10.0 pp, 95% ci \u22121.3 to 21.4, p = 0.072). our impact estimates may underestimate the full potential of such a multipronged intervention because the evaluation lacked a \u201cpure control\u201d area with no mm or national/provincial pa. conclusions at-scale interventions combining intensive ipc with mm, cm, and pa had greater positive impacts on breastfeeding practices in bangladesh and viet nam than standard counseling with less intensive mm, cm, and pa. to our knowledge, this study is the first to document implementation and impacts of breastfeeding promotion at scale using rigorous evaluation designs. strategies to design and deliver similar programs could improve breastfeeding practices in other contexts. trial registration clinicaltrials.gov nct01678716 (bangladesh) and nct01676623 (viet nam)"
        },
        {
            "id": "R41562",
            "label": "Improving relation extraction by pre-trained language representations",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R41602",
                    "label": "learn implicit linguistic features solely from plain text corpora by unsupervised pre-training, before fine-tuning the learned language representations on the relation extraction task"
                },
                {
                    "id": "R44342",
                    "label": "Relation extraction"
                }
            ],
            "abstract": "current state-of-the-art relation extraction methods typically rely on a set of lexical, syntactic, and semantic features, explicitly computed in a pre-processing step. training feature extraction models requires additional annotated language resources, which severely restricts the applicability and portability of relation extraction to novel languages. similarly, pre-processing introduces an additional source of error. to address these limitations, we introduce tre, a transformer for relation extraction, extending the openai generative pre-trained transformer [radford et al., 2018]. unlike previous relation extraction models, tre uses pre-trained deep language representations instead of explicit linguistic features to inform the relation classification and combines it with the self-attentive transformer architecture to effectively model long-range dependencies between entity mentions. tre allows us to learn implicit linguistic features solely from plain text corpora by unsupervised pre-training, before fine-tuning the learned language representations on the relation extraction task. tre obtains a new state-of-the-art result on the tacred and semeval 2010 task 8 datasets, achieving a test f1 of 67.4 and 87.1, respectively. furthermore, we observe a significant increase in sample efficiency. with only 20% of the training examples, tre matches the performance of our baselines and our model trained from scratch on 100% of the tacred dataset. we open-source our trained models, experiments, and source code."
        },
        {
            "id": "R171516",
            "label": "Missed opportunities: Do states require screening of children for health conditions that interfere with learning?",
            "doi": "10.1371/journal.pone.0190254",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "strong evidence supports the existence of health barriers to learning (hbls)\u2014health conditions that when untreated or unmanaged can interfere with a child\u2019s ability to learn and succeed in school. these hbls include vision and hearing deficits, uncontrolled asthma, mental and behavioral problems, dental pain, persistent hunger, and the effects of lead exposure. however, 19% of us children aged 6 to 11 did not receive their annual checkup in the past year. school requirements for health screenings can help identify children with hbls. this study explores which states require health screening for children in elementary school, and the extent to which the 7 hbls are included. methods investigators reviewed websites of state departments of health and education, and legislation for all 50 states and dc. for states with mandated screenings and a required form, investigators applied structured analysis to assess hbl inclusion. results no state mandated that schools require screening for all 7 hbls. less than half (49%) required comprehensive school health examinations and only 12 states plus dc required a specific form. of these, 12 of the forms required documentation of vision screening, 11 of hearing screening, and 12 of dental screening. ten forms asked about asthma and 9 required documentation of lead testing. seven asked about general well-being, emotional problems, or mental health. none addressed hunger. when including states without comprehensive school health examination requirements, the most commonly required hbl screenings were for vision (80% of states; includes dc), hearing (75% of states; includes dc) and dental (24% of state; includes dc). conclusion the lack of state mandated requirements for regular student health screening represents a missed opportunity to identify children with hbls. without state mandates, accompanying comprehensive forms, and protocols, children continue to be at risk of untreated health conditions that can undermine their success in school."
        },
        {
            "id": "R131032",
            "label": "Adaptive Input Representations for Neural Language Modeling",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "we introduce adaptive input representations for neural language modeling which extend the adaptive softmax of grave et al. (2017) to input representations of variable capacity. there are several choices on how to factorize the input and output layers, and whether to model words, characters or sub-word units. we perform a systematic comparison of popular choices for a self-attentional architecture. our experiments show that models equipped with adaptive embeddings are more than twice as fast to train than the popular character input cnn while having a lower number of parameters. on the wikitext-103 benchmark we achieve 18.7 perplexity, an improvement of 10.5 perplexity compared to the previously best published result and on the billion word benchmark, we achieve 23.02 perplexity."
        },
        {
            "id": "R139226",
            "label": "Affiliation policy rhetoric and reality in the Ghanaian higher education context",
            "doi": "10.1080/1360080x.2019.1575176",
            "research_field": {
                "id": "R136113",
                "label": "Education Systems and Educational Institutions"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract the present affiliation policy regime of ghana\u2019s higher education system has existed for more than two decades. however, empirical studies to examine the policy rhetoric and reality with regard to building quality assurance capacity in mentored institutions appear non-existent. this paper is based on an illustrative qualitative case study undertaken to examine the achievements and challenges of implementing the policy to build internal quality assurance capacities in mentored institutions. the study was guided by institutional theory using 12 key informant in-depth interviews and document reviews as data collection sources. the findings indicate a minimal achievement of the policy intent on internal quality assurance capacity building due to key implementation challenges such as a tripartite relationship structure; increasing cost on mentored institutions and increasing workload on mentor institutions. the study concludes that the gap between the policy rhetoric and reality in the studied mentored institutions appears undesirable and requires stakeholders\u2019 attention."
        },
        {
            "id": "R170892",
            "label": "The Effect of Personality on Daily Life Emotional Processes",
            "doi": "10.1371/journal.pone.0110907",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "personality features are associated with individual differences in daily emotional life, such as negative and positive affectivity, affect variability and affect reactivity. the existing literature is somewhat mixed and inconclusive about the nature of these associations. the aim of this study was to shed light on what personality features represent in daily life by investigating the effect of the five factor traits on different daily emotional processes using an ecologically valid method. the experience sampling method was used to collect repeated reports of daily affect and experiences from 104 healthy university students during one week of their normal lives. personality traits of the five factor model were assessed using neo five factor inventory. hierarchical linear modeling was used to analyze the effect of the personality traits on daily emotional processes. neuroticism predicted higher negative and lower positive affect, higher affect variability, more negative subjective evaluations of daily incidents, and higher reactivity to stressors. conscientiousness, by contrast, predicted lower average level, variability, and reactivity of negative affect. agreeableness was associated with higher positive and lower negative affect, lower variability of sadness, and more positive subjective evaluations of daily incidents. extraversion predicted higher positive affect and more positive subjective evaluations of daily activities. openness had no effect on average level of affect, but predicted higher reactivity to daily stressors. the results show that the personality features independently predict different aspects of daily emotional processes. neuroticism was associated with all of the processes. identifying these processes can help us to better understand individual differences in daily emotional life."
        },
        {
            "id": "R74723",
            "label": "Disability, Mobility and Transport in Low- and Middle-Income Countries: A Thematic Review",
            "doi": "doi:10.3390/su12020589  ",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this paper discusses issues affecting the transport and mobility needs of people with disabilities in middle- and low-income countries and how disability intersects with a range of other factors to impact on transport needs, use and engagement. the paper is intended to stimulate discussion and identify areas for further research, and identifies a number of key issues that are salient to discussions around equitable and inclusive transport provision, including patterns of transport use, behaviour and experiences, solutions and policy directions, measuring access and inclusion, policies and intersectionality. the paper also identifies gaps in knowledge and provision, barriers to addressing these gaps, and some possible solutions to overcoming these barriers. these include shifting the focus from access to inclusion, reconceptualising how \u2018special\u2019 transport might be provided, and most importantly listening to the voices and experiences of adults and children with disabilities. despite lack of transport often being cited as a reason for lack of inclusion of people with disabilities, there is surprisingly little evidence which either quantifies this or translates what this lack of access means to people with disabilities in their daily lives in low- and middle-income countries."
        },
        {
            "id": "R75658",
            "label": "Epilepsy prevalence and socioeconomic deprivation in England",
            "doi": "10.1111/epi.12763",
            "research_field": {
                "id": "R58",
                "label": "Neuroscience and Neurobiology"
            },
            "research_problems": [
                {
                    "id": "R75664",
                    "label": "Prevalence of epilepsy in Europe"
                }
            ],
            "abstract": "whilst the link between epilepsy prevalence and socioeconomic deprivation is documented, the factors that comprise this deprivation are not understood. we aimed to investigate the association between epilepsy, individual elements of deprivation and geographical region. analysis of epilepsy prevalence data, as recorded by general practitioners via the quality and outcomes framework, and deprivation, as recorded by the index of multiple deprivation (imd), at local authority level for the population of england. epilepsy prevalence was evaluated for correlation against all indicators within the imd. of the 37699503 patients in this study, 304331 were registered as having epilepsy (prevalence 0.80%(range 0.43%\u20131.16%)). we present maps illustrating epilepsy prevalence and imd score and results of statistical analysis between these two variables. positive correlation was seen with total imd score (r=0.468, p<0.01); education skills and training (r=0.665, p<0.01); employment deprivation (r=0.629, p<0.01); health deprivation and disability (r=0.617, p<0.01); income deprivation (r=0.358, p<0.01); crime (r=0.232, p<0.01) but not living environment (r=0.079, p=0.08). negative correlation was seen between epilepsy prevalence and barriers to housing and services (r=-0.415, p<0.01). when the data were analysed excluding london, all correlations were strengthened."
        },
        {
            "id": "R49542",
            "label": "You Only Look Once: Unified, Real-Time Object Detection",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present yolo, a new approach to object detection. prior work on object detection repurposes classifiers to perform detection. instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. a single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. our unified architecture is extremely fast. our base yolo model processes images in real-time at 45 frames per second. a smaller version of the network, fast yolo, processes an astounding 155 frames per second while still achieving double the map of other real-time detectors. compared to state-of-the-art detection systems, yolo makes more localization errors but is less likely to predict false positives on background. finally, yolo learns very general representations of objects. it outperforms other detection methods, including dpm and r-cnn, when generalizing from natural images to other domains like artwork."
        },
        {
            "id": "R75857",
            "label": "Methicillin-resistant Staphylococcus pseudintermedius synthesizes deoxyadenosine to cause persistent infection",
            "doi": "10.1080/21505594.2021.1903691",
            "research_field": {
                "id": "R40",
                "label": "Immunology and Infectious Disease"
            },
            "research_problems": [
                {
                    "id": "R75860",
                    "label": "Lack of knowlage on staphylococcus pseudintermedius virulence factors"
                }
            ],
            "abstract": "abstract methicillin-resistant staphylococcus pseudintermedius (mrsp) is an emerging zoonotic pathogen of canine origin that causes an array of fatal diseases, including bacteremia and endocarditis. despite large-scale genome sequencing projects have gained substantial insights into the genomic landscape of mrsp, current knowledge on virulence determinants that contribute to s. pseudintermedius pathogenesis during human or canine infection is very limited. using a panel of genetically engineered mrsp variants and a mouse abscess model, we here identified the major secreted nuclease of s. pseudintermedius designated nucb and adenosine synthase a (adsa) as two synergistically acting enzymes required for mrsp pathogenesis. similar to staphylococcus aureus, s. pseudintermedius requires nuclease secretion along with the activity of adsa to degrade mammalian dna for subsequent biosynthesis of cytotoxic deoxyadenosine. in this manner, s. pseudintermedius selectively kills macrophages during abscess formation thereby antagonizing crucial host immune cell responses. ultimately, bioinformatics analyses revealed that nucb and adsa are widespread in the global s. pseudintermedius population. together, these data suggest that s. pseudintermedius deploys the canonical nuc/adsa pathway to persist during invasive disease and may aid in the development of new therapeutic strategies to combat infections caused by mrsp."
        },
        {
            "id": "R109012",
            "label": "Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and Convolutional-LSTM Network",
            "doi": "10.1145/3307339.3342161",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "R108870",
                    "label": "Comparison of drug-drug interaction prediction"
                },
                {
                    "id": "R109036",
                    "label": "DDI prediction"
                }
            ],
            "abstract": "interference between pharmacological substances can cause serious medical injuries. correctly predicting so-called drug-drug interactions (ddi) does not only reduce these cases but can also result in a reduction of drug development cost. presently, most drug-related knowledge is the result of clinical evaluations and post-marketing surveillance; resulting in a limited amount of information. existing data-driven prediction approaches for ddis typically rely on a single source of information, while using information from multiple sources would help improve predictions. machine learning (ml) techniques are used, but the techniques are often unable to deal with skewness in the data. hence, we propose a new ml approach for predicting ddis based on multiple data sources. for this task, we use 12,000 drug features from drugbank, pharmgkb, and kegg drugs, which are integrated using knowledge graphs (kgs). to train our prediction model, we first embed the nodes in the graph using various embedding approaches. we found that the best performing combination was a complex embedding method creating using pytorch-biggraph (pbg) with a convolutional-lstm network and classic machine learning-based prediction models. the model averaging ensemble method of three best classifiers yields up to 0.94, 0.92, 0.80 for aupr, f1 f1-score, and mcc, respectively during 5-fold cross-validation tests."
        },
        {
            "id": "R111213",
            "label": "Scalable join processing on very large RDF graphs",
            "doi": "10.1145/1559845.1559911",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "with the proliferation of the rdf data format, engines for rdf query processing are faced with very large graphs that contain hundreds of millions of rdf triples. this paper addresses the resulting scalability problems. recent prior work along these lines has focused on indexing and other physical-design issues. the current paper focuses on join processing, as the fine-grained and schema-relaxed use of rdf often entails star- and chain-shaped join queries with many input streams from index scans. we present two contributions for scalable join processing. first, we develop very light-weight methods for sideways information passing between separate joins at query run-time, to provide highly effective filters on the input streams of joins. second, we improve previously proposed algorithms for join-order optimization by more accurate selectivity estimations for very large rdf graphs. experimental studies with several rdf datasets, including the uniprot collection, demonstrate the performance gains of our approach, outperforming the previously fastest systems by more than an order of magnitude."
        },
        {
            "id": "R171505",
            "label": "Association of loneliness with all-cause mortality: A meta-analysis",
            "doi": "10.1371/journal.pone.0190033",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction loneliness has social and health implications. the aim of this article is to evaluate the association of loneliness with all-cause mortality. methods pubmed, psycinfo, cinahl and scopus databases were searched through june 2016 for published articles that measured loneliness and mortality. the main characteristics and the effect size values of each article were extracted. moreover, an evaluation of the quality of the articles included was also carried out. a meta-analysis was performed firstly with all the included articles and secondly separating by gender, using a random effects model. results a total of 35 articles involving 77220 participants were included in the systematic review. loneliness is a risk factor for all-cause mortality [pooled hr = 1.22, 95% ci = (1.10, 1.35), p < 0.001] for both genders together, and for women [pooled hr = 1.26, 95% ci = (1.07, 1.48); p = 0.005] and men [pooled hr = 1.44; 95% ci = (1.19, 1.76); p < 0.001] separately. conclusions loneliness shows a harmful effect for all-cause mortality and this effect is slightly stronger in men than in women. moreover, the impact of loneliness was independent from the quality evaluation of each article and the effect of depression."
        },
        {
            "id": "R170297",
            "label": "Socioeconomic Inequalities in Body Mass Index across Adulthood: Coordinated Analyses of Individual Participant Data from Three British Birth Cohort Studies Initiated in 1946, 1958 and 1970",
            "doi": "10.1371/journal.pmed.1002214",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background high body mass index (bmi) is an important contributor to the global burden of ill-health and health inequality. lower socioeconomic position (sep) in both childhood and adulthood is associated with higher adult bmi, but how these associations have changed across time is poorly understood. we used longitudinal data to examine how childhood and adult sep relates to bmi across adulthood in three national british birth cohorts. methods and findings the sample comprised up to 22,810 participants with 77,115 bmi observations in the 1946 mrc national survey of health and development (ages 20 to 60\u201364), the 1958 national child development study (ages 23 to 50), and the 1970 british cohort study (ages 26 to 42). harmonized social class-based sep data (registrar general\u2019s social class) was ascertained in childhood (father\u2019s class at 10/11 y) and adulthood (42/43 years), and bmi repeatedly across adulthood, spanning 1966 to 2012. associations between sep and bmi were examined using linear regression and multilevel models. lower childhood sep was associated with higher adult bmi in both genders, and differences were typically larger at older ages and similar in magnitude in each cohort. the strength of association between adult sep and bmi did not vary with age in any consistent pattern in these cohorts, but were more evident in women than men, and inequalities were larger among women in the 1970 cohort compared with earlier-born cohorts. for example, mean differences in bmi at 42/43 y amongst women in the lowest compared with highest social class were 2.0 kg/m2 (95% ci: \u22120.1, 4.0) in the 1946 nshd, 2.3 kg/m2 (1.1, 3.4) in the 1958 ncds, and 3.9 kg/m2 (2.3, 5.4) the in the 1970 bcs; mean (sd) bmi in the highest and lowest social classes were as follows: 24.9 (0.8) versus 26.8 (0.7) in the 1946 nshd, 24.2 (0.4) versus 26.5 (0.4) in the 1958 ncds, and 24.2 (0.3) versus 28.1 (0.8) in the 1970 bcs. findings did not differ whether using overweight or obesity as an outcome. limitations of this work include the use of social class as the sole indicator of sep\u2014while it was available in each cohort in both childhood and adulthood, trends in bmi inequalities may differ according to other dimensions of sep such as education or income. although harmonized data were used to aid inferences about birth cohort differences in bmi inequality, differences in other factors may have also contributed to findings\u2014for example, differences in missing data. conclusions given these persisting inequalities and their public health implications, new and effective policies to reduce inequalities in adult bmi that tackle inequality with respect to both childhood and adult sep are urgently required"
        },
        {
            "id": "R142290",
            "label": "A Single Dose of Self-Transcribing and Replicating RNA Based SARS-CoV-2 Vaccine Produces Protective Adaptive Immunity In Mice",
            "doi": "10.1101/2020.09.03.280446",
            "research_field": {
                "id": "R40",
                "label": "Immunology and Infectious Disease"
            },
            "research_problems": [
                {
                    "id": "R142250",
                    "label": "COVID-19 Vaccine"
                }
            ],
            "abstract": "abstract a self-transcribing and replicating rna (starr\u2122) based vaccine (lunar \u00ae -cov19) has been developed to prevent sars-cov-2 infection. the vaccine encodes an alphavirus-based replicon and the sars-cov-2 full length spike glycoprotein. translation of the replicon produces a replicase complex that amplifies and prolong sars-cov-2 spike glycoprotein expression. a single prime vaccination in mice led to robust antibody responses, with neutralizing antibody titers increasing up to day 60. activation of cell mediated immunity produced a strong viral antigen specific cd8 + t lymphocyte response. assaying for intracellular cytokine staining for ifn-\u03b3 and il-4 positive cd4 + t helper lymphocytes as well as anti-spike glycoprotein igg2a/igg1 ratios supported a strong th1 dominant immune response. finally, single lunar-cov19 vaccination at both 2 \u03bcg and 10 \u03bcg doses completely protected human ace2 transgenic mice from both mortality and even measurable infection following wild-type sars-cov-2 challenge. our findings collectively suggest the potential of lunar-cov19 as a single dose vaccine."
        },
        {
            "id": "R134713",
            "label": "Going deeper with Image Transformers",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R38570",
                    "label": "Image Classification"
                }
            ],
            "abstract": "transformers have been recently adapted for large scale image classification, achieving high scores shaking up the long supremacy of convolutional neural networks. however the optimization of vision transformers has been little studied so far. in this work, we build and optimize deeper transformer networks for image classification. in particular, we investigate the interplay of architecture and optimization of such dedicated transformers. we make two architecture changes that significantly improve the accuracy of deep transformers. this leads us to produce models whose performance does not saturate early with more depth, for in-stance we obtain 86.5% top-1 accuracy on imagenet when training with no external data, we thus attain the current sate of the art with less floating-point operations and parameters. our best model establishes the new state of the art on imagenet with reassessed labels and imagenet-v2 / match frequency, in the setting with no additional training data. we share our code and models1."
        },
        {
            "id": "R154399",
            "label": "Selective catalytic conversion of guaiacol to phenols over a molybdenum carbide catalyst",
            "doi": "10.1039/c5cc01900a",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "an activated carbon supported \u03b1-molybdenum carbide catalyst (\u03b1-moc 1\u2212x /ac) showed remarkable activity in the selective deoxygenation of guaiacol to substituted mono-phenols in low carbon number alcohol solvents."
        },
        {
            "id": "R74479",
            "label": "Contribution of big data in E-learning. A methodology to process academic data from heterogeneous sources",
            "doi": "10.1109/SCCC.2016.7836014",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74478",
                    "label": "Big Data"
                },
                {
                    "id": "R109109",
                    "label": "Big Data"
                }
            ],
            "abstract": "big data covers a wide spectrum of technologies, which tends to support the processing of big amounts of heterogeneous data. the paper identifies the powerful benefits and the application areas of big data in the on-line education context. considering the boom of academic services on-line, and the free access to the educative content, a great amount of data is being generated in the formal educational field as well as in less formal contexts. in this sense, big data can help stakeholders, involved in education decision making, to reach the objective of improving the quality of education and the learning outcomes. in this paper, a methodology is proposed to process big amounts of data coming from the educational field. the current study ends with a specific case study where the data of a well-known ecuadorian institution that has more than 80 branches is analyzed."
        },
        {
            "id": "R169925",
            "label": "Evidence of horizontal gene transfer by transposase gene analyses in Fervidobacterium species",
            "doi": "10.1371/journal.pone.0173961",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "horizontal gene transfer (hgt) plays an important role in the physiology and evolution of microorganisms above all thermophilic prokaryotes. some members of the phylum thermotogae (i.e., thermotoga spp.) have been reported to present genomes constituted by a mosaic of genes from a variety of origins. this study presents a novel approach to search on the potential plasticity of fervidobacterium genomes using putative transposase-encoding genes as the target of analysis. transposases are key proteins involved in genomic dna rearrangements. a comprehensive comparative analysis, including phylogeny, non-metric multidimensional scaling analysis of tetranucleotide frequencies, repetitive flanking sequences and divergence estimates, was performed on the transposase genes detected in four fervidobacterium genomes: f. nodosum, f. pennivorans, f. islandicum and a new isolate (fervidobacterium sp. fc2004). transposase sequences were classified in different groups by their degree of similarity. the different methods used in this study pointed that over half of the transposase genes represented putative hgt events with closest relative sequences within the phylum firmicutes, being caldicellulosiruptor the genus showing highest gene sequence proximity. these results confirmed a direct evolutionary relationship through hgt between specific fervidobacterium species and thermophilic firmicutes leading to potential gene sequence and functionality sharing to thrive under similar environmental conditions. transposase-encoding genes represent suitable targets to approach the plasticity and potential mosaicism of bacterial genomes."
        },
        {
            "id": "R201372",
            "label": "Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation",
            "doi": "10.5244/C.24.12",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we investigate the task of 2d articulated human pose estimation in unconstrained still images. this is extremely challenging because of variation in pose, anatomy, clothing, and imaging conditions. current methods use simple models of body part appearance and plausible configurations due to limitations of available training data and constraints on computational expense. we show that such models severely limit accuracy. building on the successful pictorial structure model (psm) we propose richer models of both appearance and pose, using state-of-the-art discriminative classifiers without introducing unacceptable computational expense. we introduce a new annotated database of challenging consumer images, an order of magnitude larger than currently available datasets, and demonstrate over 50% relative improvement in pose estimation accuracy over a stateof-the-art method."
        },
        {
            "id": "R188128",
            "label": "Cone-KG: A semantic knowledge graph with news content and social context for studying Covid-19 news articles on social media",
            "doi": "",
            "research_field": {
                "id": "R33",
                "label": "Epidemiology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "semantic knowledge graphs provide very significant benefits for structuring and analysing huge amounts of aggregated data across diverse heterogeneous sources. beyond quick and efficient data query and analysis, they facilitate inference from data and generation of insights for several purposes. with the multi-faceted global challenges posed by the covid-19 pandemic, this research focused on the use of a semantic knowledge graph to model, structure and store covid-related news articles centrally and semantically towards knowledge discovery, knowledge acquisition and advanced data analytics for understanding varying metrics relating to the virus towards curbing its spread. the semantic knowledge graph provides a platform for researchers, data analysts and data scientists across societal sectors to investigate and recommend strategies towards addressing the challenges it poses to the global society."
        },
        {
            "id": "R171173",
            "label": "\u00e2\u0080\u009cI Know that You Know that I Know\u00e2\u0080\u009d: Neural Substrates Associated with Social Cognition Deficits in DM1 Patients",
            "doi": "10.1371/journal.pone.0156901",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "myotonic dystrophy type-1 (dm1) is a genetic multi-systemic disorder involving several organs including the brain. despite the heterogeneity of this condition, some patients with non-congenital dm1 can present with minimal cognitive impairment on formal testing but with severe difficulties in daily-living activities including social interactions. one explanation for this paradoxical mismatch can be found in patients\u2019 dysfunctional social cognition, which can be assessed in the framework of the theory of mind (tom). we hypothesize here that specific disease driven abnormalities in dm1 brains may result in tom impairments. we recruited 20 dm1 patients who underwent the \u201creading the mind in the eyes\u201d and the tom-story tests. these patients, together with 18 healthy controls, also underwent resting-state functional mri. a composite theory of mind score was computed for all recruited patients and correlated with their brain functional connectivity. this analysis provided the patients\u2019 \u201ctheory of mind-network\u201d, which was compared, for its topological properties, with that of healthy controls. we found that dm1 patients showed deficits in both tests assessing tom. these deficits were associated with specific patterns of abnormal connectivity between the left inferior temporal and fronto-cerebellar nodes in dm1 brains. the results confirm the previous suggestions of tom dysfunctions in patients with dm1 and support the hypothesis that difficulties in social interactions and personal relationships are a direct consequence of brain abnormalities, and not a reaction symptom. this is relevant not only for a better pathophysiological comprehension of dm1, but also for non-pharmacological interventions to improve clinical aspects and impact on patients\u2019 success in life."
        },
        {
            "id": "R170715",
            "label": "Enrichment and Training Improve Cognition in Rats with Cortical Malformations",
            "doi": "10.1371/journal.pone.0084492",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "children with malformations of cortical development (mcd) frequently have associated cognitive impairments which reduce quality of life. we hypothesized that cognitive deficits associated with mcd can be improved with environmental manipulation or additional training. the e17 methylazoxymethanol acetate (mam) exposure model bears many anatomical hallmarks seen in human mcds as well as similar behavioral and cognitive deficits. we divided control and mam exposed sprague-dawley rats into enriched and non-enriched groups and tested performance in the morris water maze. another group similarly divided underwent sociability testing and also underwent magnetic resonance imaging (mri) scans pre and post enrichment. a third group of control and mam rats without enrichment were trained until they reached criterion on the place avoidance task. mam rats had impaired performance on spatial tasks and enrichment improved performance of both control and mam animals. although mam rats did not have a deficit in sociability they showed similar improvement with enrichment as controls. mri revealed a whole brain volume decrease with mam exposure, and an increase in both mam and control enriched volumes in comparison to non-enriched animals. in the place avoidance task, mam rats required approximately 3 times as long to reach criterion as control animals, but with additional training were able to reach control performance. environmental manipulation and additional training can improve cognition in a rodent mcd model. we therefore suggest that patients with mcd may benefit from appropriate alterations in educational strategies, social interaction and environment. these factors should be considered in therapeutic strategies."
        },
        {
            "id": "R110242",
            "label": "Comparison, synthesis and evaluation of anticancer drug-loaded polymeric nanoparticles on breast cancer cell lines",
            "doi": "10.3109/21691401.2015.1008510",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R3070",
                    "label": "Breast cancer"
                },
                {
                    "id": "R110161",
                    "label": "Polymeric nanoparticles for cancer treatment"
                }
            ],
            "abstract": "breast cancer is a major form of cancer, with a high mortality rate in women. it is crucial to achieve more efficient and safe anticancer drugs. recent developments in medical nanotechnology have resulted in novel advances in cancer drug delivery. cisplatin, doxorubicin, and 5-fluorouracil are three important anti-cancer drugs which have poor water-solubility. in this study, we used cisplatin, doxorubicin, and 5-fluorouracil-loaded polycaprolactone-polyethylene glycol (pcl-peg) nanoparticles to improve the stability and solubility of molecules in drug delivery systems. the nanoparticles were prepared by a double emulsion method and characterized with fourier transform infrared (ftir) spectroscopy and hydrogen-1 nuclear magnetic resonance (1hnmr). cells were treated with equal concentrations of cisplatin, doxorubicin and 5-fluorouracil-loaded pcl-peg nanoparticles, and free cisplatin, doxorubicin and 5-fluorouracil. the 3-[4,5-dimethylthiazol-2yl]-2,5-diphenyl tetrazolium bromide (mtt) assay confirmed that cisplatin, doxorubicin, and 5-fluorouracil-loaded pcl-peg nanoparticles enhanced cytotoxicity and drug delivery in t47d and mcf7 breast cancer cells. however, the ic50 value of doxorubicin was lower than the ic50 values of both cisplatin and 5-fluorouracil, where the difference was statistically considered significant (p\u02c20.05). however, the ic50 value of all drugs on t47d were lower than those on mcf7."
        },
        {
            "id": "R170676",
            "label": "Reliability and Validity of the CogState Battery Chinese Language Version in Schizophrenia",
            "doi": "10.1371/journal.pone.0074258",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background cognitive impairment in patients with schizophrenia is a core symptom of this disease. the computerized cogstate battery (csb) has been used to detect seven of the most common cognitive domains in schizophrenia. the aim of this study was to examine the reliability and validity of the chinese version of the csb (csb-c), in chinese patients with schizophrenia. methodology/principal findings sixty chinese patients with schizophrenia and 58 age, sex, and education matched healthy controls were enrolled. all subjects completed the csb-c and the repeated battery for the assessment of neuropsychological status (rbans). to examine the test-retest reliability of csb-c, we tested 33 healthy controls twice, at a one month interval. the cronbach \u03b1 value of csb-c in patients was 0.81. the test-retest correlation coefficients of the two back task, gronton maze learning task, social emotional cognition task, and continuous paired association learning task were between 0.39 and 0.62 (p<0.01) in healthy controls. the composite scores and all subscores for the csb-c in patients were significantly (p<0.01) lower than those of healthy controls. furthermore, composite scores for patients on the rbans were also significantly lower than those of healthy controls. interestingly, there was a positive correlation (r \\u200a=\\u200a 0.544, p<0.001) between the composite scores on csb-c and rbans for patients. additionally, in the attention and memory cognitive domains, corresponding subsets from the two batteries correlated significantly (p<0.05). moreover, factor analysis showed a two-factor model, consisting of speed, memory and reasoning. conclusions/significance the csb-c shows good reliability and validity in measuring the broad cognitive domains of schizophrenia in affected chinese patients. therefore, the csb-c can be used as a cognitive battery, to assess the therapeutic effects of potential cognitive-enhancing agents in this cohort."
        },
        {
            "id": "R148626",
            "label": "Dynamics of localized dissipative structures in a generalized Lugiato\u00e2\u0080\u0093Lefever model with negative quartic group-velocity dispersion",
            "doi": "10.1364/ol.392180",
            "research_field": {
                "id": "R137635",
                "label": "Optics, Quantum Optics and Physics of Atoms, Molecules and Plasmas"
            },
            "research_problems": [
                {
                    "id": "R148598",
                    "label": "Formation of two-frequency pulse compounds"
                }
            ],
            "abstract": "we study localized dissipative structures in a generalized lugiato-lefever equation, exhibiting normal group-velocity dispersion and anomalous quartic group-velocity dispersion. in the conservative system, this parameter-regime has proven to enable generalized dispersion kerr solitons. here, we demonstrate via numerical simulations that our dissipative system also exhibits equivalent localized states, including special molecule-like two-color bound states recently reported. we investigate their generation, characterize the observed steady-state solution, and analyze their propagation dynamics under perturbations."
        },
        {
            "id": "R198706",
            "label": "Challenging Incompleteness of Performance Requirements by Sentence Patterns",
            "doi": "10.1109/re.2016.24",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "performance requirements play an important role in software development. they describe system behavior that directly impacts the user experience. specifying performance requirements in a way that all necessary content is contained, i.e., the completeness of the individual requirements, is challenging, yet project critical. furthermore, it is still an open question, what content is necessary to make a performance requirement complete. to address this problem, we introduce a framework for specifying performance requirements. this framework (i) consists of a unified model derived from existing performance classifications, (ii) denotes completeness through a content model, and (iii) is operationalized through sentence patterns. we evaluate both the applicability of the framework as well as its ability uncover incompleteness with performance requirements taken from 11 industrial specifications. in our study, we were able to specify 86% of the examined performance requirements by means of our framework. furthermore, we show that 68% of the specified performance requirements are incomplete with respect to our notion of completeness. we argue that our framework provides an actionable definition of completeness for performance requirements."
        },
        {
            "id": "R171312",
            "label": "A randomized controlled trial of a group-based gaze training intervention for children with Developmental Coordination Disorder",
            "doi": "10.1371/journal.pone.0171782",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the aim of this study was to integrate a gaze training intervention (i.e., quiet eye training; qet) that has been shown to improve the throwing and catching skill of children with developmental coordination disorder (dcd), within an approach (i.e., group therapy) that might alleviate the negative psychosocial impact of these motor skill deficits. twenty-one children with dcd were split into either qet (8 male 3 female, mean age of 8.6 years (sd = 1.04) or technical training (tt) groups (7 male 3 female, mean age of 8.6 years (sd = 1.84). the tt group were given movement-related instructions via video, relating to the throw and catch phases, while the qet group were also taught to fixate a target location on the wall prior to the throw (qe1) and to track the ball prior to the catch (qe2). each group partook in a 4-week, group therapy intervention and measurements of qe duration and catching performance were taken before and after training, and at a 6-week delayed retention test. parental feedback on psychosocial and motor skill outcomes was provided at delayed retention. children improved their gaze control and catching coordination following qet, compared to tt. mediation analysis showed that a longer qe aiming duration (qe1) predicted an earlier onset of tracking the ball prior to catching (qe2) which predicted catching success. parents reported enhanced perceptions of their child\u2019s catching ability and general coordination in the qet group compared to the tt group. all parents reported improvements in their child\u2019s confidence, social skills and predilection for physical activity following the trial. the findings offer initial support for an intervention that practitioners could apply to address deficits in the motor and psychosocial skills of children with dcd. trial registration: clinicaltrials.gov nct02904980"
        },
        {
            "id": "R168653",
            "label": "SCOTTI: Efficient Reconstruction of Transmission within Outbreaks with the Structured Coalescent",
            "doi": "10.1371/journal.pcbi.1005130",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "exploiting pathogen genomes to reconstruct transmission represents a powerful tool in the fight against infectious disease. however, their interpretation rests on a number of simplifying assumptions that regularly ignore important complexities of real data, in particular within-host evolution and non-sampled patients. here we propose a new approach to transmission inference called scotti (structured coalescent transmission tree inference). this method is based on a statistical framework that models each host as a distinct population, and transmissions between hosts as migration events. our computationally efficient implementation of this model enables the inference of host-to-host transmission while accommodating within-host evolution and non-sampled hosts. scotti is distributed as an open source package for the phylogenetic software beast2. we show that scotti can generally infer transmission events even in the presence of considerable within-host variation, can account for the uncertainty associated with the possible presence of non-sampled hosts, and can efficiently use data from multiple samples of the same host, although there is some reduction in accuracy when samples are collected very close to the infection time. we illustrate the features of our approach by investigating transmission from genetic and epidemiological data in a foot and mouth disease virus (fmdv) veterinary outbreak in england and a klebsiella pneumoniae outbreak in a nepali neonatal unit. transmission histories inferred with scotti will be important in devising effective measures to prevent and halt transmission."
        },
        {
            "id": "R169097",
            "label": "Ethanol Seeking by Long Evans Rats Is Not Always a Goal-Directed Behavior",
            "doi": "10.1371/journal.pone.0042886",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background two parallel and interacting processes are said to underlie animal behavior, whereby learning and performance of a behavior is at first via conscious and deliberate (goal-directed) processes, but after initial acquisition, the behavior can become automatic and stimulus-elicited (habitual). with respect to instrumental behaviors, animal learning studies suggest that the duration of training and the action-outcome contingency are two factors involved in the emergence of habitual seeking of \u201cnatural\u201d reinforcers (e.g., sweet solutions, food or sucrose pellets). to rigorously test whether behaviors reinforced by abused substances such as ethanol, in particular, similarly become habitual was the primary aim of this study. methodology/principal findings male long evans rats underwent extended or limited operant lever press training with 10% sucrose/10% ethanol (10s10e) reinforcement (variable interval (vi) or (vr) ratio schedule of reinforcement), or with 10% sucrose (10s) reinforcement (vi schedule only). once training and pretesting were complete, the impact of outcome devaluation on operant behavior was evaluated after lithium chloride injections were paired with the reinforcer, or unpaired 24 hours later. after limited, but not extended instrumental training, lever pressing by groups trained under vr with 10s10e and under vi with 10s was sensitive to outcome devaluation. in contrast, responding by both the extended and limited training 10s10e vi groups was not sensitive to ethanol devaluation during the test for habitual behavior. conclusions/significance operant behavior by rats trained to self-administer an ethanol-sucrose solution showed variable sensitivity to a change in the value of ethanol, with relative insensitivity developing sooner in animals that received time-variable ethanol reinforcement during training sessions. one important implication, with respect to substance abuse in humans, is that initial learning about the relationship between instrumental actions and the opportunity to consume ethanol-containing drinks can influence the time course for the development or expression of habitual ethanol seeking behavior."
        },
        {
            "id": "R111316",
            "label": "Difference in reproductive mode rather than ploidy explains niche differentiation in sympatric sexual and apomictic populations of\n            Potentilla puberula",
            "doi": "10.1002/ece3.4992",
            "research_field": {
                "id": "R27",
                "label": "Botany"
            },
            "research_problems": [
                {
                    "id": "R111324",
                    "label": "ecological parthenogenesis"
                }
            ],
            "abstract": "abstract apomicts tend to have larger geographical distributional ranges and to occur in ecologically more extreme environments than their sexual progenitors. however, the expression of apomixis is typically linked to polyploidy. thus, it is a priori not clear whether intrinsic effects related to the change in the reproductive mode or rather in the ploidy drive ecological differentiation. we used sympatric sexual and apomictic populations of potentilla puberula to test for ecological differentiation. to distinguish the effects of reproductive mode and ploidy on the ecology of cytotypes, we compared the niches (a) of sexuals (tetraploids) and autopolyploid apomicts (penta\u2010, hepta\u2010, and octoploids) and (b) of the three apomictic cytotypes. we based comparisons on a ploidy screen of 238 populations along a latitudinal transect through the eastern european alps and associated bioclimatic, and soil and topographic data. sexual tetraploids preferred primary habitats at drier, steeper, more south\u2010oriented slopes, while apomicts mostly occurred in human\u2010made habitats with higher water availability. contrariwise, we found no or only marginal ecological differentiation among the apomictic higher ploids. based on the pronounced ecological differences found between sexuals and apomicts, in addition to the lack of niche differentiation among cytotypes of the same reproductive mode, we conclude that reproductive mode rather than ploidy is the main driver of the observed differences. moreover, we compared our system with others from the literature, to stress the importance of identifying alternative confounding effects (such as hybrid origin). finally, we underline the relevance of studying ecological parthenogenesis in sympatry, to minimize the effects of differential migration abilities."
        },
        {
            "id": "R170750",
            "label": "Association between Socioeconomic Factors and Cancer Risk: A Population Cohort Study in Scotland (1991-2006)",
            "doi": "10.1371/journal.pone.0089513",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background lung and upper aero-digestive tract (uadt) cancer risk are associated with low socioeconomic circumstances and routinely measured using area socioeconomic indices. we investigated effect of country of birth, marital status, one area deprivation measure and individual socioeconomic variables (economic activity, education, occupational social class, car ownership, household tenure) on risk associated with lung, uadt and all cancer combined (excluding non melanoma skin cancer). methods we linked scottish longitudinal study and scottish cancer registry to follow 203,658 cohort members aged 15+ years from 1991\u20132006. relative risks (rr) were calculated using poisson regression models by sex offset for person-years of follow-up. results 21,832 first primary tumours (including 3,505 lung, 1,206 uadt) were diagnosed. regardless of cancer, economically inactivity (versus activity) was associated with increased risk (male: rr 1.14, 95% ci 1.10\u20131.18; female: rr 1.06, 95% ci 1.02\u20131.11). for lung cancer, area deprivation remained significant after full adjustment suggesting the area deprivation cannot be fully explained by individual variables. no or non degree qualification (versus degree) was associated with increased lung risk; likewise for uadt risk (females only). occupational social class associations were most pronounced and elevated for uadt risk. no car access (versus ownership) was associated with increased risk (excluding all cancer risk, males). renting (versus home ownership) was associated with increased lung cancer risk, uadt cancer risk (males only) and all cancer risk (females only). regardless of cancer group, elevated risk was associated with no education and living in deprived areas. conclusions different and independent socioeconomic variables are inversely associated with different cancer risks in both sexes; no one socioeconomic variable captures all aspects of socioeconomic circumstances or life course. association of multiple socioeconomic variables is likely to reflect the complexity and multifaceted nature of deprivation as well as the various roles of these dimensions over the life course."
        },
        {
            "id": "R170721",
            "label": "Vision-Related Quality of Life in Herpetic Anterior Uveitis Patients",
            "doi": "10.1371/journal.pone.0085224",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we investigated the vision-related quality of life (vr-qol) and the prevalence and severity of depression in patients with herpetic anterior uveitis (au). this study was conducted in 2012 at the ophthalmology department of the university medical center of groningen (tertiary referral center). we selected patients from an existing uveitis database, all eligible patients were approached. thirty-six of 66 (55%) patients with herpetic au (herpes simplex virus or varicella zoster virus) participated, patients were 18 years or older. the diagnosis was made by clinical presentation or a positive anterior chamber tap. all patients received an information letter, informed consent form, national eye institute visual functioning questionnaire-25 (nei vfq-25), beck depression inventory (bdi-ii), social support list \u2013 interactions (ssl-i), social support list \u2013 discrepancies (ssl-d) and an additional questionnaire for gathering general information. medical records were reviewed for clinical characteristics. analyses were conducted on various patient and ocular characteristics. we compared our nei vfq-25 scores with those previously found in the literature. our main outcome measures were vr-qol, prevalence and severity of depression, social support and various patient and ocular characteristics that could influence the vr-qol. we found that the nei vfq-25 mean overall composite score (ocs) was 88.1\u00b110.6. compared with other ocular diseases our ocs is relatively high, but lower than that found in a normal working population. the mean general health score was 59.0\u00b119.0; this score is lower than in patients with other ocular diseases, except for untreated beh\u00e7et\u2019s patients. depression was scarce, with only one patient (2.8%) having a moderate depression (bdi-ii score of 21). we concluded that herpetic au affects the vr-qol in a moderate way. the prevalence of depression in our group of herpetic au patients was low and therefore does not seem to indicate a need for specific screening and intervention measures in these patients."
        },
        {
            "id": "R108643",
            "label": "Tools for Analytics and Cognition Framework for a Car-Sharing Use Case",
            "doi": "10.23919/mipro48935.2020.9245127",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the development of tools that can improve efficiency and inject intelligent insights into operational and mission-critical social media businesses through guided analytics is crucial for consumers, prosumers, and business markets. these tools will provide contextualised socially aware and spatial-temporal data aggregation, knowledge extraction, cognitive learning about users\u2018 behaviour, and risk quantification for the car-sharing use case. the proposed tools for analytics and cognition (tac) framework will provide a tool-set of guided analytics software for smart aggregation, cognition and interactive visualisation with a monitoring dashboard for the car-sharing use cases. the proposed tac framework uses the dashboard to visually analyse the behaviour and engagement of the social media actors, diagnose performance risks and provide guided analytics to consumer prosumers and application providers to improve collaboration and revenues, using the established car-sharing qualitative mapping model. this framework has supplied a seamless coupling with distributed blockchain-based services for early alert, real-time tracking and updated data triggers for reach and engagement analysis of car-sharing events. moreover, the tac framework will allow car-sharing providers to analyse, control and track their investment to enhance monetary inclusion in the collaborative social media ecosystem."
        },
        {
            "id": "R139681",
            "label": "Communicating Built Heritage Information Using Tangible Interaction Approach",
            "doi": "10.1145/3024969.3025035",
            "research_field": {
                "id": "R136112",
                "label": "General and Domain-Specific Teaching and Learning"
            },
            "research_problems": [
                {
                    "id": "R139684",
                    "label": "How does the physical affordance of tangible interaction affect the communication of built heritage information?"
                }
            ],
            "abstract": "\"built heritage objects possess multiple types of information, varying from simple, factual aspects to more complex qualitative information and values, such as the architectural qualities, the construction techniques, or symbolic meanings of monuments. this qualitative information is relatively difficult to communicate using the conventional ways like museum labels or audio guides. nonetheless, tangible interaction is a promising paradigm for communicating tacit information, its qualities have been demonstrated in a wide range of applications in different realms. therefore, this study investigates how tangible interaction can enable the communication of qualitative information of built heritage to lay visitors. the main objectives of this study are communicating tacit and architectural qualities of built heritage in a physical form, investigating the effect of tangible interaction on social interaction among heritage visitors, and enhancing visitors' in-situ experience of built heritage or 1:1 replicas. our early findings indicate the capability of tangible interaction for engaging museum visitors to accomplish additional endeavors, and facilitating their understanding of cultural values and architectural qualities of built heritage.\""
        },
        {
            "id": "R160152",
            "label": "A revised nitrogen budget for the Arabian Sea",
            "doi": "10.1029/1999GB001228",
            "research_field": {
                "id": "R172",
                "label": "Oceanography"
            },
            "research_problems": [
                {
                    "id": "R160135",
                    "label": "N2O gas emission estimation from the Indian Ocean"
                }
            ],
            "abstract": "despite its importance for the global oceanic nitrogen (n) cycle, considerable uncertainties exist about the n fluxes of the arabian sea. on the basis of our recent measurements during the german arabian sea process study as part of the joint global ocean flux study (jgofs) in 1995 and 1997, we present estimates of various n sources and sinks such as atmospheric dry and wet depositions of n aerosols, pelagic denitrification, nitrous oxide (n2o) emissions, and advective n input from the south. additionally, we estimated the n burial in the deep sea and the sedimentary shelf denitrification. on the basis of our measurements and literature data, the n budget for the arabian sea was reassessed. it is dominated by the n loss due to denitrification, which is balanced by the advective input of n from the south. the role of n fixation in the arabian sea is still difficult to assess owing to the small database available; however, there are hints that it might be more important than previously thought. atmospheric n depositions are important on a regional scale during the intermonsoon in the central arabian sea; however, they play only a minor role for the overall n cycling. emissions of n2o and ammonia, deep\u2010sea n burial, and n inputs by rivers and marginal seas (i.e., persian gulf and red sea) are of minor importance. we found that the magnitude of the sedimentary denitrification at the shelf might be \u223c17% of the total denitrification in the arabian sea, indicating that the shelf sediments might be of considerably greater importance for the n cycling in the arabian sea than previously thought. sedimentary and pelagic denitrification together demand \u223c6% of the estimated particulate organic nitrogen export flux from the photic zone. the main northward transport of n into the arabian sea occurs in the intermediate layers, indicating that the n cycle of the arabian sea might be sensitive to variations of the intermediate water circulation of the indian ocean."
        },
        {
            "id": "R170816",
            "label": "Dynamic Eye Tracking Based Metrics for Infant Gaze Patterns in the Face-Distractor Competition Paradigm",
            "doi": "10.1371/journal.pone.0097299",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective to develop new standardized eye tracking based measures and metrics for infants\u2019 gaze dynamics in the face-distractor competition paradigm. method eye tracking data were collected from two samples of healthy 7-month-old (total n\\u200a=\\u200a45), as well as one sample of 5-month-old infants (n\\u200a=\\u200a22) in a paradigm with a picture of a face or a non-face pattern as a central stimulus, and a geometric shape as a lateral stimulus. the data were analyzed by using conventional measures of infants\u2019 initial disengagement from the central to the lateral stimulus (i.e., saccadic reaction time and probability) and, additionally, novel measures reflecting infants gaze dynamics after the initial disengagement (i.e., cumulative allocation of attention to the central vs. peripheral stimulus). results the results showed that the initial saccade away from the centrally presented stimulus is followed by a rapid re-engagement of attention with the central stimulus, leading to cumulative preference for the central stimulus over the lateral stimulus over time. this pattern tended to be stronger for salient facial expressions as compared to non-face patterns, was replicable across two independent samples of 7-month-old infants, and differentiated between 7 and 5 month-old infants. conclusion the results suggest that eye tracking based assessments of infants\u2019 cumulative preference for faces over time can be readily parameterized and standardized, and may provide valuable techniques for future studies examining normative developmental changes in preference for social signals. significance standardized measures of early developing face preferences may have potential to become surrogate biomarkers of neurocognitive and social development."
        },
        {
            "id": "R214325",
            "label": "A German Corpus for Fine-Grained Named Entity Recognition and Relation Extraction of Traffic and Industry Events",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "monitoring mobility- and industry-relevant events is important in areas such as personal travel planning and supply chain management, but extracting events pertaining to specific companies, transit routes and locations from heterogeneous, high-volume text streams remains a significant challenge. this work describes a corpus of german-language documents which has been annotated with fine-grained geo-entities, such as streets, stops and routes, as well as standard named entity types. it has also been annotated with a set of 15 traffic- and industry-related n-ary relations and events, such as accidents, traffic jams, acquisitions, and strikes. the corpus consists of newswire texts, twitter messages, and traffic reports from radio stations, police and railway companies. it allows for training and evaluating both named entity recognition algorithms that aim for fine-grained typing of geo-entities, as well as n-ary relation extraction systems."
        },
        {
            "id": "R211411",
            "label": "Openness and requirements: Opportunities and tradeoffs in software ecosystems",
            "doi": "10.1109/re.2014.6912263",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a growing number of software systems is characterized by continuous evolution as well as by significant interdependence with other systems (e.g. services, apps). such software ecosystems promise increased innovation power and support for consumer oriented software services at scale, and are characterized by a certain openness of their information flows. while such openness supports project and reputation management, it also brings some challenges to requirements engineering (re) within the ecosystem. we report from a mixed-method study of ibm\u00ae's clm\u00ae ecosystem that uses an open commercial development model. we analyzed data from from interviews within several ecosystem actors, participatory observation, and software repositories, to describe the flow of product requirements information through the ecosystem, how the open communication paradigm in software ecosystems provides opportunities for `just-in-time' re, as well as some of the challenges faced when traditional requirements engineering approaches are applied within such an ecosystem. more importantly, we discuss two tradeoffs brought about the openness in software ecosystems: i) allowing open, transparent communication while keeping intellectual property confidential within the ecosystem, and ii) having the ability to act globally on a long-term strategy while empowering product teams to act locally to answer end-users' context specific needs in a timely manner."
        },
        {
            "id": "R155854",
            "label": "Visible Light Photoredox Catalysis with Transition Metal Complexes: Applications in Organic Synthesis",
            "doi": "10.1021/cr300503r",
            "research_field": {
                "id": "R130",
                "label": "Physical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R155888",
                    "label": "Iridium-based photoredox catalyst"
                }
            ],
            "abstract": "a fundamental aim in the field of catalysis is the development of new modes of small molecule activation. one approach toward the catalytic activation of organic molecules that has received much attention recently is visible light photoredox catalysis. in a general sense, this approach relies on the ability of metal complexes and organic dyes to engage in single-electron-transfer (set) processes with organic substrates upon photoexcitation with visible light. \\n \\nmany of the most commonly employed visible light photocatalysts are polypyridyl complexes of ruthenium and iridium, and are typified by the complex tris(2,2\u2032-bipyridine) ruthenium(ii), or ru(bpy)32+ (figure 1). these complexes absorb light in the visible region of the electromagnetic spectrum to give stable, long-lived photoexcited states.1,2 the lifetime of the excited species is sufficiently long (1100 ns for ru(bpy)32+) that it may engage in bimolecular electron-transfer reactions in competition with deactivation pathways.3 although these species are poor single-electron oxidants and reductants in the ground state, excitation of an electron affords excited states that are very potent single-electron-transfer reagents. importantly, the conversion of these bench stable, benign catalysts to redox-active species upon irradiation with simple household lightbulbs represents a remarkably chemoselective trigger to induce unique and valuable catalytic processes. \\n \\n \\n \\nfigure 1 \\n \\nruthenium polypyridyl complexes: versatile visible light photocatalysts. \\n \\n \\n \\nthe ability of ru(bpy)32+ and related complexes to function as visible light photocatalysts has been recognized and extensively investigated for applications in inorganic and materials chemistry. in particular, photoredox catalysts have been utilized to accomplish the splitting of water into hydrogen and oxygen4 and the reduction of carbon dioxide to methane.5 ru(bpy)32+ and its analogues have been used (i) as components of dye-sensitized solar cells6 and organic light-emitting diodes,7 (ii) to initiate polymerization reactions,8 and (iii) in photo-dynamic therapy.9 \\n \\nuntil recently, however, these complexes had been only sporadically employed as photocatalysts in the area of organic synthesis. the limited exploration of this area is perhaps surprising, as single-electron, radical processes have long been employed in c\u2013c bond construction and often provide access to reactivity that is complementary to that of closed-shell, two-electron pathways.10 in 2008, concurrent reports from the yoon group and our own lab detailed the use of ru(bpy)32+ as a visible light photoredox catalyst to perform a [2 + 2] cycloaddition11 and an \u03b1-alkylation of aldehydes,12 respectively. shortly thereafter, stephenson and co-workers disclosed a photoredox reductive dehalogenation of activated alkyl halides mediated by the same catalyst.13 the combined efforts of these three research groups have helped to initiate a renewed interest in this field, prompting a diversity of studies into the utility of photoredox catalysis as a conceptually novel approach to synthetic organic reaction development. \\n \\nmuch of the promise of visible light photoredox catalysis hinges on its ability to achieve unique, if not exotic bond constructions that are not possible using established protocols. for instance, photoredox catalysis may be employed to perform overall redox neutral reactions. as both oxidants and reductants may be transiently generated in the same reaction vessel, photoredox approaches may be used to develop reactions requiring both the donation and the reception of electrons at disparate points in the reaction mechanism. this approach stands in contrast to methods requiring stoichiometric chemical oxidants and reductants, which are often incompatible with each other, as well as to electrochemical approaches, which are not amenable to redox neutral transformations. furthermore, single-electron-transfer events often provide access to radical ion intermediates having reactivity patterns fundamentally different from those of their ground electronic or excited states.14 access to these intermediates using other means of activation is often challenging or requires conditions under which their unique reactivity cannot be productively harnessed. \\n \\nat the same time, photoredox catalysts such as ru(bpy)32+ may also be employed to generate radicals for use in a diverse range of established radical chemistries. photoredox reactions occur under extremely mild conditions, with most reactions proceeding at room temperature without the need for highly reactive radical initiators. the irradiation source is typically a commercial household light bulb, a significant advantage over the specialized equipment required for processes employing high-energy ultraviolet (uv) light. additionally, because organic molecules generally do not absorb visible light, there is little potential for deleterious side reactions that might arise from photoexcitation of the substrate itself. finally, photoredox catalysts may be employed at very low loadings, with 1 mole % or less being typical. \\n \\nthis review will highlight the early work on the use of transition metal complexes as photoredox catalysts to promote reactions of organic compounds (prior to 2008), as well as cover the surge of work that has appeared since 2008. we have for the most part grouped reactions according to whether the organic substrate undergoes reduction, oxidation, or a redox neutral reaction and throughout have sought to highlight the variety of reactive intermediates that may be accessed via this general reaction manifold.15 \\n \\nstudies on the use of transition metal complexes as visible light photocatalysts for organic synthesis have benefited tremendously from advances in the related fields of organic and semiconductor photocatalysis. many organic molecules may function as visible light photocatalysts; analogous to metal complexes such as ru(bpy)32+, organic dyes such as eosin y, 9,10-dicyanoanthracene, and triphenylpyrylium salts absorb light in the visible region to give excited states capable of single-electron transfer. these catalysts have been employed to achieve a vast range of bond-forming reactions of broad utility in organic synthesis.16 visible light photocatalysis has also been carried out with heterogeneous semiconductors such as mesoporous carbon nitride17 and various metal oxides and sulfides.18 these approaches are often complementary to photoredox catalysis with transition metal-polypyridyl complexes, and we have referred to work in these areas when it is similar to the chemistry under discussion. however, an in-depth discussion of the extensive literature in these fields is outside the scope of this review, and readers are directed to existing reviews on these topics.16\u201318"
        },
        {
            "id": "R4290",
            "label": "Analyzing Computer Programming Job Trend Using Web Data Mining",
            "doi": "10.28945/1989",
            "research_field": {
                "id": "R370",
                "label": "Work, Economy and Organizations"
            },
            "research_problems": [
                {
                    "id": "R4295",
                    "label": "Analyzing trends in IT jobs"
                }
            ],
            "abstract": "today\u2019s rapid changing and competitive environment requires educators to stay abreast of the job market in order to prepare their students for the jobs being demanded. this is more relevant about information technology (it) jobs than others. however, to stay abreast of the market job demands require retrieving, sifting and analyzing large volume of data in order to understand the trends of the job market. traditional methods of data collection and analysis are not sufficient for this kind of analysis due to the large volume of job data that is generated through the web and elsewhere. luckily, the field of data mining has emerged to collect and sift through such large data volumes. however, even with data mining, appropriate data collection techniques and analysis need to be followed in order to correctly understand the trend. this paper illustrates our experience with employing mining techniques to understand the trend in it technology jobs. data was collect using data mining techniques over a number of years from an online job agency. the data was then analyzed to reach a conclusion about the trends in the job market. our experience in this regard along with literature review of the relevant topics is illustrated in this paper."
        },
        {
            "id": "R50589",
            "label": "2,3-Pentandion [MAK Value Documentation in German language, 2017]",
            "doi": "10.1002/3527600418.mb60014d0062",
            "research_field": {
                "id": "R69",
                "label": "Toxicology"
            },
            "research_problems": [
                {
                    "id": "R50592",
                    "label": "Sch\u00e4digung durch maximale Konzentration von 2,3-Pentandion am Arbeitsplatz"
                }
            ],
            "abstract": "2,3-pentanedione [pentane-2,3-dione] \\n \\nthe german commission for the investigation of health hazards of chemical compounds in the work area has evaluated 2,3-pentanedione to derive a maximum concentration at the workplace (mak value), considering all toxicity endpoints. the critical effects of 2,3-pentanedione were inflammation, necrosis, ulceration and fibrosis in the lung and inflammation, exudates and metaplasia in the nasal cavity in rats and mice after inhalation for 14 days. in this study the noaec in rats was 49\\xa0ml/m3 and the loaec in mice was 49\\xa0ml/m3 for effects in the lung. the occurrence of fibrosis after only two weeks of inhalation is assessed as a severe effect. due to the structural similarity of 2,3-pentanedione to diacetyl (2,3-butanedione), which is responsible for bronchiolitis obliterans in popcorn workers, and the likeliness of lung effects in rodents, a mak value of 0.02\\xa0ml/m3 is set in analogy to diacetyl. as the critical effect is systemic, 2,3-pentanedione is assigned to peak limitation category ii. the excursion factor of 1 is set in analogy to diacetyl. skin contact may contribute significantly to systemic toxicity and 2,3-pentanedione is designated with an \u201ch\u201d. in analogy to diacetyl, skin sensitization (sh) is expected but not airway sensitization. because there are no studies on developmental toxicity, the substance is assigned to pregnancy risk group d. 2,3-pentanedione is neither genotoxic nor carcinogenic. \\n \\n \\nkeywords: \\n \\n2,3-pentandion; \\nacetylpropionyl; \\nwirkungsmechanismus; \\ntoxikokinetik; \\nmetabolismus; \\n(sub)akute toxizitat; \\n(sub)chronische toxizitat; \\nreizwirkung; \\nallergene wirkung; \\ngenotoxizitat; \\nspitzenbegrenzung; \\nfruchtschadigende wirkung; \\nkrebserzeugende wirkung; \\nkeimzellmutagene wirkung; \\nhautresorption; \\nsensibilisierende wirkung; \\narbeitsstoff; \\nmaximale arbeitsplatzkonzentration; \\nmak-wert; \\ntoxizitat; \\ngefahrstoff"
        },
        {
            "id": "R144086",
            "label": "A cationic fluorescent polymeric thermometer for the ratiometric sensing of intracellular temperature",
            "doi": "10.1039/c5an00420a",
            "research_field": {
                "id": "R130",
                "label": "Physical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R144063",
                    "label": "Nanothermometer"
                }
            ],
            "abstract": "the temperature-dependent fluorescence spectra of a new polymeric thermometer enabled highly sensitive and practical ratiometric temperature sensing inside mammalian cells."
        },
        {
            "id": "R110813",
            "label": "Resveratrol loaded polymeric micelles for theranostic targeting of breast cancer cells",
            "doi": "10.7150/ntno.51955",
            "research_field": {
                "id": "R67",
                "label": "Medicinal Chemistry and Pharmaceutics"
            },
            "research_problems": [
                {
                    "id": "R3070",
                    "label": "Breast cancer"
                },
                {
                    "id": "R110161",
                    "label": "Polymeric nanoparticles for cancer treatment"
                }
            ],
            "abstract": "treatment of breast cancer underwent extensive progress in recent years with molecularly targeted therapies. however, non-specific pharmaceutical approaches (chemotherapy) persist, inducing severe side-effects. phytochemicals provide a promising alternative for breast cancer prevention and treatment. specifically, resveratrol (res) is a plant-derived polyphenolic phytoalexin with potent biological activity but displays poor water solubility, limiting its clinical use. here we have developed a strategy for delivering res using a newly synthesized nano-carrier with the potential for both diagnosis and treatment. methods: res-loaded nanoparticles were synthesized by the emulsion method using pluronic f127 block copolymer and vitamin e-tpgs. nanoparticle characterization was performed by sem and tunable resistive pulse sensing. encapsulation efficiency (ee%) and drug loading (dl%) content were determined by analysis of the supernatant during synthesis. nanoparticle uptake kinetics in breast cancer cell lines mcf-7 and mda-mb-231 as well as in mcf-10a breast epithelial cells were evaluated by flow cytometry and the effects of res on cell viability via mtt assay. results: res-loaded nanoparticles with spherical shape and a dominant size of 179\u00b122 nm were produced. res was loaded with high ee of 73\u00b10.9% and dl content of 6.2\u00b10.1%. flow cytometry revealed higher uptake efficiency in breast cancer cells compared to the control. an mtt assay showed that res-loaded nanoparticles reduced the viability of breast cancer cells with no effect on the control cells. conclusions: these results demonstrate that the newly synthesized nanoparticle is a good model for the encapsulation of hydrophobic drugs. additionally, the nanoparticle delivers a natural compound and is highly effective and selective against breast cancer cells rendering this type of nanoparticle an excellent candidate for diagnosis and therapy of difficult to treat mammary malignancies."
        },
        {
            "id": "R137698",
            "label": "Low dietary fiber promotes enteric expansion of a Crohn's disease-associated pathobiont independent of obesity.",
            "doi": "10.1152/ajpendo.00134.2021",
            "research_field": {
                "id": "R84",
                "label": "Food Microbiology"
            },
            "research_problems": [
                {
                    "id": "R137697",
                    "label": "['Effect of low dietry fiber on Crohn\u00b4s disease']"
                }
            ],
            "abstract": "it is commonly thought that obesity or a high-fat diet alters pathogenic bacteria and promotes inflammatory gut diseases. we found that lower dietary fiber is a key factor that expands a gut pathobiont linked to crohn\u2019s disease, independent of obesity status in mice."
        },
        {
            "id": "R201315",
            "label": "Motion capture from inertial sensing for untethered humanoid teleoperation",
            "doi": "10.1109/ICHR.2004.1442670",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we describe the design of a modular system for untethered real-time kinematic motion capture using sensors with inertial measuring units (imu). our system is comprised of a set of small and lightweight sensors. each sensor provides its own global orientation (3 degrees of freedom) and is physically and computationally independent, requiring only external communication. orientation information from sensors is communicated via wireless to host computer for processing. we present results of the real-time usage of our untethered motion capture system for teleoperating the nasa robonaut. we also discuss potential applications for untethered motion capture with respect to humanoid robotics."
        },
        {
            "id": "R194718",
            "label": "MQALD: Evaluating the impact of modifiers in question answering over knowledge graphs",
            "doi": "10.3233/sw-210440",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R165792",
                    "label": "question answering for knowledge graphs"
                }
            ],
            "abstract": "question answering (qa) over knowledge graphs (kg) aims to develop a system that is capable of answering users\u2019 questions using the information coming from one or multiple knowledge graphs, like dbpedia, wikidata, and so on. question answering systems need to translate the user\u2019s question, written using natural language, into a query formulated through a specific data query language that is compliant with the underlying kg. this translation process is already non-trivial when trying to answer simple questions that involve a single triple pattern. it becomes even more troublesome when trying to cope with questions that require modifiers in the final query, i.e., aggregate functions, query forms, and so on. the attention over this last aspect is growing but has never been thoroughly addressed by the existing literature. starting from the latest advances in this field, we want to further step in this direction. this work aims to provide a publicly available dataset designed for evaluating the performance of a qa system in translating articulated questions into a specific data query language. this dataset has also been used to evaluate three qa systems available at the state of the art."
        },
        {
            "id": "R78124",
            "label": "Serial interval of novel coronavirus (COVID-19) infections",
            "doi": "",
            "research_field": {
                "id": "R12",
                "label": "Life Sciences"
            },
            "research_problems": [
                {
                    "id": "R78054",
                    "label": "Covid-19_Infectious Disease"
                }
            ],
            "abstract": "abstract objective to estimate the serial interval of novel coronavirus (covid-19) from information on 28 infector-infectee pairs. methods we collected dates of illness onset for primary cases (infectors) and secondary cases (infectees) from published research articles and case investigation reports. we subjectively ranked the credibility of the data and performed analyses on both the full dataset ( n =28) and a subset of pairs with highest certainty in reporting ( n =18). in addition, we adjusting for right truncation of the data as the epidemic is still in its growth phase. results accounting for right truncation and analyzing all pairs, we estimated the median serial interval at 4.0 days (95% credible interval [cri]: 3.1, 4.9). limiting our data to only the most certain pairs, the median serial interval was estimated at 4.6 days (95% cri: 3.5, 5.9). conclusions the serial interval of covid-19 is shorter than its median incubation period. this suggests that a substantial proportion of secondary transmission may occur prior to illness onset. the covid-19 serial interval is also shorter than the serial interval of severe acute respiratory syndrome (sars), indicating that calculations made using the sars serial interval may introduce bias. highlights - the serial interval of novel coronavirus (covid-19) infections was estimated from a total of 28 infector-infectee pairs. - the median serial interval is shorter than the median incubation period, suggesting a substantial proportion of pre-symptomatic transmission. - a short serial interval makes it difficult to trace contacts due to the rapid turnover of case generations."
        },
        {
            "id": "R75895",
            "label": "Exploring Deep Multimodal Fusion of Text and Photo for Hate Speech Classification",
            "doi": "10.18653/v1/W19-3502",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R75890",
                    "label": "hate speech detection"
                },
                {
                    "id": "R75891",
                    "label": "multimodal hate speech detection"
                }
            ],
            "abstract": "interactions among users on social network platforms are usually positive, constructive and insightful. however, sometimes people also get exposed to objectionable content such as hate speech, bullying, and verbal abuse etc. most social platforms have explicit policy against hate speech because it creates an environment of intimidation and exclusion, and in some cases may promote real-world violence. as users\u2019 interactions on today\u2019s social networks involve multiple modalities, such as texts, images and videos, in this paper we explore the challenge of automatically identifying hate speech with deep multimodal technologies, extending previous research which mostly focuses on the text signal alone. we present a number of fusion approaches to integrate text and photo signals. we show that augmenting text with image embedding information immediately leads to a boost in performance, while applying additional attention fusion methods brings further improvement."
        },
        {
            "id": "R195176",
            "label": "Bi-bimodal Modality Fusion for Correlation-Controlled Multimodal Sentiment Analysis",
            "doi": "10.1145/1122445.1122456",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R140853",
                    "label": "Determining Sentiment Intensity"
                },
                {
                    "id": "R127504",
                    "label": "Humor Detection"
                }
            ],
            "abstract": "recently, generative adversarial networks (gans) have received enormous progress, which makes them able to learn complex data distributions in particular faces. more and more efficient gan architectures have been designed and proposed to learn the different variations of faces, such as cross pose, age, expression and style. these gan based approaches need to be reviewed, discussed, and categorized in terms of architectures, applications, and metrics. several reviews that focus on the use and advances of gan in general have been proposed. however, the gan models applied to the face, that we call facial gans, have never been addressed. in this article, we review facial gans and their different applications. we mainly focus on architectures, problems and performance evaluation with respect to each application and used datasets. more precisely, we reviewed the progress of architectures and we discussed the contributions and limits of each. then, we exposed the encountered problems of facial gans and proposed solutions to handle them. additionally, as gans evaluation has become a notable current defiance, we investigate the state of the art quantitative and qualitative evaluation metrics and their applications. we concluded the article with a discussion on the face generation challenges and proposed open research issues."
        },
        {
            "id": "R170949",
            "label": "Development of a Comprehensive Hospital-Based Elder Abuse Intervention: An Initial Systematic Scoping Review",
            "doi": "10.1371/journal.pone.0125105",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction elder abuse, a universal human rights problem, is associated with many negative consequences. in most jurisdictions, however, there are no comprehensive hospital-based interventions for elder abuse that address the totality of needs of abused older adults: psychological, physical, legal, and social. as the first step towards the development of such an intervention, we undertook a systematic scoping review. objectives our primary objective was to systematically extract and synthesize actionable and applicable recommendations for components of a multidisciplinary intersectoral hospital-based elder abuse intervention. a secondary objective was to summarize the characteristics of the responses reviewed, including methods of development and validation. methods the grey and scholarly literatures were systematically searched, with two independent reviewers conducting the title, abstract and full text screening. documents were considered eligible for inclusion if they: 1) addressed a response (e.g., an intervention) to elder abuse, 2) contained recommendations for responding to abused older adults with potential relevance to a multidisciplinary and intersectoral hospital-based elder abuse intervention; and 3) were available in english. analysis the extracted recommendations for care were collated, coded, categorized into themes, and further reviewed for relevancy to a comprehensive hospital-based response. characteristics of the responses were summarized using descriptive statistics. results 649 recommendations were extracted from 68 distinct elder abuse responses, 149 of which were deemed relevant and were categorized into 5 themes: initial contact; capacity and consent; interview with older adult, caregiver, collateral contacts, and/or suspected abuser; assessment: physical/forensic, mental, psychosocial, and environmental/functional; and care plan. only 6 responses had been evaluated, suggesting a significant gap between development and implementation of recommendations. discussion to address the lack of evidence to support the recommendations extracted in this review, in a future study, a group of experts will formally evaluate each recommendation for its inclusion in a comprehensive hospital-based response."
        },
        {
            "id": "R171386",
            "label": "Is there a correlation between socioeconomic disparity and functional outcome after acute ischemic stroke?",
            "doi": "10.1371/journal.pone.0181196",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background to investigate the impact of low socioeconomic status (ses), indicated by low level of education, occupation and income, on 3 months functional outcome after ischemic stroke. methods we analyzed data from the china national stroke registry (cnsr), a multicenter and prospective registry of consecutive patients with acute cerebrovascular events occurred between september 2007 and august 2008. 11226 patients with ischemic stroke had ses and clinical characteristics data collected at baseline and mrs measured as indicator of functional outcome in 3 months follow up. multinomial and ordinal logistic regression models were performed to examine associations between ses and the functional outcome. results at 3 months after stroke, 5.3% of total patients had mrs scored at 5, 11.3% at score 4, 11.1% at score 3, 14.4% at score 2, 34.2% at score 1 and 23.7% at score 0. compared to patients with educational level of \u2265 6 years and non-manual laboring, those < 6 years and manual laboring tended to have higher mrs score (p<0.001). multinomial adjusted odds ratios (ors) of outcome in manual workers were significantly increased (ors from1.38 to 1.87), but or in patients with less income was not significant. there were similar patterns of association the impact may be stronger in patients aged <65 years (p = 0.003, p<0.001 respectively) and being male (p = 0.001, p<0.001 respectively). conclusions our study provides evidence that people who are relatively more deprived in socioeconomic status suffer poorer outcome after ischemic stroke. the influence of low educational level and manual laboring can be more intensive than low income level on 3-month outcome. health policy and service should target the deprived populations to reduce the public health burden in the society."
        },
        {
            "id": "R136019",
            "label": "Ontology-based E-learning Content Recommender System for Addressing the Pure Cold-start Problem",
            "doi": "10.1145/3429251",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R69628",
                    "label": "Recommender Systems"
                },
                {
                    "id": "R136028",
                    "label": "Cold-start Problem"
                }
            ],
            "abstract": "e-learning recommender systems are gaining significance nowadays due to its ability to enhance the learning experience by providing tailor-made services based on learner preferences. a personalized learning environment (ple) that automatically adapts to learner characteristics such as learning styles and knowledge level can recommend appropriate learning resources that would favor the learning process and improve learning outcomes. the pure cold-start problem is a relevant issue in ples, which arises due to the lack of prior information about the new learner in the ple to create appropriate recommendations. this article introduces a semantic framework based on ontology to address the pure cold-start problem in content recommenders. the ontology encapsulates the domain knowledge about the learners as well as learning objects (los). the semantic model that we built has been experimented with different combinations of the key learner parameters such as learning style, knowledge level, and background knowledge. the proposed framework utilizes these parameters to build natural learner groups from the learner ontology using sparql queries. the ontology holds 480 learners\u2019 data, 468 annotated learning objects with 5,600 learner ratings. a multivariate k-means clustering algorithm, an unsupervised machine learning technique for grouping similar data, is used to evaluate the learner similarity computation accuracy. the learner satisfaction achieved with the proposed model is measured based on the ratings given by the 40 participants of the experiments. from the evaluation perspective, it is evident that 79% of the learners are satisfied with the recommendations generated by the proposed model in pure cold-start condition."
        },
        {
            "id": "R185333",
            "label": "Mechanisms Underlying Interferon-\u00ce\u00b3-Induced Priming of Microglial Reactive Oxygen Species Production",
            "doi": "10.1371/journal.pone.0162497",
            "research_field": {
                "id": "R71",
                "label": "Cellular and Molecular Physiology"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "microglial priming and enhanced reactivity to secondary insults cause substantial neuronal damage and are hallmarks of brain aging, traumatic brain injury and neurodegenerative diseases. it is, thus, of particular interest to identify mechanisms involved in microglial priming. here, we demonstrate that priming of microglia with interferon-\u03b3 (ifn \u03b3) substantially enhanced production of reactive oxygen species (ros) following stimulation of microglia with atp. priming of microglial ros production was substantially reduced by inhibition of p38 mapk activity with sb203580, by increases in intracellular glutathione levels with n-acetyl-l-cysteine, by blockade of nadph oxidase subunit nox2 activity with gp91ds-tat or by inhibition of nitric oxide production with l-name. together, our data indicate that priming of microglial ros production involves reduction of intracellular glutathione levels, upregulation of nadph oxidase subunit nox2 and increases in nitric oxide production, and suggest that these simultaneously occurring processes result in enhanced production of neurotoxic peroxynitrite. furthermore, ifn\u03b3-induced priming of microglial ros production was reduced upon blockade of kir2.1 inward rectifier k+ channels with ml133. inhibitory effects of ml133 on microglial priming were mediated via regulation of intracellular glutathione levels and nitric oxide production. these data suggest that microglial kir2.1 channels may represent novel therapeutic targets to inhibit excessive ros production by primed microglia in brain pathology."
        },
        {
            "id": "R170680",
            "label": "Chimpanzees Show a Developmental Increase in Susceptibility to Contagious Yawning: A Test of the Effect of Ontogeny and Emotional Closeness on Yawn Contagion",
            "doi": "10.1371/journal.pone.0076266",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "contagious yawning has been reported for humans, dogs and several non-human primate species, and associated with empathy in humans and other primates. still, the function, development and underlying mechanisms of contagious yawning remain unclear. humans and dogs show a developmental increase in susceptibility to yawn contagion, with children showing an increase around the age of four, when also empathy-related behaviours and accurate identification of others\u2019 emotions begin to clearly evince. explicit tests of yawn contagion in non-human apes have only involved adult individuals and examined the existence of conspecific yawn contagion. here we report the first study of heterospecific contagious yawning in primates, and the ontogeny of susceptibility thereto in chimpanzees, pan troglodytes verus. we examined whether emotional closeness, defined as attachment history with the yawning model, affected the strength of contagion, and compared the contagiousness of yawning to nose-wiping. thirty-three orphaned chimpanzees observed an unfamiliar and familiar human (their surrogate human mother) yawn, gape and nose-wipe. yawning, but not nose-wiping, was contagious for juvenile chimpanzees, while infants were immune to contagion. like humans and dogs, chimpanzees are subject to a developmental trend in susceptibility to contagious yawning, and respond to heterospecific yawn stimuli. emotional closeness with the model did not affect contagion. the familiarity-biased social modulatory effect on yawn contagion previously found among some adult primates, seem to only emerge later in development, or be limited to interactions with conspecifics. the influence of the \u2018chameleon effect\u2019, targeted vs. generalised empathy, perspective-taking and visual attention on contagious yawning is discussed."
        },
        {
            "id": "R195995",
            "label": "Requirements Capture and Analysis in ASSERT(TM)",
            "doi": "10.1109/re.2017.54",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "capturing high-level requirements in a human readable but formal representation suitable for analysis is an important goal for ge. to that end we have augmented an existing controlled-english modeling language with a new controlled-english requirements capture language to create the requirements capture frontend of the assert(tm) tool suite. requirements captured in assert can be analyzed for a number of possible shortcomings, both individually and collectively. once a set of requirements has reached a satisfactory level of completeness, consistency, etc., it can then be further used to generate test cases and test procedures. this paper will focus on the requirements capture and analysis functions of assert and will illustrate its capabilities with a sample problem previously used as a challenge problem for requirements specification."
        },
        {
            "id": "R109777",
            "label": "Sta\u00ef\u00ac\u0080 Shortage in German Intensive Care Units During the COVID-19 Pandemic - Not only a Sensed Dilemma: Results from a Nationwide Survey",
            "doi": "10.21203/rs.3.rs-323586/v1",
            "research_field": {
                "id": "R359",
                "label": "Medicine and Health"
            },
            "research_problems": [
                {
                    "id": "R109781",
                    "label": "Healthcare staff shortage"
                },
                {
                    "id": "R109783",
                    "label": "COVID-19"
                },
                {
                    "id": "R109784",
                    "label": "Nursing shortage"
                }
            ],
            "abstract": "abstract \\n background : the surge in patients during the covid-19 pandemic has exacerbated the looming problem of sta\ufb00 shortage in german icus possibly leading to worse outcomes for patients. methods : within the german evidence ecosystem ceosys network, we conducted an online national mixed-methods survey assessing the standard of care in german icus treating patients with covid-19. results : a total of 171 german icus reported a median ideal number of patients per intensivist of 8 (interquartile range, iqr = 3rd quartile - 1st quartile = 4.0) and per nurse of 2.0 (iqr = 1.0). for covid-19 patients, the median target was a maximum of 6.0 (iqr = 2.0) patients per intensivist or 2.0 (iqr = 0.0) patients per nurse. targets for intensivists were rarely met by 15.2% and never met by 3.5% of responding institutions. targets for nursing sta\ufb03ng could rarely be met in 32.2% and never in 5.3% of responding institutions. conclusions : shortages of sta\ufb03ng in the critical care setting are eminent during the covid-19 pandemic and might not only negatively a\ufb00ect patient outcomes, but also sta\ufb00 wellbeing and healthcare costs. a joint e\ufb00ort that scrutinizes the demands and structures of our health care system seems fundamental to be prepared for the future."
        },
        {
            "id": "R187780",
            "label": "The Impact of Open-Access Status on Journal Indices: Respiratory and Pulmonology Journals",
            "doi": "10.2174/1573398x15666190214154531",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R187776",
                    "label": "Impact of open access on publication volume"
                }
            ],
            "abstract": "\\n background: \\n open access (oa) publishing is rapidly emerging in almost all disciplines,\\nwith variable intensity and effect on the discipline itself. the move toward oa is also observed in the\\nfield of respiratory and pulmonology, where both oa data repositories and oa journals are rapidly\\nemerging. \\n \\n \\n objective: \\n we aim to study the open-access status of respiratory and pulmonology journals and the\\nimpact of the open-access status on journal indices. \\n \\n \\n methods: \\n we collected journal\u2019s data from scopus source list on 1st of november 2018. we filtered\\nthe list for respiratory and pulmonology journals. open access journals covered by scopus are\\nrecognized as open access if the journal is listed in the directory of open access journals (doaj)\\nand/or the directory of open access scholarly resources (road). for each journal, we used\\nseveral metrics to measure its strength, and then we compared these metrics between oa and non-\\noa journals. \\n \\n \\n results: \\n there were 125 respiratory and pulmonology journals, a number that has increased by\\n12.6% since 2011. moreover, the percentage of oa journals has increased from 21.6% to 26.4%\\nduring the same period. non-oa journals have significantly higher scholarly output (p= 0.033), but\\noa journals have significantly higher percentage of citation (p= 0.05). \\n \\n \\n conclusion: \\n publishing in oa journals will yield a higher citation percentage compared to non-oa\\njournals. although this should not be the only reason to publish in an oa journal, it is still an\\nimportant factor to decide where to publish. \\n"
        },
        {
            "id": "R170752",
            "label": "Is Financial Hardship Associated with Reduced Health in Disability? The Case of Spinal Cord Injury in Switzerland",
            "doi": "10.1371/journal.pone.0090130",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective to investigate socioeconomic inequalities in a comprehensive set of health indicators among persons with spinal cord injury in a wealthy country, switzerland. methods observational cross-sectional data from 1549 participants of the swiss spinal cord injury cohort study (swisci), aged over 16 years, and living in switzerland were analyzed. socioeconomic circumstances were operationalized by years of formal education, net equivalent household income and financial hardship. health indicators including secondary conditions, comorbidities, pain, mental health, participation and quality of life were used as outcomes. associations between socioeconomic circumstances and health indicators were evaluated using ordinal regressions. results financial hardship was consistently associated with more secondary conditions (or 3.37, 95% ci 2.18\u20135.21), comorbidities (or 2.88, 95% ci 1.83\u20134.53) and pain (or 3.32, 95% ci 2.21\u20134.99), whereas mental health (or 0.23, 95% ci 0.15\u20130.36), participation (or 0.30, 95% ci 0.21\u20130.43) and quality of life (or 0.22, 95% ci 0.15\u20130.33) were reduced. persons with higher education reported better mental health (or 1.04, 95% ci 1.00\u20131.07) and higher quality of life (or 1.06, 95% ci 1.02\u20131.09); other health indicators were not associated with education. household income was not related to any of the studied health indicators when models were controlled for financial hardship. conclusions suffering from financial hardship goes along with significant reductions in physical health, functioning and quality of life, even in a wealthy country with comprehensive social and health policies."
        },
        {
            "id": "R200049",
            "label": "Assessment of risk perception in security requirements composition",
            "doi": "10.1109/re.2015.7320417",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"security requirements analysis depends on how well-trained analysts perceive security risk, understand the impact of various vulnerabilities, and mitigate threats. when systems are composed of multiple machines, configurations, and software components that interact with each other, risk perception must account for the composition of security requirements. in this paper, we report on how changes to security requirements affect analysts risk perceptions and their decisions about how to modify the requirements to reach adequate security levels. we conducted two user surveys of 174 participants wherein participants assess security levels across 64 factorial vignettes. we analyzed the survey results using multi-level modeling to test for the effect of security requirements composition on participants' overall security adequacy ratings and on their ratings of individual requirements. we accompanied this analysis with grounded analysis of elicited requirements aimed at lowering the security risk. our results suggest that requirements composition affects experts' adequacy ratings on security requirements. in addition, we identified three categories of requirements modifications, called refinements, replacements and reinforcements, and we measured how these categories compare with overall perceived security risk. finally, we discuss the future impact of our work in security requirements assessment practice.\""
        },
        {
            "id": "R150069",
            "label": "Contemporary factors influencing association conference attendance",
            "doi": "10.1080/15470148.2020.1719948",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "R150072",
                    "label": "Identify factors influencing conference attendance"
                }
            ],
            "abstract": "abstract competition amongst conference tourism destinations has intensified. understanding the factors influencing delegate attendance thus becomes increasingly important. this paper aims to extend the current body of academic knowledge by examining motivators and inhibitors deriving from not only previous academic research but also contemporary industry reports. delegate expectations relating to new and established factors influencing conference attendance are explored, while motivating and inhibiting factors are ranked in order of importance. proactive management and organization responses to these factors are proposed. the research findings are important to destination managers in prioritizing the investment of their limited resources aiming to address the higher-importance factors. this allows such destinations to improve in their competitiveness in attracting conference tourism and conference delegates."
        },
        {
            "id": "R170549",
            "label": "Associations and Impact Factors between Living Arrangements and Functional Disability among Older Chinese Adults",
            "doi": "10.1371/journal.pone.0053879",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives to examine the association of living arrangements with functional disability among older persons and explore the mediation of impact factors on the relationship. design cross-sectional analysis using data from healthy aging study in zhejiang province. participants analyzed sample was drawn from a representative rural population of older persons in wuyi county, zhejiang province, including 1542 participants aged 60 and over in the second wave of the study. measurements living arrangements, background, functional disability, self-rated health, number of diseases, along with contemporaneous circumstances including income, social support (physical assistance and emotional support). instrument was activities of daily living (adl) scale, including basic activities daily living (badl) and instrumental activities of daily living (iadl). results living arrangements were significantly associated with badl, iadl and adl disability. married persons living with or without children were more advantaged on all three dimensions of functional disability. unmarried older adults living with children only had the worst functional status, even after controlling for background, social support, income and health status variables (compared with the unmarried living alone, \u00df for badl: \u22121.262, \u00df for iadl: \u22122.112, \u00df for adl: \u22123.388; compared with the married living with children only, \u00df for badl: \u22121.166, \u00df for iadl: \u22122.723, \u00df for adl: \u22123.902). in addition, older adults without difficulty in receiving emotional support, in excellent health and with advanced age had significantly better badl, iadl and adl function. however, a statistically significant association between physical assistance and functional disability was not found. conclusion functional disabilities vary by living arrangements with different patterns and other factors. our results highlight the association of unmarried elders living with children only and functioning decline comparing with other types. our study implies policy makers should pay closer attention to unmarried elders living with children in community. community service especially emotional support such as psychological counseling is important social support and should be improved."
        },
        {
            "id": "R191297",
            "label": "Publicly Available Clinical BERT Embeddings",
            "doi": "10.18653/v1/W19-1909",
            "research_field": {
                "id": "R238",
                "label": "Biomedical"
            },
            "research_problems": [
                {
                    "id": "R140304",
                    "label": "Representation Learning on Biomedical Data"
                },
                {
                    "id": "R191274",
                    "label": "Representation Learning"
                }
            ],
            "abstract": "contextual word embedding models such as elmo and bert have dramatically improved performance for many natural language processing (nlp) tasks in recent months. however, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained bert models yet exist. in this work, we address this need by exploring and releasing bert models for clinical text: one for generic clinical text and another for discharge summaries specifically. we demonstrate that using a domain-specific model yields performance improvements on 3/5 clinical nlp tasks, establishing a new state-of-the-art on the mednli dataset. we find that these domain-specific models are not as performant on 2 clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text."
        },
        {
            "id": "R209488",
            "label": "Ontology Development towards Expressive and Reasoning-enabled Building Information Model for an Intelligent Energy Management System",
            "doi": "10.5220/0004540300380047",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in recent years, energy consumption in buildings has been rising and is currently representing a significant percentage of the whole energy consumption on earth. the eu has responded this trend by requiring zero energy consumption by 2020 and by supporting innovative research approaches for improving energy efficiency in buildings without decreasing inhabitants comfort. this paper describes the approach to develop an intelligent system for building specific energy management that allows occupants and facility managers to monitor and control the energy consumption and also detects their wasting points. an ontology based information model for building energy management offering expressive representation and reasoning capability is also introduced in this paper. we highlight an approach to develop the ontology as the knowledge base providing the intelligence of the system. furthermore we demonstrate how the energy performance analysis is improved using the ontology based approach."
        },
        {
            "id": "R139377",
            "label": "Stable Cu2O nanocrystals grown on functionalized graphene sheets and room temperature H2S gas sensing with ultrahigh sensitivity",
            "doi": "10.1039/c2nr33164k",
            "research_field": {
                "id": "R123",
                "label": "Analytical Chemistry"
            },
            "research_problems": [
                {
                    "id": "R139327",
                    "label": "Chemical sensors"
                }
            ],
            "abstract": "stable cu(2)o nanocrystals of around 3 nm were uniformly and densely grown on functionalized graphene sheets (fgs), which act as molecular templates instead of surfactants for controlled nucleation; the distribution density of nanocrystals can be easily controlled by fgs with different c/o ratios. the nanocomposite displays improved stability of the crystalline phase in wet air, which is attributed to finite-size effects that the high-symmetry crystalline phase is to be more stable at smaller size. meanwhile, we conjecture that the oxygen adsorbed on the interfacial surface prefers to extract electrons from fgs, thus the interfacial bonding also makes a contribution in alleviating the process of corrosion to some extent. more importantly, the cu(2)o-fgs nanocomposite based sensor realizes room temperature sensing to h(2)s with fantastic sensitivity (11%); even at the exposed concentration of 5 ppb, the relative resistance changes show good linearity with the logarithm of the concentration. the enhancement of sensitivity is attributed to the synergistic effect of cu(2)o and fgs; on the one hand, surfactant-free capped cu(2)o nanocrystals display higher surface activity to adsorb gas molecules, and on the other hand, fgs acting as conducting network presents greater electron transfer efficiency. these observations show that the cu(2)o-fgs nanocomposite based sensors have potential applications for monitoring air pollution at room temperature with low cost and power consumption."
        },
        {
            "id": "R171681",
            "label": "The neuroelectric dynamics of the emotional anticipation of other people\u00e2\u0080\u0099s pain",
            "doi": "10.1371/journal.pone.0200535",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "when we observe a dynamic emotional facial expression, we usually automatically anticipate how that expression will develop. our objective was to study a neurocognitive biomarker of this anticipatory process for facial pain expressions, operationalized as a mismatch effect. for this purpose, we studied the behavioral and neuroelectric (event-related potential, erp) correlates, of a match or mismatch, between the intensity of an expression of pain anticipated by the participant, and the intensity of a static test expression of pain displayed with the use of a representational momentum paradigm. here, the paradigm consisted in displaying a dynamic facial pain expression which suddenly disappeared, and participants had to memorize the final intensity of the dynamic expression. we compared erps in response to congruent (intensity the same as the one memorized) and incongruent (intensity different from the one memorized) static expression intensities displayed after the dynamic expression. this paradigm allowed us to determine the amplitude and direction of this intensity anticipation by measuring the observer\u2019s memory bias. results behaviorally showed that the anticipation was backward (negative memory bias) for high intensity expressions of pain (participants expected a return to a neutral state) and more forward (memory bias less negative, or even positive) for less intense expressions (participants expected increased intensity). detecting mismatch (incongruent intensity) led to faster responses than detecting match (congruent intensity). the neuroelectric correlates of this mismatch effect in response to the testing of expression intensity ranged from p100 to lpp (late positive potential). path analysis and source localization suggested that the medial frontal gyrus was instrumental in mediating the mismatch effect through top-down influence on both the occipital and temporal regions. moreover, having the facility to detect incongruent expressions, by anticipating emotional state, could be useful for prosocial behavior and the detection of trustworthiness."
        },
        {
            "id": "R74412",
            "label": "Supporting openness of MOOCs contents through of an OER and OCW framework based on Linked Data technologies",
            "doi": "10.1109/EDUCON.2014.6826249",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74397",
                    "label": "Linked Data Interoperability"
                },
                {
                    "id": "R109063",
                    "label": "Linked Data Interoperability"
                }
            ],
            "abstract": "the arrival of massive open online courses (moocs) and the growth of open and online education - open educational resources (oer), opencourseware (ocw)- is increasingly the focus to self-learners as the primary target group. the oer movement has tended to define \u201copenness\u201d in terms of access for use and reuse to educational materials, and to address the geographical and financial barriers, between students, teachers and self-learners with distinguished educational institutions. mooc initiatives emphasize free access and interactive features rather than static content. the dominant message is of the quantity of access rather than the openness of educational resources for use, re-use, adaptation or repurpose. the purpose of this paper is to present the main aspects to considerer building a framework based on semantic web technologies to support the inclusion of open materials in massive online courses and significantly to improve discovery, accessibility, visibility, and to promote reuse of open educational content in massive courses. this framework will provide a set of services that allows the discovery and access of open educational resources that are extracted from open repositories distributed. our principal oer providers are ocw institutions. in this context, we opted to apply the principles of linked data to integrate, interoperate and mashup data from distributed and heterogeneous repositories of open educational materials."
        },
        {
            "id": "R168902",
            "label": "Quantification of Leishmania (Viannia) Kinetoplast DNA in Ulcers of Cutaneous Leishmaniasis Reveals Inter-site and Inter-sampling Variability in Parasite Load",
            "doi": "10.1371/journal.pntd.0003936",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background cutaneous leishmaniasis (cl) is a skin disease caused by the protozoan parasite leishmania. few studies have assessed the influence of the sample collection site within the ulcer and the sampling method on the sensitivity of parasitological and molecular diagnostic techniques for cl. sensitivity of the technique can be dependent upon the load and distribution of leishmania amastigotes in the lesion. methodology/principal findings we applied a quantitative real-time pcr (qpcr) assay for leishmania (viannia) minicircle kinetoplast dna (kdna) detection and parasite load quantification in biopsy and scraping samples obtained from 3 sites within each ulcer (border, base, and center) as well as in cytology brush specimens taken from the ulcer base and center. a total of 248 lesion samples from 31 patients with laboratory confirmed cl of recent onset (\u22643 months) were evaluated. the kdna-qpcr detected leishmania dna in 97.6% (242/248) of the examined samples. median parasite loads were significantly higher in the ulcer base and center than in the border in biopsies (p<0.0001) and scrapings (p = 0.0002). there was no significant difference in parasite load between the ulcer base and center (p = 0.80, 0.43, and 0.07 for biopsy, scraping, and cytology brush specimens, respectively). the parasite load varied significantly by sampling method: in the ulcer base and center, the descending order for the parasite load levels in samples was: cytology brushes, scrapings, and biopsies (p<0.0001); in the ulcer border, scrapings had higher parasite load than biopsies (p<0.0001). there was no difference in parasite load according to l. braziliensis and l. peruviana infections (p = 0.4). conclusion/significance our results suggest an uneven distribution of leishmania amastigotes in acute cl ulcers, with higher parasite loads in the ulcer base and center, which has implications for bedside collection of diagnostic specimens. the use of scrapings and cytology brushes is recommended instead of the more invasive biopsy."
        },
        {
            "id": "R110128",
            "label": "Mixed language usage in Belarus: the sociostructural background of language choice",
            "doi": "10.1515/ijsl.2010.048",
            "research_field": {
                "id": "R408",
                "label": "Slavic Languages and Societies"
            },
            "research_problems": [
                {
                    "id": "R110040",
                    "label": "mixed language in Belarus "
                }
            ],
            "abstract": "abstract this article reports findings from a survey on language usage in belarus, which encompasses bilingual belarusian and russian. first, the distribution of language usage is discussed. then the dependency of language usage on some sociocultural conditions is explored. finally, the changes in language usage over three generations are discussed. we find that a mixed belarusian\u2013russian form of speech is widely used in the cities studied and that it is spoken across all educational levels. however, it seems to be predominantly utilized in informal communication, especially among friends and family members, leaving russian and belarusian to more formal or public venues."
        },
        {
            "id": "R12100",
            "label": "Supervised models for multimodal image retrieval based on visual, semantic and geographic information",
            "doi": "10.1109/cbmi.2012.6269806",
            "research_field": {
                "id": "R234",
                "label": "Digital Communications and Networking"
            },
            "research_problems": [
                {
                    "id": "R12077",
                    "label": "Multimodal information retrieval"
                }
            ],
            "abstract": "nowadays, large-scale networked social media need better search technologies to achieve suitable performance. multimodal approaches are promising technologies to improve image ranking. this is particularly true when metadata are not completely reliable, which is a rather common case as far as user annotation, time and location are concerned. in this paper, we propose to properly combine visual information with additional multi-faceted information, to define a novel multimodal similarity measure. more specifically, we combine visual features, which strongly relate to the image content, with semantic information represented by manually annotated concepts, and geo tagging, very often available in the form of object/subject location. furthermore, we propose a supervised machine learning approach, based on support vector machines (svms), to automatically learn optimized weights to combine the above features. the resulting models is used as a ranking function to sort the results of a multimodal query."
        },
        {
            "id": "R196139",
            "label": "The Effect of Using Dictionary to Develop Students\u00e2\u0080\u0099 Vocabulary in MTs. Al- Musthofa",
            "doi": "10.2991/assehr.k.200427.036",
            "research_field": {
                "id": "R324",
                "label": "First/Second Language Acquisition"
            },
            "research_problems": [
                {
                    "id": "R196142",
                    "label": "Impact of a paper dictionary on vocabulary size growth"
                },
                {
                    "id": "R196148",
                    "label": "Dictionary users' enthusiasm when using dictionary"
                }
            ],
            "abstract": "language is a global area that has specific areas which one of them is called the vocabulary. vocabulary is not a skill in english but when we do not learn about the language we cannot reck. in language, vocabulary has the main role because vocabulary can be used in all language skills. vocabulary is one important knowledge in a language that has a beneficial role for learners in increasing their language ability [1]. vocabulary in language learning is very important and therefore it is needed to be taught to students. when some people learn about vocabulary, they automatically increasing their skills step by step because vocabulary is a tool to connect with all of the skills. according to viera (2017) \"vocabulary knowledge is an essential tool for any language skills\" which can be used to comprehend both written and spoken text [8]. vocabulary knowledge in the production of written texts: a case study on efl language learners.\" by using vocabulary our understanding of the writing and speaking will be clear enough. in this case, writing and speaking skills always consists of words. vocabulary focuses on the words, so that is why this is having an important role in all language skills. however, vocabulary is not only about to learn about the meaning of the words but we must also know about the function of the words when we must use the words in the good situation. if we know the meaning and the function of the words it can make people enjoy to express their ideas. while if the students are still confuse and have limitation on their vocabulary, it will make big problems. based on the viera cited in min, y.k (2017) if students have a good vocabularies knowledge in their mind, they can communicate easily, while without vocabulary knowledge, they cannot do effective communication [8]. from the explanation above, if someone still confuses about vocabulary it will affect to their speaking and writing ability. speaking and writing skills always appear in every activity especially for the students. not only that, if the students feel the vocabulary is difficult and always think harder, they can be not confident with their vocabulary. every student has a different vocabulary knowledge in their mind because they have the limitation. especially for the people as a foreign language that still have the limitation of vocabularies. as a foreign language, they still have difficulties in two aspects; meaning and function. those are will be a common problem the students learn about english especially for vocabulary. there are other problems, according to dellar h and hocking d, innovations, ltp states \"if you spend most of your time studying grammar, your english will not improve very much. you will see most improvement if you learn more words and expressions [7]. there are a lot of students that feel afraid when they learn english because they think english is always focused only on grammar. it is not true, because every skill needs vocabulary. nowadays, students need to solve the problem of their difficulty when they learn about vocabulary. there are a lot of treatments for efl students to decrease their misunderstanding when they learn about vocabulary. one of abstract\u2014learning vocabulary is not an easy thing"
        },
        {
            "id": "R194428",
            "label": "Predicting How to Test Requirements: An Automated Approach",
            "doi": "10.1109/re.2019.00023",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "an important task in requirements engineering is to identify and determine how to verify a requirement (e.g., by manual review, testing, or simulation; also called potential verification method). this information is required to effectively create test cases and verification plans for requirements. [objective] in this paper, we propose an automatic approach to classify natural language requirements with respect to their potential verification methods (pvm). [method] our approach uses a convolutional neural network architecture to implement a multiclass and multilabel classifier that assigns probabilities to a predefined set of six possible verification methods, which we derived from an industrial guideline. additionally, we implemented a backtracing approach to analyze and visualize the reasons for the network\u2019s decisions. [results] in a 10-fold cross validation on a set of about 27,000 industrial requirements, our approach achieved a macro averaged f1 score of 0.79 across all labels. for the classification into test or non-test, the approach achieves an even higher f1 score of 0.94. [conclusions] the results show that our approach might help to increase the quality of requirements specifications with respect to the pvm attribute and guide engineers in effectively deriving test cases and verification plans."
        },
        {
            "id": "R193718",
            "label": "Modelling compression with discourse constraints",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "sentence compression holds promise for many applications ranging from summarisation to subtitle generation and subtitle generation. the task is typically performed on isolated sentences without taking the surrounding context into account, even though most applications would operate over entire documents. in this paper we present a discourse informed model which is capable of producing document compressions that are coherent and informative. our model is inspired by theories of local coherence and formulated within the framework of integer linear programming. experimental results show significant improvements over a stateof-the-art discourse agnostic approach."
        },
        {
            "id": "R170542",
            "label": "Behavioral Abnormalities Observed in Zfhx2-Deficient Mice",
            "doi": "10.1371/journal.pone.0053114",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "zfhx2 (also known as zfh-5) encodes a transcription factor containing three homeobox domains and 18 zn-finger motifs. we have reported that zfhx2 mrna is expressed mainly in differentiating neurons in the mouse brain and its expression level is negatively regulated by the antisense transcripts of zfhx2. although the expression profile of zfhx2 suggests that zfhx2 might have a role in a particular step of neuronal differentiation, the specific function of the gene has not been determined. we generated a zfhx2-deficient mouse line and performed a comprehensive battery of behavioral tests to elucidate the function of zfhx2. homozygous zfhx2-deficient mice showed several behavioral abnormalities, namely, hyperactivity, enhanced depression-like behaviors, and an aberrantly altered anxiety-like phenotype. these behavioral phenotypes suggest that zfhx2 might play roles in controlling emotional aspects through the function of monoaminergic neurons where zfhx2 is expressed. moreover, considering their phenotypes, the zfhx2-deficient mice may provide a novel model of human psychiatric disorders."
        },
        {
            "id": "R169642",
            "label": "Profiling the Succession of Bacterial Communities throughout the Life Stages of a Higher Termite Nasutitermes arborum (Termitidae, Nasutitermitinae) Using 16S rRNA Gene Pyrosequencing",
            "doi": "10.1371/journal.pone.0140014",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "previous surveys of the gut microbiota of termites have been limited to the worker caste. termite gut microbiota has been well documented over the last decades and consists mainly of lineages specific to the gut microbiome which are maintained across generations. despite this intimate relationship, little is known of how symbionts are transmitted to each generation of the host, especially in higher termites where proctodeal feeding has never been reported. the bacterial succession across life stages of the wood-feeding higher termite nasutitermes arborum was characterized by 16s rrna gene deep sequencing. the microbial community in the eggs, mainly affiliated to proteobacteria and actinobacteria, was markedly different from the communities in the following developmental stages. in the first instar and last instar larvae and worker caste termites, proteobacteria and actinobacteria were less abundant than firmicutes, bacteroidetes, spirochaetes, fibrobacteres and the candidate phylum tg3 from the last instar larvae. most of the representatives of these phyla (except firmicutes) were identified as termite-gut specific lineages, although their relative abundances differed. the most salient difference between last instar larvae and worker caste termites was the very high proportion of spirochaetes, most of which were affiliated to the treponema ic, ia and if subclusters, in workers. the results suggest that termite symbionts are not transmitted from mother to offspring but become established by a gradual process allowing the offspring to have access to the bulk of the microbiota prior to the emergence of workers, and, therefore, presumably through social exchanges with nursing workers."
        },
        {
            "id": "R131642",
            "label": "MultiFiT: Efficient Multi-lingual Language Model Fine-tuning",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124044",
                    "label": "Cross-Lingual Document Classification"
                }
            ],
            "abstract": "pretrained language models are promising particularly for low-resource languages as they only require unlabelled data. however, training existing models requires huge amounts of compute, while pretrained cross-lingual models often underperform on low-resource languages. we propose multi-lingual language model fine-tuning (multifit) to enable practitioners to train and fine-tune language models efficiently in their own language. in addition, we propose a zero-shot method using an existing pretrained cross-lingual model. we evaluate our methods on two widely used cross-lingual classification datasets where they outperform models pretrained on orders of magnitude more data and compute. we release all models and code."
        },
        {
            "id": "R170013",
            "label": "Cluster-based analysis improves predictive validity of spike-triggered receptive field estimates",
            "doi": "10.1371/journal.pone.0183914",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "spectrotemporal receptive field (strf) characterization is a central goal of auditory physiology. strfs are often approximated by the spike-triggered average (sta), which reflects the average stimulus preceding a spike. in many cases, the raw sta is subjected to a threshold defined by gain values expected by chance. however, such correction methods have not been universally adopted, and the consequences of specific gain-thresholding approaches have not been investigated systematically. here, we evaluate two classes of statistical correction techniques, using the resulting strf estimates to predict responses to a novel validation stimulus. the first, more traditional technique eliminated strf pixels (time-frequency bins) with gain values expected by chance. this correction method yielded significant increases in prediction accuracy, including when the threshold setting was optimized for each unit. the second technique was a two-step thresholding procedure wherein clusters of contiguous pixels surviving an initial gain threshold were then subjected to a cluster mass threshold based on summed pixel values. this approach significantly improved upon even the best gain-thresholding techniques. additional analyses suggested that allowing threshold settings to vary independently for excitatory and inhibitory subfields of the strf resulted in only marginal additional gains, at best. in summary, augmenting reverse correlation techniques with principled statistical correction choices increased prediction accuracy by over 80% for multi-unit strfs and by over 40% for single-unit strfs, furthering the interpretational relevance of the recovered spectrotemporal filters for auditory systems analysis."
        },
        {
            "id": "R171459",
            "label": "Recurrence analysis of ant activity patterns",
            "doi": "10.1371/journal.pone.0185968",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in this study, we used recurrence quantification analysis (rqa) and recurrence plots (rps) to compare the movement activity of individual workers of three ant species, as well as a gregarious beetle species. rqa and rps quantify the number and duration of recurrences of a dynamical system, including a detailed quantification of signals that could be stochastic, deterministic, or both. first, we found substantial differences between the activity dynamics of beetles and ants, with the results suggesting that the beetles have quasi-periodic dynamics and the ants do not. second, workers from different ant species varied with respect to their dynamics, presenting degrees of predictability as well as stochastic signals. finally, differences were found among minor and major caste of the same (dimorphic) ant species. our results underscore the potential of rqa and rps in the analysis of complex behavioral patterns, as well as in general inferences on animal behavior and other biological phenomena."
        },
        {
            "id": "R137073",
            "label": "Selective, Nickel-Catalyzed Hydrogenolysis of Aryl Ethers",
            "doi": "10.1126/science.1200437",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R137056",
                    "label": "Activation of C-O bond"
                }
            ],
            "abstract": "a catalyst that cleaves aryl-oxygen bonds but not carbon-carbon bonds may help improve lignin processing."
        },
        {
            "id": "R8683",
            "label": "The Uncoordinated Potential of Libraries to Achieve Open Access Now: How the Transition to Open Access Could be Accelerated by Libraries Working Together",
            "doi": "10.12685/027.7-2-1-48",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R8686",
                    "label": "accelerate open access"
                },
                {
                    "id": "R8687",
                    "label": "transition to open access"
                },
                {
                    "id": "R8688",
                    "label": "collective action"
                }
            ],
            "abstract": "doi: 10.12685/027.7-2-1-48the last ten years have shown, that open access is not only a vision, but has become real. libraries are in a good position to push open access even further, as they currently fully pay the production costs of the traditional subscription model. scoap3 demonstrates that coordination among libraries is not unlikely and could lead to more open access immediately.die letzten zehn jahren haben gezeigt, dass open access nicht nur eine vision ist, sondern tats\u00e4chlich funktioniert. bibliotheken k\u00f6nnten open access ganz zum durchbruch verhelfen, da sie zurzeit vollst\u00e4ndig f\u00fcr die produktionskosten beim subskriptionsmodell aufkommen. scoap3 zeigt, dass die koordination zwischen bibliotheken m\u00f6glich ist und sofort zu mehr open access f\u00fchren kann."
        },
        {
            "id": "R169886",
            "label": "Validation of the International HIV Dementia Scale as a Screening Tool for HIV-Associated Neurocognitive Disorders in a German-Speaking HIV Outpatient Clinic",
            "doi": "10.1371/journal.pone.0168225",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background hiv-associated neurocognitive disorders (hand) are widely present among people living with hiv. especially its milder forms, asymptomatic neurocognitive impairment (ani) and mild neurocognitive disorder (mnd), remain highly prevalent worldwide. diagnosing these conditions is subject to a time and resource consuming neuropsychological assessment. selecting patients at a higher risk of cognitive impairment by using a simple but effective screening tool helps to organise access to further neuropsychological diagnosis. the international hiv dementia scale (ihds) has until now been a well-established screening tool in african and american countries, however these populations\u2019 demographics defer significantly from ours, so using the same parameters could be ineffective. objectives to calculate the prevalence of this condition among people attending an hiv outpatient clinic in berlin and to validate the use of the ihds as a screening tool for hand in a german-speaking population. methods we screened 480 hiv-infected patients using the ihds, 89% of them were on a stable antiretroviral treatment. ninety of them completed a standardised neuropsychological battery of tests and a specific cognitive complaints questionnaire. the same procedure was applied to a control group of 30 hiv-negative participants. hand diagnosis was established according to the frascati criteria. results the overall prevalence of hand in our cohort was 43% (20% ani, 17% mnd and 6% hiv-associated dementia). the optimal cut-off on the ihds for detecting hand cases was set at 11 and achieved both a sensitivity and a specificity of 80%. when specifically screening for the more severe form of hand, hiv-associated dementia, a cut-off value of 10 offered an increase in both sensitivity (94%) and specificity (86%). the youden index for diagnostic accuracy was 0.6 and 0.8, respectively. conclusions the prevalence of hand was comparable to the reported by recent studies performed in countries with a similar economic development. the study confirms the ihds to be a useful hand screening tool in primary care settings and establishes new recommendations for its use in german-speaking countries."
        },
        {
            "id": "R197698",
            "label": "UDPipe at SIGMORPHON 2019: Contextualized Embeddings, Regularization with Morphological Categories, Corpora Merging",
            "doi": "10.18653/v1/w19-4212",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R197685",
                    "label": "Contextual morphological analysis"
                }
            ],
            "abstract": "we present our contribution to the sigmorphon 2019 shared task: crosslinguality and context in morphology, task 2: contextual morphological analysis and lemmatization. we submitted a modification of the udpipe 2.0, one of best-performing systems of the conll 2018 shared task: multilingual parsing from raw text to universal dependencies and an overall winner of the the 2018 shared task on extrinsic parser evaluation. as our first improvement, we use the pretrained contextualized embeddings (bert) as additional inputs to the network; secondly, we use individual morphological features as regularization; and finally, we merge the selected corpora of the same language. in the lemmatization task, our system exceeds all the submitted systems by a wide margin with lemmatization accuracy 95.78 (second best was 95.00, third 94.46). in the morphological analysis, our system placed tightly second: our morphological analysis accuracy was 93.19, the winning system\u2019s 93.23."
        },
        {
            "id": "R170978",
            "label": "Predictors for Mild and Severe Hypoglycemia in Insulin-Treated Japanese Diabetic Patients",
            "doi": "10.1371/journal.pone.0130584",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the objective of this study was to explore predictors, including social factors, lifestyle factors, and factors relevant to glycemic control and treatment, for mild and severe hypoglycemia in insulin-treated japanese diabetic patients. this study included 123 insulin-treated diabetic patients who were referred to the diabetes clinic between january and july 2013 at shiga university of medical science hospital. after a survey examining the various factors, patients were followed for 6 months. during the follow-up period, blood glucose was self-monitored. mild hypoglycemia was defined as blood glucose level 50\u201369 mg/dl, and severe hypoglycemia was defined as blood glucose level \u226449 mg/dl. multinomial logistic regression was used to estimate the adjusted odds ratio (or) and 95% confidence interval (ci) of each factor for mild and severe hypoglycemia. during the 6-month follow-up period, 41 (33.3%) patients experienced mild hypoglycemia, and 20 (16.3%) experienced severe hypoglycemia. in multivariable-adjusted analyses, assistance from family members at the time of the insulin injection [presence/absence, or (95% ci): 0.39 (0.16\u20130.97)] and drinking [current drinker/non- and ex-drinker, or (95% ci): 4.89 (1.68\u201314.25)] affected mild hypoglycemia. assistance from family members at the time of insulin injection [presence/absence, or (95% ci): 0.19 (0.05\u20130.75)] and intensive insulin therapy [yes/no, or (95% ci): 3.61 (1.06\u201312.26)] affected severe hypoglycemia. in conclusion, our findings suggest that not only a factor relevant to glycemic control and treatment (intensive insulin therapy) but also a social factor (assistance from family members) and a lifestyle factor (current drinking) were predictors for mild or severe hypoglycemia in japanese insulin-treated diabetic patients."
        },
        {
            "id": "R196615",
            "label": "Heterogeneous Social Linked Data Integration and Sharing for Public Transportation",
            "doi": "10.1155/2022/6338365",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "R193600",
                    "label": "Application of Social Linked Data (Solid) to a specific use case"
                }
            ],
            "abstract": "solid (social linked data) technology has made significant progress in social web applications developed, such as facebook, twitter, and wikipedia. solid is based on semantic web and rdf (resource description framework) technologies. solid platforms can provide decentralized authentication, data management, and developer support in the form of libraries and web applications. however, thus far, little research has been conducted on understanding the problems involved in sharing public transportation data through solid technology. it is challenging to provide personalized and adaptable public transportation services for citizens because the public transportation data originate from different devices and are heterogeneous in nature. a novel approach is proposed in this study, in order to provide personalized sharing of public transportation data between different users through integrating and sharing these heterogeneous data. this approach not only integrates diverse data types into a uniform data type using the semantic web but also stores these data in a personal online data store and retrieves data through sparql on the solid platform; these data are visualized on the web pages using google maps. to the best of our knowledge, we are the first to apply solid in public transportation. furthermore, we conduct performance tests of the new c2rmf (csv to rdf mapping file) algorithm and functional and non-functional tests to demonstrate the stability and effectiveness of the approach. our results indicate the feasibility of the proposed approach in facilitating public transportation data integration and sharing through solid and semantic web technologies."
        },
        {
            "id": "R110005",
            "label": "New Technique to Determine the Total Organic Carbon Based on Well Logs Using Artificial Neural Network (White Box)",
            "doi": "",
            "research_field": {
                "id": "R148",
                "label": "Geophysics and Seismology"
            },
            "research_problems": [
                {
                    "id": "R110013",
                    "label": "To estimate total organic carbon, an important source rock characterization parameter, using well logs."
                }
            ],
            "abstract": "abstract \\n total organic carbon (toc) is the amount of carbon present in an organic compound and is often used as an essential factor for unconventional shale resources evaluation. the previous models for toc determination were either based on density log data only and considered the presence of organic matter is proportional to the bulk density, or based on resistivity log, sonic or density logs as well as the formation level of maturity (lom), where these models assumed a linear relation between resistivity and porosity logs. the average absolute deviation (add) of the previous model was not less than 1.20wt% of toc with a coefficient of determination (r2) of less than 0.85. \\n the objective of this research is to develop new empirical correlation to determine the toc based on well logs using artificial neural network for barnett shale formation. core toc data (442 data point) and well logs (resistivity, gamma ray, sonic transit time, and bulk density) were used to develop the ann model. for the first time, the ann model will change to a white box by extracting the weights and biases of the model to form the empirical equation. \\n the results obtained showed that toc is strong function of bulk density, and moderate function of gamma ray, compressional sonic time, and week function of deep resistivity. the developed ann model is able to predict the toc based on conventional log data with high accuracy (the add is 0.91wt% of toc and r2 between estimated and actual toc is 0.93). the developed empirical equation for toc determination from the ann model outperformed the previous available models, which had an add of 1.20 wt% or more and r2 of less than 0.85. the developed toc model and equation can be applied using simple computer without the need for a specific software. \\n the novelty of this new research is the simplicity and high accuracy of the developed model for estimating the total organic carbon based on conventional log data. the developed empirical equation will help the geologists and reservoir engineers to predict the toc without the need for hard lab work or complicated softwares."
        },
        {
            "id": "R193655",
            "label": "Research on Chinese-Urdu Machine Translation Based On Deep Learning",
            "doi": "10.32629/jai.v3i2.279",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R193652",
                    "label": "high to low resources language translation"
                }
            ],
            "abstract": "\" urdu is pakistan 's national language. however, chinese expertise is very negligible in pakistan and the asian nations. yet fewer research has been undertaken in the area of computer translation on chinese to urdu. in order to solve the above problems, we designed of an electronic dictionary for chinese-urdu, and studied the sentence-level machine translation technology which is based on deep learning. the design of an electronic dictionary chinese-urdu machine translation system we collected and constructed an electronic dictionary containing 24000 entries from chinese to urdu. for sentence we used english as an intermediate language, and based on the existing parallel corpus of chinese to english and english to urdu, we constructed a bilingual parallel corpus containing 66000 sentences from chinese to urdu. the corpus has trained by using two nmt models (lstm,transformer model) and the above two translation model were compared to the desired translation, with the help of bilingual valuation understudy (bleu) score.\\xa0 on nmt, the lstm model is gain of 0.067 to 0.41 in bleu score while on transformer model, there is gain of 0.077 to 0.52 in bleu which is better than from lstm model score. furthermore, we compared the proposed model with google and microsoft translation. \""
        },
        {
            "id": "R74580",
            "label": "Scholarly event characteristics in four fields of science: a metrics-based analysis",
            "doi": "10.1007/s11192-020-03391-y",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R74591",
                    "label": "Analyzing metadata of scholarly events"
                }
            ],
            "abstract": "abstract one of the key channels of scholarly knowledge exchange are scholarly events such as conferences, workshops, symposiums, etc.; such events are especially important and popular in computer science, engineering, and natural sciences.\\nhowever, scholars encounter problems in finding relevant information about upcoming events and statistics on their historic evolution.\\nin order to obtain a better understanding of scholarly event characteristics in four fields of science, we analyzed the metadata of scholarly events of four major fields of science, namely computer science, physics, engineering, and mathematics using scholarly events quality assessment suite, a suite of ten metrics.\\nin particular, we analyzed renowned scholarly events belonging to five sub-fields within computer science, namely world wide web, computer vision, software engineering, data management, as well as security and privacy.\\nthis analysis is based on a systematic approach using descriptive statistics as well as exploratory data analysis. the findings are on the one hand interesting to observe the general evolution and success factors of scholarly events; on the other hand, they allow (prospective) event organizers, publishers, and committee members to assess the progress of their event over time and compare it to other events in the same field; and finally, they help researchers to make more informed decisions when selecting suitable venues for presenting their work.\\nbased on these findings, a set of recommendations has been concluded to different stakeholders, involving event organizers, potential authors, proceedings publishers, and sponsors. our comprehensive dataset of scholarly events of the aforementioned fields is openly available in a semantic format and maintained collaboratively at openresearch.org ."
        },
        {
            "id": "R189507",
            "label": "Agricultural cropland extent and areas of South Asia derived using Landsat satellite 30-m time-series big-data using random forest machine learning algorithms on the Google Earth Engine cloud",
            "doi": "10.1080/15481603.2019.1690780",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R189336",
                    "label": "Agricultural mapping using remote sensing data"
                }
            ],
            "abstract": "abstract the south asia (india, pakistan, bangladesh, nepal, sri lanka and bhutan) has a staggering 900 million people (~43% of the population) who face food insecurity or severe food insecurity as per united nations, food and agriculture organization\u2019s (fao) the food insecurity experience scale (fies). the existing coarse-resolution (\u2265250-m) cropland maps lack precision in geo-location of individual farms and have low map accuracies. this also results in uncertainties in cropland areas calculated from such products. thereby, the overarching goal of this study was to develop a high spatial resolution (30-m or better) baseline cropland extent product of south asia for the year 2015 using landsat satellite time-series big-data and machine learning algorithms (mlas) on the google earth engine (gee) cloud computing platform. to eliminate the impact of clouds, 10 time-composited landsat bands (blue, green, red, nir, swir1, swir2, thermal, evi, ndvi, ndwi) were derived for each of the three time-periods over 12 months (monsoon: days of the year (doy) 151\u2013300; winter: doy 301\u2013365 plus 1\u201360; and summer: doy 61\u2013150), taking the every 8-day data from landsat-8 and 7 for the years 2013\u20132015, for a total of 30-bands plus global digital elevation model (gdem) derived slope band. this 31-band mega-file big data-cube was composed for each of the five agro-ecological zones (aez\u2019s) of south asia and formed a baseline data for image classification and analysis. knowledge-base for the random forest (rf) mlas were developed using spatially well spread-out reference training data (n = 2179) in five aezs. the classification was performed on gee for each of the five aezs using well-established knowledge-base and rf mlas on the cloud. map accuracies were measured using independent validation data (n = 1185). the survey showed that the south asia cropland product had a producer\u2019s accuracy of 89.9% (errors of omissions of 10.1%), user\u2019s accuracy of 95.3% (errors of commission of 4.7%) and an overall accuracy of 88.7%. the national and sub-national (districts) areas computed from this cropland extent product explained 80-96% variability when compared with the national statistics of the south asian countries. the full-resolution imagery can be viewed at full-resolution, by zooming-in to any location in south asia or the world, at www.croplands.org and the cropland products of south asia downloaded from the land processes distributed active archive center (lp daac) of national aeronautics and space administration (nasa) and the united states geological survey (usgs): https://lpdaac.usgs.gov/products/gfsad30saafgircev001/."
        },
        {
            "id": "R169718",
            "label": "Testosterone and Androgen Receptor Sensitivity in Relation to Hyperactivity Symptoms in Boys with Autism Spectrum Disorders",
            "doi": "10.1371/journal.pone.0149657",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction autism spectrum disorders (asd) and hyperactivity symptoms exhibit an incidence that is male-biased. thus androgen activity can be considered a plausible biological risk factor for these disorders. however, there is insufficient information about the association between increased androgen activity and hyperactivity symptoms in children with asd. methods in the present study, the relationship between parameters of androgenicity (plasmatic testosterone levels and androgen receptor sensitivity) and hyperactivity in 60 boys (age 3\u201315) with asd is investigated. given well documented differences in parent and trained examiners ratings of symptom severity, we employed a standardized parent`s questionnaire (nisonger child behavior rating form) as well as a direct examiner`s rating (autism diagnostic observation schedule) for assessment of hyperactivity symptoms. results although it was found there was no significant association between actual plasmatic testosterone levels and hyperactivity symptoms, the number of cag triplets was significantly negatively correlated with hyperactivity symptoms (r2 = 0.118, p = 0.007) in the sample, indicating increased androgen receptor sensitivity in association with hyperactivity symptoms. direct trained examiner\u00b4s assessment appeared to be a relevant method for evaluating of behavioral problems in the investigation of biological underpinnings of these problems in our study. conclusions a potential asd subtype characterized by increased rates of hyperactivity symptoms might have distinct etiopathogenesis and require a specific behavioral and pharmacological approach. we propose an increase of androgen receptor sensitivity as a biomarker for a specific asd subtype accompanied with hyperactivity symptoms. findings are discussed in terms of their implications for practice and future research."
        },
        {
            "id": "R210003",
            "label": "Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition",
            "doi": "10.1109/tpami.2009.83",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "interpretation of images and videos containing humans interacting with different objects is a daunting task. it involves understanding scene or event, analyzing human movements, recognizing manipulable objects, and observing the effect of the human movement on those objects. while each of these perceptual tasks can be conducted independently, recognition rate improves when interactions between them are considered. motivated by psychological studies of human perception, we present a bayesian approach which integrates various perceptual tasks involved in understanding human-object interactions. previous approaches to object and action recognition rely on static shape or appearance feature matching and motion analysis, respectively. our approach goes beyond these traditional approaches and applies spatial and functional constraints on each of the perceptual elements for coherent semantic interpretation. such constraints allow us to recognize objects and actions when the appearances are not discriminative enough. we also demonstrate the use of such constraints in recognition of actions from static images without using any motion information."
        },
        {
            "id": "R170251",
            "label": "Examining individual and geographic factors associated with social isolation and loneliness using Canadian Longitudinal Study on Aging (CLSA) data",
            "doi": "10.1371/journal.pone.0211143",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background a large body of research shows that social isolation and loneliness have detrimental health consequences. identifying individuals at risk of social isolation or loneliness is, therefore, important. the objective of this study was to examine personal (e.g., sex, income) and geographic (rural/urban and sociodemographic) factors and their association with social isolation and loneliness in a national sample of canadians aged 45 to 85 years. methods the study involved cross-sectional analyses of baseline data from the canadian longitudinal study on aging that were linked to 2016 census data at the forward sortation area (fsa) level. multilevel logistic regression analyses were conducted to examine the association between personal factors and geographic factors and social isolation and loneliness for the total sample, and women and men, respectively. results the prevalence of social isolation and loneliness was 5.1% and 10.2%, respectively, but varied substantially across personal characteristics. personal characteristics (age, sex, education, income, functional impairment, chronic diseases) were significantly related to both social isolation and loneliness, although some differences emerged in the direction of the relationships for the two measures. associations also differed somewhat for women versus men. associations between some geographic factors emerged for social isolation, but not loneliness. living in an urban core was related to increased odds of social isolation, an effect that was no longer significant when fsa-level factors were controlled for. fsas with a higher percentage of 65+ year old residents with low income were consistently associated with higher odds of social isolation. conclusion the findings indicate that socially isolated individuals are, to some extent, clustered into areas with a high proportion of low-income older adults, suggesting that support and resources could be targeted at these areas. for loneliness, the focus may be less on where people live, but rather on personal characteristics that place individuals at risk."
        },
        {
            "id": "R171321",
            "label": "Oxytocin receptor binding sites in the periphery of the neonatal mouse",
            "doi": "10.1371/journal.pone.0172904",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "oxytocin (oxt) is a pleiotropic regulator of physiology and behavior. an emerging body of evidence demonstrates a role for oxt in the transition to postnatal life of the infant. to identify potential sites of oxt action via the oxt receptor (oxtr) in the newborn mouse, we performed receptor autoradiography on 20 \u03bcm sagittal sections of whole postnatal day 0 male and female mice on a c57bl/6j background using the 125iodinated ornithine vasotocin analog ([125i]-ovta) radioligand. a competitive binding assay on both wild-type (wt) and oxtr knockout (oxtr ko) tissue was used to assess the selectivity of [125i]-ovta for neonatal oxtr. radioactive ligand (0.05 nm [125i]-ovta) was competed against concentrations of 0 nm, 10 nm, and 1000 nm excess unlabeled oxt. autoradiographs demonstrated the high selectivity of the radioligand for infant peripheral oxtr. specific ligand binding activity for oxtr was observed in the oronasal cavity, the eye, whisker pads, adrenal gland, and anogenital region in the neonatal oxtr wt mouse, but was absent in neonatal oxtr ko. nonspecific binding was observed in areas with a high lipid content such as the scapular brown adipose tissue and the liver: in these regions, binding was present in both oxtr wt and ko mice, and could not be competed away with oxt in either wt or ko mice. collectively, these data confirm novel oxt targets in the periphery of the neonate. these peripheral oxtr sites, coupled with the immaturity of the neonate\u2019s own oxt system, suggest a role for exogenous oxt in modulating peripheral physiology and development."
        },
        {
            "id": "R38438",
            "label": "Towards a Large Corpus of Richly Annotated Web Tables for Knowledge Base Population",
            "doi": "",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "R38435",
                    "label": "Knowledge base completion"
                },
                {
                    "id": "R38441",
                    "label": "Web Table Understanding"
                }
            ],
            "abstract": "\"web table understanding in the context of knowledge base population and the semantic web is the task of i) linking the content of tables retrieved from the web to an rdf knowledge base, ii) of building hypotheses about the tables' structures and contents, iii) of extracting novel information from these tables, and iv) of adding this new information to a knowledge base. knowledge base population has gained more and more interest in the last years due to the increased demand in large knowledge graphs which became relevant for artificial intelligence applications such as question answering and semantic search. \\nin this paper we describe a set of basic tasks which are relevant for web table understanding in the mentioned context. \\nthese tasks incrementally enrich a table with hypotheses about the table's content. in doing so, in the case of multiple interpretations, selecting one interpretation and thus deciding against other interpretations is avoided as much as possible. by postponing these decision, we enable table understanding approaches to decide by themselves, thus increasing the usability of the annotated table data. \\nwe present statistics from analyzing and annotating 1.000.000 tables from the web table corpus 2015 and make this dataset as well as our code available online.\""
        },
        {
            "id": "R74953",
            "label": "Colour and Architecture: An Empirical Study of a New Paradigm of Painting of Residential Buildings and Ownership in Kumasi",
            "doi": "2224-607X ISSN",
            "research_field": {
                "id": "R374",
                "label": "Urban Studies and Planning"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "colours have been classically used to inspire taste in architecture from antiquity. colours provide \u2018joie de vivre\u2019 (joy of life). however, a cursory observation reveals a noticeable trend in ghana where residential buildings are receiving paints and colour notations of multinational companies. this paper presents empirical research on colour through multiple methodological approaches and tactics. the research findings presented in this paper used kumasi, the capital of the ashanti region of ghana as main case study area. the data analysis of findings revealed that about seventy-five percent of the houses painted in multinational companies\u2019 colours along major arterial roads in kumasi were approached for advertisement purposes. in addition, the owners of the sampled houses chose to paint with a particular colour for a mark of distinction and monetary reasons. this paper concludes that the companies\u2019 objectives were adhoc and were not guided by any planned scheme as required to enhance the sensibility and aesthetic appeals through the use of colour for buildings and their genus loci in an urban environment. the paper recommends revisions to the current ghana national building regulations of 1996 \u2013 the legislative instruments 1630 to recognize the importance of colour aesthetics in city environments. keywords: company colour and paint, architecture, incentivization, building regulations, kumasi-ashante"
        },
        {
            "id": "R172170",
            "label": "Are women more generous than men? A meta-analysis",
            "doi": "10.1007/s40881-021-00105-9",
            "research_field": {
                "id": "R303",
                "label": "Behavioral Economics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract we perform a meta analysis of gender differences in the standard windfall gains dictator game (dg) by collecting raw data from 53 studies with 117 conditions, giving us 15,016 unique individual observations. we find that women on average give 4 percentage points more than men (cohen\u2019s $$d=0.16$$ \\n \\n d \\n = \\n 0.16 \\n \\n ), and that this difference decreases to $$3.1\\\\%$$ \\n \\n 3.1 \\n % \\n \\n points (cohen\u2019s $$d=0.13$$ \\n \\n d \\n = \\n 0.13 \\n \\n ) if we exclude studies where dictators can only give all or nothing. the gender difference is larger if the recipient in the dg is a charity, compared to the standard dg with an anonymous individual as the recipient (a 10.9 versus a $$2.3\\\\%$$ \\n \\n 2.3 \\n % \\n \\n points gender difference). these effect sizes imply that many individual studies on gender differences are underpowered; the median power in our sample of standard dg studies is only $$9\\\\%$$ \\n \\n 9 \\n % \\n \\n to detect the meta-analytic gender difference at the $$5\\\\%$$ \\n \\n 5 \\n % \\n \\n significance level. moving forward on this topic, sample sizes should thus be substantially larger than what has been the norm in the past."
        },
        {
            "id": "R170866",
            "label": "Motor Contagion during Human-Human and Human-Robot Interaction",
            "doi": "10.1371/journal.pone.0106172",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"motor resonance mechanisms are known to affect humans' ability to interact with others, yielding the kind of \u201cmutual understanding\u201d that is the basis of social interaction. however, it remains unclear how the partner's action features combine or compete to promote or prevent motor resonance during interaction. to clarify this point, the present study tested whether and how the nature of the visual stimulus and the properties of the observed actions influence observer's motor response, being motor contagion one of the behavioral manifestations of motor resonance. participants observed a humanoid robot and a human agent move their hands into a pre-specified final position or put an object into a container at various velocities. their movements, both in the object- and non-object- directed conditions, were characterized by either a smooth/curvilinear or a jerky/segmented trajectory. these trajectories were covered with biological or non-biological kinematics (the latter only by the humanoid robot). after action observation, participants were requested to either reach the indicated final position or to transport a similar object into another container. results showed that motor contagion appeared for both the interactive partner except when the humanoid robot violated the biological laws of motion. these findings suggest that the observer may transiently match his/her own motor repertoire to that of the observed agent. this matching might mediate the activation of motor resonance, and modulate the spontaneity and the pleasantness of the interaction, whatever the nature of the communication partner.\""
        },
        {
            "id": "R171202",
            "label": "Internal and Predictive Validity of the French Health of the Nation Outcome Scales: Need for Future Directions",
            "doi": "10.1371/journal.pone.0160360",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the health of the nation outcome scales (honos) is a widely used measure of health and social functioning of people with mental illness. the goals of this study were to verify the internal validity of the one factor and several four-factor scoring structures and to evaluate the predictive validity of honos items with regards to duration of hospitalization, probability of readmission in the following year and time before readmission. 6175 hospital stays at the department of psychiatry of lausanne university hospital were screened and the first honos of each patient was taken into account (n = 2722). data were analyzed through confirmatory factor analysis (cfa) and the predictive validity of honos items was evaluated with two approaches: item level regressions and latent class analysis (lca). cfa indicated that the suggested factor structures were not supported by the data. predictive validity of the 12 items was weak but lca revealed five distinct and meaningful profiles that were related to length of stay or readmission. honos may be more adapted to the evaluation of patients case-mix rather than to the individual level and concepts such as predictive validity may be more appropriate than internal validity to guide its use."
        },
        {
            "id": "R209980",
            "label": "Understanding Transit Scenes: A Survey on Human Behavior-Recognition Algorithms",
            "doi": "10.1109/tits.2009.2030963",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "visual surveillance is an active research topic in image processing. transit systems are actively seeking new or improved ways to use technology to deter and respond to accidents, crime, suspicious activities, terrorism, and vandalism. human behavior-recognition algorithms can be used proactively for prevention of incidents or reactively for investigation after the fact. this paper describes the current state-of-the-art image-processing methods for automatic-behavior-recognition techniques, with focus on the surveillance of human activities in the context of transit applications. the main goal of this survey is to provide researchers in the field with a summary of progress achieved to date and to help identify areas where further research is needed. this paper provides a thorough description of the research on relevant human behavior-recognition methods for transit surveillance. recognition methods include single person (e.g., loitering), multiple-person interactions (e.g., fighting and personal attacks), person-vehicle interactions (e.g., vehicle vandalism), and person-facility/location interactions (e.g., object left behind and trespassing). a list of relevant behavior-recognition papers is presented, including behaviors, data sets, implementation details, and results. in addition, algorithm's weaknesses, potential research directions, and contrast with commercial capabilities as advertised by manufacturers are discussed. this paper also provides a summary of literature surveys and developments of the core technologies (i.e., low-level processing techniques) used in visual surveillance systems, including motion detection, classification of moving objects, and tracking."
        },
        {
            "id": "R156617",
            "label": "Immunopathological and ultrastructural features in a case of papular elastorrhexis",
            "doi": "10.1111/ddg.12760",
            "research_field": {
                "id": "R37",
                "label": "Genetics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "papular elastorrhexis (pe) is an uncommon elastic tissue disease that often affects female adolescents. thirty-one cases of pe have been reported [ 1 ] , but immunohistochemical and ultrastructural data is limited. in august 2013, a 13-year-old boy presented with a 7-year history of asymptomatic white papules on the trunk and proximal extremities. the lesions had appeared spontaneously and gradually increased. he had no history of acne or any relevant family history. physical examination showed multiple nonfollicular white papules, 1\u20135 mm in diameter, on the chest, abdomen, shoulders, and thighs (figure 1 a). a complete blood cell count, liver function tests, and urinalysis were normal. x-rays of the hands revealed no osteopoikilosis. direct microscopy of lesional scrapings displayed a few short hyphae and spherical spores, but fungal cultures were negative. the biopsy of an abdominal lesion showed focal hyperkeratosis, mild acanthosis, and focally thickened and homogenized collagen bundles as well as perivascular lymphohistiocytic infi ltration in the papillary dermis (figure 1 b). van gieson staining revealed a localized loss and partial fragmentation of elastic fi bers in the upper dermis (figure 2 a). alcian blue, alizarin red s, and periodic acid-schiff (pas) staining showed neither mucin nor calcium deposition, and no epidermal or dermal fungal elements. elastin immunostaining yielded a remarkable reduction of elastic fi bers in the dermis, especially in the papillary dermis (figure 2 b). the number of epidermal s100-positive and melan a-positive cells (per millimeter of the basement membrane zone) in ten different fi elds (x 200 magnifi cation) was similar to that in abdominal skin of a healthy 26-year-old man (1.51 \u00b1 0.74 vs. 1.85 \u00b1 0.55, p = 0.257; 1.18 \u00b1 0.31 vs. 1.43 \u00b1 0.41, p = 0.064). the dermal infl ammatory infi ltrate predominantly consisted of cd3-positive and few interspersed cd20-positive cells. the number of cd4-positive cells was similar to that of cd8-positive cells. the patient was treated with oral itraconazole (200 mg every day) and topical bifonazole cream (1 %) for three weeks. without clinical improvement, he returned to our department in may 2014. fungal cultures were again negative, and histopathological results were identical to those obtained initially. electron microscopy of the second biopsy specimen showed a decrease and also degeneration of fi broblasts and elastic fi bers as well as swelling of dermal collagen fi bers (figure 2 c, d). in 1987, pe was initially considered a variant of nevus anelasticus [ 1 ] . later, in 1994, it was proposed to be an abortive form of buschke-ollendorff syndrome (bos) [ 2 ] . however, recent fi ndings suggest that pe is not an incomplete variant of bos, as there have been two cases of pe failing to show lemd3 mutations [ 3 ] . papular elastorrhexis typically presents with asymptomatic, nonfollicular, whitish or skin-colored papules, 1\u20135 mm in diameter, distributed over the trunk and extremities, and occasionally, face and scalp. histopathologically, the prominent feature is fragmentation, thinning, or complete loss of dermal elastic fi bers. collagen fi bers may be focally thickened and homogenized or normal. papular elastorrhexis is distinct from several elastic tissue disorders including nevus anelasticus, bos, eruptive collagenoma, pseudoxanthoma elasticum-like papillary dermal elastolysis, and white fi brous papulosis of the neck [ 1 ] . in our case, several features pointed to the diagnosis of pe, including the nonfollicular papules and predilection sites, the absence of osteopoikilosis and family history, as well as the histopathological evidence of focal loss and fragmentation of elastic fi bers. the etiopathogenesis of pe remains unknown. while, in two previous cases, mucin deposition was observed around the abnormal elastic fi bers [ 4 ] , there was no mucin or calcium depositions in our patient. another case showed a reduction in epidermal melanin granules, while the number of s100-positive melanocytes was normal [ 5 ] ; in our case the number of melan a-positive and s100-positive cells"
        },
        {
            "id": "R170874",
            "label": "A \u00e2\u0080\u009cMigrant Friendly Hospital\u00e2\u0080\u009d Initiative in Geneva, Switzerland: Evaluation of the Effects on Staff Knowledge and Practices",
            "doi": "10.1371/journal.pone.0106758",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background international migration poses important challenges to european health care systems. the development of \u201cmigrant friendly hospitals\u201d has been identified as a priority in both europe and switzerland. methods a multi-pronged initiative was developed at geneva university hospitals (hug) to improve staff knowledge and use of existing \u201cmigrant friendly\u201d resources. a self-administered questionnaire was sent pre and post-intervention to random samples of 4 major professional groups with direct patient contact at the hug. the questionnaire assessed staff knowledge, attitudes and reported practices regarding the care of migrant patients. results overall response rate was 51% (n\\u200a=\\u200a1460) in 2010 but only 19% (n\\u200a=\\u200a761) in 2013 owing to an institutionally imposed change in survey method. despite these difficulties, and after adjusting for sample differences, we found that respondents in 2013 were significantly more likely to have received training in how to organize an appointment with an interpreter, how to work with an interpreter and about health and social services available for migrant patients. respondents were also significantly more likely to have used several migrant friendly structures at the hug. use of, preference for and perceived skill at working with professional interpreters all improved, and respondents were both more likely to be encouraged by their supervisors to use professional interpreters, and less likely to be encouraged to look for alternative solutions for communicating with non francophone patients. finally, 2013 respondents encountered fewer difficulties caring for migrant patients, although lack of time and language barriers continued to be the most important sources of difficulty. conclusion our results suggest that an institution-wide information campaign may contribute to increased awareness and use of migrant friendly resources by clinical staff. hospital commitment and financing, along with inter-departmental participation in all activities were important in creating and maintaining project visibility, and in contributing to a migrant friendly institutional culture."
        },
        {
            "id": "R155250",
            "label": "Fairness in Simple Bargaining Experiments",
            "doi": "10.1006/game.1994.1021",
            "research_field": {
                "id": "R303",
                "label": "Behavioral Economics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract we present an experiment to test whether fairness alone can explain proposers\u2032 willingness to make nontrivial offers in simple bargaining games. we examine two treatments: game (ultimatum or dictator) and pay (pay or no pay). the outcomes of the ultimatum and dictator games with pay are significantly different, implying that fairness, by itself, cannot explain the observed behavior. doubling the amount of money available in games with pay does not affect these results. the outcomes of both games are replicable when players are paid, but the outcome of the ultimatum game is not replicable when players are not paid. journal of economic literature classification numbers: 026, 215."
        },
        {
            "id": "R195679",
            "label": "Reinforcing Security Requirements with Multifactor Quality Measurement",
            "doi": "10.1109/re.2017.77",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "choosing how to write natural language scenarios is challenging, because stakeholders may over-generalize their descriptions or overlook or be unaware of alternate scenarios. in security, for example, this can result in weak security constraints that are too general, or missing constraints. another challenge is that analysts are unclear on where to stop generating new scenarios. in this paper, we introduce the multifactor quality method (mqm) to help requirements analysts to empirically collect system constraints in scenarios based on elicited expert preferences. the method combines quantitative statistical analysis to measure system quality with qualitative coding to extract new requirements. the method is bootstrapped with minimal analyst expertise in the domain affected by the quality area, and then guides an analyst toward selecting expert-recommended requirements to monotonically increase system quality. we report the results of applying the method to security. this include 550 requirements elicited from 69 security experts during a bootstrapping stage, and subsequent evaluation of these results in a verification stage with 45 security experts to measure the overall improvement of the new requirements. security experts in our studies have an average of 10 years of experience. our results show that using our method, we detect an increase in the security quality ratings collected in the verification stage. finally, we discuss how our proposed method helps to improve security requirements elicitation, analysis, and measurement."
        },
        {
            "id": "R44491",
            "label": "Suspected phenobarbital-induced pseudolymphoma in a cat",
            "doi": "10.2460/javma.238.3.353",
            "research_field": {
                "id": "R77",
                "label": "Animal Sciences"
            },
            "research_problems": [
                {
                    "id": "R44421",
                    "label": "Antiepileptic drugs' safety and effectiveness"
                }
            ],
            "abstract": "case description\\na 4.5-year-old spayed female domestic shorthair cat was evaluated because of a generalized seizure disorder that developed after an anesthesia-related hypoxic event.\\n\\n\\nclinical findings\\nfollowing administration of phenobarbital, the seizures stopped but the cat developed severe generalized lymphadenopathy. results of a cbc and serum biochemical analysis were unremarkable. cytologic examination of the lymph nodes revealed a reactive lymphocyte population. differential diagnoses included neoplasia and infection, but results of related diagnostic tests were all negative.\\n\\n\\ntreatment and outcome\\ntreatment was changed from phenobarbital to levetiracetam. ten days following discontinuation of phenobarbital, the lymph node enlargement resolved, and the cat remained free of seizures with levetiracetam as treatment.\\n\\n\\nclinical relevance\\npseudolymphoma and anticonvulsant hypersensitivity syndrome are recognized potential sequelae to anticonvulsant administration in humans. however, a pseudolymphoma-like reaction to anticonvulsants in veterinary species has not previously been reported. this case highlighted a potentially serious yet reversible sequela to phenobarbital treatment that may have been mistaken for more severe illness such as neoplasia."
        },
        {
            "id": "R149058",
            "label": "SCORVoc: vocabulary-based information integration and exchange in supply networks",
            "doi": "",
            "research_field": {
                "id": "R141823",
                "label": "Semantic Web"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"advanced, highly specialized economies require instant, robust and efficient information flows within its value-added and supply chain networks. especially also in the context of the recent industry 4.0, smart manufacturing or cyber-physical systems initiatives more efficient and effective information exchange in supply networks is of paramount importance. the supply chain operation reference (scor) is a cross-industry approach to lay the groundwork for this goal by defining a conceptual model for supply chain related information. semantics-based approaches could facilitate information flows in supply networks, and enable to analyze, monitor and optimize supply chains (in particular for robustness). this paper first reviews existing formalizations of the supply chain council's scor standard. it then introduces the scorvoc rdfs vocabulary which fully formalizes the latest scor standard, while over-coming the identified limitations of existing work. scorvoc is operationalized by a set of sparql queries, that enable to evaluate metrics and key performance indicator (kpis) defined by scor, on-the-fly, in an information systems that adheres to the vocabulary. finally, we define concrete test scenarios and implement a synthetic benchmark to demonstrate the practicality of scorvoc.\""
        },
        {
            "id": "R74481",
            "label": "Open educational resources and standards in the eMadrid network",
            "doi": "10.1109/SIIE.2016.7751873",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74406",
                    "label": "Open Education"
                },
                {
                    "id": "R109069",
                    "label": "Open Education"
                }
            ],
            "abstract": "this paper presents the main results achieved in the program emadrid program in open educational resources, free software, open data, and about formats and standardization of content and services."
        },
        {
            "id": "R185380",
            "label": "Estimating Uncertainty and Interpretability in Deep Learning for Coronavirus (COVID-19) Detection",
            "doi": "",
            "research_field": {
                "id": "R40",
                "label": "Immunology and Infectious Disease"
            },
            "research_problems": [
                {
                    "id": "R185383",
                    "label": "COVID-19 Diagnosis"
                }
            ],
            "abstract": "deep learning has achieved state of the art performance in medical imaging. however, these methods for disease detection focus exclusively on improving the accuracy of classification or predictions without quantifying uncertainty in a decision. knowing how much confidence there is in a computer-based medical diagnosis is essential for gaining clinicians trust in the technology and therefore improve treatment. today, the 2019 coronavirus (sars-cov-2) infections are a major healthcare challenge around the world. detecting covid-19 in x-ray images is crucial for diagnosis, assessment and treatment. however, diagnostic uncertainty in the report is a challenging and yet inevitable task for radiologist. in this paper, we investigate how drop-weights based bayesian convolutional neural networks (bcnn) can estimate uncertainty in deep learning solution to improve the diagnostic performance of the human-machine team using publicly available covid-19 chest x-ray dataset and show that the uncertainty in prediction is highly correlates with accuracy of prediction. we believe that the availability of uncertainty-aware deep learning solution will enable a wider adoption of artificial intelligence (ai) in a clinical setting."
        },
        {
            "id": "R170729",
            "label": "Untangling the Influences of Voluntary Running, Environmental Complexity, Social Housing and Stress on Adult Hippocampal Neurogenesis",
            "doi": "10.1371/journal.pone.0086237",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "environmental enrichment (ee) exerts powerful effects on brain physiology, and is widely used as an experimental and therapeutic tool. typical ee paradigms are multifactorial, incorporating elements of physical exercise, environmental complexity, social interactions and stress, however the specific contributions of these variables have not been separable using conventional housing paradigms. here, we evaluated the impacts of these individual variables on adult hippocampal neurogenesis by using a novel \u201calternating ee\u201d paradigm. for 4 weeks, adult male cd1 mice were alternated daily between two enriched environments; by comparing groups that differed in one of their two environments, the individual and combinatorial effects of ee variables could be resolved. the alternating ee paradigm revealed that (1) voluntary running for 3 days/week was sufficient to increase both mitotic and post-mitotic stages of hippocampal neurogenesis, confirming the central importance of exercise; (2) a complex environment (comprised of both social interactions and rotated inanimate objects) had no effect on neurogenesis itself, but enhanced depolarization-induced c-fos expression (attributable to social interactions) and buffered stress-induced plasma corticosterone levels (attributable to inanimate objects); and (3) neither social isolation, group housing, nor chronically increased levels of plasma corticosterone had a prolonged impact on neurogenesis. mouse strain, handling and type of running apparatus were tested and excluded as potential confounding factors. these findings provide valuable insights into the relative effects of key ee variables on adult neurogenesis, and this \u201calternating ee\u201d paradigm represents a useful tool for exploring the contributions of individual ee variables to mechanisms of neural plasticity."
        },
        {
            "id": "R155372",
            "label": "MoS2\n-Based Tactile Sensor for Electronic Skin Applications",
            "doi": "10.1002/adma.201505124",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R155374",
                    "label": "Performance of strain sensors based on 2D materials "
                }
            ],
            "abstract": "a conformal tactile sensor based on mos2 and graphene is demonstrated. the mos2 tactile sensor exhibits excellent sensitivity, high uniformity, and good repeatability in terms of various strains. in addition, the outstanding flexibility enables the mos2 strain tactile sensor to be realized conformally on a finger tip. the mos2 -based tactile sensor can be utilized for wearable electronics, such as electronic skin."
        },
        {
            "id": "R209610",
            "label": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference",
            "doi": "10.18653/v1/D18-1009",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "given a partial description like \u201cshe opened the hood of the car,\u201d humans can reason about the situation and anticipate what might come next (\u201dthen, she examined the engine\u201d). in this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. we present swag, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. to address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose adversarial filtering (af), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. to account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. we provide comprehensive analysis that indicates significant opportunities for future research."
        },
        {
            "id": "R170423",
            "label": "Differential Immediate and Sustained Memory Enhancing Effects of Alpha7 Nicotinic Receptor Agonists and Allosteric Modulators in Rats",
            "doi": "10.1371/journal.pone.0027014",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"the \u03b17 nicotinic acetylcholine receptor (nachr) is a potential target for the treatment of cognitive deficits in patients with schizophrenia, adhd and alzheimer's disease. here we test the hypothesis that upregulation of \u03b17 nachr levels underlies the enhanced and sustained procognitive effect of repeated administration of \u03b17 nachr agonists. we further compare the effect of agonists to that of \u03b17 nachr positive allosteric modulators (pams), which do not induce upregulation of the \u03b17 nachr. using the social discrimination test as a measure of short-term memory, we show that the \u03b17 nachr agonist a-582941 improves short-term memory immediately after repeated (7\u00d7 daily), but not a single administration. the \u03b17 nachr pams pnu-120596 and avl-3288 do not affect short-term memory immediately after a single or repeated administration. this demonstrates a fundamental difference in the behavioral effects of agonists and pams that may be relevant for clinical development. importantly, a-582941 and avl-3288 increase short-term memory 24 hrs after repeated, but not a single, administration, suggesting that repeated administration of both agonists and pams may produce sustained effects on cognitive performance. subsequent [125i]-bungarotoxin autoradiography revealed no direct correlation between \u03b17 nachr levels in frontal cortical or hippocampal brain regions and short-term memory with either compound. additionally, repeated treatment with a-582941 did not affect mrna expression of ric-3 or the lynx-like gene products lynx1, lynx2, psca, or ly6h, which are known to affect nachr function. in conclusion, both \u03b17 nachr agonists and pams exhibit sustained pro-cognitive effects after repeated administration, and altered levels of the \u03b17 nachr per se, or that of endogenous regulators of nachr function, are likely not the major cause of this effect.\""
        },
        {
            "id": "R170564",
            "label": "Increased Drinking following Social Isolation Rearing: Implications for Polydipsia Associated with Schizophrenia",
            "doi": "10.1371/journal.pone.0056105",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "primary polydipsia, excessive drinking without known medical cause, is especially associated with a diagnosis of schizophrenia. we used animal models of schizophrenia-like symptoms to examine the effects on schedule-induced polydipsia: post-weaning social isolation rearing, subchronic mk-801 treatment (an nmda-receptor antagonist) or the two combined. male, sprague-dawley rats reared in groups or in isolation beginning at postnatal day 21 were further divided to receive subchronic mk-801 (0.5 mg/kg twice daily) or saline for 7 days beginning on postnatal day 62. following a 4-day withdrawal period, all groups were trained on a schedule-induced polydipsia paradigm. under food-restriction, animals reared in isolation and receiving food pellets at 1-min intervals developed significantly more drinking behavior than those reared with others. the addition of subchronic mk-801 treatment did not significantly augment the amount of water consumed. these findings suggest a predisposition to polydipsia is a schizophrenia-like behavioral effect of post-weaning social isolation."
        },
        {
            "id": "R74446",
            "label": "A user profile definition in context of recommendation of open educational resources. An approach based on linked open vocabularies",
            "doi": "10.1109/FIE.2015.7344314",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74409",
                    "label": "Knowledge Representation"
                },
                {
                    "id": "R109071",
                    "label": "Knowledge Representation"
                }
            ],
            "abstract": "open educational resources include a diverse range of materials making it the most representative icon arisen within the open content movement. users who access and use oers could be classified into one of these three groups: instructor, student and self-learner. to provide personalized lists of oers according to the user profile and personal preferences, the user should be characterized by an open and scalable model. in this paper, an open linked vocabulary is proposed to describe user profiles of the open educational resources, which take into account the challenges and opportunities that an open and extensible platform as the web can provide to learn about the oer users, and from this knowledge, offer the most appropriate resources."
        },
        {
            "id": "R171335",
            "label": "Childhood adversities and distress - The role of resilience in a representative sample",
            "doi": "10.1371/journal.pone.0173826",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "while adverse childhood experiences have been shown to contribute to adverse health outcomes in adulthood, specifically distress and somatic symptoms, few studies have examined their joint effects with resilient coping style on adult adjustment. hence, we aim to determine the association between resilient coping and distress in participants with and without reported childhood adversities. a representative german community sample (n = 2508) between 14\u201392 years (1334 women; 1174 men) was examined by the short form of the childhood trauma questionnaire, the brief resilience coping scale, standardized scales of distress and somatoform symptoms. childhood adversity was associated with reduced adjustment, social support and resilience. it was also strongly associated with increased distress and somatoform complaints. resilient coping was not only associated with lower distress, it also buffered the effects of childhood adversity on distress. our study corroborates the buffering effect of resilience in a representative german sample. high trait resilient subjects show less distress and somatoform symptoms despite reported childhood adversities in comparison to those with low resilient coping abilities."
        },
        {
            "id": "R144869",
            "label": "Arrays of Solar-Blind Ultraviolet Photodetector Based on \u00ce\u00b2-Ga2O3 Epitaxial Thin Films",
            "doi": "10.1109/lpt.2018.2826560",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R144785",
                    "label": " Application of Gallium Oxide Films in Photodetectors"
                }
            ],
            "abstract": "recently, the $\\\\beta $ -ga 2 o 3 -based solar-blind ultraviolet photodetector has attracted intensive attention due to its wide application prospects. photodetector arrays can act as an imaging detector and also improve the detecting sensitivity by series or parallel of detector cells. in this letter, the highly integrated metal-semiconductor-metal structured photodetector arrays of $32\\\\times 32$ , $16\\\\times 16$ , $8\\\\times 8$ , and $4\\\\times 4$ have been designed and fabricated for the first time. herein, we present a 4-1 photodetector cell chosen from a $4\\\\times 4$ photodetector array as an example to demonstrate the performance. the photo responsivity is $8.926 \\\\times 10^{-1}$ a/w @ 250 nm at a 10-v bias voltage, corresponding to a quantum efficiency of 444%. all of the photodetector cells exhibit the solar-blind ultraviolet photoelectric characteristic and the consistent photo responsivity with a standard deviation of 12.1%. the outcome of the study offers an efficient route toward the development of high-performance and low-cost duv photodetector arrays."
        },
        {
            "id": "R146689",
            "label": "A Novel Method for Measuring the Timing of Heart Sound Components through Digital Phonocardiography",
            "doi": "10.3390/s19081868",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the auscultation of heart sounds has been for decades a fundamental diagnostic tool in clinical practice. higher effectiveness can be achieved by recording the corresponding biomedical signal, namely the phonocardiographic signal, and processing it by means of traditional signal processing techniques. an unavoidable processing step is the heart sound segmentation, which is still a challenging task from a technical viewpoint\u2014a limitation of state-of-the-art approaches is the unavailability of trustworthy techniques for the detection of heart sound components. the aim of this work is to design a reliable algorithm for the identification and the classification of heart sounds\u2019 main components. the proposed methodology was tested on a sample population of 24 healthy subjects over 10-min-long simultaneous electrocardiographic and phonocardiographic recordings and it was found capable of correctly detecting and classifying an average of 99.2% of the heart sounds along with their components. moreover, the delay of each component with respect to the corresponding r-wave peak and the delay among the components of the same heart sound were computed: the resulting experimental values are coherent with what is expected from the literature and what was obtained by other studies."
        },
        {
            "id": "R171378",
            "label": "Knowledge, attitude and perceived stigma towards tuberculosis among pastoralists; Do they differ from sedentary communities? A comparative cross-sectional study",
            "doi": "10.1371/journal.pone.0181032",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background ethiopia is ninth among the world high tuberculosis (tb) burden countries, pastoralists being the most affected population. however, there is no published report whether the behavior related to tb are different between pastoralist and the sedentary communities. therefore, the main aim of this study is to assess the pastoralist community knowledge, attitude and perceived stigma towards tuberculosis and their health care seeking behavior in comparison to the neighboring sedentary communities and this may help to plan tb control interventions specifically for the pastoralist communities. method a community-based cross-sectional survey was carried out from september 2014 to january 2015, among 337 individuals from pastoralist and 247 from the sedentary community of kereyu district. data were collected using structured questionnaires. three focus group discussions were used to collect qualitative data, one with men and the other with women in the pastoralist and one with men in the sedentary groups. data were analyzed using statistical software for social science, spss v 22 and stata. results a lower proportion of pastoralists mentioned bacilli (bacteria) as the cause of ptb compared to the sedentary group (63.9% vs. 81.0%, p<0.01), respectively. however, witchcraft was reported as the causes of tb by a higher proportion of pastoralists than the sedentary group (53.6% vs.23.5%, p<0.01), respectively. similarly, a lower proportion of pastoralists indicated ptb is preventable compared to the sedentary group (95.8% vs. 99.6%, p<0.01), respectively. moreover, majority of the pastoralists mentioned that most people would reject a tb patient in their community compared to the sedentary group (39.9% vs. 8.9%, p<0.001), respectively, and the pastoralists expressed that they would be ashamed/embarrassed if they had tb 68% vs.36.4%, p<0.001), respectively. conclusion the finding indicates that there is a lower awareness about tb, a negative attitude towards tb patients and a higher perceived stigma among pastoralists compared to their neighbor sedentary population. strategic health communications pertinent to the pastoralists way of life should be planned and implemented to improve the awareness gap about tuberculosis."
        },
        {
            "id": "R197050",
            "label": "Automatic Speech Recognition Datasets in Cantonese: A Survey and New Dataset",
            "doi": "",
            "research_field": {
                "id": "R404",
                "label": "East Asian Languages and Societies"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "automatic speech recognition (asr) on low resource languages improves the access of linguistic minorities to technological advantages provided by artificial intelligence (ai). in this paper, we address the problem of data scarcity for the hong kong cantonese language by creating a new cantonese dataset. our dataset, multi-domain cantonese corpus (mdcc), consists of 73.6 hours of clean read speech paired with transcripts, collected from cantonese audiobooks from hong kong. it comprises philosophy, politics, education, culture, lifestyle and family domains, covering a wide range of topics. we also review all existing cantonese datasets and analyze them according to their speech type, data source, total size and availability. we further conduct experiments with fairseq s2t transformer, a state-of-the-art asr model, on the biggest existing dataset, common voice zh-hk, and our proposed mdcc, and the results show the effectiveness of our dataset. in addition, we create a powerful and robust cantonese asr model by applying multi-dataset learning on mdcc and common voice zh-hk."
        },
        {
            "id": "R46407",
            "label": "Iterative alternating neural attention for machine reading",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46405",
                    "label": "Machine comprehension"
                },
                {
                    "id": "R46425",
                    "label": "Machine Reading"
                },
                {
                    "id": "R46426",
                    "label": "answering Cloze - style queries with respect to a document"
                }
            ],
            "abstract": "we propose a novel neural attention architecture to tackle machine comprehension tasks, such as answering cloze-style queries with respect to a document. unlike previous models, we do not collapse the query into a single vector, instead we deploy an iterative alternating attention mechanism that allows a fine-grained exploration of both the query and the document. our model outperforms state-of-the-art baselines in standard machine comprehension benchmarks such as cnn news articles and the children\u2019s book test (cbt) dataset."
        },
        {
            "id": "R194253",
            "label": "Can a Conversation Paint a Picture? Mining Requirements In Software Forums",
            "doi": "10.1109/re.2019.00014",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the modern software landscape is highly competitive. software companies need to quickly fix reported bugs and release requested new features, or they risk negative reviews and reduced market share. the amount of online user feedback prevents manual analysis. past research has investigated automated requirement mining techniques on online platforms like app stores and twitter, but online product forums have not been studied. in this paper, we show that online product forums are a rich source of user feedback that may be used to elicit product requirements. the information contained in forum questions is different from what has been described in the related work on app stores or twitter. users often provide detailed context to specific problems they encounter with a software product and other users respond with workarounds or to confirm the problem. through the analysis of two large forums, we identify 18 different types of information (classifications) contained in forums that can be relevant to maintenance and evolution tasks. we show that a state-of-the-art app store tool is unable to accurately classify forum data, which may be due to the differences in content. thus, specific techniques are likely needed to mine requirements from product forums. in an exploratory study, we developed classifiers with forum specific features. promising results are achieved for all classifiers with f-measure scores ranging from 70.3% to 89.8%."
        },
        {
            "id": "R130521",
            "label": "When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "large language models have become increasingly difficult to train because of the growing computation time and cost. in this work, we present sru++, a highly-efficient architecture that combines fast recurrence and attention for sequence modeling. sru++ exhibits strong modeling capacity and training efficiency. on standard language modeling tasks such as enwik8, wiki-103 and billion word datasets, our model obtains better bits-per-character and perplexity while using 3x-10x less training cost compared to top-performing transformer models. for instance, our model achieves a state-of-the-art result on the enwik8 dataset using 1.6 days of training on an 8-gpu machine. we further demonstrate that sru++ requires minimal attention for near state-of-the-art performance. our results suggest jointly leveraging fast recurrence with little attention as a promising direction for accelerating model training and inference."
        },
        {
            "id": "R133383",
            "label": "Value Prediction Network",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "this paper proposes a novel deep reinforcement learning (rl) architecture, called value prediction network (vpn), which integrates model-free and model-based rl methods into a single neural network. in contrast to typical model-based rl methods, vpn learns a dynamics model whose abstract states are trained to make option-conditional predictions of future values (discounted sum of rewards) rather than of future observations. our experimental results show that vpn has several advantages over both model-free and model-based baselines in a stochastic environment where careful planning is required but building an accurate observation-prediction model is difficult. furthermore, vpn outperforms deep q-network (dqn) on several atari games even with short-lookahead planning, demonstrating its potential as a new way of learning a good state representation."
        },
        {
            "id": "R170406",
            "label": "A Maternal Influence on Reading the Mind in the Eyes Mediated by Executive Function: Differential Parental Influences on Full and Half-Siblings",
            "doi": "10.1371/journal.pone.0023236",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background parent-of-origin effects have been found to influence the mammalian brain and cognition and have been specifically implicated in the development of human social cognition and theory of mind. the experimental design in this study was developed to detect parent-of-origin effects on theory of mind, as measured by the \u2018reading the mind in the eyes\u2019 (eyes) task. eyes scores were also entered into a principal components analysis with measures of empathy, social skills and executive function, in order to determine what aspect of theory of mind eyes is measuring. methodology/principal findings maternal and paternal influences on eyes scores were compared using correlations between pairs of full (70 pairs), maternal (25 pairs) and paternal siblings (15 pairs). structural equation modelling supported a maternal influence on eyes scores over the normal range but not low-scoring outliers, and also a sex-specific influence on males acting to decrease male eyes scores. it was not possible to differentiate between genetic and environmental influences in this particular sample because maternal siblings tended to be raised together while paternal siblings were raised apart. the principal components analysis found eyes was associated with measures of executive function, principally behavioural inhibition and attention, rather than empathy or social skills. conclusions/significance in conclusion, the results suggest a maternal influence on eye scores in the normal range and a sex-specific influence acting to reduce scores in males. this influence may act via aspects of executive function such as behavioural inhibition and attention. there may be different influences acting to produce the lowest eyes scores which implies that the heratibility and/or maternal influence on poor theory of mind skills may be qualitatively different to the influence on the normal range."
        },
        {
            "id": "R170771",
            "label": "Multiple White Matter Volume Reductions in Patients with Panic Disorder: Relationships between Orbitofrontal Gyrus Volume and Symptom Severity and Social Dysfunction",
            "doi": "10.1371/journal.pone.0092862",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"numerous brain regions are believed to be involved in the neuropathology of panic disorder (pd) including fronto-limbic regions, thalamus, brain stem, and cerebellum. however, while several previous studies have demonstrated volumetric gray matter reductions in these brain regions, there have been no studies evaluating volumetric white matter changes in the fiber bundles connecting these regions. in addition, although patients with pd typically exhibit social, interpersonal and occupational dysfunction, the neuropathologies underlying these dysfunctions remain unclear. a voxel-based morphometry study was conducted to evaluate differences in regional white matter volume between 40 patients with pd and 40 healthy control subjects (hc). correlation analyses were performed between the regional white matter volumes and patients' scores on the panic disorder severity scale (pdss) and the global assessment of functioning (gaf). patients with pd demonstrated significant volumetric reductions in widespread white matter regions including fronto-limbic, thalamo-cortical and cerebellar pathways (p<0.05, fdr corrected). furthermore, there was a significant negative relationship between right orbitofrontal gyrus (ofg) white matter volume and the severity of patients' clinical symptoms, as assessed with the pdss. a significant positive relationship was also observed between patients' right ofg volumes and their scores on the gaf. our results suggest that volumetric reductions in widespread white matter regions may play an important role in the pathology of pd. in particular, our results suggest that structural white matter abnormalities in the right ofg may contribute to the social, personal and occupational dysfunction typically experienced by patients with pd.\""
        },
        {
            "id": "R78277",
            "label": "BitConduite: Exploratory Visual Analysis of Entity Activity on the Bitcoin Network",
            "doi": "10.1109/mcg.2021.3070303",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we present bitconduite, a visual analytics approach for explorative analysis of financial activity within the bitcoin network, offering a view on transactions aggregated by entities, i.e., by individuals, companies, or other groups actively using bitcoin. bitconduite makes bitcoin data accessible to nontechnical experts through a guided workflow around entities analyzed according to several activity metrics. analyses can be conducted at different scales, from large groups of entities down to single entities. bitconduite also enables analysts to cluster entities to identify groups of similar activities as well as to explore characteristics and temporal patterns of transactions. to assess the value of our approach, we collected feedback from domain experts."
        },
        {
            "id": "R187763",
            "label": "The open access advantage for studies of human electrophysiology: Impact on citations and Altmetrics",
            "doi": "10.1016/j.ijpsycho.2021.03.006",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R187758",
                    "label": "Open access citation advantage"
                },
                {
                    "id": "R188795",
                    "label": "Differences in impact between different open access models"
                }
            ],
            "abstract": "barriers to accessing scientific findings contribute to knowledge inequalities based on financial resources and decrease the transparency and rigor of scientific research. recent initiatives aim to improve access to research as well as methodological rigor via transparency and openness. we sought to determine the impact of such initiatives on open access publishing in the sub-area of human electrophysiology and the impact of open access on the attention articles received in the scholarly literature and other outlets. data for 35,144 articles across 967 journals from the last 20 years were examined. approximately 35% of articles were open access, and the rate of publication of open-access articles increased over time. open access articles showed 9 to 21% more pubmed and crossref citations and 39% more altmetric mentions than closed access articles. green open access articles (i.e., author archived) did not differ from non-green open access articles (i.e., publisher archived) with respect to citations and were related to higher altmetric mentions. these findings demonstrate that open-access publishing is increasing in popularity in the sub-area of human electrophysiology and that open-access articles enjoy the \u201copen access advantage\u201d in citations similar to the larger scientific literature. the benefit of the open access advantage may motivate researchers to make their publications open access and pursue publication outlets that support it. in consideration of the direct connection between citations and journal impact factor, journal editors may improve the accessibility and impact of published articles by encouraging authors to self-archive manuscripts on preprint servers."
        },
        {
            "id": "R171893",
            "label": "Alien plants can be associated with a decrease in local and regional native richness even when at low abundance",
            "doi": "10.1111/1365-2745.13124",
            "research_field": {
                "id": "R30",
                "label": "Terrestrial and Aquatic Ecology"
            },
            "research_problems": [
                {
                    "id": "R171910",
                    "label": "Measuring impact of invasive species"
                },
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the impacts of alien plants on native richness are usually assessed at small spatial scales and in locations where the alien is at high abundance. but this raises two questions: to what extent do impacts occur where alien species are at low abundance, and do local impacts translate to effects at the landscape scale? in an analysis of 47 widespread alien plant species occurring across a 1,000 km2 landscape, we examined the relationship between their local abundance and native plant species richness in 594 grassland plots. we first defined the critical abundance at which these focal alien species were associated with a decline in native \u03b1\u2010richness (plot\u2010scale species numbers), and then assessed how this local decline was translated into declines in native species \u03b3\u2010richness (landscape\u2010scale species numbers). after controlling for sampling biases and environmental gradients that might lead to spurious relationships, we found that eight out of 47 focal alien species were associated with a significant decline in native \u03b1\u2010richness as their local abundance increased. most of these significant declines started at low to intermediate classes of abundance. for these eight species, declines in native \u03b3\u2010richness were, on average, an order of magnitude (32.0 vs. 2.2 species) greater than those found for native \u03b1\u2010richness, mostly due to spatial homogenization of native communities. the magnitude of the decrease at the landscape scale was best explained by the number of plots where an alien species was found above its critical abundance. synthesis. even at low abundance, alien plants may impact native plant richness at both local and landscape scales. local impacts may result in much greater declines in native richness at larger spatial scales. quantifying impact at the landscape scale requires consideration of not only the prevalence of an alien plant, but also its critical abundance and its effect on native community homogenization. this suggests that management approaches targeting only those locations dominated by alien plants might not mitigate impacts effectively. our integrated approach will improve the ranking of alien species risks at a spatial scale appropriate for prioritizing management and designing conservation policies."
        },
        {
            "id": "R44970",
            "label": "Evaluation of geese theatre's re-connect program: Addressing resettlement issues in prison",
            "doi": "10.1177/0306624X10370452",
            "research_field": {
                "id": "R343",
                "label": "Psychology"
            },
            "research_problems": [
                {
                    "id": "R44963",
                    "label": "Psychodrama psychotherapy"
                }
            ],
            "abstract": "this study examined the impact of geese theatre\u2019s re-connect program on a sample of offenders who attended it. this program used theatre performance, experiential exercises, skills practice role-plays, and metaphors such as the masks to invite a group of offenders to consider and explore issues connected with their release and reconnecting with a life outside prison. pre- and postprogram psychometric tests, behavior ratings, and interviews were completed to assess the effectiveness of the program. significant changes were observed from pre- to posttreatment in terms of self-efficacy, motivation to change, and improved confidence in skills (i.e., social and friendship, occupational, family and intimacy, dealing with authority, alternatives to aggression or offending, and self-management and self-control skills). improved behavior and engagement within the program was observed over the 3 days of the program. interviews also revealed the positive impact the program had on the participants. this provides evidence supporting the short-term effectiveness of the re-connect program."
        },
        {
            "id": "R171608",
            "label": "The impact of attachment distress on affect-centered mentalization: An experimental study in psychosomatic patients and healthy adults",
            "doi": "10.1371/journal.pone.0195430",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction we investigated the impact of attachment distress on affect-centered mentalization in a clinical and a non-clinical sample, comparing mentalization in a baseline condition to mentalization under a condition of attachment distress. methods the sample consisted of 127 adults who underwent inpatient psychosomatic treatment, and 34 mentally healthy adults. affect-centered mentalization was assessed by analyzing participants\u2019 narratives on interpersonal situations in a baseline condition with the levels of emotional awareness scale (leas), and an experimental condition inducing attachment distress with the adult attachment projective picture system (aap). unlike the leas, the aap is specifically designed to trigger attachment distress. in both conditions, the narratives were evaluated using the leas scoring system. additionally, we assessed the impact of childhood trauma on affect-centered mentalization with the childhood trauma questionnaire (ctq). results while the non-clinical sample displayed the same level of affect-centered mentalization in both conditions, the majority of the clinical sample reached higher scores in the attachment distress condition. there was no strong relationship between reported trauma and mentalization scores. discussion our findings lend strong empirical support to the assumption that affect-centered mentalization is modulated by attachment-related distress. several possible explanations for the differences between and within the clinical and the non-clinical sample are discussed."
        },
        {
            "id": "R209426",
            "label": "Optimal Placement of Accelerometers for the Detection of Everyday Activities",
            "doi": "10.3390/s130709183",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this article describes an investigation to determine the optimal placement of accelerometers for the purpose of detecting a range of everyday activities. the paper investigates the effect of combining data from accelerometers placed at various bodily locations on the accuracy of activity detection. eight healthy males participated within the study. data were collected from six wireless tri-axial accelerometers placed at the chest, wrist, lower back, hip, thigh and foot. activities included walking, running on a motorized treadmill, sitting, lying, standing and walking up and down stairs. the support vector machine provided the most accurate detection of activities of all the machine learning algorithms investigated. although data from all locations provided similar levels of accuracy, the hip was the best single location to record data for activity detection using a support vector machine, providing small but significantly better accuracy than the other investigated locations. increasing the number of sensing locations from one to two or more statistically increased the accuracy of classification. there was no significant difference in accuracy when using two or more sensors. it was noted, however, that the difference in activity detection using single or multiple accelerometers may be more pronounced when trying to detect finer grain activities. future work shall therefore investigate the effects of accelerometer placement on a larger range of these activities."
        },
        {
            "id": "R134043",
            "label": "Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R124884",
                    "label": "Atari Games"
                }
            ],
            "abstract": "recent advances in off-policy deep reinforcement learning (rl) have led to impressive success in complex tasks from visual observations. experience replay improves sample-ef\ufb01ciency by reusing experiences from the past, and convolutional neural networks (cnns) process high-dimensional inputs effectively. however, such techniques demand high memory and computational bandwidth. in this paper, we present stored embeddings for ef\ufb01cient reinforcement learning (seer), a simple modi\ufb01cation of existing off-policy rl methods, to address these computational and memory requirements. to reduce the computational overhead of gradient updates in cnns, we freeze the lower layers of cnn encoders early in training due to early convergence of their parameters. additionally, we reduce memory requirements by storing the low-dimensional latent vectors for experience replay instead of high-dimensional images, enabling an adaptive increase in the replay buffer capacity, a useful technique in constrained-memory settings. in our experiments, we show that seer does not degrade the performance of rl agents while signi\ufb01cantly saving computation and memory across a diverse set of deepmind control environments and atari games."
        },
        {
            "id": "R187629",
            "label": "Gender Disparity in the Authorship of Biomedical Research Publications During the COVID-19 Pandemic: Retrospective Observational Study",
            "doi": "10.2196/25379",
            "research_field": {
                "id": "R281",
                "label": "Social and Behavioral Sciences"
            },
            "research_problems": [
                {
                    "id": "R5105",
                    "label": "gender"
                },
                {
                    "id": "R175174",
                    "label": "impact of COVID-19 pandemic on academics"
                },
                {
                    "id": "R178510",
                    "label": "research productivity"
                },
                {
                    "id": "R178512",
                    "label": "publication"
                },
                {
                    "id": "R187504",
                    "label": "COVID-19 pandemic"
                },
                {
                    "id": "R187506",
                    "label": "research"
                },
                {
                    "id": "R187643",
                    "label": "COVID-19 research"
                }
            ],
            "abstract": "\\n background \\n gender imbalances in academia have been evident historically and persist today. for the past 60 years, we have witnessed the increase of participation of women in biomedical disciplines, showing that the gender gap is shrinking. however, preliminary evidence suggests that women, including female researchers, are disproportionately affected by the covid-19 pandemic in terms of unequal distribution of childcare, elderly care, and other kinds of domestic and emotional labor. sudden lockdowns and abrupt shifts in daily routines have had disproportionate consequences on their productivity, which is reflected by a sudden drop in research output in biomedical research, consequently affecting the number of female authors of scientific publications. \\n \\n \\n objective \\n the objective of this study is to test the hypothesis that the covid-19 pandemic has had a disproportionate adverse effect on the productivity of female researchers in the biomedical field in terms of authorship of scientific publications. \\n \\n \\n methods \\n this is a retrospective observational bibliometric study. we investigated the proportion of male and female researchers who published scientific papers during the covid-19 pandemic, using bibliometric data from biomedical preprint servers and selected springer-nature journals. we used the ordinary least squares regression model to estimate the expected proportions over time by correcting for temporal trends. we also used a set of statistical methods, such as the kolmogorov-smirnov test and regression discontinuity design, to test the validity of the results. \\n \\n \\n results \\n a total of 78,950 papers from the biorxiv and medrxiv repositories and from 62 selected springer-nature journals by 346,354 unique authors were analyzed. the acquired data set consisted of papers that were published between january 1, 2019, and august 2, 2020. the proportion of female first authors publishing in the biomedical field during the pandemic dropped by 9.1%, on average, across disciplines (expected arithmetic mean yest=0.39; observed arithmetic mean y=0.35; standard error of the estimate, sest=0.007; standard error of the observation, \u03c3x=0.004). the impact was particularly pronounced for papers related to covid-19 research, where the proportion of female scientists in the first author position dropped by 28% (yest=0.39; y=0.28; sest=0.007; \u03c3x=0.007). when looking at the last authors, the proportion of women dropped by 7.9%, on average (yest=0.25; y=0.23; sest=0.005; \u03c3x=0.003), while the proportion of women writing about covid-19 as the last author decreased by 18.8% (yest=0.25; y=0.21; sest=0.005; \u03c3x=0.007). further, by geocoding authors\u2019 affiliations, we showed that the gender disparities became even more apparent when disaggregated by country, up to 35% in some cases. \\n \\n \\n conclusions \\n our findings document a decrease in the number of publications by female authors in the biomedical field during the global pandemic. this effect was particularly pronounced for papers related to covid-19, indicating that women are producing fewer publications related to covid-19 research. this sudden increase in the gender gap was persistent across the 10 countries with the highest number of researchers. these results should be used to inform the scientific community of this worrying trend in covid-19 research and the disproportionate effect that the pandemic has had on female academics. \\n"
        },
        {
            "id": "R110154",
            "label": "In the grip of replacive bilingualism: the Belarusian language in contact with Russian",
            "doi": "10.1515/IJSL.2007.006",
            "research_field": {
                "id": "R408",
                "label": "Slavic Languages and Societies"
            },
            "research_problems": [
                {
                    "id": "R110040",
                    "label": "mixed language in Belarus "
                }
            ],
            "abstract": "abstract belarusian occupies a very specific position among the slavic languages. in spite of the fact that it can be characterized as a \u201cmiddle-sized\u201d slavic language, the contiguity and all-embracing rivalry with the \u201cstrong\u201d russian language make it into an eternally \u201csmall\u201d language. the modern belarusian standard language was elaborated in the early twentieth century. there was a brief but fruitful period of its promotion in the 1920s, but then russification became a relevant factor in its development for the following decades. political factors have always held great significance in the development of belarusian. the linguistic affinity of belarusian and russian in combination with other factors is an insurmountable obstacle for the spread of the belarusian language. on the one hand, russian speakers living in belarus, as a rule, understand belarusian but do not make the effort to acquire it as an active medium of communication. on the other hand, belarusian speakers proficient in russian do not have enough motivation to use belarusian routinely, on account of the pervading presence of russian in belarusian society. as a result, they often lose their belarusian language skills. there is considerable dissent as to the perspectives of belarusian. though it is the \u201ctitular\u201d language, which determines its importance in belarus, it is also a minority language and thus faces the corresponding challenges."
        },
        {
            "id": "R169531",
            "label": "Biological Motion Primes the Animate/Inanimate Distinction in Infancy",
            "doi": "10.1371/journal.pone.0116910",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "given that biological motion is both detected and preferred early in life, we tested the hypothesis that biological motion might be instrumental to infants\u2019 differentiation of animate and inanimate categories. infants were primed with either point-light displays of realistic biological motion, random motion, or schematic biological motion of an unfamiliar shape. after being habituated to these displays, 12-month-old infants categorized animals and vehicles as well as furniture and vehicles with the sequential touching task. the findings indicated that infants primed with point-light displays of realistic biological motion showed better categorization of animates than those exposed to random or schematic biological motion. these results suggest that human biological motion might be one of the motion cues that provide the building blocks for infants\u2019 concept of animacy."
        },
        {
            "id": "R196427",
            "label": "Infants' ability to consult the speaker for clues to word reference",
            "doi": "10.1017/s0305000900008345",
            "research_field": {
                "id": "R324",
                "label": "First/Second Language Acquisition"
            },
            "research_problems": [
                {
                    "id": "R196442",
                    "label": "Infants' ability to actively seek information from a speaker regarding the referent"
                }
            ],
            "abstract": "\" abstract this research examines whether infants actively seek information from a speaker regarding the referent of the speaker's utterance. forty-eight infants (in three age groups: 1;2\u20131;3, 1;4\u20131;5, and 1;6\u20131;7) heard novel labels for novel objects in two situations: follow-in labelling (the experimenter looked at and labelled the toy of the infant's focus) vs. discrepant labelling (the experimenter looked at and labelled a different toy than that of the infant's focus). subsequently, half of the infants were asked comprehension questions (e.g. \u2018where's the peri ?\u2019). the other half were asked preference questions (e.g. \u2018where's the one you like?\u2019), to ensure that their comprehension performance was not merely the result of preferential responding. the comprehension results revealed developmental change in both ( a ) infants' ability to establish new word-object mappings (infants aged 1;2\u20131;3 failed to establish stable word-object links even in follow-in labelling), and ( b ) infants' ability to pinpoint the correct referent during discrepant labelling (only infants aged 1;6\u20131;7 succeeded). thus the period between 1;2 and 1;7 represents a time of change in infants' ability to establish new word-object mappings: infants are becoming increasingly adept at acquiring new labels under minimal learning conditions. \""
        },
        {
            "id": "R171702",
            "label": "Considering parental hearing status as a social determinant of deaf population health: Insights from experiences of the \"dinner table syndrome\"",
            "doi": "10.1371/journal.pone.0202169",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the influence of early language and communication experiences on lifelong health outcomes is receiving increased public health attention. most deaf children have non-signing hearing parents, and are at risk for not experiencing fully accessible language environments, a possible factor underlying known deaf population health disparities. childhood indirect family communication\u2013such as spontaneous conversations and listening in the routine family environment (e.g. family meals, recreation, car rides)\u2013is an important source of health-related contextual learning opportunities. the goal of this study was to assess the influence of parental hearing status on deaf people\u2019s recalled access to childhood indirect family communication. we analyzed data from the rochester deaf health survey\u20132013 (n = 211 deaf adults) for associations between sociodemographic factors including parental hearing status, and recalled access to childhood indirect family communication. parental hearing status predicted deaf adults\u2019 recalled access to childhood indirect family communication (\u03c72 = 31.939, p < .001). the likelihood of deaf adults reporting \u201csometimes to never\u201d for recalled comprehension of childhood family indirect communication increased by 17.6 times for those with hearing parents. no other sociodemographic or deaf-specific factors in this study predicted deaf adults\u2019 access to childhood indirect family communication. this study finds that deaf people who have hearing parents were more likely to report limited access to contextual learning opportunities during childhood. parental hearing status and early childhood language experiences, therefore, require further investigation as possible social determinants of health to develop interventions that improve lifelong health and social outcomes of the underserved deaf population."
        },
        {
            "id": "R171297",
            "label": "Explicit Not Implicit Preferences Predict Conservation Intentions for Endangered Species and Biomes",
            "doi": "10.1371/journal.pone.0170973",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "conservation of biodiversity is determined in part by human preferences. preferences relevant to conservation have been examined largely via explicit measures (e.g., a self-reported degree of liking), with implicit measures (e.g., preconscious, automatic evaluations) receiving relatively less attention. this is the case despite psychological evidence from other contexts that implicit preferences are more informative of behavior. thus, the type of measure that predicts conservation intentions for biodiversity is unknown. we conducted three studies to examine conservation intentions in light of people\u2019s explicit and implicit preferences toward four endangered species (sea otter, american badger, caribou, yellow-breasted chat) and four biomes (forest, ocean, grassland, tundra). in study 1 (n = 55), we found that people implicitly preferred caribou most, but explicitly preferred sea otter most, with a significant multiple regression where participants\u2019 explicit preferences dictated their stated intended donations for conservation of each species. in study 2 (n = 57) we found that people implicitly and explicitly preferred forest and ocean over grassland and tundra. explicit rather than implicit preferences predicted the intended donation for conservation of the ocean biome. study 3 involved a broader online sample of participants (n = 463) and also found that explicit preferences dictated the intended donations for conservation of biomes and species. our findings reveal discrepancies between implicit and explicit preferences toward species, but not toward biomes. importantly, the results demonstrate that explicit rather than implicit preferences predict conservation intentions for biodiversity. the current findings have several implications for conservation and the communication of biodiversity initiatives."
        },
        {
            "id": "R169457",
            "label": "Analysis of Interleukin-8 Gene Variants Reveals Their Relative Importance as Genetic Susceptibility Factors for Chronic Periodontitis in the Han Population",
            "doi": "10.1371/journal.pone.0104436",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "interleukin (il)-8, an important chemokine that regulates the inflammatory response, plays an important role in periodontitis. previous studies indicate that certain il-8 gene polymorphisms are associated with periodontitis susceptibility in some populations. however, the literature is somewhat contradictory, and not all il-8 polymorphisms have been examined, particularly in han chinese individuals. the aim of this study was to investigate the association of every il-8 snp with chronic periodontitis in han chinese individuals. we analyzed 23 snps with minor allele frequency (maf)\u22650.01, which were selected from 219 snps in the ncbi dbsnp and preliminary hapmap data analyses from a cohort of 400 cases and 750 controls from genetically independent han chinese individuals. single snp, haplotype and gender-specific associations were performed. we found that rs4073 and rs2227307 were significantly associated with chronic periodontitis. further haplotype analysis indicated that a haplotype block (rs4073-rs2227307-rs2227306) that spans the promoter and exon1 of il-8 was highly associated with chronic periodontitis. additionally, the atc haplotype in this block was increased 1.5-fold in these cases. however, when analyzing the samples by gender, no significant gender-specific associations in il-8 were observed, similar to the results of haplotype association analyses in female and male subgroups. our results provide further evidence that il-8 is associated with chronic periodontitis in han chinese individuals. furthermore, our results confirm previous reports suggesting the intriguing possibilities that il-8 plays a role in the pathogenesis of chronic periodontitis and that this gene may be involved in the etiology of this condition."
        },
        {
            "id": "R144199",
            "label": "Machine learning in remote sensing data processing",
            "doi": "10.1109/MLSP.2009.5306233",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R144182",
                    "label": "Importance of Machine learning in processing the data from Remote sensing sensors"
                }
            ],
            "abstract": "remote sensing data processing deals with real-life applications with great societal values. for instance urban monitoring, fire detection or flood prediction from remotely sensed multispectral or radar images have a great impact on economical and environmental issues. to treat efficiently the acquired data and provide accurate products, remote sensing has evolved into a multidisciplinary field, where machine learning and signal processing algorithms play an important role nowadays. this paper serves as a survey of methods and applications, and reviews the latest methodological advances in machine learning for remote sensing data analysis."
        },
        {
            "id": "R110739",
            "label": "Evaluation of sleep\u00e2\u0080\u0090disordered breathing and its relationship with respiratory parameters in children with mucopolysaccharidosis Type\n            IVA\n            and\n            VI",
            "doi": "10.1002/ajmg.a.62229",
            "research_field": {
                "id": "R37",
                "label": "Genetics"
            },
            "research_problems": [
                {
                    "id": "R110748",
                    "label": "The frequency of obstructive sleep apnea (OSA) in patients with mucopolysaccharidosis (MPS)"
                }
            ],
            "abstract": "the aims of the study were to evaluate the prevalence of sleep\u2010disordered breathing (sdb) by using polysomnography (psg) in children with mps iva and mps vi who underwent enzyme replacement therapy (ert) and to analyze the effect on sdb of having upper airway surgery, pulmonary functions, and exercise capacity. a retrospective cross\u2010sectional study was conducted on patients with mps iva (n:17) and mps vi (n:11) aged under 19\\u2009years who underwent polysomnography. descriptive and nonparametric analyses were performed for demographic, psg, pulmonary function and exercise capacity variables. the frequency of sleep apnea in the study sample was 85.7% (24/28). four patients (14.3%) had no sleep apnea, 15 (53.6%) had mild, and nine (32.1%) had moderate\u2010to\u2010severe sleep apnea. two patients (7.1%) had central sleep apnea and 22 had obstructive sleep apnea (osa) (78.6%). forced expiratory volume in 1\\u2009s (fev1) and forced vital capacity (fvc) were negatively correlated to apnea\u2010hypopnea index (ahi) (r =\\u2009\u22120.594, p =\\u2009.009; r =\\u2009\u22120.636, p =\\u2009.005, respectively). despite ert and previous upper airway surgery, the prevalence of osa was high in patients with mps iva\u2013mps iv, emphasizing the importance of psg screening for sleep disorders. pulmonary function tests may be useful for predicting sleep apnea in patients with mps iva and mps vi."
        },
        {
            "id": "R170560",
            "label": "Sharing of Potential Nest Sites by Etheostoma olmstedi Males Suggests Mutual Tolerance in an Alloparental Species",
            "doi": "10.1371/journal.pone.0056041",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "when reproductive competitors tolerate or cooperate with one another, they may gain particular benefits, such as collectively guarding resources or attracting mates. shared resources may be those essential to reproduction, such as a breeding site or nest. using the tessellated darter, a species where males but not females compete over potential nest sites, we examined site use and sharing under controlled conditions of differing competitor density. sharing was observed even when competitor density was low and individuals could have each occupied a potential nest site without same-sex sharing. males were more likely to share a nest site with one other when the difference in size between them was larger rather than smaller. there was no evidence that female sharing was dependent on their relative size. fish were generally more likely to use and share larger sites, in accordance with the greater relative surface area they offered. we discuss how one or both sharing males may potentially benefit, and how male sharing of potential nest sites could relate to female mating preferences. tessellated darter males are known to provide alloparental care for eggs but this occurs without any social contact between the alloparent and the genetic father of the young. thus, the suggestion that they may also share sites and maintain social contact with reproductive competitors highlights the importance of increased focus on the potential complexity of reproductive systems."
        },
        {
            "id": "R201341",
            "label": "PERSONAL KNOWLEDGE GRAPH POPULATION FROM USER UTTERANCES IN CONVERSATIONAL UNDERSTANDING",
            "doi": "",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R205001",
                    "label": "Exploring Personal Knowledge Graph Literature"
                }
            ],
            "abstract": "knowledge graphs provide a powerful representation of entities and the relationships between them, but automatically constructing such graphs from spoken language utterances presents the novelty and numerous challenges. in this paper, we introduce a statistical language understanding approach to automatically construct personal (user-centric) knowledge graphs in conversational dialogs. such information has the potential to better understand the users' requests, fulfilling them, and enabling other technologies such as developing better inferences or proactive interactions. knowledge encoded in semantic graphs such as freebase has been shown to benefit semantic parsing and interpretation of natural language utterances. hence, as a first step, we exploit the personal factual relation triples from freebase to mine natural language snippets with a search engine, and the resulting snippets containing pairs of related entities to create the training data. this data is then used to build three key language understanding components: (1) personal assertion classification identifies the user utterances that are relevant with personal facts, e.g., \u201cmy mother's name is rosa\u201d; (2) relation detection classifies the personal assertion utterance into one of the predefined relation classes, e.g., \u201cparents\u201d; and (3) slot filling labels the attributes or arguments of relations, e.g., \u201cname(parents): rosa\u201d. our experiments using the microsoft conversational understanding system demonstrate the performance of this proposed approach on the population of personal knowledge graphs."
        },
        {
            "id": "R110819",
            "label": "Sleep abnormalities in untreated patients with mucopolysaccharidosis type VI",
            "doi": "10.1002/ajmg.a.33902",
            "research_field": {
                "id": "R37",
                "label": "Genetics"
            },
            "research_problems": [
                {
                    "id": "R110828",
                    "label": "The frequency of obstructive sleep apnea (OSA) in patients with mucopolysaccharidosis (MPS)"
                }
            ],
            "abstract": "mucopolysaccharidosis type vi (mps vi) is a lysosomal storage disease that affects an enzyme responsible for the degradation of glycosaminoglycans (gags). partially degraded gags accumulate in several tissues, such as the upper airways (ua), which leads to the development of obstructive sleep apnea (osa). our objective was to determine the prevalence of osa in a group of untreated patients with mps vi and the association of osa with clinical and echocardiographic findings. patients aged 4 years or older with a biochemical diagnosis of mps vi were included. data about clinical history, physical examination, doppler echocardiogram, and overnight polysomnography (psg) were collected. our results showed that of the 28 participants, 14 were boys; mean age was 98.5 months, and mean age at mps vi diagnosis was 48.4 months. snoring, witnessed apnea, pectus carinatum, and macroglossia were the main clinical findings. psg results showed that 23:27 patients (85.1%) had osa which was mild in 4, moderate in 5, and severe in 14 patients. echocardiograms showed evidence of pulmonary hypertension (ph) in 14 patients. lower (p\\u2009=\\u20090.037) and nadir spo2 (p\\u2009=\\u20090.007) were positively associated with ph. clinical signs suggestive of respiratory abnormalities during sleep were not significantly correlated with the results of psg. we conclude that the prevalence of osa in patients with mps vi was high, and the level of desaturation was positively correlated with ph. symptoms during sleep were not associated with psg findings, which suggests that this population should undergo routine psg as earlier as possible. this study provides baseline data to estimate the potential impact of specific treatments in the sleep abnormalities presented by patients with mps vi. \u00a9 2011 wiley\u2010liss, inc."
        },
        {
            "id": "R170968",
            "label": "Wasted Food: U.S. Consumers' Reported Awareness, Attitudes, and Behaviors",
            "doi": "10.1371/journal.pone.0127881",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the u.s. wastes 31 to 40% of its post-harvest food supply, with a substantial portion of this waste occurring at the consumer level. globally, interventions to address wasted food have proliferated, but efforts are in their infancy in the u.s. to inform these efforts and provide baseline data to track change, we performed a survey of u.s. consumer awareness, attitudes and behaviors related to wasted food. the survey was administered online to members of a nationally representative panel (n=1010), and post-survey weights were applied. the survey found widespread (self-reported) awareness of wasted food as an issue, efforts to reduce it, and knowledge about how to do so, plus moderately frequent performance of waste-reducing behaviors. three-quarters of respondents said they discard less food than the average american. the leading motivations for waste reduction were saving money and setting an example for children, with environmental concerns ranked last. the most common reasons given for discarding food were concern about foodborne illness and a desire to eat only the freshest food. in some cases there were modest differences based on age, parental status, and income, but no differences were found by race, education, rural/urban residence or other demographic factors. respondents recommended ways retailers and restaurants could help reduce waste. this is the first nationally representative consumer survey focused on wasted food in the u.s. it provides insight into u.s. consumers\u2019 perceptions related to wasted food, and comparisons to existing literature. the findings suggest approaches including recognizing that many consumers perceive themselves as being already-knowledgeable and engaged, framing messages to focus on budgets, and modifying existing messages about food freshness and aesthetics. this research also suggests opportunities to shift retail and restaurant practice, and identifies critical research gaps."
        },
        {
            "id": "R171238",
            "label": "Getting to the Heart of Emotion Regulation in Youth: The Role of Interoceptive Sensitivity, Heart Rate Variability, and Parental Psychopathology",
            "doi": "10.1371/journal.pone.0164615",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "emotion regulation and associated autonomic activation develop throughout childhood and adolescence under the influence of the family environment. specifically, physiological indicators of autonomic nervous system activity such as interoceptive sensitivity and vagally mediated heart rate variability (hrv) can inform on emotion regulation. although the effect of parental emotion socialization on emotion regulation appears to be influenced by autonomic processes, research on physiological regulation and the influence of parental factors remains scarce. this study investigated the relationship between self-reported habitual emotion regulation strategies and hrv at rest as well as interoceptive sensitivity in forty-six youngsters (27 female; age: m = 13.00, sd = 2.13). secondly, the association between these autonomic correlates and parental psychopathology was also studied. whereas better interoceptive sensitivity was related to reduced maladaptive emotion regulation, specifically rumination, high hrv was related to more use of external emotion regulation strategies (i.e., support seeking). in addition, increased hrv and decreased interoceptive sensitivity were associated with maternal internalizing and there was evidence for a possible mediation effect of hrv in the relationship between maternal internalizing and child external emotion regulation. this study elucidates the link between cognitive emotion regulation strategies and underlying physiological regulation in adolescents but also indicates a putative influence of maternal internalizing symptoms on emotion regulation in their offspring."
        },
        {
            "id": "R75661",
            "label": "Prevalence of epilepsy in Croatia: a population-based survey",
            "doi": "10.1111/j.1600-0404.2007.00881.x",
            "research_field": {
                "id": "R58",
                "label": "Neuroscience and Neurobiology"
            },
            "research_problems": [
                {
                    "id": "R75664",
                    "label": "Prevalence of epilepsy in Europe"
                }
            ],
            "abstract": "objectives\\u2002\u2013\\u2002 to investigate the prevalence of active epilepsy in croatia."
        },
        {
            "id": "R197288",
            "label": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
            "doi": "10.48550/ARXIV.1907.11692",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R197043",
                    "label": "Semantic similarity computation performance at sentence- or document-level"
                }
            ],
            "abstract": "language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. we present a replication study of bert pretraining (devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. we find that bert was significantly undertrained, and can match or exceed the performance of every model published after it. our best model achieves state-of-the-art results on glue, race and squad. these results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. we release our models and code."
        },
        {
            "id": "R131102",
            "label": "Robotic Grasp Detection using Deep Convolutional Neural Networks",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R121349",
                    "label": "Robotic Grasping"
                }
            ],
            "abstract": "deep learning has significantly advanced computer vision and natural language processing. while there have been some successes in robotics using deep learning, it has not been widely adopted. in this paper, we present a novel robotic grasp detection system that predicts the best grasping pose of a parallel-plate robotic gripper for novel objects using the rgb-d image of the scene. the proposed model uses a deep convolutional neural network to extract features from the scene and then uses a shallow convolutional neural network to predict the grasp configuration for the object of interest. our multi-modal model achieved an accuracy of 89.21% on the standard cornell grasp dataset and runs at real-time speeds. this redefines the state-of-the-art for robotic grasp detection."
        },
        {
            "id": "R74535",
            "label": "Towards Exploring Literals to Enrich Data Linking in Knowledge Graphs",
            "doi": "10.1109/aike.2018.00024",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R74011",
                    "label": "entity linking"
                }
            ],
            "abstract": "knowledge graph completion is still a challenging solution that uses techniques from distinct areas to solve many different tasks. most recent works, which are based on embedding models, were conceived to improve an existing knowledge graph using the link prediction task. however, even considering the ability of these solutions to solve other tasks, they did not present results for data linking, for example. furthermore, most of these works focuses only on structural information, i.e., the relations between entities. in this paper, we present an approach for data linking that enrich entity embeddings in a model with their literal information and that do not rely on external information of these entities. the key aspect of this proposal is that we use a blocking scheme to improve the effectiveness of the solution in relation to the use of literals. thus, in addition to the literals from object elements in a triple, we use other literals from subjects and predicates. by merging entity embeddings with their literal information it is possible to extend many popular embedding models. preliminary experiments were performed on real-world datasets and our solution showed competitive results to the performance of the task of data linking."
        },
        {
            "id": "R213545",
            "label": "An automatically generated annotated corpus for albanian named entity recognition",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "abstract named entity recognition (ner) is an important task in many nlp pipelines. it has become especially important for knowledge bases that power many of the nowadays information retrieval systems. in order to cope with the high demand for annotated training corpora for supervised ner systems, automatic generation approaches have been proposed. in this paper we report on the first automatically generated ne annotated corpus for albanian. news articles from albanian news media were used as a document source. they were automatically tagged using a custom generated gazetteer from the albanian wikipedia. our evaluation results show that this corpus can be used as a baseline corpus for human annotated ones or as a training corpus where no other is available."
        },
        {
            "id": "R171625",
            "label": "Single transcranial direct current stimulation in schizophrenia: Randomized, cross-over study of neurocognition, social cognition, ERPs, and side effects",
            "doi": "10.1371/journal.pone.0197023",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "over the last decades, the treatment of schizophrenia has shifted fundamentally from a focus on symptom reduction to a focus on recovery and improving aspects of functioning. in this study, we examined the effect of transcranial direct current stimulation (tdcs) on social cognitive and nonsocial neurocognitive functions, as well as on electroencephalogram (eeg) measures, in individuals with schizophrenia. thirty-seven individuals with schizophrenia were administered one of three different tdcs conditions (cathodal, anodal, and sham) per visit over the course of three visits, with approximately one week between each visit. order of conditions was randomized and counterbalanced across subjects. for the active conditions, the electrode was placed over the left dorsolateral prefrontal cortex with the reference electrode over right supraorbital cortex. current intensity was 2 ma and was maintained for two 20-minute sessions, with a one hour break between the sessions. assessments were conducted immediately following each session, in a counterbalanced order of administration. no systematic effects were found across the social and nonsocial cognitive domains, and no significant effects were detected on event-related potentials (erps). the very small effect sizes, further validated by post-hoc power analyses (large critical ns), demonstrated that these findings were not due to lack of statistical power. except for mild local discomfort, no significant side effects were reported. findings demonstrate the safety and ease of administration of this procedure, but suggest that a single dose of tdcs over these areas does not yield a therapeutic effect on cognition in schizophrenia. trial registration: clinicaltrials.gov nct02539797."
        },
        {
            "id": "R170794",
            "label": "Reaction Time and Incident Cancer: 25 Years of Follow-Up of Study Members in the UK Health and Lifestyle Survey",
            "doi": "10.1371/journal.pone.0095054",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives to investigate the association of reaction time with cancer incidence. methods 6900 individuals aged 18 to 94 years who participated in the uk health and lifestyle survey in 1984/1985 and were followed for a cancer registration for 25 years. results disease surveillance gave rise to 1015 cancer events from all sites. in general, there was essentially no clear pattern of association for either simple or choice reaction time with cancer of all sites combined, nor specific malignancies. however, selected associations were found for lung cancer, colorectal cancer and skin cancer. conclusions in the present study, reaction time and its components were not generally related to cancer risk."
        },
        {
            "id": "R110941",
            "label": "Microwave-Assisted Cobinamide Synthesis",
            "doi": "10.1021/jo501364b",
            "research_field": {
                "id": "R129",
                "label": "Organic Chemistry"
            },
            "research_problems": [
                {
                    "id": "R110949",
                    "label": "Synthesis of cobinamide"
                }
            ],
            "abstract": "we present a new method for the preparation of cobinamide (cn)2cbi, a vitamin b12 precursor, that should allow its broader utility. treatment of vitamin b12 with only nacn and heating in a microwave reactor affords (cn)2cbi as the sole product. the purification procedure was greatly simplified, allowing for easy isolation of the product in 94% yield. the use of microwave heating proved beneficial also for (cn)2cbi(c-lactone) synthesis. treatment of (cn)2cbi with triethanolamine led to (cn)2cbi(c-lactam)."
        },
        {
            "id": "R78266",
            "label": "Evaluating the impact of visualization of risk upon emergency route-planning",
            "doi": "10.1080/13658816.2019.1701677",
            "research_field": {
                "id": "R317",
                "label": "Geographic Information Sciences"
            },
            "research_problems": [
                {
                    "id": "R78273",
                    "label": "route-planning under risk"
                }
            ],
            "abstract": "abstract this paper reports on a controlled experiment evaluating how different cartographic representations of risk affect participants\u2019 performance on a complex spatial decision task: route planning. the specific experimental scenario used is oriented towards emergency route-planning during flood response. the experiment compared six common abstract and metaphorical graphical symbolizations of risk. the results indicate a pattern of less-preferred graphical symbolizations associated with slower responses and lower-risk route choices. one mechanism that might explain these observed relationships would be that more complex and effortful maps promote closer attention paid by participants and lower levels of risk taking. such user considerations have important implications for the design of maps and mapping interfaces for emergency planning and response. the data also highlights the importance of the \u2018right decision, wrong outcome problem\u2019 inherent in decision-making under uncertainty: in individual instances, more risky decisions do not always lead to worse outcomes."
        },
        {
            "id": "R73135",
            "label": "The data-literature interlinking service: Towards a common infrastructure for sharing data-article links",
            "doi": "10.1108/prog-06-2016-0048",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R1033",
                    "label": "Scholarly communications representation"
                }
            ],
            "abstract": "\\n purpose \\n research data publishing is today widely regarded as crucial for reproducibility, proper assessment of scientific results, and as a way for researchers to get proper credit for sharing their data. however, several challenges need to be solved to fully realize its potential, one of them being the development of a global standard for links between research data and literature. current linking solutions are mostly based on bilateral, ad hoc agreements between publishers and data centers. these operate in silos so that content cannot be readily combined to deliver a network graph connecting research data and literature in a comprehensive and reliable way. the research data alliance (rda) publishing data services working group (pds-wg) aims to address this issue of fragmentation by bringing together different stakeholders to agree on a common infrastructure for sharing links between datasets and literature. the paper aims to discuss these issues. \\n \\n \\n design/methodology/approach \\n this paper presents the synergic effort of the rda pds-wg and the openaire infrastructure toward enabling a common infrastructure for exchanging data-literature links by realizing and operating the data-literature interlinking (dli) service. the dli service populates and provides access to a graph of data set-literature links (at the time of writing close to five million, and growing) collected from a variety of major data centers, publishers, and research organizations. \\n \\n \\n findings \\n to achieve its objectives, the service proposes an interoperable exchange data model and format, based on which it collects and publishes links, thereby offering the opportunity to validate such common approach on real-case scenarios, with real providers and consumers. feedback of these actors will drive continuous refinement of the both data model and exchange format, supporting the further development of the service to become an essential part of a universal, open, cross-platform, cross-discipline solution for collecting, and sharing data set-literature links. \\n \\n \\n originality/value \\n this realization of the dli service is the first technical, cross-community, and collaborative effort in the direction of establishing a common infrastructure for facilitating the exchange of data set-literature links. as a result of its operation and underlying community effort, a new activity, name scholix, has been initiated involving the technological level stakeholders such as datacite and crossref. \\n"
        },
        {
            "id": "R170447",
            "label": "Physiological State Influences the Social Interactions of Two Honeybee Nest Mates",
            "doi": "10.1371/journal.pone.0032677",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"physiological state profoundly influences the expression of the behaviour of individuals and can affect social interactions between animals. how physiological state influences food sharing and social behaviour in social insects is poorly understood. here, we examined the social interactions and food sharing behaviour of honeybees with the aim of developing the honeybee as a model for understanding how an individual's state influences its social interactions. the state of individual honeybees was manipulated by either starving donor bees or feeding them sucrose or low doses of ethanol to examine how a change in hunger or inebriation state affected the social behaviours exhibited by two closely-related nestmates. using a lab-based assay for measuring individual motor behaviour and social behaviour, we found that behaviours such as antennation, willingness to engage in trophallaxis, and mandible opening were affected by both hunger and ethanol intoxication. inebriated bees were more likely to exhibit mandible opening, which may represent a form of aggression, than bees fed sucrose alone. however, intoxicated bees were as willing to engage in trophallaxis as the sucrose-fed bees. the effects of ethanol on social behaviors were dose-dependent, with higher doses of ethanol producing larger effects on behaviour. hungry donor bees, on the other hand, were more likely to engage in begging for food and less likely to antennate and to display mandible opening. we also found that when nestmates received food from donors previously fed ethanol, they began to display evidence of inebriation, indicating that ethanol can be retained in the crop for several hours and that it can be transferred between honeybee nestmates during trophallaxis.\""
        },
        {
            "id": "R170719",
            "label": "Workplace Social Capital and Mental Health among Chinese Employees: A Multi-Level, Cross-Sectional Study",
            "doi": "10.1371/journal.pone.0085005",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background whereas the majority of previous research on social capital and health has been on residential neighborhoods and communities, the evidence remains sparse on workplace social capital. to address this gap in the literature, we examined the association between workplace social capital and health status among chinese employees in a large, multi-level, cross-sectional study. methods by employing a two-stage stratified random sampling procedure, 2,796 employees were identified from 35 workplaces in shanghai during march to november 2012. workplace social capital was assessed using a validated and psychometrically tested eight-item measure, and the chinese language version of the who-five well-being index (who-5) was used to assess mental health. control variables included sex, age, marital status, education level, occupation status, smoking status, physical activity, and job stress. multilevel logistic regression analysis was conducted to explore whether individual- and workplace-level social capital was associated with mental health status. results in total, 34.9% of workers reported poor mental health (who-5<13). after controlling for individual-level socio-demographic and lifestyle variables, compared to workers with the highest quartile of personal social capital, workers with the third, second, and lowest quartiles exhibited 1.39 to 3.54 times greater odds of poor mental health, 1.39 (95% ci: 1.10\u20131.75), 1.85 (95% ci: 1.38\u20132.46) and 3.54 (95% ci: 2.73\u20134.59), respectively. corresponding odds ratios for workplace-level social capital were 0.95 (95% ci: 0.61\u20131.49), 1.14 (95% ci: 0.72\u20131.81) and 1.63 (95% ci: 1.05\u20132.53) for the third, second, and lowest quartiles, respectively. conclusions higher workplace social capital is associated with lower odds of poor mental health among chinese employees. promoting social capital at the workplace may contribute to enhancing employees\u2019 mental health in china."
        },
        {
            "id": "R170451",
            "label": "A Selective Emotional Decision-Making Bias Elicited by Facial Expressions",
            "doi": "10.1371/journal.pone.0033461",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "emotional and social information can sway otherwise rational decisions. for example, when participants decide between two faces that are probabilistically rewarded, they make biased choices that favor smiling relative to angry faces. this bias may arise because facial expressions evoke positive and negative emotional responses, which in turn may motivate social approach and avoidance. we tested a wide range of pictures that evoke emotions or convey social information, including animals, words, foods, a variety of scenes, and faces differing in trustworthiness or attractiveness, but we found only facial expressions biased decisions. our results extend brain imaging and pharmacological findings, which suggest that a brain mechanism supporting social interaction may be involved. facial expressions appear to exert special influence over this social interaction mechanism, one capable of biasing otherwise rational choices. these results illustrate that only specific types of emotional experiences can best sway our choices."
        },
        {
            "id": "R172579",
            "label": "WISARD\u00c2\u00b7a radical step forward in image recognition",
            "doi": "10.1108/eb007637",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R172647",
                    "label": "Facial recognition"
                }
            ],
            "abstract": "the wisard recognition system invented at brunei university has been developed into an industrialised product by computer recognition systems under licence from the british technology group. using statistical pattern classification it already shows great potential in rapid sorting, and research indicates that it will track objects with positional feedback, rather like the human eye."
        },
        {
            "id": "R198904",
            "label": "NANE: Identifying Misuse Cases Using Temporal Norm Enactments",
            "doi": "10.1109/re.2016.34",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "recent data breaches in domains such as healthcare where confidentiality of data is crucial indicate that breaches often originate from misuses, not only from vulnerabilities in the technical (software or hardware) architecture. current requirements engineering (re) approaches determine what access control mechanisms are needed to protect sensitive resources (assets). however, current re approaches inadequately characterize how a user is expected to interact with others in relation to the relevant assets. consequently, a requirements analyst cannot readily identify misuses by legitimate users. we adopt social norms as a natural, formal means of characterizing user interactions whereby potential misuses map to norm violations. our research goal is to help analysts identify misuse cases by formal reasoning about norm enactments. we propose nane, a formal framework for identifying such misuse cases using a semiautomated process. we demonstrate how nane enables monitoring of potential misuses on a healthcare scenario."
        },
        {
            "id": "R171156",
            "label": "Relationship between Resilience, Psychological Distress and Physical Activity in Cancer Patients: A Cross-Sectional Observation Study",
            "doi": "10.1371/journal.pone.0154496",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective psychological distress remains a major challenge in cancer care. the complexity of psychological symptoms in cancer patients requires multifaceted symptom management tailored to individual patient characteristics and active patient involvement. we assessed the relationship between resilience, psychological distress and physical activity in cancer patients to elucidate potential moderators of the identified relationships. method a cross-sectional observational study to assess the prevalence of symptoms and supportive care needs of oncology patients undergoing chemotherapy, radiotherapy or chemo-radiation therapy in a tertiary oncology service. resilience was assessed using the 10-item connor-davidson resilience scale (cd-risc 10), social support was evaluated using the 12-item multidimensional scale of perceived social support (mspss) and both psychological distress and activity level were measured using corresponding subscales of the rotterdam symptom checklist (rscl). socio-demographic and medical data were extracted from patient medical records. correlation analyses were performed and structural equation modeling was employed to assess the associations between resilience, psychological distress and activity level as well as selected socio-demographic variables. results data from 343 patients were included in the analysis. our revised model demonstrated an acceptable fit to the data (\u03c72(163) = 313.76, p = .000, comparative fit index (cfi) = .942, tucker-lewis index (tli) = .923, root mean square error of approximation (rmsea) = .053, 90% ci [.044.062]). resilience was negatively associated with psychological distress (\u03b2 = -.59), and positively associated with activity level (\u03b2 = .20). the relationship between resilience and psychological distress was moderated by age (\u03b2 = -0.33) but not social support (\u03b2 = .10, p = .12). conclusion cancer patients with higher resilience, particularly older patients, experience lower psychological distress. patients with higher resilience are physically more active. evaluating levels of resilience in cancer patients then tailoring targeted interventions to facilitate resilience may help improve the effectiveness of psychological symptom management interventions."
        },
        {
            "id": "R169793",
            "label": "The Impact of Visual Guided Order Picking on Ocular Comfort, Ocular Surface and Tear Function",
            "doi": "10.1371/journal.pone.0157564",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose we investigated the effects of a visual picking system on ocular comfort, the ocular surface and tear function compared to those of a voice guided picking solution. design prospective, observational, cohort study. method setting: institutional. study population: a total of 25 young asymptomatic volunteers performed commissioning over 10 hours on two consecutive days. main outcome measures: the operators were guided in the picking process by two different picking solutions, either visually or by voice while their subjective symptoms and ocular surface and tear function parameters were recorded. results the visual analogue scale (vas) values, according to subjective dry eye symptoms, in the visual condition were significantly higher at the end of the commissioning than the baseline measurements. in the voice condition, the vas values remained stable during the commissioning. the tear break-up time (but) values declined significantly in the visual condition (pre-task: 16.6 sec and post-task: 9.6 sec) in the right eyes, that were exposed to the displays, the left eyes in the visual condition showed only a minor decline, whereas the but values in the voice condition remained constant (right eyes) or even increased (left eyes) over the time. no significant differences in the tear meniscus height values before and after the commissioning were observed in either condition. conclusion in our study, the use of visually guided picking solutions was correlated with post-task subjective symptoms and tear film instability."
        },
        {
            "id": "R169964",
            "label": "Incidence and risk factors for developing infection in patients presenting with uninfected diabetic foot ulcers",
            "doi": "10.1371/journal.pone.0177916",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective there is a paucity of research on patients presenting with uninfected diabetic foot ulcers (dfu) that go on to develop infection. we aimed to investigate the incidence and risk factors for developing infection in a large regional cohort of patients presenting with uninfected dfus. methods we performed a secondary analysis of data collected from a validated prospective state-wide clinical diabetic foot database in queensland (australia). patients presenting for their first visit with an uninfected dfu to a diabetic foot service in one of thirteen queensland regions between january 2012 and december 2013 were included. socio-demographic, medical history, foot disease history, dfu characteristics and treatment variables were captured at the first visit. patients were followed until their dfu healed, or if their dfu did not heal for 12-months, to determine if they developed a foot infection in that period. results overall, 853 patients were included; mean(standard deviation) age 62.9(12.8) years, 68.0% male, 90.9% type 2 diabetes, 13.6% indigenous australians. foot infection developed in 342 patients for an overall incidence of 40.1%; 32.4% incidence in dfus healed <3 months, 55.9% in dfus healed between 3\u201312 months (p<0.05). independent risk factors (odds ratio (95% confidence interval)) for developing infection were: dfus healed between 3\u201312 months (2.3 (1.6\u20133.3)), deep dfus (2.2 (1.2\u20133.9)), peripheral neuropathy (1.8 (1.1\u20132.9)), previous dfu history (1.7 (1.2\u20132.4)), foot deformity (1.4 (1.0\u20132.0)), female gender (1.5 (1.1\u20132.1)) and years of age (0.98 (0.97\u20130.99)) (all p<0.05). conclusions a considerable proportion of patients presenting with an uninfected dfu will develop an infection prior to healing. to prevent infection clinicians treating patients with uninfected dfus should be particularly vigilant with those presenting with deep dfus, previous dfu history, peripheral neuropathy, foot deformity, younger age, female gender and dfus that have not healed by 3 months after presentation."
        },
        {
            "id": "R131098",
            "label": "Real-world multiobject, multigrasp detection",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R121349",
                    "label": "Robotic Grasping"
                }
            ],
            "abstract": "a deep learning architecture is proposed to predict graspable locations for robotic manipulation. it considers situations where no, one, or multiple object(s) are seen. by defining the learning problem to be classified with null hypothesis competition instead of regression, the deep neural network with red, green, blue and depth (rgb-d) image input predicts multiple grasp candidates for a single object or multiple objects, in a single shot. the method outperforms state-of-the-art approaches on the cornell dataset with 96.0% and 96.1% accuracy on imagewise and objectwise splits, respectively. evaluation on a multiobject dataset illustrates the generalization capability of the architecture. grasping experiments achieve 96.0% grasp localization and 89.0% grasping success rates on a test set of household objects. the real-time process takes less than 0.25\\xa0s from image to plan."
        },
        {
            "id": "R145374",
            "label": "Using Syndromic Data for Opioid Overdose Surveillance in Utah",
            "doi": "10.5210/ojphi.v10i1.8988",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "objective:\\xa0 to monitor opioid-related overdose in real-time using emergency department visit data and to develop an opioid overdose surveillance report for utah department of health (udoh) and its public health partners. introduction:\\xa0 the current surveillance system for opioid-related overdoses at udoh has been limited to mortality data provided by the office of the medical examiner (ome). timeliness is a major concern with ome data due to the considerable lag in its availability, often up to six months or more. to enhance opioid overdose surveillance, udoh has implemented additional surveillance using timely syndromic data to monitor fatal and nonfatal opioid-related overdoses in utah. methods:\\xa0 as one of the agencies participating in the national syndromic surveillance program (nssp), udoh submits de-identified data on emergency department visit from utah\u2019s hospitals and urgent care facilities in close to real-time to the nssp platform. emergency department visit data are available for analysis using the electronic surveillance system for the early notification of community-based epidemics (essence) system provided by nssp. essence provides udoh with patient-level syndromic data for analysis and early detection of abnormal patterns in emergency visits. a total of 38 out of 48 acute care hospitals and multiple urgent care facilities are enrolled in the system in utah. more than 90% of these hospitals report chief complaint data, and discharge data are available from about 15% of the facilities. data were analyzed by querying key terms in the chief complaint field including: any entry of: \u2018overdose\u2019, drug and brand names for opioids, street names, \u2018naloxone\u2019, and miss-spellings. exclusion terms included any mention of: \u2018denies\u2019, \u2018quit\u2019, \u2018refill\u2019, \u2018withdraw\u2019, \u2018dependence\u2019, etc. data containing any icd entry of: t40.0-t40.4, t40.60, and t40.69 were included in the analysis. results:\\xa0 between september 1, 2016 and august 31, 2017, utah department of health identified 4,063 opioid-related overdose emergency department (ed) visits through the essence system using both chief complaint and discharge diagnosis queries. of these visits, 3,865 (95%) were identified using chief complaints alone and 198 (5%) visits were added by searching the discharge diagnosis field. opioid-related visits comprised approximately 0.3% of the total ed visits (1,267,244) reported during this time (graph 1). more than half of the opioid-related emergency visits were reported from just five facilities. rate of opioid-related visits ranging from 0 to 292 visits per 100,000 population per year (median: 108 visits per 100,000 population per year), with an overall rate for the state of 129 visits per100, 000 population per year. the highest rate of opioid-related visits occurred among patients aged 18 to 24 (219 visits per 100,000 population per year), and 59% of all opioid-related patients in utah were female. conclusions:\\xa0 the results presented are estimates of opioid-related overdoses reported using close to real-time data. these results would not include visits with incomplete or incorrectly coded chief complaints or discharge codes, or cases of opioid overdose who do not present to an emergency department or urgent care facility. the results from using syndromic data are consistent with existing surveillance findings using mortality data in utah. this suggests that syndromic surveillance data are useful for rapidly capturing opioid events, which may allow for a timelier public health response. udoh is currently evaluating syndromic surveillance data versus hospital discharge data for opioid-related emergency department visits, which may further optimize queries in essence, in order to provide improved opioid surveillance data to local public health partners. this analysis demonstrates that using syndromic surveillance data provides a more time-efficient alternative, enabling more rapid public health interventions, which improved opportunities to reduce opioid-related morbidity and mortality in utah."
        },
        {
            "id": "R111061",
            "label": "Reversed urbanism: Inferring urban performance through behavioral patterns in temporal telecom data",
            "doi": "10.1177/2399808319840668",
            "research_field": {
                "id": "R317",
                "label": "Geographic Information Sciences"
            },
            "research_problems": [
                {
                    "id": "R111004",
                    "label": "Determining land use based on mobile call records"
                }
            ],
            "abstract": "abstract a fundamental aspect of well performing cities is successful public spaces. for centuries, understanding these places has been limited to sporadic observations and laborious data collection. this study proposes a novel methodology to analyze citywide, discrete urban spaces using highly accurate anonymized telecom data and machine learning algorithms. through superposition of human dynamics and urban features, this work aims to expose clear correlations between the design of the city and the behavioral patterns of its users. geolocated telecom data, obtained for the state of andorra, were initially analyzed to identify \u201cstay-points\u201d\u2014events in which cellular devices remain within a certain roaming distance for a given length of time. these stay-points were then further analyzed to find clusters of activity characterized in terms of their size, persistence, and diversity. multivariate linear regression models were used to identify associations between the formation of these clusters and various urban features such as urban morphology or land-use within a 25\u201350 meters resolution. some of the urban features that were found to be highly related to the creation of large, diverse and long-lasting clusters were the presence of service and entertainment amenities, natural water features, and the betweenness centrality of the road network; others, such as educational and park amenities were shown to have a negative impact. ultimately, this study suggests a \u201creversed urbanism\u201d methodology: an evidence-based approach to urban design, planning, and decision making, in which human behavioral patterns are instilled as a foundational design tool for inferring the success rates of highly performative urban places."
        },
        {
            "id": "R169194",
            "label": "Standardized Environmental Enrichment Supports Enhanced Brain Plasticity in Healthy Rats and Prevents Cognitive Impairment in Epileptic Rats",
            "doi": "10.1371/journal.pone.0053888",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "environmental enrichment of laboratory animals influences brain plasticity, stimulates neurogenesis, increases neurotrophic factor expression, and protects against the effects of brain insult. however, these positive effects are not constantly observed, probably because standardized procedures of environmental enrichment are lacking. therefore, we engineered an enriched cage (the marlau\u2122 cage), which offers: (1) minimally stressful social interactions; (2) increased voluntary exercise; (3) multiple entertaining activities; (4) cognitive stimulation (maze exploration), and (5) novelty (maze configuration changed three times a week). the maze, which separates food pellet and water bottle compartments, guarantees cognitive stimulation for all animals. compared to rats raised in groups in conventional cages, rats housed in marlau\u2122 cages exhibited increased cortical thickness, hippocampal neurogenesis and hippocampal levels of transcripts encoding various genes involved in tissue plasticity and remodeling. in addition, rats housed in marlau\u2122 cages exhibited better performances in learning and memory, decreased anxiety-associated behaviors, and better recovery of basal plasma corticosterone level after acute restraint stress. marlau\u2122 cages also insure inter-experiment reproducibility in spatial learning and brain gene expression assays. finally, housing rats in marlau\u2122 cages after severe status epilepticus at weaning prevents the cognitive impairment observed in rats subjected to the same insult and then housed in conventional cages. by providing a standardized enriched environment for rodents during housing, the marlau\u2122 cage should facilitate the uniformity of environmental enrichment across laboratories."
        },
        {
            "id": "R111748",
            "label": "The Coupled Brains of Captivated Audiences: An Investigation of the Collective Brain Dynamics of an Audience Watching \t\t\t\t\ta Suspenseful Film",
            "doi": "10.1027/1864-1105/a000271",
            "research_field": {
                "id": "R111778",
                "label": "Communication Neuroscience"
            },
            "research_problems": [],
            "abstract": "abstract. suspense not only creates a strong psychological tension within individuals, but it does so reliably across viewers who become collectively engaged with the story. despite its prevalence in media psychology, limited work has examined suspense from a media neuroscience perspective, and thus the biological underpinnings of suspense remain unknown. here we examine continuous brain responses of 494 viewers watching a suspenseful movie. to create a time-resolved measure of the degree to which a movie aligns audience-wide brain responses, we computed dynamic inter-subject correlations of functional magnetic resonance imaging (fmri) time series among all viewers using sliding-window analysis. in parallel, we captured in-the-moment reports of suspense in an independent sample via continuous response measurement (crm). we found that dynamic inter-subject correlations over the course of the movie tracked well with the reported suspense in the crm sample, particularly in regions associated with emotional salience and higher cognitive processes. these results are compatible with theoretical views on motivated attention and psychological tension. the finding that fmri-based audience response measurement relates to audience reports of suspense creates new opportunities for research on the mechanisms of suspense and other entertainment phenomena and has applied potential for measuring audience responses in a nonreactive and objective fashion."
        },
        {
            "id": "R170738",
            "label": "Mate Recognition and Expression of Affective State in Croop Calls of Northern Bald Ibis (Geronticus eremita)",
            "doi": "10.1371/journal.pone.0088265",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "northern bald ibis are socially monogamous and year-round colonial birds with a moderate repertoire of calls. their \u2018croop\u2019, for example, is used during greeting of mates, but also during agonistic encounters, and provides an ideal case to study whether calls are revealing with respect to motivational states. we recorded croop calls in a semi-tame and free-roaming flock of northern bald ibis in austria, and analysed the vocal structure to identify parameters (e.g. call duration, fundamental frequency) potentially differing between social contexts, sexes and individuals. additionally, we conducted playback experiments to test whether mated pairs would discriminate each other by their greeting croops. acoustic features showed highly variable temporal and structural parameters. almost all calls could be classified correctly and assigned to the different social contexts and sexes. classification results of greeting croops were less clear for individuality. however, incubating individuals looked up more often and longer in response to playbacks of the greeting calls of their mate than to other colony members, indicating mate recognition. we show that acoustic parameters of agonistic and greeting croops contain features that may indicate the expression of affective states, and that greeting croops encode individual differences that are sufficient for individual recognition."
        },
        {
            "id": "R130890",
            "label": "Regularizing and Optimizing LSTM Language Models",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "recurrent neural networks (rnns), such as long short-term memory networks (lstms), serve as a fundamental building block for many sequence learning tasks, including machine translation, language modeling, and question answering. in this paper, we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing lstm-based models. we propose the weight-dropped lstm which uses dropconnect on hidden-to-hidden weights as a form of recurrent regularization. further, we introduce nt-asgd, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. using these and other regularization strategies, we achieve state-of-the-art word level perplexities on two data sets: 57.3 on penn treebank and 65.8 on wikitext-2. in exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on penn treebank and 52.0 on wikitext-2."
        },
        {
            "id": "R188503",
            "label": "Scrutinising what Open Access Journals Mean for Global Inequalities",
            "doi": "10.1007/s12109-020-09771-9",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R188318",
                    "label": "Differences between publication costs relative to purchasing power by country"
                }
            ],
            "abstract": "abstract in the current article, we tested our hypothesis by which high-impact journals tend to have higher article processing charges (apcs) by comparing journal if metrics with the oa publishing fees they charge. our study engaged with both journals in science, technology, engineering and mathematics (stem) fields and the humanities and social sciences (hss) and included hybrid, diamond and no oa journals. the overall findings demonstrate a positive relationship between apcs and journals with high if for two of the subject areas we examined but not for the third, which could be mediated by the characteristics and market environment of the publishers. we also found significant differences between the analysed research fields in terms of apc policies, as well as differences in the relationship between apcs and the if across periodicals. the study and analysis conducted reinforces our concerns that hybrid oa models are likely to perpetuate inequalities in knowledge production."
        },
        {
            "id": "R171695",
            "label": "Trauma exposure and IPV experienced by Afghan women: Analysis of the baseline of a randomised controlled trial",
            "doi": "10.1371/journal.pone.0201974",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background four decades of conflict has indelibly impacted the lives of afghans, exposing many to different forms of trauma. the aim of this paper investigate a hypothesis that (mostly war related) trauma is a key driver of partner violence in afghanistan. methods 1,463 women aged 18\u201348 were recruited into a randomised controlled trial (rct) to evaluate a women empowerment intervention in 8 villages of kabul and nangarhar provinces. the women were interviewed at baseline. the analysis uses multivariable logistic regression and structural equation modelling (sem) to describe relationships between measures. results 57.4% of women reported exposure to one of four types of trauma: 23.3% an armed attack, 39.4% had felt close to death, 10.6% witnessed a friend or family member being killed and 21.4% witnessed the death of a stranger or someone unknown. trauma exposure was associated with being older, pashtan, madrassa educated, and food insecure. women who were trauma exposed were more likely to have ever experienced ipv, have hit their children in the last 4 weeks, and be hit by a sibling or relative of their husband or their mother-in-law in the last year. they held less patriarchal personal gender attitudes and perceived the community to be more patriarchal. the sem showed that all pathways between trauma exposure and ipv were ultimately mediated by either (mostly mental) ill-health or quarrelling, but not both of these. there were multiple paths through which trauma exposure impacted women\u2019s past year experience of physical ipv. one was mediated by childhood trauma exposure and a latent variable for ill health. other paths were mediated by women\u2019s education and personal gender attitudes and ill-health, or else by quarrelling. trauma exposure was related to lower educational levels. another path was mediated by less patriarchal personal gender attitudes and ill health. community gender attitudes was a mediating variable on a path which was also mediated by ill health and another mediated by quarrelling. it was also a mediator on a path which included personal gender attitudes and ill-health. food insecurity mediated another path with ill health. it was also connected to childhood trauma, community gender attitudes and educational level. conclusion trauma exposure due to conflict will persist until the conflict ends but the impact on women can be ameliorated. this analysis suggests interventions to reduce women\u2019s exposure to ipv should focus on reducing poverty, changing social norms on gender, providing relationship skills to help reduce quarrelling and supporting women\u2019s mental health."
        },
        {
            "id": "R198000",
            "label": "Sentinel-2 Exposed Soil Composite for Soil Organic Carbon Prediction",
            "doi": "10.3390/rs13091791",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R196702",
                    "label": "Monitoring of soil organic carbon (SOC)"
                }
            ],
            "abstract": "pilot studies have demonstrated the potential of remote sensing for soil organic carbon (soc) mapping in exposed croplands. however, the use of remote sensing for soc prediction is often hindered by disturbing factors at the soil surface, such as photosynthetic active and non-photosynthetic active vegetation, variation in soil moisture or surface roughness. with the increasing amount of freely available satellite data, recent studies have focused on stabilizing the soil reflectance by building image composites. these composites tend to minimize the disturbing effects by applying sets of criteria. here, we aim to develop a robust method that allows selecting sentinel-2 (s-2) pixels with minimal influence of the following disturbing factors: crop residues, surface roughness and soil moisture. we selected all s-2 cloud-free images covering the belgian loam belt from january 2019 to december 2020 (in total 36 images). we then built nine exposed soil composites based on four sets of criteria: (1) lowest normalized burn ratio (nbr2), (2) normalized difference vegetation index (ndvi) &lt; 0.25, (3\u20135) ndvi &lt; 0.25 and nbr2 &lt; threshold, (6) the \u2018greening-up\u2019 period of a crop and (7\u20139) the \u2018greening-up\u2019 period of a crop and nbr2 &lt; threshold. the \u2018greening-up\u2019 period was selected based on the ndvi timeline, where \u2018greening-up\u2019 is considered as the last date of acquisition where the soil is exposed (ndvi &lt; 0.25) before the crop develops (ndvi &gt; 0.25). we then built a partial least square regression (plsr) model with 10-fold cross-validation to estimate the soc content based on 137 georeferenced calibration samples on the nine composites. we obtained non-satisfactory results (r2 &lt; 0.30, rmse &gt; 2.50 g c kg\u20131, and rpd &lt; 1.4, n &gt; 68) for all composites except for the composite in the \u2018greening-up\u2019 stage with a nbr2 &lt; 0.07 (r2 = 0.54 \u00b1 0.12, rpd = 1.68 \u00b1 0.45 and rmse = 2.09 \u00b1 0.39 g c kg\u20131, n = 49). hence, the \u2018greening-up\u2019 method combined with a strict nbr2 threshold allows selecting the purest exposed soil pixels suitable for soc prediction. the limit of this method might be its coverage of the total cropland area, which in a two-year period reached 62%, compared to 95% coverage if only the ndvi threshold is applied."
        },
        {
            "id": "R148537",
            "label": "A Twisted Thieno[3,4-b\n]thiophene-Based Electron Acceptor Featuring a 14-\u00cf\u0080-Electron Indenoindene Core for High-Performance Organic Photovoltaics",
            "doi": "10.1002/adma.201704510",
            "research_field": {
                "id": "R126",
                "label": "Materials Chemistry"
            },
            "research_problems": [
                {
                    "id": "R146783",
                    "label": "Organic solar cells"
                }
            ],
            "abstract": "with an indenoindene core, a new thieno[3,4\u2010b]thiophene\u2010based small\u2010molecule electron acceptor, 2,2\u2032\u2010((2z,2\u2032z)\u2010((6,6\u2032\u2010(5,5,10,10\u2010tetrakis(2\u2010ethylhexyl)\u20105,10\u2010dihydroindeno[2,1\u2010a]indene\u20102,7\u2010diyl)bis(2\u2010octylthieno[3,4\u2010b]thiophene\u20106,4\u2010diyl))bis(methanylylidene))bis(5,6\u2010difluoro\u20103\u2010oxo\u20102,3\u2010dihydro\u20101h\u2010indene\u20102,1\u2010diylidene))dimalononitrile (niti), is successfully designed and synthesized. compared with 12\u2010\u03c0\u2010electron fluorene, a carbon\u2010bridged biphenylene with an axial symmetry, indenoindene, a carbon\u2010bridged e\u2010stilbene with a centrosymmetry, shows elongated \u03c0\u2010conjugation with 14 \u03c0\u2010electrons and one more sp3 carbon bridge, which may increase the tunability of electronic structure and film morphology. despite its twisted molecular framework, niti shows a low optical bandgap of 1.49 ev in thin film and a high molar extinction coefficient of 1.90 \u00d7 105m\u22121 cm\u22121 in solution. by matching niti with a large\u2010bandgap polymer donor, an extraordinary power conversion efficiency of 12.74% is achieved, which is among the best performance so far reported for fullerene\u2010free organic photovoltaics and is inspiring for the design of new electron acceptors."
        },
        {
            "id": "R170606",
            "label": "Socially-Assigned Race, Healthcare Discrimination and Preventive Healthcare Services",
            "doi": "10.1371/journal.pone.0064522",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background race and ethnicity, typically defined as how individuals self-identify, are complex social constructs. self-identified racial/ethnic minorities are less likely to receive preventive care and more likely to report healthcare discrimination than self-identified non-hispanic whites. however, beyond self-identification, these outcomes may vary depending on whether racial/ethnic minorities are perceived by others as being minority or white; this perception is referred to as socially-assigned race. purpose to examine the associations between socially-assigned race and healthcare discrimination and receipt of selected preventive services. methods cross-sectional analysis of the 2004 behavioral risk factor surveillance system \u201creactions to race\u201d module. respondents from seven states and the district of columbia were categorized into 3 groups, defined by a composite of self-identified race/socially-assigned race: minority/minority (m/m, n\\u200a=\\u200a6,837), minority/white (m/w, n\\u200a=\\u200a929), and white/white (w/w, n\\u200a=\\u200a25,913). respondents were 18 years or older, with 61.7% under age 60; 51.8% of respondents were female. measures included reported healthcare discrimination and receipt of vaccinations and cancer screenings. results racial/ethnic minorities who reported being socially-assigned as minority (m/m) were more likely to report healthcare discrimination compared with those who reported being socially-assigned as white (m/w) (8.9% vs. 5.0%, p\\u200a=\\u200a0.002). those reporting being socially-assigned as white (m/w and w/w) had similar rates for past-year influenza (73.1% vs. 74.3%) and pneumococcal (69.3% vs. 58.6%) vaccinations; however, rates were significantly lower among m/m respondents (56.2% and 47.6%, respectively, p-values<0.05). there were no significant differences between the m/m and m/w groups in the receipt of cancer screenings. conclusions racial/ethnic minorities who reported being socially-assigned as white are more likely to receive preventive vaccinations and less likely to report healthcare discrimination compared with those who are socially-assigned as minority. socially-assigned race/ethnicity is emerging as an important area for further research in understanding how race/ethnicity influences health outcomes."
        },
        {
            "id": "R146467",
            "label": "Formulation of a model for automating infection surveillance: algorithmic detection of central-line associated bloodstream infection",
            "doi": "10.1197/jamia.m3196",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "objective\\nto formulate a model for translating manual infection control surveillance methods to automated, algorithmic approaches.\\n\\n\\ndesign\\nwe propose a model for creating electronic surveillance algorithms by translating existing manual surveillance practices into automated electronic methods. our model suggests that three dimensions of expert knowledge be consulted: clinical, surveillance, and informatics. once collected, knowledge should be applied through a process of conceptualization, synthesis, programming, and testing.\\n\\n\\nresults\\nwe applied our framework to central vascular catheter associated bloodstream infection surveillance, a major healthcare performance outcome measure. we found that despite major barriers such as differences in availability of structured data, in types of databases used and in semantic representation of clinical terms, bloodstream infection detection algorithms could be deployed at four very diverse medical centers.\\n\\n\\nconclusions\\nwe present a framework that translates existing practice-manual infection detection-to an automated process for surveillance. our experience details barriers and solutions discovered during development of electronic surveillance for central vascular catheter associated bloodstream infections at four hospitals in a variety of data environments. moving electronic surveillance to the next level-availability at a majority of acute care hospitals nationwide-would be hastened by the incorporation of necessary data elements, vocabularies and standards into commercially available electronic health records."
        },
        {
            "id": "R162898",
            "label": "ClearTK 2.0: Design Patterns for Machine Learning in UIMA",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R162905",
                    "label": "constructing machine learning classifiers based on sets of features"
                }
            ],
            "abstract": "cleartk adds machine learning functionality to the uima framework, providing wrappers to popular machine learning libraries, a rich feature extraction library that works across different classifiers, and utilities for applying and evaluating machine learning models. since its inception in 2008, cleartk has evolved in response to feedback from developers and the community. this evolution has followed a number of important design principles including: conceptually simple annotator interfaces, readable pipeline descriptions, minimal collection readers, type system agnostic code, modules organized for ease of import, and assisting user comprehension of the complex uima framework."
        },
        {
            "id": "R149049",
            "label": "Ontologies for supply chain simulation modeling",
            "doi": "",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "simulation might be an effective decision support tool in supply chain management. the review of supply chain simulation modeling methodologies revealed some issues one of which is the practicability of simulation in the supply chain environment. the supply chain environment is dynamic, information intensive, geographically dispersed, and heterogeneous. in order to develop usable supply chain simulation models, the models should be feasibly applicable in the supply chain environment. distributed simulation models have been used by several researchers, however, their complexity and usability hindered their continuation. in this paper, a new approach is proposed. the approach is based on ontologies to integrate several supply chain views and models, which captures the required distributed knowledge to build simulation models. the ontology core is based on the scor model as the widely shared supply chain concepts. the ontology can define any supply chain and help the user to build the required simulation models"
        },
        {
            "id": "R107613",
            "label": "Static analysis and optimization of semantic web queries",
            "doi": "10.1145/2500130",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R75732",
                    "label": "SPARQL query optimization"
                }
            ],
            "abstract": "\\n static analysis is a fundamental task in query optimization. in this article we study static analysis and optimization techniques for sparql, which is the standard language for querying semantic web data. of particular interest for us is the\\n optionality \\n feature in sparql. it is crucial in semantic web data management, where data sources are inherently incomplete and the user is usually interested in partial answers to queries. this feature is one of the most complicated constructors in sparql and also the one that makes this language depart from classical query languages such as relational conjunctive queries. we focus on the class of well-designed sparql queries, which has been proposed in the literature as a fragment of the language with good properties regarding query evaluation. we first propose a tree representation for sparql queries, called pattern trees, which captures the class of well-designed sparql graph patterns. among other results, we propose several rules that can be used to transform pattern trees into a simple normal form, and study equivalence and containment. we also study the evaluation and enumeration problems for this class of queries.\\n"
        },
        {
            "id": "R171089",
            "label": "Differences in Anticipatory Behaviour between Rats (Rattus norvegicus) Housed in Standard versus Semi-Naturalistic Laboratory Environments",
            "doi": "10.1371/journal.pone.0147595",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "laboratory rats are usually kept in relatively small cages, but research has shown that they prefer larger and more complex environments. the physiological, neurological and health effects of standard laboratory housing are well established, but fewer studies have addressed the sustained emotional impact of a standard cage environment. one method of assessing affective states in animals is to look at the animals\u2019 anticipatory behaviour between the presentation of a cue signalling the arrival of a reward and the arrival of that reward. the primary aim of this study was to use anticipatory behaviour to assess the affective state experienced by female rats a) reared and housed long-term in a standard laboratory cage versus a semi-naturalistic environment, and b) before and after treatment with an antidepressant or an anxiolytic. a secondary aim was to add to the literature on anticipatory behaviour by describing and comparing the frequency and duration of individual elements of anticipatory behaviour displayed by rats reared in these two systems. in all experiments, total behavioural frequency was higher in standard-housed rats compared to rats from the semi-naturalistic condition, suggesting that standard-housed rats were more sensitive to rewards and experiencing poorer welfare than rats reared in the semi-naturalistic environment. what rats did in anticipation of the reward also differed between housing treatments, with standard-housed rats mostly rearing and rats from the semi-naturalistic condition mostly sitting facing the direction of the upcoming treat. drug interventions had no effect on the quantity or form of anticipatory behaviour, suggesting that the poorer welfare experienced by standard-housed rats was not analogous to depression or anxiety, or alternatively that the drug interventions were ineffective. this study adds to mounting evidence that standard laboratory housing for rats compromises rat welfare, and provides further scientific support for recommendations that current minimum standards be raised."
        },
        {
            "id": "R169739",
            "label": "Effect of Village Health Team Home Visits and Mobile Phone Consultations on Maternal and Newborn Care Practices in Masindi and Kiryandongo, Uganda: A Community-Intervention Trial",
            "doi": "10.1371/journal.pone.0153051",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction the world health organisation recommends home visits conducted by community health workers (in uganda known as village health teams\u2014vhts) in order to improve maternal and newborn health. this study measured the effect of home visits combined with mobile phone consultations on maternal and newborn care practices. method in a community intervention trial design 16 health centres in masindi and kiryandongo districts, uganda were randomly and equally allocated to one of two arms: control and intervention arms. eight control health centres received the usual maternal and newborn educational messages offered by professional health workers and eight intervention health centres that received an intervention package for maternal care and essential newborn care practices. in the intervention arm vhts made two prenatal and one postnatal home visit to households. vhts were provided with mobile phones to enable them make regular telephone consultations with health workers at the health centre serving the catchment area. the primary outcome was health facility delivery. other outcomes included antenatal attendances, birth preparedness, cord and thermal care and breastfeeding practices. analysis was by intention-to-treat. results a total of 1385 pregnant women were analysed: 758 and 627 in the control and intervention arms respectively. significant post-intervention differences were: delivery place [adjusted odds ratio aor: 17.94(95%ci: 6.26\u201351.37); p<0.001], cord care [aor: 3.05(95%ci: 1.81\u20135.12); p<0.001] thermal care [aor: 7.58(95%ci: 2.52\u201322.82); p<0.001], and timely care-seeking for newborn illness [aor: 4.93(95%ci: 1.59\u201315.31); p = 0.006]. conclusion vhts can have an effect in promoting proper cord and thermal care for the newborn and improve timely care-seeking for health facility delivery and newborn illness, because they could answer questions and refer patients correctly. however, vhts should be supported by professional health workers through the use of mobile phones. trial registration clinicaltrials.gov nct02084680"
        },
        {
            "id": "R108934",
            "label": "Detector system with high time resolution for the continuous measurement of spectra in the vacuum ultraviolet wavelength range",
            "doi": "10.1063/1.1763261",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R108990",
                    "label": "VUV spectroscopy in low pressure plasmas"
                }
            ],
            "abstract": "a new detector system with high time resolution (1 ms) has been developed and applied for the continuous measurement of spectra in the vacuum ultraviolet (vuv) and extreme ultraviolet (euv) wavelength region at the fusion plasma experiment torus experiment for technology-oriented research (textor). the system consists of an open multichannel-plate (mcp) detector with subsequent first generation (gen i) light amplifier and a camera head which is based on a linear photodiode array with 1024 elements (pixels). the camera head provides the output signals of the individual pixels sequentially as an analog voltage with a full spectra rate of 1000 per second, which are measured using a pc-based data acquisition system. three vacuum spectrometers operating in the vuv/euv region (10\u2013130 nm) have been equipped with the new system and a successful campaign of measurements from about 4000 discharges at textor has been performed. spectra are recorded with a usable linear dynamic range of 10 bit and a wavelength resolution corresponding to a width of 3\u20134 pixels.a new detector system with high time resolution (1 ms) has been developed and applied for the continuous measurement of spectra in the vacuum ultraviolet (vuv) and extreme ultraviolet (euv) wavelength region at the fusion plasma experiment torus experiment for technology-oriented research (textor). the system consists of an open multichannel-plate (mcp) detector with subsequent first generation (gen i) light amplifier and a camera head which is based on a linear photodiode array with 1024 elements (pixels). the camera head provides the output signals of the individual pixels sequentially as an analog voltage with a full spectra rate of 1000 per second, which are measured using a pc-based data acquisition system. three vacuum spectrometers operating in the vuv/euv region (10\u2013130 nm) have been equipped with the new system and a successful campaign of measurements from about 4000 discharges at textor has been performed. spectra are recorded with a usable linear dynamic range of 10 bit and a wavelength resolu..."
        },
        {
            "id": "R171299",
            "label": "Exposure to digital marketing enhances young adults\u00e2\u0080\u0099 interest in energy drinks: An exploratory investigation",
            "doi": "10.1371/journal.pone.0171226",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "young adults experience faster weight gain and consume more unhealthy food than any other age groups. the impact of online food marketing on \u201cdigital native\u201d young adults is unclear. this study examined the effects of online marketing on young adults\u2019 consumption behaviours, using energy drinks as a case example. the elaboration likelihood model of persuasion was used as the theoretical basis. a pre-test post-test experimental research design was adopted using mixed-methods. participants (aged 18\u201324) were randomly assigned to control or experimental groups (n = 30 each). experimental group participants\u2019 attitudes towards and intended purchase and consumption of energy drinks were examined via surveys and semi-structured interviews after their exposure to two popular energy drink brands\u2019 websites and social media sites (exposure time 8 minutes). exposure to digital marketing contents of energy drinks improved the experimental group participants\u2019 attitudes towards and purchase and consumption intention of energy drinks. this study indicates the influential power of unhealthy online marketing on cognitively mature young adults. this study draws public health attentions to young adults, who to date have been less of a focus of researchers but are influenced by online food advertising."
        },
        {
            "id": "R77123",
            "label": "Heuristics-based query optimisation for SPARQL",
            "doi": "10.1145/2247596.2247635",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R75732",
                    "label": "SPARQL query optimization"
                }
            ],
            "abstract": "query optimization in rdf stores is a challenging problem as sparql queries typically contain many more joins than equivalent relational plans, and hence lead to a large join order search space. in such cases, cost-based query optimization often is not possible. one practical reason for this is that statistics typically are missing in web scale setting such as the linked open datasets (lod). the more profound reason is that due to the absence of schematic structure in rdf, join-hit ratio estimation requires complicated forms of correlated join statistics; and currently there are no methods to identify the relevant correlations beforehand. for this reason, the use of good heuristics is essential in sparql query optimization, even in the case that are partially used with cost-based statistics (i.e., hybrid query optimization). in this paper we describe a set of useful heuristics for sparql query optimizers. we present these in the context of a new heuristic sparql planner (hsp) that is capable of exploiting the syntactic and the structural variations of the triple patterns in a sparql query in order to choose an execution plan without the need of any cost model. for this, we define the variable graph and we show a reduction of the sparql query optimization problem to the maximum weight independent set problem. we implemented our planner on top of the monetdb open source column-store and evaluated its effectiveness against the state-of-the-art rdf-3x engine as well as comparing the plan quality with a relational (sql) equivalent of the benchmarks."
        },
        {
            "id": "R155421",
            "label": "Compositional stratigraphy of clay-bearing layered deposits at Mawrth Vallis, Mars: STRATIGRAPHY OF CLAY-BEARING DEPOSITS ON MARS",
            "doi": "10.1029/2008GL034385",
            "research_field": {
                "id": "R138056",
                "label": "Planetary Sciences"
            },
            "research_problems": [
                {
                    "id": "R155417",
                    "label": "Composition of clay bearing deposits using MRO CRISM"
                }
            ],
            "abstract": "phyllosilicates have previously been detected in layered outcrops in and around the martian outflow channel mawrth vallis. crism spectra of these outcrops exhibit features diagnostic of kaolinite, montmorillonite, and fe/mg\u2010rich smectites, along with crystalline ferric oxide minerals such as hematite. these minerals occur in distinct stratigraphic horizons, implying changing environmental conditions and/or a variable sediment source for these layered deposits. similar stratigraphic sequences occur on both sides of the outflow channel and on its floor, with al\u2010clay\u2010bearing layers typically overlying fe/mg\u2010clay\u2010bearing layers. this pattern, combined with layer geometries measured using topographic data from hirise and hrsc, suggests that the al\u2010clay\u2010bearing horizons at mawrth vallis postdate the outflow channel and may represent a later sedimentary or altered pyroclastic deposit that drapes the topography."
        },
        {
            "id": "R170443",
            "label": "Self-Assemblage and Quorum in the Earthworm Eisenia fetida (Oligochaete, Lumbricidae)",
            "doi": "10.1371/journal.pone.0032564",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "despite their ubiquity and ecological significance in temperate ecosystems, the behavioural ecology of earthworms is not well described. this study examines the mechanisms that govern aggregation behaviour specially the tendency of individuals to leave or join groups in the compost earthworm eisenia fetida, a species with considerable economic importance, especially in waste management applications. through behavioural assays combined with mathematical modelling, we provide the first evidence of self-assembled social structures in earthworms and describe key mechanisms involved in cluster formation. we found that the probability of an individual joining a group increased with group size, while the probability of leaving decreased. moreover, attraction to groups located at a distance was observed, suggesting a role for volatile cues in cluster formation. the size of earthworm clusters appears to be a key factor determining the stability of the group. these findings enhance our understanding of intra-specific interactions in earthworms and have potential implications for extraction and collection of earthworms in vermicomposting processes."
        },
        {
            "id": "R196786",
            "label": "Deep neural networks ensemble for detecting medication mentions in tweets",
            "doi": "10.1093/jamia/ocz156",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R196783",
                    "label": "medication mentions in tweets"
                }
            ],
            "abstract": "abstract objective twitter posts are now recognized as an important source of patient-generated data, providing unique insights into population health. a fundamental step toward incorporating twitter data in pharmacoepidemiologic research is to automatically recognize medication mentions in tweets. given that lexical searches for medication names suffer from low recall due to misspellings or ambiguity with common words, we propose a more advanced method to recognize them. materials and methods we present kusuri, an ensemble learning classifier able to identify tweets mentioning drug products and dietary supplements. kusuri (\u85ac, \u201cmedication\u201d in japanese) is composed of 2 modules: first, 4 different classifiers (lexicon based, spelling variant based, pattern based, and a weakly trained neural network) are applied in parallel to discover tweets potentially containing medication names; second, an ensemble of deep neural networks encoding morphological, semantic, and long-range dependencies of important words in the tweets makes the final decision. results on a class-balanced (50-50) corpus of 15 005 tweets, kusuri demonstrated performances close to human annotators with an f1 score of 93.7%, the best score achieved thus far on this corpus. on a corpus made of all tweets posted by 112 twitter users (98 959 tweets, with only 0.26% mentioning medications), kusuri obtained an f1 score of 78.8%. to the best of our knowledge, kusuri is the first system to achieve this score on such an extremely imbalanced dataset. conclusions the system identifies tweets mentioning drug names with performance high enough to ensure its usefulness, and is ready to be integrated in pharmacovigilance, toxicovigilance, or more generally, public health pipelines that depend on medication name mentions."
        },
        {
            "id": "R155867",
            "label": "Psychological distance towards COVID-19: Geographical and hypothetical distance predict attitudes and mediate knowledge",
            "doi": "10.1007/s12144-021-02415-x",
            "research_field": {
                "id": "R350",
                "label": "Health Psychology"
            },
            "research_problems": [
                {
                    "id": "R155873",
                    "label": "How is people's psychological distance related to their attitudes and behavior?"
                }
            ],
            "abstract": "abstract while different antecedents have been examined to explain peoples\u2019 reactions towards covid-19, there is only scarce understanding about the role of the subjective closeness and distance to the pandemic. within the current study, we applied the concept of psychological distance to understand the distance towards covid-19 and investigated its (1) connection with preventive attitudes and proactive behaviors, (2) context-specific antecedents, and its (3) mediating effect of knowledge on attitudes. using an online sample from a german quantitative cross-sectional study ( n \\u2009=\\u2009395, m \\u2009=\\u200932.2\\xa0years, sd \\u2009=\\u200913.9\\xa0years, 64.3% female) in july 2020, a time with a general low incidence of people infected with sars-cov2, we measured relevant socio-psychological constructs addressing covid-19 and included further information from external sources. based on a path model, we found geographical distance as a significant predictor of cognitive attitudes towards covid-19. furthermore, hypothetical distance (i.e., feeling to be likely affected by covid-19) predicted not only participants\u2019 affective, cognitive, and behavioral attitudes, but also the installation of a corona warning-app. while several variables affected the different dimensions of psychological distance, hypothetical and geographical distance mediated the effect of knowledge on attitudes. these results underline the role of geographical and hypothetical distance for health-related behaviors and education. for example, people will only comply with preventive measures if they feel geographically concerned by the disease, which is particularly challenging for fast-spreading global diseases such as covid-19. therefore, there is a need to clearly communicate the personal risks of diseases and address peoples\u2019 hypothetical distance."
        },
        {
            "id": "R193531",
            "label": "Biomechanical Validation of Upper-Body and Lower-Body Joint Movements of Kinect Motion Capture Data for Rehabilitation Treatments",
            "doi": "10.1109/iNCoS.2012.66",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"new and powerful hardware like kinect introduces the possibility of changing biomechanics paradigm, usually based on expensive and complex equipment. kinect is a markerless and cheap technology recently introduced from videogame industry. in this work we conduct a comparison study of the precision in the computation of joint angles between kinect and an optical motion capture professional system. we obtain a range of disparity that guaranties enough precision for most of the clinical rehabilitation treatments prescribed nowadays for patients. this way, an easy and cheap validation of these treatments can be obtained automatically, ensuring a better quality control process for the patient's rehabilitation.\""
        },
        {
            "id": "R168713",
            "label": "4Cin: A computational pipeline for 3D genome modeling and virtual Hi-C analyses from 4C data",
            "doi": "10.1371/journal.pcbi.1006030",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the use of 3c-based methods has revealed the importance of the 3d organization of the chromatin for key aspects of genome biology. however, the different caveats of the variants of 3c techniques have limited their scope and the range of scientific fields that could benefit from these approaches. to address these limitations, we present 4cin, a method to generate 3d models and derive virtual hi-c (vhi-c) heat maps of genomic loci based on 4c-seq or any kind of 4c-seq-like data, such as those derived from ng capture-c. 3d genome organization is determined by integrative consideration of the spatial distances derived from as few as four 4c-seq experiments. the 3d models obtained from 4c-seq data, together with their associated vhi-c maps, allow the inference of all chromosomal contacts within a given genomic region, facilitating the identification of topological associating domains (tad) boundaries. thus, 4cin offers a much cheaper, accessible and versatile alternative to other available techniques while providing a comprehensive 3d topological profiling. by studying tad modifications in genomic structural variants associated to disease phenotypes and performing cross-species evolutionary comparisons of 3d chromatin structures in a quantitative manner, we demonstrate the broad potential and novel range of applications of our method."
        },
        {
            "id": "R6178",
            "label": "Network based Framework for Author Name Disambiguation Applications",
            "doi": "10.14257/ijunesst.2015.8.9.09",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R6000",
                    "label": "Author name disambiguation"
                }
            ],
            "abstract": "with the rapid development of digital libraries, name disambiguation becomes more and more important technique to distinguish authors with same names from physical persons. many algorithms have been developed to accomplish the task. however, they are usually based on some restricted preconditions and rarely concern how to be incorporated into a practical application. in this paper, name disambiguation is regarded as the technique of learning module integrated with a knowledge base. a network is defined for the modeling of publication information, which facilitates the representation of differenttypes of relations among the attributes. the knowledge base component serves as the user interface for domain knowledge input. furthermore, this paper exploits a random walk with restart algorithm and affinity propagation clustering algorithm to finally output name disambiguation results."
        },
        {
            "id": "R191800",
            "label": "Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India",
            "doi": "10.3390/su132413758",
            "research_field": {
                "id": "R145",
                "label": "Environmental Sciences"
            },
            "research_problems": [
                {
                    "id": "R191805",
                    "label": "Land use and cover change (LUCC)\t\t\t\t\t"
                }
            ],
            "abstract": "the growing human population accelerates alterations in land use and land cover (lulc) over time, putting tremendous strain on natural resources. monitoring and assessing lulc change over large areas is critical in a variety of fields, including natural resource management and climate change research. lulc change has emerged as a critical concern for policymakers and environmentalists. as the need for the reliable estimation of lulc maps from remote sensing data grows, it is critical to comprehend how different machine learning classifiers perform. the primary goal of the present study was to classify lulc on the google earth engine platform using three different machine learning algorithms\u2014namely, support vector machine (svm), random forest (rf), and classification and regression trees (cart)\u2014and to compare their performance using accuracy assessments. the lulc of the study area was classified via supervised classification. for improved classification accuracy, ndvi (normalized difference vegetation index) and ndwi (normalized difference water index) indices were also derived and included. for the years 2016, 2018, and 2020, multitemporal sentinel-2 and landsat-8 data with spatial resolutions of 10 m and 30 m were used for the lulc classification. \u2018water bodies\u2019, \u2018forest\u2019, \u2018barren land\u2019, \u2018vegetation\u2019, and \u2018built-up\u2019 were the major land use classes. the average overall accuracy of svm, rf, and cart classifiers for landsat-8 images was 90.88%, 94.85%, and 82.88%, respectively, and 93.8%, 95.8%, and 86.4% for sentinel-2 images. these results indicate that rf classifiers outperform both svm and cart classifiers in terms of accuracy."
        },
        {
            "id": "R75785",
            "label": "SemEval-2020 Task 5: Counterfactual Recognition",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R75795",
                    "label": "Counterfactual recognition"
                },
                {
                    "id": "R75954",
                    "label": "Recognizing Counterfactual Statements"
                },
                {
                    "id": "R75955",
                    "label": "RCS"
                },
                {
                    "id": "R76000",
                    "label": "Detecting Antecedent and Consequent"
                },
                {
                    "id": "R76001",
                    "label": "DAC"
                }
            ],
            "abstract": "we present a counterfactual recognition (cr) task, the shared task 5 of semeval-2020. counterfactuals describe potential outcomes (consequents) produced by actions or circumstances that did not happen or cannot happen and are counter to the facts (antecedent). counterfactual thinking is an important characteristic of the human cognitive system; it connects antecedents and consequent with causal relations. our task provides a benchmark for counterfactual recognition in natural language with two subtasks. subtask-1 aims to determine whether a given sentence is a counterfactual statement or not. subtask-2 requires the participating systems to extract the antecedent and consequent in a given counterfactual statement. during the semeval-2020 official evaluation period, we received 27 submissions to subtask-1 and 11 to subtask-2. our data and baseline code are made publicly available at https://zenodo.org/record/3932442. the task website and leaderboard can be found at https://competitions.codalab.org/competitions/21691."
        },
        {
            "id": "R155276",
            "label": "Experimental Characterization of a Vernier Strain Sensor Using Cascaded Fiber Rings",
            "doi": "10.1109/lpt.2012.2222369",
            "research_field": {
                "id": "R194",
                "label": "Engineering"
            },
            "research_problems": [
                {
                    "id": "R155279",
                    "label": " Performance of  fiber optic strain sensors"
                }
            ],
            "abstract": "a highly sensitive strain sensor consisting of two cascaded fiber ring resonators based on the vernier effect is proposed. each fiber ring resonator, composed of an input optical coupler, an output optical coupler, and a polarization controller, has a comb-like transmission spectrum with peaks at its resonance wavelengths. as a result, the vernier effect will be generated, due to the displacement of the two transmission spectra. using this technique, strain measurements can be achieved by measuring the free spectral range of the cascaded fiber ring resonators. the experimental results show that the sensing setup can operate in large strain range with a sensitivity of 0.0129 nm-1/\u03bc\u03b5. the new generation of vernier strain sensor can also be useful for micro-displacement measurement."
        },
        {
            "id": "R211075",
            "label": "Efficient Transformers: A Survey",
            "doi": "10.1145/3530811",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "transformer model architectures have garnered immense interest lately due to their effectiveness across a range of domains like language, vision and reinforcement learning. in the field of natural language processing for example, transformers have become an indispensable staple in the modern deep learning stack. recently, a dizzying number of \u201cx-former\u201d models have been proposed - reformer, linformer, performer, longformer, to name a few - which improve upon the original transformer architecture, many of which make improvements around computational and memory efficiency . with the aim of helping the avid researcher navigate this flurry, this paper characterizes a large and thoughtful selection of recent efficiency-flavored \u201cx-former\u201d models, providing an organized and comprehensive overview of existing work and models across multiple domains."
        },
        {
            "id": "R188496",
            "label": "Researchers Outside APC-Financed Open Access: Implications for Scholars Without a Paying Institution",
            "doi": "10.1177/2158244014551714",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R188495",
                    "label": "Article processing charges as an obstacle for authors without affiliation to a scientific institution"
                }
            ],
            "abstract": "the article processing charge (apc) financed open access is a publication model that provides immediate and free access to scientific articles. more than half of the world\u2019s open access articles are published according to this concept. however, a side effect of the model is that research is not published if researchers cannot pay the publication charge. the study examines the nature of this phenomenon, its extent, and implications. the study places a special focus on authors who are not affiliated with a research institution. the proportion of these authors is identified among 2,184 danish authors in danish periodicals in 2010. the possibility for poor researchers to receive compensation from publishers is investigated as well. paying the apc is a problem for many researchers\u2014represented by around 30% of authors who have published in danish journals (unemployed scientists, students, as well as retired and private employees). grants from publishers exist, but they are small and too uncertain to ensure that research is published optimally. this study predicts that a large amount of valuable research risks not being published if this publishing model dominates without alternatives or countermeasures."
        },
        {
            "id": "R213376",
            "label": "Multilingual Entity Task (MET): Japanese Results",
            "doi": "",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R69806",
                    "label": "Named Entity Recognition"
                }
            ],
            "abstract": "japanese was one of the languages selected for evaluation of named entity identification algorithms in the tipster-sponsored multilingual entity task (met) program. as with the spanish and chinese groups (table 1), japanese systems automatically marked the names of organizations, people, and places within entity name expressions (enamex), dates and times within time expressions (timex), and percents and money within number expressions (numex). the participant japanese systems were developed in a four-month period of time and output results comparable to the message understanding conference-6 (muc-6) [1] english language systems with f-measures between 70 - 90% [2]."
        },
        {
            "id": "R130498",
            "label": "Dynamic Evaluation of Transformer Language Models",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "this research note combines two methods that have recently improved the state of the art in language modeling: transformers and dynamic evaluation. transformers use stacked layers of self-attention that allow them to capture long range dependencies in sequential data. dynamic evaluation fits models to the recent sequence history, allowing them to assign higher probabilities to re-occurring sequential patterns. by applying dynamic evaluation to transformer-xl models, we improve the state of the art on enwik8 from 0.99 to 0.94 bits/char, text8 from 1.08 to 1.04 bits/char, and wikitext-103 from 18.3 to 16.4 perplexity points."
        },
        {
            "id": "R171405",
            "label": "Experiences of operational costs of HPV vaccine delivery strategies in Gavi-supported demonstration projects",
            "doi": "10.1371/journal.pone.0182663",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "from 2012 to 2016, gavi, the vaccine alliance, provided support for countries to conduct small-scale demonstration projects for the introduction of the human papillomavirus vaccine, with the aim of determining which human papillomavirus vaccine delivery strategies might be effective and sustainable upon national scale-up. this study reports on the operational costs and cost determinants of different vaccination delivery strategies within these projects across twelve countries using a standardized micro-costing tool. the world health organization cervical cancer prevention and control costing tool was used to collect costing data, which were then aggregated and analyzed to assess the costs and cost determinants of vaccination. across the one-year demonstration projects, the average economic and financial costs per dose amounted to us$19.98 (standard deviation \u00b112.5) and us$8.74 (standard deviation \u00b15.8), respectively. the greatest activities representing the greatest share of financial costs were social mobilization at approximately 30% (range, 6\u201367%) and service delivery at about 25% (range, 3\u201346%). districts implemented varying combinations of school-based, facility-based, or outreach delivery strategies and experienced wide variation in vaccine coverage, drop-out rates, and service delivery costs, including transportation costs and per diems. size of target population, number of students per school, and average length of time to reach an outreach post influenced cost per dose. although the operational costs from demonstration projects are much higher than those of other routine vaccine immunization programs, findings from our analysis suggest that hpv vaccination operational costs will decrease substantially for national introduction. vaccination costs may be decreased further by annual vaccination, high initial investment in social mobilization, or introducing/strengthening school health programs. our analysis shows that drivers of cost are dependent on country and district characteristics. we therefore recommend that countries carry out detailed planning at the national and district levels to define a sustainable strategy for national hpv vaccine roll-out, in order to achieve the optimal balance between coverage and cost."
        },
        {
            "id": "R195182",
            "label": "On the Impact of Semantic Transparency on Understanding and Reviewing Social Goal Models",
            "doi": "10.1109/re.2018.00031",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"context: i* is one of the most influential languages in the requirements engineering research community. perhaps due to its complexity and low adoption in industry, it became a natural candidate for studies aiming at improving its concrete syntax and the stakeholders' ability to correctly interpret i* models. objectives: we evaluate the impact of semantic transparency on understanding and reviewing i* models, in the presence of a language key. methods: we performed a quasi-experiment comparing the standard i* concrete syntax with an alternative that has an increased semantic transparency. we asked 57 novice participants to perform understanding and reviewing tasks on i* models, and measured their accuracy, speed and ease, using metrics of task success, time and effort, collected with eye-tracking and participants' feedback. results: we found no evidence of improved accuracy or speed attributable to the alternative concrete syntax. although participants' perceived ease was similar, they devoted significantly less visual effort to the model and the provided language key, when using the alternative concrete syntax. conclusions: the context provided by the model and language key may mitigate the i* symbol recognition deficit reported in previous works. however, the alternative concrete syntax required a significantly lower visual effort.\""
        },
        {
            "id": "R209433",
            "label": "Open platform, eight-channel, portable bio-potential and activity data logger for wearable medical device development",
            "doi": "10.1049/EL.2015.2764",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the design of a wearable, portable and reconfigurable physical activity and an eight-channel bio-potential data logger, capable of increasing compliance by enabling customised feedback (i.e. calories expenditure and amount of physical activity) is presented while recording clinically meaningful information regarding a subject's health. here an application of the device to the cardio-vascular system comprising simultaneous recording of ecg and activity in both resting and under-stress conditions is presented (clinical trials are performed under the supervision of expert cardiologists at prince of wales hospital nsw, australia). the designed device (based around the low-power lpc1768 arm processor and the bio-potential front-end ads1298) is an open-source one and is provided under the gpl gnu 3.0 collaborative licence."
        },
        {
            "id": "R191289",
            "label": "BioELECTRA:Pretrained Biomedical text Encoder using Discriminators",
            "doi": "10.18653/v1/2021.bionlp-1.16",
            "research_field": {
                "id": "R238",
                "label": "Biomedical"
            },
            "research_problems": [
                {
                    "id": "R191274",
                    "label": "Representation Learning"
                }
            ],
            "abstract": "recent advancements in pretraining strategies in nlp have shown a significant improvement in the performance of models on various text mining tasks. we apply \u2018replaced token detection\u2019 pretraining technique proposed by electra and pretrain a biomedical language model from scratch using biomedical text and vocabulary. we introduce bioelectra, a biomedical domain-specific language encoder model that adapts electra for the biomedical domain. we evaluate our model on the blurb and blue biomedical nlp benchmarks. bioelectra outperforms the previous models and achieves state of the art (sota) on all the 13 datasets in blurb benchmark and on all the 4 clinical datasets from blue benchmark across 7 different nlp tasks. bioelectra pretrained on pubmed and pmc full text articles performs very well on clinical datasets as well. bioelectra achieves new sota 86.34%(1.39% accuracy improvement) on mednli and 64% (2.98% accuracy improvement) on pubmedqa dataset."
        },
        {
            "id": "R110803",
            "label": "A new insight into land use classification based on aggregated mobile phone data",
            "doi": "10.1080/13658816.2014.913794",
            "research_field": {
                "id": "R317",
                "label": "Geographic Information Sciences"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "land-use classification is essential for urban planning. urban land-use types can be differentiated either by their physical characteristics (such as reflectivity and texture) or social functions. remote sensing techniques have been recognized as a vital method for urban land-use classification because of their ability to capture the physical characteristics of land use. although significant progress has been achieved in remote sensing methods designed for urban land-use classification, most techniques focus on physical characteristics, whereas knowledge of social functions is not adequately used. owing to the wide usage of mobile phones, the activities of residents, which can be retrieved from the mobile phone data, can be determined in order to indicate the social function of land use. this could bring about the opportunity to derive land-use information from mobile phone data. to verify the application of this new data source to urban land-use classification, we first construct a vector of aggregated mobile phone data to characterize land-use types. this vector is composed of two aspects: the normalized hourly call volume and the total call volume. a semi-supervised fuzzy c-means clustering approach is then applied to infer the land-use types. the method is validated using mobile phone data collected in singapore. land use is determined with a detection rate of 58.03%. an analysis of the land-use classification results shows that the detection rate decreases as the heterogeneity of land use increases, and increases as the density of cell phone towers increases."
        },
        {
            "id": "R171576",
            "label": "Trait anger modulates neural activity in the fronto-parietal attention network",
            "doi": "10.1371/journal.pone.0194444",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "anger is considered a unique high-arousal and approach-related negative emotion. the influence of individual differences in trait anger on the processing of visual stimuli is relevant to questions about emotional processing and remains to be explored. using functional magnetic resonance imaging (fmri), we explored the neural responses to standardized images, selected based on valence and arousal ratings in a group of men with high trait anger compared to those with normative to low anger scores (controls). results show increased activation in the left-lateralized ventral fronto-parietal attention network to unpleasant images by individuals with high trait anger. there was also a group by arousal interaction in the left thalamus/pulvinar such that individuals with high trait anger had increased pulvinar activation to the high-arousal (versus low arousal) unpleasant images as compared to controls. thus, individual differences in trait anger in men are associated with brain regions subserving executive attentional and sensory integration during the processing of unpleasant emotional stimuli, particularly to high arousal images."
        },
        {
            "id": "R149019",
            "label": "A review and analysis of supply chain operations reference (SCOR) model",
            "doi": "",
            "research_field": {
                "id": "R308",
                "label": "Industrial Organization"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "research on supply chain management can be broadly classified into three categories, namely, operational, design, and strategic. while many analytical and numerical models have been proposed to handle operational and design issues, formal models for strategic planning are scarce. the supply chain operations reference (scor) model, developed by the supply chain council, is a strategic planning tool that allows senior managers to simplify the complexity of supply chain management. it is firmly rooted in industrial practices and is poised to become an industrial standard that enables next\u2010generation supply chain management. this paper gives a brief introduction to the scor model, analyzes its strength and weakness, and discusses how it can be used to assist managers for strategic decision making."
        },
        {
            "id": "R74410",
            "label": "An approach for description of open educational resources based on semantic technologies",
            "doi": "10.1109/EDUCON.2010.5492453",
            "research_field": {
                "id": "R230",
                "label": "Computer Engineering"
            },
            "research_problems": [
                {
                    "id": "R74409",
                    "label": "Knowledge Representation"
                },
                {
                    "id": "R109071",
                    "label": "Knowledge Representation"
                }
            ],
            "abstract": "open educational resources are accessed through the web, whose real setting shows an explosion in the use and development of tools and services based on social software. however, the growth of this data repository makes it difficult to find information of value, and reduces the possibilities of sharing and exchanging resources. using semantic technologies to describe educational resources enables any agent (human or software-based) to process and understand its content (applying inference rules on more structured knowledge). metadata standards can be used to annotate educational resources; they facilitate their interoperability and discovery. in this work, we propose, oer-cc ontology, for the description of open educational resources under creative commons licenses. this approach is based on standard technology and metadata standards. the ontology could be utilized in higher education institutions (and organizations) to facilitate sharing and discovery of their digital content. this electronic document is a \u201clive\u201d template. the various components of your paper [title, text, heads, etc.] are already defined on the style sheet, as illustrated by the portions given in this document."
        },
        {
            "id": "R171779",
            "label": "The characteristics and patterns of utilization of healthcare services among Omanis with substance use disorders attending therapy for cessation",
            "doi": "10.1371/journal.pone.0210532",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background it is indicated that oman is witnessing an increase in issues pertinent to alcohol and psychoactive substance use. aim the aim of this study was to identify the characteristics of omanis with substance use disorder attending a specialized hospital in oman and the pattern of their utilization of healthcare services. a related aim was to ascertain the age group most vulnerable to alcohol and substance use in oman. method a cross-sectional study was conducted in a tertiary care center specialized for treatment of those engaging in substance use in oman. the participants in the study were selected from a convenience sample among patients seeking consultation at the center for alcohol and substance use. a six-part questionnaire was designed to obtain information regarding socio-demographic background, clinical history, healthcare utilization and perceived hurdles to access. chi-square analyses were used to evaluate the significance of differences among categorical data. logistic regression modelling was used to obtain measures of association after adjusting for confounding factors. results among the patients (n = 293) seeking cessation therapy, 99% were male and less than 30 years of age. peer influences on the initiation of substance use were significant. most patients had a history of polysubstance use, including intravenous substance use. cannabis and alcohol were the first substances consumed by most patients and hepatitis c and psychiatric disorders were found to be the most common co-morbidities. the participants that reported use of cannabis and benzodiazepines were more likely to perceive \u201cimprovement\u201d upon receiving treatment. conclusion this study indicated that males below 30 years of age with a history of polysubstance use were likely to attend a hospital specialized in treating substance use disorder in oman. this study identified information regarding socio-demographic background, risk factors and perceived hurdles to healthcare that could serve as groundwork for further studies conducted on newly emerging issues of substance use in oman."
        },
        {
            "id": "R110083",
            "label": "Optimal Sizing and Scheduling of Hybrid Energy Systems: The Cases of Morona Santiago and the Galapagos Islands",
            "doi": "10.3390/en13153933",
            "research_field": {
                "id": "R267",
                "label": "Energy Systems"
            },
            "research_problems": [
                {
                    "id": "R110137",
                    "label": "Optimal sizing and scheduling of hybrid energy systems and microgrids"
                }
            ],
            "abstract": "hybrid energy systems (hess) generate electricity from multiple energy sources that complement each other. recently, due to the reduction in costs of photovoltaic (pv) modules and wind turbines, these types of systems have become economically competitive. in this study, a mathematical programming model is applied to evaluate the techno-economic feasibility of autonomous units located in two isolated areas of ecuador: first, the province of galapagos (subtropical island) and second, the province of morona santiago (amazonian tropical forest). the two case studies suggest that hess are potential solutions to reduce the dependence of rural villages on fossil fuels and viable mechanisms to bring electrical power to isolated communities in ecuador. our results reveal that not only from the economic but also from the environmental point of view, for the case of the galapagos province, a hybrid energy system with a pv\u2013wind\u2013battery configuration and a levelized cost of energy (lcoe) equal to 0.36 $/kwh is the optimal energy supply system. for the case of morona santiago, a hybrid energy system with a pv\u2013diesel\u2013battery configuration and an lcoe equal to 0.37 $/kwh is the most suitable configuration to meet the load of a typical isolated community in ecuador. the proposed optimization model can be used as a decision-support tool for evaluating the viability of autonomous hes projects at any other location."
        },
        {
            "id": "R135264",
            "label": "Optimization of a nano-cantilever biosensor for reduced self-heating effects and improved performance metrics",
            "doi": "10.1088/1361-6439/aabeaf",
            "research_field": {
                "id": "R279",
                "label": "Nanoscience and Nanotechnology"
            },
            "research_problems": [
                {
                    "id": "R135259",
                    "label": "Theoretical considerations on the performance of nanocantilevers as biosensors"
                }
            ],
            "abstract": "over the last decade, surface stress-based piezoresistive cantilever biosensors have been extensively explored as a potential alternative for conventional clinical diagnostic techniques. the design of piezoresistive cantilever sensors is a complex multi-variable problem which involves the interplay between the thermal, electrical and mechanical design aspects of their constituent materials and geometry. even though the literature includes examples where researchers have devised designs of piezoresistive cantilever biosensors, a majority of them have focused primarily on improving the electrical sensitivity by either dimensional optimization or material changes of their constituent layers. however, there are two important aspects of the sensor design which have been seldom addressed: (i) the negative impact of the transverse section of the u-shaped piezoresistor on the electrical sensitivity, and (ii) thermal drift in the output characteristics of the sensor. although a few researchers have focused on the aforementioned factors, they have analysed them independently without considering their interdependence and cumulative impact on the sensor performance. in this paper, we devise a dual material multi-part u-shaped piezoresistor comprised of two p-type single crystalline silicon longitudinal sections and a p-type polysilicon transverse section. evaluation of the proposed piezoresistor is performed in two stages using a finite element method-based numerical tool. in the first stage, the performance of the sensor with the multi-part piezoresistor is compared with the reported piezoresistors available in the literature. in the second stage, a comprehensive investigation of the multi-part piezoresistor is carried out to maximize the sensor performance. results show that, compared to a conventional u-shaped piezoresistor, the proposed piezoresistor achieves improvement in the sensitivity ratio by 8.12 times."
        },
        {
            "id": "R144015",
            "label": "A Raman spectroscopic study of humite minerals",
            "doi": "10.1002/jrs.1601",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R144001",
                    "label": "Raman spectral analysis for humite minerals"
                }
            ],
            "abstract": "raman spectroscopy has been used to study the structure of the humite mineral group ((a2sio4)n\u2013a(oh, f)2 where n represents the number of olivine and brucite layers in the structure and is 1, 2, 3 or 4 and a2+ is mg, mn, fe or some mix of these cations). the humite group of minerals forms a morphotropic series with the minerals olivine and brucite. the members of the humite group contain layers of the olivine structure that alternate with layers of the brucite-like sheets. the minerals are characterized by a complex set of bands in the 800\u20131000 cm\u22121 region attributed to the stretching vibrations of the olivine (sio4)4\u2212 units. the number of bands in this region is influenced by the number of olivine layers. characteristic bending modes of the (sio4)4\u2212 units are observed in the 500\u2013650 cm\u22121 region. the brucite sheets are characterized by the oh stretching vibrations in the 3475\u20133625 cm\u22121 wavenumber region. the position of the oh stretching vibrations is determined by the strength of the hydrogen bond formed between the brucite-like oh units and the olivine silica layer. the number of olivine sheets and not the chemical composition determines the strength of the hydrogen bonds. copyright \u00a9 2006 john wiley & sons, ltd."
        },
        {
            "id": "R170628",
            "label": "Factors Influencing Adult Physical Health after Controlling for Current Health Conditions: Evidence from a British Cohort",
            "doi": "10.1371/journal.pone.0066204",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "this study explored a longitudinal data set of 6875 british adults examining the effects of parental social status (measured at birth), cognitive ability (at age 11 yrs), personality traits, education and occupational attainment on physical health and functioning (all measured at age 50 yrs), after taking account of current health conditions (number of illness). correlation analysis showed that parental social class, childhood cognitive ability, education and occupation, and two personality traits (emotional stability/neuroticism, and conscientiousness) were all significantly associated with adult physical health variables. structural equation modelling showed that health conditions and personality traits were significantly, and inversely, associated with physical health (indicated by good daily physical functioning, relative absence of pain, perceived health, and low level of limitations at work due to physical health). parental social status, childhood intelligence, educational and occupational attainment were all modestly, but significantly and directly, associated with adult physical health. the effect of childhood intelligence on adult physical health was, in part, mediated through emotional stability and conscientiousness. after controlling for health conditions emotional stability was the strongest predictor of physical health. implications and limitations are discussed."
        },
        {
            "id": "R6629",
            "label": "The University of Michigan at DUC 2004",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6544",
                    "label": "Automatic text summarization"
                }
            ],
            "abstract": "we present the results of michigan\u2019s participation in duc 2004. our system, mead, ranked as one of the top systems in four of the five tasks. we introduce our new feature, lexpagerank, a new measure of sentence centrality inspired by the prestige concept in social networks. lexpagerank gave promising results in multi-document summarization. our approach for task 5, biographical summarization, was simplistic, yet succesful. we used regular expression matching to boost up the scores of the sentences that are likely to contain biographical information patterns."
        },
        {
            "id": "R170706",
            "label": "Stakeholder Perspectives and Values when Setting Waterbird Population Targets: Implications for Flyway Management Planning in a European Context",
            "doi": "10.1371/journal.pone.0081836",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "managing and controlling wildlife species within europe is an acknowledged part of conservation management, yet deciding and setting a population target in order to control a population is perceived to be conceptually very challenging. we interviewed stakeholders, within a variety of governmental and non-governmental organizations, to evaluate their perspectives about setting population targets as part of waterbird management for controlling population sizes. we conclude that the setting of a quantifiable population target is beneficial as a measurable objective for monitoring and evaluating management actions. however, it must be recognised as just one possible measurable objective and there may well be multiple supporting objectives that encapsulate the management aims of different stakeholders. when considering wide-scale control of waterbirds species, where it is likely that population size matters, any population target should be coupled to the issues being addressed. we highlight that it is important to actively engage with stakeholders as part of the decision-making process, not only to gain consensus but to share knowledge. a clear understanding of the context and the rationale for controlling a waterbird species is needed to align the interests of diverse stakeholders. the provision of scientific data and the continuous monitoring of management actions is viewed as beneficial and demanded by stakeholders, as part of any decision-making process when setting population targets. this facilitates effective evaluation of management actions, helping managers make wise decisions as well as enabling the continued development of management plans."
        },
        {
            "id": "R170621",
            "label": "Reporting Quality of Social and Psychological Intervention Trials: A Systematic Review of Reporting Guidelines and Trial Publications",
            "doi": "10.1371/journal.pone.0065442",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background previous reviews show that reporting guidelines have improved the quality of trial reports in medicine, yet existing guidelines may not be fully suited for social and psychological intervention trials. objective/design we conducted a two-part study that reviewed (1) reporting guidelines for and (2) the reporting quality of social and psychological intervention trials. data sources (1) to identify reporting guidelines, we systematically searched multiple electronic databases and reporting guideline registries. (2) to identify trials, we hand-searched 40 journals with the 10 highest impact factors in clinical psychology, criminology, education, and social work. eligibility (1) reporting guidelines consisted of articles introducing a checklist of reporting standards relevant to social and psychological intervention trials. (2) trials reported randomised experiments of complex interventions with psychological, social, or health outcomes. results (1) we identified 19 reporting guidelines that yielded 147 reporting standards relevant to social and psychological interventions. social and behavioural science guidelines included 89 standards not found in consort guidelines. however, consort guidelines used more recommended techniques for development and dissemination compared to other guidelines. (2) our review of trials (n\\u200a=\\u200a239) revealed that many standards were poorly reported, such as identification as a randomised trial in titles (20% reported the information) and abstracts (55%); information about blinding (15%), sequence generation (23%), and allocation concealment (17%); and details about actual delivery of experimental (43%) and control interventions (34%), participant uptake (25%), and service environment (28%). only 11 of 40 journals referenced reporting guidelines in \u201cinstructions to authors.\u201d conclusion existing reporting guidelines have important limitations in content, development, and/or dissemination. important details are routinely missing from trial publications; most leading journals in social and behavioural sciences do not ask authors to follow reporting standards. findings demonstrate a need to develop a consort extension with updated standards for social and psychological intervention trials."
        },
        {
            "id": "R109952",
            "label": "Epidemiology of Shiga toxin-producingEscherichia coliO157 in very young calves in the North Island of New Zealand",
            "doi": "10.1080/00480169.2011.627063",
            "research_field": {
                "id": "R33",
                "label": "Epidemiology"
            },
            "research_problems": [
                {
                    "id": "R109948",
                    "label": "Prevalence of STEC in New Zealand"
                }
            ],
            "abstract": "abstract aims:\\u2003to study the occurrence and spatial distribution of shiga toxin-producing escherichia coli (stec) o157 in calves less than 1-week-old (bobby calves) born on dairy farms in the north island of new zealand, and to determine the association of concentration of igg in serum, carcass weight, gender and breed with occurrence of e. coli o157 in these calves. methods:\\u2003in total, 309 recto-anal mucosal swabs and blood samples were collected from bobby calves at two slaughter plants in the north island of new zealand. the address of the farm, tag number, carcass weight, gender and breed of the sampled animals were recorded. swabs were tested for the presence of e. coli o157 using real time pcr (rt-pcr). all the farms were mapped geographically to determine the spatial distribution of farms positive for e. coli o157. k function analysis was used to test for clustering of these farms. multiplex pcr was used for the detection of shiga toxin 1 (stx1), shiga toxin 2 (stx2), e. coli attaching and effacing (eae) and enterohaemolysin (ehxa) genes in e. coli o157 isolates. genotypes of isolates from this study (n = 10) along with human (n = 18) and bovine isolates (n = 4) obtained elsewhere were determined using bacteriophage insertion typing for stx encoding. results:\\u2003of the 309 samples, 55 (17.7%) were positive for e. coli o157 by rt-pcr and originated from 47/197 (23.8%) farms. e. coli o157 was isolated from 10 samples of which seven isolates were positive for stx2, eae and ehxa genes and the other three isolates were positive for stx1, stx2, eae and ehxa. bacteriophage insertion typing for stx encoding revealed that 12/18 (67%) human and 13/14 (93%) bovine isolates belonged to genotypes 1 and 3. k function analysis showed some clustering of farms positive for e. coli o157. there was no association between concentration of igg in serum, carcass weight and gender of the calves, and samples positive for e. coli o157, assessed using linear mixed-effects models. however, jersey calves were less likely to be positive for e. coli o157 by rt-pcr than friesian calves (p = 0.055). conclusions:\\u2003healthy bobby calves are an asymptomatic reservoir of e. coli o157 in new zealand and may represent an important source of infection for humans. carriage was not associated with concentration of igg in serum, carcass weight or gender."
        },
        {
            "id": "R145430",
            "label": "Pandemic response in low-resource settings requires effective syndromic surveillance",
            "doi": "10.1111/irv.12098",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "to the editor: starbuck et al. have identified a significant gap in any future global response to a severe influenza pandemic. the threat of inadequate preparedness and limited public health responses in low-resource settings, leading to uncontrolled transmission is a real and unwelcome possibility during a pandemic. the authors recommend that detailed authoritative guidance should be developed for low-resource settings and that support should be given to governments in these settings to adapt and implement these guidelines. however, an appropriate public health response and effective management of cases depend primarily on early detection of suspected cases. this remains a major challenge in many developing countries, but syndromic surveillance offers a potential solution in these settings. a novel and visionary system, using a simple but standardised set of symptoms, was first developed by t. jacob john in the early 1980s in southern india. the system utilised a district-level disease surveillance system in a low-resource setting, to control and limit disease outbreaks through early detection. this approach was further adapted in a rural african setting with a focus on rural hospitals reporting presentations of nine core clinical syndromes, including cholera and meningitis-like disease to ensure early identification of infectious disease outbreaks. a similar syndromic surveillance system for outbreak detection and response has recently been implemented in pacific island countries and territories (picts). in 2010, picts agreed to develop a regional standardised, simple and sustainable event-based syndromic surveillance system to ensure compliance with ihr requirements (rapid outbreak detection, information sharing and response to outbreaks). health resources vary across the region that includes a number of countries that are categorised as least developed countries (ldc). the system is based on the early detection and reporting of four core syndromes (influenza-like illness, diarrhoea, prolonged fever and acute fever with rash) and the immediate reporting of unusual events. the system uses standardised case definitions and processes rather than focussing on a technology platform used to collect or analyse the data. a pacific outbreak manual has been developed as an integral component of the system; to ensure that health workers have rapid access to robust and practical guidelines on the clinical and public health management of infectious disease outbreaks, including influenza-like illness, and triggers for action. this provides picts with authoritative guidance on appropriate response measures during a severe influenza pandemic. a recent evaluation highlighted the need for standardised surveillance to help meet ihr obligations and to ensure early warning of infectious disease outbreaks across the pacific. while there is variation in system implementation, it is apparent that this is a strength in a region that includes lowresource communities. despite differences in personnel resources, medical informatics systems and processes, picts have productively participated in and contributed to a regional early warning system. the syndromic surveillance system expanded from six to twenty participating picts within 1 year, indicating a high level of acceptance of the system. while there are remaining challenges in ensuring uniform data quality, the system has proven effective in detecting outbreaks, its simplicity and the standardisation of both case definitions and responses are key elements in its usefulness. detection of future influenza pandemics or other emerging infectious disease outbreaks in the south pacific should be greatly assisted by this syndromic surveillance system. syndromic surveillance is particularly useful in settings where access to laboratory diagnosis is not timely, allowing containment measures to be implemented prior to having a definitive diagnosis. however, there are inherent limitations in a system based purely on syndromes due to the broad range of diseases that may cause certain syndromes, including influenza-like illness. to avoid exhausting public health doi:10.1111/irv.12098 www.influenzajournal.com letter to the editor"
        },
        {
            "id": "R187771",
            "label": "What happens when a journal converts to open access? A bibliometric analysis",
            "doi": "10.1007/s11192-021-03972-5",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R187758",
                    "label": "Open access citation advantage"
                },
                {
                    "id": "R187776",
                    "label": "Impact of open access on publication volume"
                }
            ],
            "abstract": "abstract in recent years, increased stakeholder pressure to transition research to open access has led to many journals converting, or \u2018flipping\u2019, from a closed access (ca) to an open access (oa) publishing model. changing the publishing model can influence the decision of authors to submit their papers to a journal, and increased article accessibility may influence citation behaviour. in this paper we aimed to understand how flipping a journal to an oa model influences the journal\u2019s future publication volumes and citation impact. we analysed two independent sets of journals that had flipped to an oa model, one from the directory of open access journals (doaj) and one from the open access directory (oad), and compared their development with two respective control groups of similar journals. for bibliometric analyses, journals were matched to the scopus database. we assessed changes in the number of articles published over time, as well as two citation metrics at the journal and article level: the normalised impact factor (if) and the average relative citations (arc), respectively. our results show that overall, journals that flipped to an oa model increased their publication output compared to journals that remained closed. mean normalised if and arc also generally increased following the flip to an oa model, at a greater rate than was observed in the control groups. however, the changes appear to vary largely by scientific discipline. overall, these results indicate that flipping to an oa publishing model can bring positive changes to a journal."
        },
        {
            "id": "R75519",
            "label": "Direct Visualization of Membrane Leakage Induced by the Antibiotic Peptides: Maculatin, Citropin, and Aurein",
            "doi": "10.1529/biophysj.105.066589",
            "research_field": {
                "id": "R16",
                "label": "Biophysics"
            },
            "research_problems": [
                {
                    "id": "R75555",
                    "label": "Antimicrobial activity"
                }
            ],
            "abstract": "membrane lysis caused by antibiotic peptides is often rationalized by means of two different models: the so-called carpet model and the pore-forming model. we report here on the lytic activity of antibiotic peptides from australian tree frogs, maculatin 1.1, citropin 1.1, and aurein 1.2, on popc or popc/popg model membranes. leakage experiments using fluorescence spectroscopy indicated that the peptide/lipid mol ratio necessary to induce 50% of probe leakage was smaller for maculatin compared with aurein or citropin, regardless of lipid membrane composition. to gain further insight into the lytic mechanism of these peptides we performed single vesicle experiments using confocal fluorescence microscopy. in these experiments, the time course of leakage for different molecular weight (water soluble) fluorescent markers incorporated inside of single giant unilamellar vesicles is observed after peptide exposure. we conclude that maculatin and its related peptides demonstrate a pore-forming mechanism (differential leakage of small fluorescent probe compared with high molecular weight markers). conversely, citropin and aurein provoke a total membrane destabilization with vesicle burst without sequential probe leakage, an effect that can be assigned to a carpeting mechanism of lytic action. additionally, to study the relevance of the proline residue on the membrane-action properties of maculatin, the same experimental approach was used for maculatin-ala and maculatin-gly (pro-15 was replaced by ala or gly, respectively). although a similar peptide/lipid mol ratio was necessary to induce 50% of leakage for popc membranes, the lytic activity of maculatin-ala and maculatin-gly decreased in popc/popg (1:1 mol) membranes compared with that observed for the naturally occurring maculatin sequence. as observed for maculatin, the lytic action of maculatin-ala and maculatin-gly is in keeping with the formation of pore-like structures at the membrane independently of lipid composition."
        },
        {
            "id": "R139820",
            "label": "Digital Media, Participatory Culture, and Difficult Heritage: Online Remediation and the Trans-Atlantic Slave Trade",
            "doi": "10.1080/21619441.2015.1124594",
            "research_field": {
                "id": "R417",
                "label": "Cultural History"
            },
            "research_problems": [
                {
                    "id": "R139830",
                    "label": "How to connect the scholarly modes of communication and stakeholder-led participatory cultures in difficult heritage?"
                }
            ],
            "abstract": "a diverse and changing array of digital media have been used to present heritage online. while websites have been created for online heritage outreach for nearly two decades, social media is employed increasingly to complement and in some cases replace the use of websites. these same social media are used by stakeholders as a form of participatory culture, to create communities and to discuss heritage independently of narratives offered by official institutions such as museums, memorials, and universities. with difficult or \u201cdark\u201d heritage\u2014places of memory centering on deaths, disasters, and atrocities\u2014these online representations and conversations can be deeply contested. examining the websites and social media of difficult heritage, with an emphasis on the trans-atlantic slave trade provides insights into the efficacy of online resources provided by official institutions, as well as the unofficial, participatory communities of stakeholders who use social media for collective memories."
        },
        {
            "id": "R170671",
            "label": "\u00e2\u0080\u009cAn Eye for an Eye\u00e2\u0080\u009d? Neural Correlates of Retribution and Forgiveness",
            "doi": "10.1371/journal.pone.0073519",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "humans have evolved strong preferences for equity and fairness. neuroimaging studies suggest that punishing unfairness is associated with the activation of a neural network comprising the anterior cingulate cortex, anterior insula, the ventral striatum, and the dorsolateral prefrontal cortex (dlpfc). here, we report the neuronal correlates of retribution and \u201cforgiveness\u201d in a scenario, in which individuals first acted as a recipient in an ultimatum game, and subsequently assumed the position of a proposer in a dictator game played against the same opponents as in the ultimatum game. most subjects responded in a tit-for-tat fashion, which was accompanied by activation of the ventral striatum, corroborating previous findings that punishing unfair behaviour has a rewarding connotation. subjects distinguished between the human opponent and computer condition by activation of the ventromedial pfc in the human condition, indicative of mentalising. a substantial number of subjects did not retaliate. neurally, this \u201cforgiveness\u201d behaviour was associated with the activation of the right (and to a lesser degree left) dlpfc, a region that serves as a cognitive control region and thus may be involved in inhibiting emotional responses against unfairness."
        },
        {
            "id": "R75305",
            "label": "Extracting ontological knowledge from Java source code using Hidden Markov Models",
            "doi": "https://doi.org/10.1515/comp-2019-0013",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R135954",
                    "label": "Ontology learning from source code"
                }
            ],
            "abstract": "abstract \\n ontologies have become a key element since many decades in information systems such as in epidemiological surveillance domain. building domain ontologies requires the access to domain knowledge owned by domain experts or contained in knowledge sources. however, domain experts are not always available for interviews. therefore, there is a lot of value in using ontology learning which consists in automatic or semi-automatic extraction of ontological knowledge from structured or unstructured knowledge sources such as texts, databases, etc. many techniques have been used but they all are limited in concepts, properties and terminology extraction leaving behind axioms and rules. source code which naturally embed domain knowledge is rarely used. in this paper, we propose an approach based on hidden markov models (hmms) for concepts, properties, axioms and rules learning from java source code. this approach is experimented with the source code of epicam, an epidemiological platform developed in java and used in cameroon for tuberculosis surveillance. domain experts involved in the evaluation estimated that knowledge extracted was relevant to the domain. in addition, we performed an automatic evaluation of the relevance of the terms extracted to the medical domain by aligning them with ontologies hosted on bioportal platform through the ontology recommender tool. the results were interesting since the terms extracted were covered at 82.9% by many biomedical ontologies such as ncit, snowmedct and ontoparon."
        },
        {
            "id": "R143827",
            "label": "A short survey of hyperspectral remote sensing applications in agriculture",
            "doi": "10.1109/RAST.2013.6581194",
            "research_field": {
                "id": "R142",
                "label": "Earth Sciences"
            },
            "research_problems": [
                {
                    "id": "R143793",
                    "label": "Application of Hyperspectral remote sensing to Agriculture"
                }
            ],
            "abstract": "\"hyperspectral sensors are devices that acquire images over hundreds of spectral bands, thereby enabling the extraction of spectral signatures for objects or materials observed. hyperspectral remote sensing has been used over a wide range of applications, such as agriculture, forestry, geology, ecological monitoring and disaster monitoring. in this paper, the specific application of hyperspectral remote sensing to agriculture is examined. the technological development of agricultural methods is of critical importance as the world's population is anticipated to continuously rise much beyond the current number of 7 billion. one area upon which hyperspectral sensing can yield considerable impact is that of precision agriculture - the use of observations to optimize the use of resources and management of farming practices. for example, hyperspectral image processing is used in the monitoring of plant diseases, insect pests and invasive plant species; the estimation of crop yield; and the fine classification of crop distributions. this paper also presents a detailed overview of hyperspectral data processing techniques and suggestions for advancing the agricultural applications of hyperspectral technologies in turkey.\""
        },
        {
            "id": "R171396",
            "label": "Seasonal variability shapes resilience of small-scale fisheries in Baja California Sur, Mexico",
            "doi": "10.1371/journal.pone.0182200",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "small-scale fisheries are an important source of food and livelihoods to coastal communities around the world. understanding the seasonality of fisheries catch and composition is crucial to fisheries management, particularly in the context of changing environmental and socioeconomic conditions. while seasonal variability directly impacts the lives of fishers, most fisheries studies focus on longer-term change. here we examine seasonal variability in the small-scale fisheries of baja california sur, mexico based on 13 years of government fisheries data. we investigate how four fisheries indicators with direct relevance to ecological resilience\u2013magnitude and variance of landed fish biomass, taxon richness and the proportion of top-trophic-level taxa in total catch\u2013vary within and among years and at multiple spatial scales. we find that these resilience indicators vary both seasonally and spatially. these results highlight the value of finer-scale monitoring and management, particularly for data-poor fisheries."
        },
        {
            "id": "R189444",
            "label": "Triple Classification for Scholarly Knowledge Graph Completion",
            "doi": "10.1145/3460210.3493582",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R74030",
                    "label": "Information Extraction"
                },
                {
                    "id": "R120473",
                    "label": "Knowledge Graph Completion"
                }
            ],
            "abstract": "structured information representing knowledge encoded in scientific publications. with the sheer volume of published scientific literature comprising a plethora of inhomogeneous entities and relations to describe scientific concepts, these kgs are inherently incomplete. we present exbert, a method for leveraging pre-trained transformer language models to perform scholarly knowledge graph completion. we model triples of a knowledge graph as text and perform triple classification (i.e., belongs to kg or not). the evaluation shows that exbert outperforms other baselines on three scholarly kg completion datasets in the tasks of triple classification, link prediction, and relation prediction. furthermore, we present two scholarly datasets as resources for the research community, collected from public kgs and online resources."
        },
        {
            "id": "R194607",
            "label": "Extracting and Analyzing Context Information in User-Support Conversations on Twitter",
            "doi": "10.1109/re.2019.00024",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "while many apps include built-in options to report bugs or request features, users still provide an increasing amount of feedback via social media, like twitter. compared to traditional issue trackers, the reporting process in social media is unstructured and the feedback often lacks basic context information, such as the app version or the device concerned when experiencing the issue. to make this feedback actionable to developers, support teams engage in recurring, effortful conversations with app users to clarify missing context items. this paper introduces a simple approach that accurately extracts basic context information from unstructured, informal user feedback on mobile apps, including the platform, device, app version, and system version. evaluated against a truthset of 3014 tweets from official twitter support accounts of the 3 popular apps netflix, snapchat, and spotify, our approach achieved precisions from 81% to 99% and recalls from 86% to 98% for the different context item types. combined with a chatbot that automatically requests missing context items from reporting users, our approach aims at auto-populating issue trackers with structured bug reports."
        },
        {
            "id": "R161108",
            "label": "Polymers and the Environment",
            "doi": "10.5772/51057",
            "research_field": {
                "id": "R131",
                "label": "Polymer Chemistry"
            },
            "research_problems": [
                {
                    "id": "R161111",
                    "label": "Polymer properties"
                }
            ],
            "abstract": "the traditional polymer materials available today, especially the plastics, are the result of decades of evolution. their production is extremely efficient in terms of utilization of raw materials and energy, as well as of waste release. the products present a series of excellent properties such as impermeability to water and microorganisms, high mechanical strength, low density (useful for transporting goods), and low cost due to manufacturing scale and process optimization [1]. however, some of their most useful features, the chemical, physical and biological inertness, and durability resulted in their accumulation in the environment if not recycled. unfortunately, the accumulation of plastics, along with other materials, is becoming a serious problem for all countries in the world. these materials occupy significant volume in landfills and dumps today. recently, the presence of huge amounts of plastic fragments on the oceans has been observed, considerable part of them coming from the streets, going through the drains with the rain, and then going into the rivers and lakes, and then to the oceans [1]. as a result, there is a very strong and irreversible movement, in all countries of the world, to use materials that do not harm the planet, that is, low environmental impact materials."
        },
        {
            "id": "R171414",
            "label": "Racial disparities in cancer-related survival in patients with squamous cell carcinoma of the esophagus in the US between 1973 and 2013",
            "doi": "10.1371/journal.pone.0183782",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background esophageal cancer makes up approximately 1% of all diagnosed cancers in the us. there is a persistent disparity in incidence and cancer-related mortality rates among different races for esophageal squamous cell carcinoma (scc). most previous studies investigated racial disparities between black and white patients, occasionally examining disparities for hispanic patients. studies including asians/pacific islanders (api) as a subgroup are rare. our objective was to determine whether there is an association between race and cancer-related survival in patients with esophageal scc. methods and findings this was a retrospective cohort study using the national cancer institute\u2019s surveillance, epidemiology, and end result (seer) database. the seer registry is a national database that collects information on all incident cancer cases in 13 states of the united states and covers nearly 26% of the us population patients aged 18 and over of white, black, or asian/pacific islander (api) race with diagnosed esophageal scc from 1973 to 2013 were included (n = 13,857). to examine overall survival, kaplan-meier curves were estimated for each race and the log-rank test was used to compare survival distributions. cox proportional hazards models were used to estimate unadjusted and adjusted hazard ratios with 95% confidence intervals. the final adjusted model controlled for sex, marital status, age at diagnosis, decade of diagnosis, ethnicity, stage at diagnosis, and form of treatment. additional analyses stratified by decade of diagnosis were conducted to explore possible changes in survival disparities over time. after adjustment for potential confounders, black patients had a statistically significantly higher hazard ratio compared to white patients (hr 1.08; 95% confidence interval (ci) 1.03\u20131.13). however, api patients did not show a statistically significant difference in survival compared with white patients (hr 1.00; 95% ci 0.93\u20131.07). patients diagnosed between 1973 and 1979 had twice the hazard of death compared to those diagnosed between 2000 and 2013 (hr 2.05, 95% ci 1.93\u20132.19). patients diagnosed in 1980\u20131989 and 1990\u20131999 had had hrs of 1.59 (95% ci 1.51\u20131.68) and 1.33 (95% ci 1.26\u20131.41), respectively. after stratification according to decade of diagnosis, the hr for black patients compared with white patients was 1.14 (95% ci 1.02\u20131.29) in 1973\u20131979 and 1.12 (95% ci 1.03\u20131.23) in 1980\u20131989. these disparities were not observed after 1990; the hr for black patients compared with white patients was 1.03 (95% ci 0.93\u20131.13) in 1990\u20131999 and 1.05 (95% ci 0.96\u20131.15) in 2000\u20132013. conclusions black patients with esophageal scc were found to have a higher hazard of death compared to white and api patients. survival disparities between races appear to have decreased over time. future research that takes insurance status and other social determinants of health into account should be conducted to further explore possible disparities by race."
        },
        {
            "id": "R170876",
            "label": "Factors that Influence Adherence to Antiretroviral Treatment in an Urban Population, Jakarta, Indonesia",
            "doi": "10.1371/journal.pone.0107543",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "introduction although the number of people receiving antiretroviral therapy (art) in indonesia has increased in recent years, little is known about the specific characteristics affecting adherence in this population. indonesia is different from most of its neighbors given that it is a geographically and culturally diverse country, with a large muslim population. we aimed to identify the current rate of adherence and explore factors that influence art adherence. methods data were collected from art-prescribed outpatients on an hiv registry at a north jakarta hospital in 2012. socio-demographic and behavioral characteristics were explored as factors associated with adherence using logistics regression analyses. chi squared test was used to compare the difference between proportions. reasons for missing medication were analyzed descriptively. results two hundred and sixty-one patients participated, of whom 77% reported art adherence in the last 3 months. the level of social support experienced was independently associated with adherence where some social support (p\\u200a=\\u200a0.018) and good social support (p\\u200a=\\u200a0.039) improved adherence compared to poor social support. frequently cited reasons for not taking art medication included forgetting to take medication (67%), busy with something else (63%) and asleep at medication time (60%). discussion this study identified that an increase in the level of social support experienced by art-prescribed patients was positively associated with adherence. social support may minimize the impact of stigma among art prescribed patients. based on these findings, if social support is not available, alternative support through community-based organizations is recommended to maximize treatment success."
        },
        {
            "id": "R171190",
            "label": "Loneliness, Depression, and Inflammation: Evidence from the Multi-Ethnic Study of Atherosclerosis",
            "doi": "10.1371/journal.pone.0158056",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objective both objective and subjective aspects of social isolation have been associated with alterations in immune markers relevant to multiple chronic diseases among older adults. however, these associations may be confounded by health status, and it is unclear whether these social factors are associated with immune functioning among relatively healthy adults. the goal of this study was to examine the associations between perceived loneliness and circulating levels of inflammatory markers among a diverse sample of adults. methods data come from a subset of the multi-ethnic study of atherosclerosis (n = 441). loneliness was measured by three items derived from the ucla loneliness scale. the association between loneliness and c-reactive protein (crp) and fibrinogen was assessed using multivariable linear regression analyses. models were adjusted for demographic and health characteristics. results approximately 50% of participants reported that they hardly ever felt lonely and 17.2% felt highly lonely. individuals who were unmarried/unpartnered or with higher depressive symptoms were more likely to report being highly lonely. there was no relationship between perceived loneliness and ln(crp) (\u03b2 = -0.051, p = 0.239) adjusting for demographic and health characteristics. loneliness was inversely associated with ln(fibrinogen) (\u03b2 = -0.091, p = 0.040), although the absolute magnitude of this relationship was small. conclusion these results indicate that loneliness is not positively associated with fibrinogen or crp among relatively healthy middle-aged adults."
        },
        {
            "id": "R170400",
            "label": "Network Stability Is a Balancing Act of Personality, Power, and Conflict Dynamics in Rhesus Macaque Societies",
            "doi": "10.1371/journal.pone.0022350",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"stability in biological systems requires evolved mechanisms that promote robustness. cohesive primate social groups represent one example of a stable biological system, which persist in spite of frequent conflict. multiple sources of stability likely exist for any biological system and such robustness, or lack thereof, should be reflected and thus detectable in the group's network structure, and likely at multiple levels. here we show how network structure and group stability are linked to the fundamental characteristics of the individual agents in groups and to the environmental and social contexts in which these individuals interact. both internal factors (e.g., personality, sex) and external factors (e.g., rank dynamics, sex ratio) were considered from the level of the individual to that of the group to examine the effects of network structure on group stability in a nonhuman primate species. the results yielded three main findings. first, successful third-party intervention behavior is a mechanism of group stability in rhesus macaques in that successful interventions resulted in less wounding in social groups. second, personality is the primary factor that determines which individuals perform the role of key intervener, via its effect on social power and dominance discrepancy. finally, individuals with high social power are not only key interveners but also key players in grooming networks and receive reconciliations from a higher diversity of individuals. the results from this study provide sound evidence that individual and group characteristics such as personality and sex ratio influence network structures such as patterns of reconciliation, grooming and conflict intervention that are indicators of network robustness and consequent health and well-being in rhesus macaque societies. utilizing this network approach has provided greater insight into how behavioral and social processes influence social stability in nonhuman primate groups.\""
        },
        {
            "id": "R75924",
            "label": "Understanding Visual Memes: An Empirical Analysis of Text Superimposed on Memes Shared on Twitter",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R75890",
                    "label": "hate speech detection"
                },
                {
                    "id": "R75891",
                    "label": "multimodal hate speech detection"
                }
            ],
            "abstract": "\"visual memes have become an important mechanism through which ideologically potent and hateful content spreads on today's social media platforms. at the same time, they are also a mechanism through which we convey much more mundane things, like pictures of cats with strange accents. little is known, however, about the relative percentage of visual memes shared by real people that fall into these, or other, thematic categories. the present work focuses on visual memes that contain superimposed text. we carry out the first large-scale study on the themes contained in the text of these memes, which we refer to as image-with-text memes. we find that 30% of the image-with-text memes in our sample which have identifiable themes are politically relevant, and that these politically relevant memes are shared more often by democrats than republicans. we also find disparities in who expresses themselves via image-with-text memes, and images in general, versus other forms of expression on twitter. the fact that some individuals use images with text to express themselves, instead of sending a plain text tweet, suggests potential consequences for the representativeness of analyses that ignore text contained in images.\""
        },
        {
            "id": "R203526",
            "label": "Kinematic programming alternatives for redundant manipulators",
            "doi": "10.1109/ROBOT.1985.1087234",
            "research_field": {
                "id": "R231",
                "label": "Computer and Systems Architecture"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "in the growing literature on redundant manipulator control, a number of techniques have been proposed for solving the inverse kinemetics problem. some of these techniques are surveyed with a discussion of strengths and weaknesses of each. a new approach, called the extended jacobian technique, is also presented. it is argued that because this technique may be expected to lift closed end effector paths to closed joint angle paths, it provides a promising approach for the control of kinematically redundant industrial manipulators. it is further shown that this technique may be implemented as a suitably parameterized generalized inverse method."
        },
        {
            "id": "R110694",
            "label": "Fast algorithm for successive computation of group betweenness centrality",
            "doi": "10.1103/physreve.76.056709",
            "research_field": {
                "id": "R141",
                "label": "Theory/Algorithms"
            },
            "research_problems": [
                {
                    "id": "R110663",
                    "label": "Time complexity of group betweenness centrality (GBC) computations"
                }
            ],
            "abstract": "in this paper, we propose a method for rapid computation of group betweenness centrality whose running time (after preprocessing) does not depend on network size. the calculation of group betweenness centrality is computationally demanding and, therefore, it is not suitable for applications that compute the centrality of many groups in order to identify new properties. our method is based on the concept of path betweenness centrality defined in this paper. we demonstrate how the method can be used to find the most prominent group. then, we apply the method for epidemic control in communication networks. we also show how the method can be used to evaluate distributions of group betweenness centrality and its correlation with group degree. the method may assist in finding further properties of complex networks and may open a wide range of research opportunities."
        },
        {
            "id": "R46321",
            "label": "Fast and accurate entity recognition with iterated dilated convolutions",
            "doi": "10.18653/v1/d17-1283",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R46343",
                    "label": "Fast and Accurate Entity Recognition"
                },
                {
                    "id": "R46344",
                    "label": "faster alternative to Bi - LSTMs for NER"
                },
                {
                    "id": "R46345",
                    "label": "democratize large-scale NLP and information extraction while minimizing our environmental footprint"
                },
                {
                    "id": "R46372",
                    "label": "NER"
                }
            ],
            "abstract": "today when many practitioners run basic nlp on the entire web and large-volume traffic, faster methods are paramount to saving time and energy costs. recent advances in gpu hardware have led to the emergence of bi-directional lstms as a standard method for obtaining per-token vector representations serving as input to labeling tasks such as ner (often followed by prediction in a linear-chain crf). though expressive and accurate, these models fail to fully exploit gpu parallelism, limiting their computational efficiency. this paper proposes a faster alternative to bi-lstms for ner: iterated dilated convolutional neural networks (id-cnns), which have better capacity than traditional cnns for large context and structured prediction. unlike lstms whose sequential processing on sentences of length n requires o(n) time even in the face of parallelism, id-cnns permit fixed-depth convolutions to run in parallel across entire documents. we describe a distinct combination of network structure, parameter sharing and training procedures that enable dramatic 14-20x test-time speedups while retaining accuracy comparable to the bi-lstm-crf. moreover, id-cnns trained to aggregate context from the entire document are more accurate than bi-lstm-crfs while attaining 8x faster test time speeds."
        },
        {
            "id": "R171256",
            "label": "Long-Term Quality of Life in Adult Patients with Strabismus after Corrective Surgery Compared to the General Population",
            "doi": "10.1371/journal.pone.0166418",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "purpose to evaluate the status of and factors associated with long-term health-related quality of life (hrqol) in adult patients with strabismus following corrective surgery. methods prospective cross-sectional study. a total of 122 adults who underwent corrective surgery and were followed up for at least 1 year were recruited. pre- and post-operative hrqol were evaluated using the chinese version of the adult strabismus 20 (as-20). demographics and clinical characteristics were recorded. eighty-nine age-matched, normal individuals without a history of strabismus were recruited as a control group. results as-20 scores improved significantly in the psychosocial subscale and total scale after surgery for all122 patients, but not in the function subscale. hrqol was better in the successful cases than in the non-successful cases (p<0.005). subjects who recovered stereo function had better hrqol than those who did not (p<0.01). compared to the control population, the patients had poorer hrqol post-operatively, with only approximately 30% of the subjects having scores within the normal threshold scores. the self-sense of a lack of ocular deviation and a successful surgical outcome were significant factors associated with post-operative hrqol status. conclusions hrqol, as evaluated by as-20 scores, improved in the patients after surgery but was worse than that in the general population. successful surgical outcomes and a sense of good alignment were the main factors that correlated with increased post-operative hrqol. positive assessments of surgical results by patients may benefit post-operative hrqol."
        },
        {
            "id": "R8559",
            "label": "Neural Duplicate Question Detection without Labeled Training Data",
            "doi": "10.18653/v1/d19-1171",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R8570",
                    "label": "Generating labeled data for duplicate question detection in online cQA forums"
                },
                {
                    "id": "R8572",
                    "label": "duplicate question detection in online cQA forums"
                }
            ],
            "abstract": "supervised training of neural models to duplicate question detection in community question answering (cqa) requires large amounts of labeled question pairs, which can be costly to obtain. to minimize this cost, recent works thus often used alternative methods, e.g., adversarial domain adaptation. in this work, we propose two novel methods\u2014weak supervision using the title and body of a question, and the automatic generation of duplicate questions\u2014and show that both can achieve improved performances even though they do not require any labeled data. we provide a comparison of popular training strategies and show that our proposed approaches are more effective in many cases because they can utilize larger amounts of data from the cqa forums. finally, we show that weak supervision with question title and body information is also an effective method to train cqa answer selection models without direct answer supervision."
        },
        {
            "id": "R169321",
            "label": "Divergent Control of Two Type VI Secretion Systems by RpoN in Pseudomonas aeruginosa",
            "doi": "10.1371/journal.pone.0076030",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "three type vi secretion system (t6ss) loci called h1- to h3-t6ss coexist in pseudomonas aeruginosa. h1-t6ss targets prokaryotic cells whereas h2-t6ss mediates interactions with both eukaryotic and prokaryotic host cells. little is known about the third system, except that it may be connected to h2-t6ss during the host infection. here we show that h3-t6ss is required for p. aeruginosa pao1 virulence in the worm model. we demonstrate that the two putative h3-t6ss operons, called \u201cleft\u201d and \u201cright\u201d, are coregulated with h2-t6ss by the las and rhl quorum sensing systems. interestingly, the rpon \u03c354 factor has divergent effects on the three operons. as for many t6sss, rpon activates the expression of h3-t6ss left. however, rpon unexpectedly represses the expression of h3-t6ss right and also h2-t6ss. sfa2 and sfa3 are putative enhancer binding proteins encoded on h2-t6ss and h3-t6ss left. in other t6sss ebps can act as \u03c354 activators to promote t6ss transcription. strikingly, we found that the rpon effects of h3-t6ss are sfa-independent while the rpon mediated repression of h2-t6ss is sfa2-dependent. this is the first example of rpon repression of a t6ss being mediated by a t6ss-encoded ebp."
        },
        {
            "id": "R170581",
            "label": "Exploring the Morphospace of Communication Efficiency in Complex Networks",
            "doi": "10.1371/journal.pone.0058070",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "\"graph theoretical analysis has played a key role in characterizing global features of the topology of complex networks, describing diverse systems such as protein interactions, food webs, social relations and brain connectivity. how system elements communicate with each other depends not only on the structure of the network, but also on the nature of the system's dynamics which are constrained by the amount of knowledge and resources available for communication processes. complementing widely used measures that capture efficiency under the assumption that communication preferentially follows shortest paths across the network (\u201crouting\u201d), we define analytic measures directed at characterizing network communication when signals flow in a random walk process (\u201cdiffusion\u201d). the two dimensions of routing and diffusion efficiency define a morphospace for complex networks, with different network topologies characterized by different combinations of efficiency measures and thus occupying different regions of this space. we explore the relation of network topologies and efficiency measures by examining canonical network models, by evolving networks using a multi-objective optimization strategy, and by investigating real-world network data sets. within the efficiency morphospace, specific aspects of network topology that differentially favor efficient communication for routing and diffusion processes are identified. charting regions of the morphospace that are occupied by canonical, evolved or real networks allows inferences about the limits of communication efficiency imposed by connectivity and dynamics, as well as the underlying selection pressures that have shaped network topology.\""
        },
        {
            "id": "R170603",
            "label": "Awareness and Willingness to Use HIV Pre-Exposure Prophylaxis amongst Gay and Bisexual Men in Scotland: Implications for Biomedical HIV Prevention",
            "doi": "10.1371/journal.pone.0064038",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "objectives to investigate the awareness of, and willingness to use, hiv pre-exposure prophylaxis (prep), and willingness to take part in a prep study among gay and bisexual men in scotland. methods cross-sectional survey of 17 gay commercial venues in glasgow and edinburgh in may 2011 (n\\u200a=\\u200a1515, 65.2% response rate); 1393 are included in the analyses. results just under one-third of participants had heard of prep (n\\u200a=\\u200a434; 31.2%), with awareness associated with being aged older than 35 years, talking to uai partners about hiv, and with having had an hiv or sti test in the previous 12 months. around half were willing to take part in a prep study (n\\u200a=\\u200a695; 49.9%) or to take prep on a daily basis (n\\u200a=\\u200a756; 54.3%). in multivariate analysis, willingness to take prep was associated with lower levels of education, regular gay scene attendance, \u2018high-risk\u2019 unprotected anal intercourse (uai) and testing for hiv or sti in the previous 12 months. reasons for not wanting to participate in a prep study or take prep included perceptions of low personal risk of hiv and concerns with using medication as an hiv prevention method. conclusions there is a willingness to engage in new forms of hiv prevention and research amongst a significant number of gay and bisexual men in scotland. future biomedical hiv interventions need to consider the links between sexual risk behaviour, testing, and potential prep use."
        },
        {
            "id": "R170485",
            "label": "Emergency Department Use by Released Prisoners with HIV: An Observational Longitudinal Study",
            "doi": "10.1371/journal.pone.0042416",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background many people living with hiv access healthcare systems through the emergency department (ed), and increased ed use may be indicative of disenfranchisement with primary hiv care, under-managed comorbid disease, or coincide with use of other healthcare resources. the goal of this study was to investigate ed use by hiv-infected prisoners transitioning to communities. methods we evaluated ed use by 151 hiv-infected released prisoners who were enrolled in a randomized controlled trial of directly administered versus self-administered antiretroviral therapy in connecticut. primary outcomes were quantity and type of ed visits and correlates of ed use were evaluated with multivariate models by poisson regression. results in the 12 months post-release, there were 227 unique ed contacts made by 85/151 (56%) subjects. ed visits were primarily for acute febrile syndromes (32.6%) or pain (20.3%), followed by substance use issues (19.4%), trauma (18%), mental illness (11%), and social access issues (4.4%). compared to those not utilizing the ed, users were more likely to be white, older, and unmarried, with less trust in their physician and poorer perceived physical health but greater social support. in multivariate models, ed use was correlated with moderate to severe depression (irr\\u200a=\\u200a1.80), being temporarily housed (irr\\u200a=\\u200a0.54), and alcohol addiction severity (irr\\u200a=\\u200a0.21) but not any surrogates of hiv severity. conclusions eds are frequent sources of care after prison-release with visits often reflective of social and psychiatric instability. future interventions should attempt to fill resource gaps, engage released prisoners in continuous hiv care, and address these substantial needs."
        },
        {
            "id": "R159811",
            "label": "Automatic Diagnosis of Attention Deficit Hyperactivity Disorder Using Machine Learning",
            "doi": "10.1080/08839514.2021.1933761",
            "research_field": {
                "id": "R205",
                "label": "Biomedical Engineering and Bioengineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract attention deficit hyperactivity disorder (adhd) is a neurodevelopmental disorder that includes symptoms such as inattentiveness, hyperactivity and impulsiveness. it is considered as an important public health issue, and prevalence of diagnosis has increased as awareness of the disease grew over the past years. supply of specialist medical experts has not kept pace with the increasing demand for assessment, both due to financial pressures on health systems and the difficulty to train new experts, resulting in growing waiting lists. patients are not being treated quickly enough causing problems in other areas of health systems (e.g. increased gp visits, increased risk of self-harm and accidents) and more broadly (e.g. time off work, relationship problems). advances in machine learning make it possible to attempt to diagnose adhd based on the analysis of relevant data, and this could inform clinical practice. this paper reports on findings related to the mental health services of a specialist trust within the uk\u2019s national health service (nhs). the analysis studied data of adult patients who underwent diagnosis over the past few years, and developed a diagnostic model for adhd in adults. the results demonstrate that it is indeed possible to correctly diagnose adhd patients with promising statistical accuracy."
        },
        {
            "id": "R155224",
            "label": "New insights into gully formation on Mars: Constraints from composition as seen by MRO/CRISM: GULLY FORMATION ON MARS AS SEEN BY CRISM",
            "doi": "10.1002/2016GL068956",
            "research_field": {
                "id": "R138056",
                "label": "Planetary Sciences"
            },
            "research_problems": [
                {
                    "id": "R155217",
                    "label": "Insights into Gully formation on Mars using MRO/CRISM"
                }
            ],
            "abstract": "over 100 martian gully sites were analyzed using orbital data collected by the compact reconnaissance imaging spectrometer for mars (crism) and high resolution imaging science experiment on the mars reconnaissance orbiter (mro). most gullies are spectrally indistinct from their surroundings, due to mantling by dust. where spectral information on gully sediments was obtained, a variety of mineralogies were identified. their relationship to the source rock suggests that gully\u2010forming processes transported underlying material downslope. there is no evidence for specific compositions being more likely to be associated with gullies or with the formation of hydrated minerals in situ as a result of recent liquid water activity. seasonal co2 and h2o frosts were observed in gullies at middle to high latitudes, consistent with seasonal frost\u2010driven processes playing important roles in the evolution of gullies. our results do not clearly indicate a role for long\u2010lived liquid water in gully formation and evolution."
        },
        {
            "id": "R69926",
            "label": "Zeitraum und Raumzeit: Dimensionen zeitlicher und r\u00c3\u00a4umlicher Narration im Theater",
            "doi": "10.1515/jlt-2019-0007",
            "research_field": {
                "id": "R465",
                "label": "Theatre and Performance Studies"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "abstract \\n the positioning in space and time of performed narration in theater poses a specific challenge to classical narratological categories of structuralist descent (developed, for example, by g\u00e9rard genette or wolf schmid, for the analysis of narrative fiction). time is the phenomenon which connects narratology and theater studies: on the one hand, it provides the basis for nearly every definition of narrativity; on the other, it grounds a number of different methodologies for the analysis of theater stagings, as well as theories of performance\\xa0\u2013 with their emphasis on transience, the ephemeral, and the unrepeatable, singular or transitory nature of the technically unreproducible art of theater (e.\\u200ag. by erika fischer-lichte). this turn towards temporality is also present in theories of postdramatic theater (by hans-thies lehman) and performance art. narrating always takes place in time; likewise, every performance is a handling of and an encounter with time. furthermore, performed narration gains a concrete spatial setting by virtue of its location on a stage or comparable performance area, so that the spatial structures contained in this setting exist in relation to the temporal structures of the act of theatrical telling, as well as the content of what is told. both temporal and spatial structures of theater stagings can be systematically described and analyzed with a narratological vocabulary. with references to seymour chatman, k\u00e4te hamburger and markus kuhn among others, the contribution discusses how narratological parameters for the analysis of temporal and spatial relations can be productively expanded in relation to theater and performance analysis. for exemplary purposes, it refers to dimiter gotscheff\u2019s staging of peter handke\u2019s immer noch sturm (which premiered in 2011 at the thalia theater hamburg in cooperation with the salzburger festspiele), focusing on its transmedial broadening of temporal categories like order, duration, and frequency, and subsequent, prior, or simultaneous narration. the broadening itself proves feasible since all categories of temporal narration can be applied to performative narration in the theater\\xa0\u2013 at times even more fruitfully than in written language, as is the case, for example, with the concept of \u203aduration\u2039. the concept of \u203atime of narration\u2039 too can be productively applied to theater. whilst a subsequent narration is frequently considered the standard case in written-language narratives on the one hand\\xa0\u2013 a conclusion that is, however, only correct if the narrator figure and narrative stand in spatiotemporal relation to one another, i.\\u200ae. if a homodiegetic narrator figure is present\\xa0\u2013 it is commonly held that in scenic-performed narration, on the other hand, the telling and the told take place simultaneously. the present contribution argues against this interpretation, as it stems from a misguided understanding of the \u203aliveness\u2039 of performance. \u203aliveness\u2039 refers only to the relationship between viewers and performers and their respective presence, but not to their temporal and spatial relationship to the told. rather, the following will argue that the time of narration in theater (as well as in film) stays unmarked in most cases. it is possible, however, to stage subsequent, prior, or simultaneous narration, too. immer noch sturm is one example for a performed subsequent narration. for audiovisual narration, then, a special case of iterative narration (telling once what happened n times) can be identified, which is to tell a few times (n minus x) what happened n times. as an additional category for the analysis of narrative temporality in audiovisual narrative media, i propose what i venture to call \u203asynchronized narration\u2039, in order to describe the specificity of spatiotemporal relations in performance. in synchronized narration, two or more events (that happen at different places or times in the narrative world) are shown at the same time on stage. this synchronized performance of several events is only realizable within the audiovisual dimension of spatial narration and not in written-language based narration. furthermore, for narrative space relations the categories \u203aspace covering\u2039, \u203aspace extending\u2039, and \u203aspace reducing narration\u2039 are suggested in order to analyze the relationships between discourse space and story space(s). discourse space emerges in the concrete physical space of the performance when narrativity is present. within this discourse space any amount of story spaces (with any expansion) can emerge. however, whilst in time-extending narration the time of the telling is longer than the time of the told, in space-extending narration the told space is bigger than the space of the telling. this principle is analogously valid for time-reducing or space-reducing narration. the transmission and media-specific broadening of temporal and spatial narratological parameters reveals how time and space form a continuum and should thus be linked and discussed alongside one another in analytical approaches to narrative artifacts. the staging of immer noch sturm actualizes a metaleptic structure, in which temporal borders are systematically dissolved and the overstepping of spatial borders becomes an indicator for the merging of different temporal levels. referring back to established narratological parameters and developing analogous conceptual tools for narrative space facilitates a comparative analysis both of specific narratives and of narrative media and thus not only offers a productive challenge of classical narratological parameters, but allows to investigate and construct a holistic\\xa0\u2013 if culture-specific\\xa0\u2013 overall view of narration."
        },
        {
            "id": "R188500",
            "label": "The cost-effectiveness of the article-processing-charge-funded model across countries in different scientific blocks: the case of Elsevier's hybrid open access journals",
            "doi": "10.47989/irpaper897",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R188204",
                    "label": "Impact of open access and development status of countries on citations"
                }
            ],
            "abstract": "\" introduction. the present study investigated the cost-effectiveness of article-processing-charge-funded model across the world countries in terms of its citation value proportional to the article processing charges. method. using a comparative citation analysis method at the macro level, it explored a sample of articles in forty-seven elsevier hybrid open access journals that had been following the model since 2007. analysis. the contributing countries' open access citation advantages were calculated based on the percentage of their open access citation surplus proportional to that of their non-open access articles. their relative open access citation cost-effectiveness was obtained based on their open access citation counts proportional to the article processing charges, normalised by those of non-open access papers. the countries were categorised into four scientific blocks using rand's categorization of countries' scientific development. descriptive and inferential statistics were used to analyse the data in spss. results. the results supported the citation advantage of the article-processing-charge-funded papers, encompassing the majority of the contributing countries in the four scientific development blocks. the articles showed relative cost-effectiveness over the years and for most countries in all the scientific development blocks. conclusions. publishing article-processing-charge-funded papers is relatively cost-effective, implying higher visibility and influence in exchange for the money paid. \""
        },
        {
            "id": "R6360",
            "label": "A joint model for question answering over multiple knowledge bases",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R6228",
                    "label": "Question answering systems evaluation"
                }
            ],
            "abstract": "\\n \\n as the amount of knowledge bases (kbs) grows rapidly, the problem of question answering (qa) over multiple kbs has drawn more attention. the most significant distinction between multiple kb-qa and single kb-qa is that the former must consider the alignments between kbs. the pipeline strategy first constructs the alignments independently, and then uses the obtained alignments to construct queries. however, alignment construction is not a trivial task, and the introduced noises would be passed on to query construction. by contrast, we notice that alignment construction and query construction are interactive steps, and jointly considering them would be beneficial. to this end, we present a novel joint model based on integer linear programming (ilp), uniting these two procedures into a uniform framework. the experimental results demonstrate that the proposed approach outperforms state-of-the-art systems, and is able to improve the performance of both alignment construction and query construction.\\n \\n"
        },
        {
            "id": "R170858",
            "label": "Cost-Effectiveness of Collaborative Care for Depression in UK Primary Care: Economic Evaluation of a Randomised Controlled Trial (CADET)",
            "doi": "10.1371/journal.pone.0104225",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "background collaborative care is an effective treatment for the management of depression but evidence on its cost-effectiveness in the uk is lacking. aims to assess the cost-effectiveness of collaborative care in a uk primary care setting. methods an economic evaluation alongside a multi-centre cluster randomised controlled trial comparing collaborative care with usual primary care for adults with depression (n\\u200a=\\u200a581). costs, quality-adjusted life-years (qalys), and incremental cost-effectiveness ratios (icer) were calculated over a 12-month follow-up, from the perspective of the uk national health service and personal social services (i.e. third party payer). sensitivity analyses are reported, and uncertainty is presented using the cost-effectiveness acceptability curve (ceac) and the cost-effectiveness plane. results the collaborative care intervention had a mean cost of \u00a3272.50 per participant. health and social care service use, excluding collaborative care, indicated a similar profile of resource use between collaborative care and usual care participants. collaborative care offered a mean incremental gain of 0.02 (95% ci: \u20130.02, 0.06) quality-adjusted life-years over 12 months, at a mean incremental cost of \u00a3270.72 (95% ci: \u2013202.98, 886.04), and resulted in an estimated mean cost per qaly of \u00a314,248. where costs associated with informal care are considered in sensitivity analyses collaborative care is expected to be less costly and more effective, thereby dominating treatment as usual. conclusion collaborative care offers health gains at a relatively low cost, and is cost-effective compared with usual care against a decision-maker willingness to pay threshold of \u00a320,000 per qaly gained. results here support the commissioning of collaborative care in a uk primary care setting."
        },
        {
            "id": "R135860",
            "label": "A design framework and exemplar metrics for FAIRness",
            "doi": "10.1038/sdata.2018.118",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [],
            "abstract": "\u201cfairness\u201d - the degree to which a digital resource is findable, accessible, interoperable, and reusable - is aspirational, yet the means of reaching it may be defined by increased adherence to measurable indicators. we report on the production of a core set of semi-quantitative metrics having universal applicability for the evaluation of fairness, and a rubric within which additional metrics can be generated by the community. this effort is the output from a stakeholder-representative group, founded by a core of fair principles\u2019 co-authors and drivers. we now seek input from the community to more broadly discuss their merit."
        },
        {
            "id": "R196490",
            "label": "What do RNN Language Models Learn about Filler\u00e2\u0080\u0093Gap Dependencies?",
            "doi": "10.18653/v1/w18-5423",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "R196494",
                    "label": "testing wether LSTM language models have learned filler\u2013gap dependencies"
                }
            ],
            "abstract": "rnn language models have achieved state-of-the-art perplexity results and have proven useful in a suite of nlp tasks, but it is as yet unclear what syntactic generalizations they learn. here we investigate whether state-of-the-art rnn language models represent long-distance filler\u2013gap dependencies and constraints on them. examining rnn behavior on experimentally controlled sentences designed to expose filler\u2013gap dependencies, we show that rnns can represent the relationship in multiple syntactic positions and over large spans of text. furthermore, we show that rnns learn a subset of the known restrictions on filler\u2013gap dependencies, known as island constraints: rnns show evidence for wh-islands, adjunct islands, and complex np islands. these studies demonstrates that state-of-the-art rnn models are able to learn and generalize about empty syntactic positions."
        },
        {
            "id": "R171070",
            "label": "Exploring the Spatial Association between Social Deprivation and Cardiovascular Disease Mortality at the Neighborhood Level",
            "doi": "10.1371/journal.pone.0146085",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "cardiovascular disease (cvd), the leading cause of death in the united states, is impacted by neighborhood-level factors including social deprivation. to measure the association between social deprivation and cvd mortality in harris county, texas, global (ordinary least squares (ols) and local (geographically weighted regression (gwr)) models were built. the models explored the spatial variation in the relationship at a census-tract level while controlling for age, income by race, and education. a significant and spatially varying association (p < .01) was found between social deprivation and cvd mortality, when controlling for all other factors in the model. the gwr model provided a better model fit over the analogous ols model (r2 = .65 vs. .57), reinforcing the importance of geography and neighborhood of residence in the relationship between social deprivation and cvd mortality. findings from the gwr model can be used to identify neighborhoods at greatest risk for poor health outcomes and to inform the placement of community-based interventions."
        },
        {
            "id": "R74213",
            "label": "ITNLP at SemEval-2021 Task 11: Boosting BERT with Sampling and Adversarial Training for Knowledge Extraction",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R10021",
                    "label": "Knowledge Graph Creation"
                },
                {
                    "id": "R74029",
                    "label": "Knowledge Graph Construction"
                },
                {
                    "id": "R74030",
                    "label": "Information Extraction"
                }
            ],
            "abstract": "this paper describes the winning system in the end-to-end pipeline phase for the nlpcontributiongraph task. the system is composed of three bert-based models and the three models are used to extract sentences, entities and triples respectively. experiments show that sampling and adversarial training can greatly boost the system. in end-to-end pipeline phase, our system got an average f1 of 0.4703, significantly higher than the second-placed system which got an average f1 of 0.3828."
        },
        {
            "id": "R168655",
            "label": "ASPASIA: A toolkit for evaluating the effects of biological interventions on SBML model behaviour",
            "doi": "10.1371/journal.pcbi.1005351",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "a calibrated computational model reflects behaviours that are expected or observed in a complex system, providing a baseline upon which sensitivity analysis techniques can be used to analyse pathways that may impact model responses. however, calibration of a model where a behaviour depends on an intervention introduced after a defined time point is difficult, as model responses may be dependent on the conditions at the time the intervention is applied. we present aspasia (automated simulation parameter alteration and sensitivity analysis), a cross-platform, open-source java toolkit that addresses a key deficiency in software tools for understanding the impact an intervention has on system behaviour for models specified in systems biology markup language (sbml). aspasia can generate and modify models using sbml solver output as an initial parameter set, allowing interventions to be applied once a steady state has been reached. additionally, multiple sbml models can be generated where a subset of parameter values are perturbed using local and global sensitivity analysis techniques, revealing the model\u2019s sensitivity to the intervention. to illustrate the capabilities of aspasia, we demonstrate how this tool has generated novel hypotheses regarding the mechanisms by which th17-cell plasticity may be controlled in vivo. by using aspasia in conjunction with an sbml model of th17-cell polarisation, we predict that promotion of the th1-associated transcription factor t-bet, rather than inhibition of the th17-associated transcription factor ror\u03b3t, is sufficient to drive switching of th17 cells towards an ifn-\u03b3-producing phenotype. our approach can be applied to all sbml-encoded models to predict the effect that intervention strategies have on system behaviour. aspasia, released under the artistic license (2.0), can be downloaded from http://www.york.ac.uk/ycil/software."
        },
        {
            "id": "R145608",
            "label": "Stark-broadening measurements of 3d\u00e2\u0086\u0092nftransitions in lithiumlike and heliumlike ions",
            "doi": "10.1103/physreva.47.374",
            "research_field": {
                "id": "R175",
                "label": "Atomic, Molecular and Optical Physics"
            },
            "research_problems": [
                {
                    "id": "R145287",
                    "label": "Spectral lines broadening in plasmas"
                }
            ],
            "abstract": "we report here on high-resolution spectral measurements of stark-broadened 3[ital d]-5[ital f] lines from lithiumlike ions and 3[ital d]-4[ital f] lines from heliumlike ions. the spectra were emitted from high-density laser-produced plasmas. plasmas were produced by irradiating thin- and thick-foil targets made of magnesium, aluminum, phosphorus, and chlorine with the omega laser in a line-focus geometry. line profiles were compared to a stark-broadening calculation that uses the static-ion approximation and an impact approximation for the electrons. the dependence of stark broadening on atomic number is discussed. for the aluminum plasmas [similar to]10% narrowing was observed in the width of the 3[ital d]-5[ital f] line as the length of the plasma was increased from 3 to 6 mm."
        },
        {
            "id": "R6172",
            "label": "ADANA: Active Name Disambiguation",
            "doi": "10.1109/ICDM.2011.19",
            "research_field": {
                "id": "R135",
                "label": "Databases/Information Systems"
            },
            "research_problems": [
                {
                    "id": "R6000",
                    "label": "Author name disambiguation"
                }
            ],
            "abstract": "\"name ambiguity has long been viewed as a challenging problem in many applications, such as scientific literature management, people search, and social network analysis. when we search a person name in these systems, many documents (e.g., papers, web pages) containing that person's name may be returned. it is hard to determine which documents are about the person we care about. although much research has been conducted, the problem remains largely unsolved, especially with the rapid growth of the people information available on the web. in this paper, we try to study this problem from a new perspective and propose an adana method for disambiguating person names via active user interactions. in adana, we first introduce a pairwise factor graph (pfg) model for person name disambiguation. the model is flexible and can be easily extended by incorporating various features. based on the pfg model, we propose an active name disambiguation algorithm, aiming to improve the disambiguation performance by maximizing the utility of the user's correction. experimental results on three different genres of data sets show that with only a few user corrections, the error rate of name disambiguation can be reduced to 3.1%. a real system has been developed based on the proposed method and is available online.\""
        },
        {
            "id": "R196629",
            "label": "Measuring and Mitigating Unintended Bias in Text Classification",
            "doi": "10.1145/3278721.3278729",
            "research_field": {
                "id": "R145261",
                "label": "Natural Language Processing"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. our definition of unintended bias is parameterized by a test set and a subset of input features. we illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from wikipedia talk pages. we also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. we use a set of common demographic identity terms as the subset of input features on which we measure bias. this technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. the mitigation method we introduce is an unsupervised approach based on balancing the training dataset. we demonstrate that this approach reduces the unintended bias without compromising overall model quality."
        },
        {
            "id": "R170070",
            "label": "A computational study on outliers in world music",
            "doi": "10.1371/journal.pone.0189399",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the comparative analysis of world music cultures has been the focus of several ethnomusicological studies in the last century. with the advances of music information retrieval and the increased accessibility of sound archives, large-scale analysis of world music with computational tools is today feasible. we investigate music similarity in a corpus of 8200 recordings of folk and traditional music from 137 countries around the world. in particular, we aim to identify music recordings that are most distinct compared to the rest of our corpus. we refer to these recordings as \u2018outliers\u2019. we use signal processing tools to extract music information from audio recordings, data mining to quantify similarity and detect outliers, and spatial statistics to account for geographical correlation. our findings suggest that botswana is the country with the most distinct recordings in the corpus and china is the country with the most distinct recordings when considering spatial correlation. our analysis includes a comparison of musical attributes and styles that contribute to the \u2018uniqueness\u2019 of the music of each country."
        },
        {
            "id": "R144754",
            "label": "Influenza surveillance in England and Wales using routine statistics: Development of \u00e2\u0080\u0098cusum\u00e2\u0080\u0099 graphs to compare 12 previous winters and to monitor the 1980/81 winter",
            "doi": "10.1017/s0022172400069928",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R144729",
                    "label": "Design and implementation of epidemiological surveillance systems"
                }
            ],
            "abstract": "summary surveillance of influenza in england and wales is made by monitoring weekly data. principal indices are deaths, sickness-benefit claims (sbc), laboratory reports and observations from general practitioners (gps). the 12 winters 1968/9 to 1979/80 have been studied to see which indices best described size and timing of influenza epidemics. a method of plotting the data (called cusums) is suggested which makes it easier to see the effect of small epidemics. cusums for gp statistics and respiratory deaths were found to be the most helpful indices for describing both size and timing of the epidemics, followed by total deaths and sbc, which were less specific to influenza, and influenza deaths, which lagged behind other indices. deaths certified as pneumonia have been increasing over these years, whereas bronchitis deaths have been decreasing and these indices should not be used separately for monitoring. the laboratory reporting system is important. it confirms the presence of influenza virus in the community and indicates prevalent strains. because it is a voluntary system with no defined population base the reports are not reliable numerically for estimating relative size of epidemics or for developing cusums. cusum plots were unanimous in describing the winter of 1980/1 as one of little influenza activity."
        },
        {
            "id": "R141824",
            "label": "Programming support for database schema refactoring (keynote)",
            "doi": "10.1145/3315507.3337954",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "database-driven applications typically undergo several schema changes during their life cycle due to performance and maintainability reasons. such changes to the database schema not only require migrating the underlying the data to a new schema but also necessitate re-implementing large chunks of the application code that query and update the database. in this talk, we describe our recent work on programming languages support for evolving database applications. specifically, we first describe our work on verifying equivalence between database applications that operate over different schema, such as those that arise before and after schema refactoring. next, we describe how to use this verification procedure to solve the corresponding synthesis problem: that is, given a database application and a new schema, we present a technique that can automatically synthesize a new, equivalent version of the program that operates over the new target schema."
        },
        {
            "id": "R110605",
            "label": "Epigenetic Hallmarks of Fetal Early Atherosclerotic Lesions in Humans",
            "doi": "10.1001/jamacardio.2018.3546",
            "research_field": {
                "id": "R20",
                "label": "Anatomy"
            },
            "research_problems": [
                {
                    "id": "R110620",
                    "label": "maternal hypercholesterolemia and atherosclerosis in off spring"
                }
            ],
            "abstract": "importance although increasingly strong evidence suggests a role of maternal total cholesterol and low-density lipoprotein cholesterol (ldlc) levels during pregnancy as a risk factor for atherosclerotic disease in the offspring, the underlying mechanisms need to be clarified for future clinical applications. objective to test whether epigenetic signatures characterize early fetal atherogenesis associated with maternal hypercholesterolemia and to provide a quantitative estimate of the contribution of maternal cholesterol level to fetal lesion size. design, setting, and participants this autopsy study analyzed 78 human fetal aorta autopsy samples from the division of human pathology, department of advanced biomedical sciences, federico ii university of naples, naples, italy. maternal levels of total cholesterol, ldlc, high-density lipoprotein cholesterol (hdlc), triglycerides, and glucose and body mass index (bmi) were determined during hospitalization owing to spontaneous fetal death. data were collected and immediately processed and analyzed to prevent degradation from january 1, 2011, through november 30, 2016. main outcomes and measurements results of dna methylation and messenger rna levels of the following genes involved in cholesterol metabolism were assessed: superoxide dismutase 2 (sod2), low-density lipoprotein receptor (ldlr), sterol regulatory element binding protein 2 (srebp2), liver x receptor &agr; (lxr&agr;), and adenosine triphosphate\u2013binding cassette transporter 1 (abca1). results among the 78 fetal samples included in the analysis (59% male; mean [sd] fetal age, 25 [3] weeks), maternal cholesterol level explained a significant proportion of the fetal aortic lesion variance in multivariate analysis (61%; p\\u2009=\\u2009.001) independently by the effect of levels of hdlc, triglycerides, and glucose and bmi. moreover, maternal total cholesterol and ldlc levels were positively associated with methylation of srebp2 in fetal aortas (pearson correlation, 0.488 and 0.503, respectively), whereas in univariate analysis, they were inversely correlated with srebp2 messenger rna levels in fetal aortas (pearson correlation, \u22120.534 and \u22120.671, respectively). epivariations of genes controlling cholesterol metabolism in cholesterol-treated human aortic endothelial cells were also observed. conclusions and relevance the present study provides a stringent quantitative estimate of the magnitude of the association of maternal cholesterol levels during pregnancy with fetal aortic lesions and reveals the epigenetic response of fetal aortic srebp2 to maternal cholesterol level. the role of maternal cholesterol level during pregnancy and epigenetic signature in offspring in cardiovascular primary prevention warrants further long-term causal relationship studies."
        },
        {
            "id": "R74378",
            "label": "A Relational Learning Approach for Collective Entity Resolution in the Web of Data",
            "doi": "",
            "research_field": {
                "id": "R133",
                "label": "Artificial Intelligence"
            },
            "research_problems": [
                {
                    "id": "R74011",
                    "label": "entity linking"
                }
            ],
            "abstract": "the integration of different datasets in the linked data cloud is a key aspect to the success of the web of data. to tackle this problem most of existent solutions have been supported by the task of entity resolution. however, many challenges still prevail specially when considering different types, structures and vocabularies used in the web. another common problem is that data usually are incomplete, inconsistent and contain outliers. to overcome these limitations, some works have applied machine learning algorithms since they are typically robust to both noise and data inconsistencies and are able to efficiently utilize nondeterministic dependencies in the data. in this paper we propose an approach based in a relational learning algorithm that addresses the problem by statistical approximation method. modeling the problem as a relational machine learning task allows exploit contextual information that might be too distant in the relational graph. the joint application of relationship patterns between entities and evidences of similarity between their descriptions can improve the effectiveness of results. furthermore, it is based on a sparse structure that scales well to large datasets. we present initial experiments based on btc2012 datasets."
        },
        {
            "id": "R187737",
            "label": "News media attention in Climate Action: latent topics and open access",
            "doi": "10.1007/s11192-021-04095-7",
            "research_field": {
                "id": "R278",
                "label": "Information Science"
            },
            "research_problems": [
                {
                    "id": "R187736",
                    "label": "Open access advantage concerning mentions in news media"
                }
            ],
            "abstract": "abstract in this study we investigated whether open access could assist the broader dissemination of scientific research in climate action (sustainable development goal 13) via news outlets. we did this by comparing (i) the share of open and non-open access documents in different climate action topics, and their news counts, and (ii) the mean of news counts for open access and non-open access documents. the data set of this study comprised 70,206 articles and reviews in sustainable development goal 13, published during 2014\u20132018, retrieved from scival. the number of news mentions for each document was obtained from altmetrics details page api using their dois, whereas the open access statuses were obtained using unpaywall.org. the analysis in this paper was done using a combination of (latent dirichlet allocation) topic modelling, descriptive statistics, and regression analysis. the covariates included in the regression analysis were features related to authors, country, journal, institution, funding, readability, news source category and topic. using topic modelling, we identified 10 topics, with topics 4 (meteorology) [21%], 5 (adaption, mitigation, and legislation) [18%] and 8 (ecosystems and biodiversity) [14%] accounting for 53% of the research in sustainable development goal 13. additionally, the results of regression analysis showed that while keeping all the variables constant in the model, open access papers in climate action had a news count advantage (8.8%) in comparison to non-open access papers. our findings also showed that while a higher share of open access documents in topics such as topic 9 (human vulnerability to risks) might not assist with its broader dissemination, in some others such as topic 5 (adaption, mitigation, and legislation), even a lower share of open access documents might accelerate its broad communication via news outlets."
        },
        {
            "id": "R110056",
            "label": "Tensor gradient based discriminative region analysis for cognitive state classification",
            "doi": "10.1109/tencon.2017.8227827",
            "research_field": {
                "id": "R205",
                "label": "Biomedical Engineering and Bioengineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "extraction of relevant features from high-dimensional multi-way functional mri (fmri) data is essential for the classification of a cognitive task. in general, fmri records a combination of neural activation signals and several other noisy components. alternatively, fmri data is represented as a high dimensional array using a number of voxels, time instants, and snapshots. the organisation of fmri data includes a number of region of interests (roi), snapshots, and thousand of voxels. the crucial step in cognitive task classification is a reduction of feature size through feature selection. extraction of a specific pattern of interest within the noisy components is a challenging task. tensor decomposition techniques have found several applications in the scientific fields. in this paper, a novel tensor gradient-based feature extraction technique for cognitive task classification is proposed. the technique has efficiently been applied on starplus fmri data. also, the technique has been used to discriminate the rois in fmri data in terms of cognitive state classification. the method has been achieved a better average accuracy when compared to other existing feature extraction methods."
        },
        {
            "id": "R196261",
            "label": "THE ROBUSTNESS OF CRITICAL PERIOD EFFECTS IN SECOND LANGUAGE\nACQUISITION",
            "doi": "10.1017/s0272263100004022",
            "research_field": {
                "id": "R320",
                "label": "Applied Linguistics"
            },
            "research_problems": [
                {
                    "id": "R196274",
                    "label": "To test the Fundamental Difference Hypothesis"
                },
                {
                    "id": "R196277",
                    "label": "To prove the existence of a Critical period in Second Language Acquisition"
                }
            ],
            "abstract": "this study was designed to test the fundamental difference hypothesis (bley-vroman,\\n1988), which states that, whereas children are known to learn language almost completely\\nthrough (implicit) domain-specific mechanisms, adults have largely lost the ability to learn a\\nlanguage without reflecting on its structure and have to use alternative mechanisms, drawing\\nespecially on their problem-solving capacities, to learn a second language. the hypothesis\\nimplies that only adults with a high level of verbal analytical ability will reach near-native\\ncompetence in their second language, but that this ability will not be a significant predictor of\\nsuccess for childhood second language acquisition. a study with 57 adult hungarian-speaking\\nimmigrants confirmed the hypothesis in the sense that very few adult immigrants scored within\\nthe range of child arrivals on a grammaticality judgment test, and that the few who did had high\\nlevels of verbal analytical ability; this ability was not a significant predictor for childhood\\narrivals. this study replicates the findings of johnson and newport (1989) and provides an\\nexplanation for the apparent exceptions in their study. these findings lead to a\\nreconceptualization of the critical period hypothesis: if the scope of this hypothesis is limited to\\nimplicit learning mechanisms, then it appears that there may be no exceptions to the age effects\\nthat the hypothesis seeks to explain."
        },
        {
            "id": "R111352",
            "label": "Patterns, sources and ecological implications of clonal diversity in apomictic Ranunculus carpaticola (Ranunculus auricomus complex, Ranunculaceae): CLONAL DIVERSITY IN APOMICTIC RANUNCULUS",
            "doi": "10.1111/j.1365-294x.2006.02800.x",
            "research_field": {
                "id": "R27",
                "label": "Botany"
            },
            "research_problems": [
                {
                    "id": "R111324",
                    "label": "ecological parthenogenesis"
                }
            ],
            "abstract": "sources and implications of genetic diversity in agamic complexes are still under debate. population studies (amplified fragment length polymorphisms, microsatellites) and karyological methods (feulgen dna image densitometry and flow cytometry) were employed for characterization of genetic diversity and ploidy levels of 10 populations of ranunculus carpaticola in central slovakia. whereas two diploid populations showed high levels of genetic diversity, as expected for sexual reproduction, eight populations are hexaploid and harbour lower degrees of genotypic variation, but maintain high levels of heterozygosity at many loci, as is typical for apomicts. polyploid populations consist either of a single aflp genotype or of one dominant and a few deviating genotypes. genotype/genodive and character incompatibility analyses suggest that genotypic variation within apomictic populations is caused by mutations, but in one population probably also by recombination. this local facultative sexuality may have a great impact on regional genotypic diversity. two microsatellite loci discriminated genotypes separated by the accumulation of few mutations (\u2018clone mates\u2019) within each aflp clone. genetic diversity is partitioned mainly among apomictic populations and is not geographically structured, which may be due to facultative sexuality and/or multiple colonizations of sites by different clones. habitat differentiation and a tendency to inhabit artificial meadows is more pronounced in apomictic than in sexual populations. we hypothesize that maintenance of genetic diversity and superior colonizing abilities of apomicts in temporally and spatially heterogeneous environments are important for their distributional success."
        },
        {
            "id": "R130962",
            "label": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "recurrent neural networks have been very successful at predicting sequences of words in tasks such as language modeling. however, all such models are based on the conventional classification framework, where the model is trained against one-hot targets, and each word is represented both as an input and as an output in isolation. this causes inefficiencies in learning both in terms of utilizing all of the information and in terms of the number of parameters needed to train. we introduce a novel theoretical framework that facilitates better learning in language modeling, and show that our framework leads to tying together the input embedding and the output projection matrices, greatly reducing the number of trainable variables. our framework leads to state of the art performance on the penn treebank with a variety of network models."
        },
        {
            "id": "R193286",
            "label": "Sentiment Classification Using Machine Learning Techniques with Syntax Features",
            "doi": "10.1109/CSCI.2015.44",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R122620",
                    "label": "Sentiment Analysis"
                },
                {
                    "id": "R193279",
                    "label": "Determining whether a review is positive or negative by overall sentiment"
                }
            ],
            "abstract": "\"sentiment classification has adopted machine learning techniques to improve its precision and efficiency. however, the features are always produced by basic words-bag methods without much consideration for words' syntactic properties, which could play an important role in the judgment of sentiment meanings. to remedy this, we firstly generate syntax trees of the sentences, with the analysis of syntactic features of the sentences. then we introduce multiple sentiment features into the basic words-bag features. such features were trained on movie reviews as data, with machine learning methods (naive bayes and support vector machines). the features and factors introduced by syntax tree were examined to generate a more accurate solution for sentiment classification.\""
        },
        {
            "id": "R189386",
            "label": "ClausIE: clause-based open information extraction",
            "doi": "10.1145/2488388.2488420",
            "research_field": {
                "id": "R322",
                "label": "Computational Linguistics"
            },
            "research_problems": [
                {
                    "id": "R189400",
                    "label": "Triple Extraction"
                }
            ],
            "abstract": "\"we propose clausie, a novel, clause-based approach to open information extraction, which extracts relations and their arguments from natural language text. clausie fundamentally differs from previous approaches in that it separates the detection of ``useful'' pieces of information expressed in a sentence from their representation in terms of extractions. in more detail, clausie exploits linguistic knowledge about the grammar of the english language to first detect clauses in an input sentence and to subsequently identify the type of each clause according to the grammatical function of its constituents. based on this information, clausie is able to generate high-precision extractions; the representation of these extractions can be flexibly customized to the underlying application. clausie is based on dependency parsing and a small set of domain-independent lexica, operates sentence by sentence without any post-processing, and requires no training data (whether labeled or unlabeled). our experimental study on various real-world datasets suggests that clausie obtains higher recall and higher precision than existing approaches, both on high-quality text as well as on noisy text as found in the web.\""
        },
        {
            "id": "R171272",
            "label": "Neighbourhood Poverty, Work Commitment and Unemployment in Early Adulthood: A Longitudinal Study into the Moderating Effect of Personality",
            "doi": "10.1371/journal.pone.0167830",
            "research_field": {
                "id": "R104",
                "label": "Bioinformatics"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "we studied how personality moderates the effect of neighbourhood disadvantage on work commitment and unemployment in early adulthood. using a personality typology of resilients, overcontrollers, and undercontrollers, we hypothesised that the association between neighbourhood poverty and both work commitment and unemployment would be stronger for overcontrollers and undercontrollers than for resilients. we used longitudinal data (n = 249) to test whether the length of exposure to neighbourhood poverty between age 16 and 21 predicts work commitment and unemployment at age 25. in line with our hypothesis, the findings showed that longer exposure was related to weaker work commitment among undercontrollers and overcontrollers and to higher unemployment among undercontrollers. resilients\u2019 work commitment and unemployment were not predicted by neighbourhood poverty."
        },
        {
            "id": "R134423",
            "label": "DocBERT: BERT for Document Classification",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R125884",
                    "label": "Text Classification"
                }
            ],
            "abstract": "we present, to our knowledge, the first application of bert to document classification. a few characteristics of the task might lead one to think that bert is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical bert input, and documents often have multiple labels. nevertheless, we show that a straightforward classification model using bert is able to achieve the state of the art across four popular datasets. to address the computational expense associated with bert inference, we distill knowledge from bert-large to small bidirectional lstms, reaching bert-base parity on multiple datasets using 30x fewer parameters. the primary contribution of our paper is improved baselines that can provide the foundation for future work."
        },
        {
            "id": "R194875",
            "label": "A Metamodeling Approach to Support the Engineering of Modeling Method Requirements",
            "doi": "10.1109/re.2019.00030",
            "research_field": {
                "id": "R140",
                "label": "Software Engineering"
            },
            "research_problems": [
                {
                    "id": "",
                    "label": ""
                }
            ],
            "abstract": "the notion of \"modeling method requirements\" refers to a category typically neglected by re taxonomies and frameworks - i.e., those requirements that motivate the realization of (conceptual) modeling methods and tools. they can be considered domain-specific, in the sense that all modeling methods provide a knowledge schema for some selected application domain (narrow or broad). besides this inherent domain-specific nature, we are investigating how the characteristics of modeling methods inform the re perspective, and how in turn re can support the engineering of such artifacts. thus, the work at hand aims to raise awareness about modeling method requirements in the re community. the core contribution is the cochaco (concept-characteristic-connector) method for the representation and management of such requirements, as well as for streamlining with subsequent engineering phases. cochaco is itself a modeling method - i.e., it achieves its goals through diagrammatic modeling means for which a supporting tool was prototyped and evolved. the proposal originates in required support for the initial phase of the agile modeling method engineering (amme) methodology, which was successfully applied in developing a variety of project-specific modeling tools. from this accumulated experience, awareness of \"modeling method requirements\" emerged and informed the design decisions of cochaco."
        },
        {
            "id": "R131048",
            "label": "Alleviating Sequence Information Loss with Data Overlapping and Prime Batch Sizes",
            "doi": "",
            "research_field": {
                "id": "R132",
                "label": "Computer Sciences"
            },
            "research_problems": [
                {
                    "id": "R120872",
                    "label": "Language Modelling"
                }
            ],
            "abstract": "in sequence modeling tasks the token order matters, but this information can be partially lost due to the discretization of the sequence into data points. in this paper, we study the imbalance between the way certain token pairs are included in data points and others are not. we denote this a token order imbalance (toi) and we link the partial sequence information loss to a diminished performance of the system as a whole, both in text and speech processing tasks. we then provide a mechanism to leverage the full token order information\u2014alleviated toi\u2014by iteratively overlapping the token composition of data points. for recurrent networks, we use prime numbers for the batch size to avoid redundancies when building batches from overlapped data points. the proposed method achieved state of the art performance in both text and speech related tasks."
        }
    ]
}