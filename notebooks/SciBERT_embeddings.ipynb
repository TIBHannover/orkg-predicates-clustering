{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SciBERT Embeddings\n",
        "Using this notebook you can simply compute the embeddings of your dataset, store them in an `.npz` format and finally download them locally.\n",
        "\n",
        "Please store you data files in a Google Drive directory of yours (``MAIN_DRIVE_DIR``).\n",
        "\n",
        "\n",
        "|       Variable       | Description |\n",
        "|:--------------------:|:--------------------------------------------------------:|\n",
        "|``MAIN_DRIVE_DIR`` | Name of your main directory in your Google Drive |\n",
        "|  `TRAINING_SET_PATH` | Path to your training set inside the `MAIN_DRIVE_DIR `|\n",
        "|  `TEST_SET_PATH` | Path to your test set inside the `MAIN_DRIVE_DIR `|\n",
        "|  `TRAINING_REPRESENTATION_PATH` | Path to your training set representations the ``MAIN_DRIVE_DIR``|\n",
        "|  `TEST_REPRESENTATION_PATH` | Path to your test set representations the ``MAIN_DRIVE_DIR``|\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8KNs63QhMwqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EhZi7mD3mV7"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "TRAINING_SET_PATH = './training_set.json'\n",
        "TEST_SET_PATH = './test_set.json'\n",
        "TRAINING_REPRESENTATIONS_PATH = './scibert_training_representations.npz'\n",
        "TEST_REPRESENTATIONS_PATH = './scibert_test_representations.npz'\n",
        "MAIN_DRIVE_DIR = 'TODO'"
      ],
      "metadata": {
        "id": "YM0l0Oqp4kOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Drive into Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp '/content/drive/MyDrive/'$MAIN_DRIVE_DIR'/'$TRAINING_SET_PATH $TRAINING_SET_PATH\n",
        "!cp '/content/drive/MyDrive/'$MAIN_DRIVE_DIR'/'$TEST_SET_PATH $TEST_SET_PATH"
      ],
      "metadata": {
        "id": "gDgUqkUQ4P2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def read_json(input_path):\n",
        "    with open(input_path, encoding='utf-8') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    return json_data"
      ],
      "metadata": {
        "id": "KTzhzvjXB1h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from scipy.sparse import csr_matrix\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ClusteringDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.data = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        instances = self.data['text']\n",
        "        \n",
        "        return '[CLS] ' + instances.iloc[[idx]].values[0] + ' [SEP]'"
      ],
      "metadata": {
        "id": "ZeFajd6C4WMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "vectorizer = SentenceTransformer('allenai/scibert_scivocab_uncased')"
      ],
      "metadata": {
        "id": "mPAbubBMYCzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from scipy import sparse\n",
        "\n",
        "for representation_path, set_path in zip([TRAINING_REPRESENTATIONS_PATH, TEST_REPRESENTATIONS_PATH], [TRAINING_SET_PATH, TEST_SET_PATH]):\n",
        "    \n",
        "    print('Processing {}. Will be saved in {}'.format(set_path, representation_path))\n",
        "             \n",
        "    data_json = read_json(set_path)\n",
        "    data_df = pd.json_normalize(data_json['instances'])\n",
        "\n",
        "    dataset = ClusteringDataset(data_df)\n",
        "    data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "    scibert_representations = None\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "      print('batch {}/{}'.format(i + 1, len(data_loader)))\n",
        "      batch_vector_representations = vectorizer.encode(batch)\n",
        "      batch_vector_representations = sparse.csr_matrix(batch_vector_representations)\n",
        "\n",
        "      try:\n",
        "        scibert_representations = sparse.vstack((scibert_representations, batch_vector_representations))\n",
        "      except:\n",
        "        scibert_representations = batch_vector_representations\n",
        "\n",
        "      print(scibert_representations.shape)\n",
        "\n",
        "    sparse.save_npz(representation_path, scibert_representations)\n",
        "    !cp $representation_path '/content/drive/MyDrive/'$MAIN_DRIVE_DIR'/scibert/'$representation_path"
      ],
      "metadata": {
        "id": "kMv7EySDBIlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for representation_path in [TRAINING_REPRESENTATIONS_PATH, TEST_REPRESENTATIONS_PATH]:\n",
        "    files.download(representation_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0WzK58XmNtWX",
        "outputId": "ddcaa9ae-28a4-4bc8-8457-6e913ff321ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7cd4288c-7bc1-4e75-94fb-8e69cd9c974d\", \"scibert_training_representations.npz\", 9762393)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b9d41c8d-c187-42e8-8ce6-dc3e988b7307\", \"scibert_test_representations.npz\", 3940686)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}