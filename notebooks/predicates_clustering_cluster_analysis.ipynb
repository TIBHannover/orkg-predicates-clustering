{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-MZfQ790VeS"
      },
      "source": [
        "# Cluster Analysis\n",
        "\n",
        "Using this notebook you can analyise one specific cluster built for the **Predicates Clustering Service** for the **Open Research Knowledge Graph**.\n",
        "\n",
        "Please search for \"TODO\"s and do them :)  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants and Utils"
      ],
      "metadata": {
        "id": "GqNEJrPkd7yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VECTORIZATION_METHOD = 'scibert'\n",
        "CLUSTERING_METHOD = 'kmeans'\n",
        "k = '3150'\n",
        "MODEL_PATH = '{}_{}_{}.pkl'.format(VECTORIZATION_METHOD, CLUSTERING_METHOD, k)\n",
        "\n",
        "TRAINING_SET_PATH = './training_set.json'\n",
        "TEST_SET_PATH = './test_set.json'\n",
        "DATA_PATH = './dataset.json'\n",
        "MAIN_DRIVE_DIR = '' # TODO: fill in the directory name in your Google Drive where you have your data files\n",
        "\n",
        "BUCKET = '' # TODO: fill in your Google Cloud Storage bucket's name"
      ],
      "metadata": {
        "id": "_1bL83fMdorc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp '/content/drive/MyDrive/'$MAIN_DRIVE_DIR'/'$TRAINING_SET_PATH $TRAINING_SET_PATH\n",
        "!cp '/content/drive/MyDrive/'$MAIN_DRIVE_DIR'/'$TEST_SET_PATH $TEST_SET_PATH\n",
        "!cp '/content/drive/MyDrive/'$MAIN_DRIVE_DIR'/'$DATA_PATH $DATA_PATH"
      ],
      "metadata": {
        "id": "YSOgmE7mehAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "def read_json(input_path):\n",
        "    with open(input_path, encoding='utf-8') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    return json_data\n",
        "\n",
        "def read_pickle(input_path):\n",
        "    with open(input_path, 'rb') as f:\n",
        "        loaded_object = pickle.load(f)\n",
        "    return loaded_object"
      ],
      "metadata": {
        "id": "wbK1M5MMxRnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9K8u-_-umaz"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gsutil cp gs://$BUCKET/$MODEL_PATH $MODEL_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEqxMocqDXmO"
      },
      "outputs": [],
      "source": [
        "model = read_pickle(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxyNBlwIvkCN"
      },
      "outputs": [],
      "source": [
        "# min, max, avg papers per cluster\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "unique, counts = np.unique(model.labels_, return_counts=True)\n",
        "print(np.min(counts))\n",
        "print(np.max(counts))\n",
        "print(np.average(counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5VlJCEW8ner"
      },
      "outputs": [],
      "source": [
        "# min, max, avg comparisons per cluster\n",
        "train_json = read_json(TRAINING_SET_PATH)\n",
        "train_df = pd.json_normalize(train_json['instances'])\n",
        "\n",
        "if CLUSTERING_METHOD == 'agglomerative':\n",
        "  test_json = read_json(TEST_SET_PATH)\n",
        "  test_df = pd.json_normalize(test_json['instances'])\n",
        "  train_df = pd.concat([train_df, test_df])\n",
        "\n",
        "try:\n",
        "  train_df.insert(1, 'cluster_id', model.labels_)\n",
        "except:\n",
        "  print('already inserted!')\n",
        "\n",
        "clusters_comparisons = train_df[['cluster_id', 'comparison_id']].drop_duplicates()\n",
        "unique, counts = np.unique(clusters_comparisons['cluster_id'], return_counts=True)\n",
        "print(np.min(counts))\n",
        "print(np.max(counts))\n",
        "print(np.average(counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejl29UAPvrwc"
      },
      "outputs": [],
      "source": [
        "# find out how the comparisons are distributed over clusters and how much pure is the distribution\n",
        "train_json = read_json(TRAINING_SET_PATH)\n",
        "train_df = pd.json_normalize(train_json['instances'])\n",
        "\n",
        "if CLUSTERING_METHOD == 'agglomerative':\n",
        "  test_json = read_json(TEST_SET_PATH)\n",
        "  test_df = pd.json_normalize(test_json['instances'])\n",
        "  train_df = pd.concat([train_df, test_df])\n",
        "\n",
        "puriteis = []\n",
        "number_of_clusters = []\n",
        "weights = []\n",
        "for comparison_id, number_of_papers in train_df['comparison_id'].value_counts().items():\n",
        "  paper_indices = train_df[train_df['comparison_id'] == comparison_id].index\n",
        "  clusters_labels = model.labels_[paper_indices]\n",
        "  clusters_comparisons = []\n",
        "  pure_clusters = 0\n",
        "\n",
        "  for cluster_label in np.unique(clusters_labels):\n",
        "    cluster_instances_indices = np.argwhere(model.labels_[:train_df.shape[0]] == cluster_label).squeeze(1)\n",
        "    cluster_instances = train_df.iloc[cluster_instances_indices]\n",
        "    cluster_instances = cluster_instances.drop_duplicates(subset='paper_id')\n",
        "    cluster_comparisons = cluster_instances['comparison_id'].unique()\n",
        "    clusters_comparisons.extend(cluster_comparisons)\n",
        "    if len(cluster_comparisons) == 1:\n",
        "      pure_clusters += 1\n",
        "\n",
        "  purity = pure_clusters / len(np.unique(clusters_labels))\n",
        "  puriteis.append(purity)\n",
        "  weights.append(number_of_papers)\n",
        "  number_of_clusters.append(len(np.unique(clusters_labels)))\n",
        "  print('comparison {} with {} papers is distributed over {} clusters containing {} comparisons, where {} clusters are pure. - Purity={}'.format(comparison_id, number_of_papers, len(np.unique(clusters_labels)), len(set(clusters_comparisons)), pure_clusters, purity))\n",
        "  print('comparisons: {}'.format(set(clusters_comparisons)))\n",
        "\n",
        "print('Weighted average purity: {:.3f}'.format(np.average(puriteis, weights=weights)))\n",
        "print('min clusters/comparison', np.min(number_of_clusters))\n",
        "print('max clusters/comparison', np.max(number_of_clusters))\n",
        "print('avg clusters/comparison', np.average(number_of_clusters))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# are there empty clusters in terms of predicates ? i.e. are there clusters that only have EMPTY comparison (uncompared papers) ?\n",
        "\n",
        "n_empty_clusters = 0\n",
        "for cluster_label in np.unique(model.labels_):\n",
        "    cluster_instances_indices = np.argwhere(model.labels_[:train_df.shape[0]] == cluster_label).squeeze(1)\n",
        "    cluster_instances = train_df.iloc[cluster_instances_indices]\n",
        "    cluster_instances = cluster_instances.drop_duplicates(subset='paper_id')\n",
        "    cluster_comparisons = cluster_instances['comparison_id'].unique()\n",
        "\n",
        "    if len(cluster_comparisons) == 1 and 'EMPTY' in cluster_comparisons:\n",
        "      n_empty_clusters += 1\n",
        "\n",
        "print('#empty clusters: {}'.format(n_empty_clusters))"
      ],
      "metadata": {
        "id": "VWDAuabjeu0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}