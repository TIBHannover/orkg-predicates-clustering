{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1qizpzlWjWg"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "TRAINING_SET_PATH = './training_set.json'\n",
        "TEST_SET_PATH = './test_set.json'\n",
        "DATA_PATH = './data.json'\n",
        "VECTORIZER_PATH = './tfidfvectorizer.pkl'\n",
        "CLUSTERING_METHOD = 'agglomerative' # or 'kmeans'\n",
        "RESULTS_PATH = './tfidf_{}_results.json'.format(CLUSTERING_METHOD)\n",
        "EXPECTED_PREDICTED_PATH = './tfidf_{}_expected_predicted.json'.format(CLUSTERING_METHOD)\n",
        "BUCKET = 'TODO'\n",
        "MODEL_TEMPLATE_PATH = 'tfidf_{}_{}.pkl'.format(CLUSTERING_METHOD, '{}')\n",
        "N_CLUSTERS = range(200, 2100, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iExIO2cvUhHB",
        "outputId": "4e6c132e-7cd9-442e-c42b-4764851428e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2.5\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"removes punctuation, stopwords, and returns a list of the remaining words, or tokens\"\"\"\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc6KZSPhU09O"
      },
      "outputs": [],
      "source": [
        "# Cleaning the text\n",
        "import string\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "def text_process(text):\n",
        "    '''\n",
        "    Takes in a string of text, then performs the following:\n",
        "    1. Remove all punctuation\n",
        "    2. Remove all stopwords\n",
        "    3. Return the cleaned text as a list of words\n",
        "    4. Remove words\n",
        "    '''\n",
        "    stemmer = WordNetLemmatizer()\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join([i for i in nopunc if not i.isdigit()])\n",
        "    nopunc =  [word.lower() for word in nopunc.split() if word not in stopwords.words('english')]\n",
        "    return ' '.join([stemmer.lemmatize(word) for word in nopunc])\n",
        "\n",
        "def read_json(input_path):\n",
        "    with open(input_path, encoding='utf-8') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    return json_data\n",
        "\n",
        "def read_pickle(input_path):\n",
        "    with open(input_path, 'rb') as f:\n",
        "        loaded_object = pickle.load(f)\n",
        "    return loaded_object\n",
        "\n",
        "def write_json(json_data, output_path):\n",
        "    with open(output_path, 'w') as json_file:\n",
        "        json.dump(json_data, json_file, indent=4)\n",
        "\n",
        "def write_pickle(data, output_path):\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(data, f)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQoakl_pVpQn",
        "outputId": "3a14814e-945d-4b2f-db5f-f0e8d65c4761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Mount Drive into Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp '/content/drive/MyDrive/master_thesis/predicates_clustering/training_set.json' $TRAINING_SET_PATH\n",
        "!cp '/content/drive/MyDrive/master_thesis/predicates_clustering/test_set.json' $TEST_SET_PATH\n",
        "!cp '/content/drive/MyDrive/master_thesis/predicates_clustering/data.json' $DATA_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG_CKON1nQVd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6t3EWXNXCX-"
      },
      "outputs": [],
      "source": [
        "# Import and process the training data\n",
        "import pandas as pd\n",
        "\n",
        "train_json = read_json(TRAINING_SET_PATH)\n",
        "train_df = pd.json_normalize(train_json['instances'])\n",
        "train_df['text'] = train_df['text'].apply(text_process)\n",
        "\n",
        "if CLUSTERING_METHOD == 'agglomerative':\n",
        "  test_json = read_json(TEST_SET_PATH)\n",
        "  test_df = pd.json_normalize(test_json['instances'])\n",
        "  test_df['text'] = test_df['text'].apply(text_process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSjBnpPYalvQ",
        "outputId": "37c3cddb-93d1-41d4-baa4-6e2204587334"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4341, 260016)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from scipy import sparse\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2)).fit(train_df['text'])\n",
        "write_pickle(vectorizer, VECTORIZER_PATH)\n",
        "\n",
        "train_df_transformed = vectorizer.transform(train_df['text'])\n",
        "\n",
        "# we need to build the clusters on the complete dataset, since the \"prediction\" in hierarchical clusterings requires re-building the clusters.\n",
        "if CLUSTERING_METHOD == 'agglomerative':\n",
        "  test_df_transformed = vectorizer.transform(test_df['text'])\n",
        "  train_df_transformed = sparse.vstack((train_df_transformed, test_df_transformed))\n",
        "\n",
        "train_df_transformed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajMbCYNEcB_X"
      },
      "outputs": [],
      "source": [
        "#checking for optimal number of clusters\n",
        "from sklearn.cluster import KMeans \n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from time import time\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "for n in N_CLUSTERS:\n",
        "    t0 = time()\n",
        "    MODEL_PATH = MODEL_TEMPLATE_PATH.format(n)\n",
        "    print(MODEL_PATH)\n",
        "\n",
        "    if CLUSTERING_METHOD == 'kmeans':\n",
        "      clustering_model = KMeans(n_clusters=n, random_state=212)\n",
        "      clustering_model = clustering_model.fit(train_df_transformed)\n",
        "    elif CLUSTERING_METHOD == 'agglomerative':\n",
        "      clustering_model = AgglomerativeClustering(n_clusters=n, linkage='ward')\n",
        "      clustering_model = clustering_model.fit(train_df_transformed.toarray())\n",
        "\n",
        "    print('{0:2f}'.format(time() - t0))\n",
        "    write_pickle(clustering_model, MODEL_PATH)\n",
        "\n",
        "    # Upload model to bucket\n",
        "    !gsutil cp {MODEL_PATH} gs://{BUCKET}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFlX1rQznFRn"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xan3GnKHnm6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_comparisons(clustering_model, test_element, test_element_index, train_df):\n",
        "    if CLUSTERING_METHOD == 'kmeans':\n",
        "      cluster_label = clustering_model.predict(test_element)\n",
        "      cluster_instances_indices = np.argwhere(clustering_model.labels_ == cluster_label).squeeze(1)\n",
        "    elif CLUSTERING_METHOD == 'agglomerative':\n",
        "      cluster_label = clustering_model.labels_[train_df.shape[0] + test_element_index]\n",
        "      cluster_instances_indices = np.argwhere(clustering_model.labels_[:train_df.shape[0]] == cluster_label).squeeze(1)\n",
        "\n",
        "    cluster_instances = train_df.iloc[cluster_instances_indices]\n",
        "    comparison_ids = cluster_instances['comparison_id'].unique()\n",
        "    return comparison_ids\n",
        "\n",
        "\n",
        "def map_to_predicates(data, comparison_ids):\n",
        "    predicate_ids = []\n",
        "    \n",
        "    for comparison in data['comparisons']:\n",
        "      if comparison['id'] in comparison_ids:\n",
        "\n",
        "        for predicate in comparison['predicates']:\n",
        "          if predicate['id'] in predicate_ids:\n",
        "            continue\n",
        "\n",
        "          predicate_ids.append(predicate['id'])\n",
        "\n",
        "    return predicate_ids\n",
        "\n",
        "def evaluate_macro(expected, predicted):\n",
        "    return compute_metrics(evaluate_micro(expected, predicted))\n",
        "\n",
        "def evaluate_micro(expected, predicted):\n",
        "    \"\"\"\n",
        "    tp: correctly predicted properties --> found in expected and predicted sets\n",
        "    fp: incorrectly predicted properties --> found only in predicted set\n",
        "    fn: incorrectly predicted properties for other classes -> found only in expected set\n",
        "    \"\"\"\n",
        "    tp = len(set(expected).intersection(predicted))\n",
        "    fp = len(set(predicted).difference(expected))\n",
        "    fn = len(set(expected).difference(predicted))\n",
        "    \n",
        "    return np.array([tp, fp, fn])\n",
        "\n",
        "\n",
        "def compute_metrics(confusion_results):\n",
        "    tp, fp, fn = confusion_results\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f_measure = 2 * ((precision * recall) / (precision + recall)) \n",
        "    \n",
        "    return np.array([precision, recall, f_measure])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYNMih-knLLn"
      },
      "outputs": [],
      "source": [
        "# Import and process the test data\n",
        "import pandas as pd\n",
        "\n",
        "train_json = read_json(TRAINING_SET_PATH)\n",
        "train_df = pd.json_normalize(train_json['instances'])\n",
        "\n",
        "test_json = read_json(TEST_SET_PATH)\n",
        "test_df = pd.json_normalize(test_json['instances'])\n",
        "test_df['text'] = test_df['text'].apply(text_process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkbjPdC3Bv8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "data = read_json(DATA_PATH)\n",
        "vectorizer = read_pickle(VECTORIZER_PATH)\n",
        "\n",
        "results = {}\n",
        "for n in N_CLUSTERS:\n",
        "    MODEL_PATH = MODEL_TEMPLATE_PATH.format(n)\n",
        "    print('evaluating model: {}'.format(MODEL_PATH))\n",
        "\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        !gsutil cp gs://$BUCKET/$MODEL_PATH $MODEL_PATH\n",
        "    clustering_model = read_pickle(MODEL_PATH)\n",
        "\n",
        "    macro_measures = np.empty((0,3), float)\n",
        "    micro_measures = np.zeros(3)\n",
        "    for test_instance_index, test_instance in test_df.iterrows():\n",
        "        expected_comparison_id, text = test_instance['comparison_id'], test_instance['text']\n",
        "        expected = map_to_predicates(data, [expected_comparison_id])\n",
        "        vectorized_text = vectorizer.transform([text])\n",
        "\n",
        "        predicted_comparison_ids = predict_comparisons(clustering_model, vectorized_text, test_instance_index, train_df)\n",
        "        predicted = map_to_predicates(data, predicted_comparison_ids)\n",
        "        macro_measures = np.vstack((macro_measures, evaluate_macro(expected, predicted)))\n",
        "        micro_measures += evaluate_micro(expected, predicted)\n",
        "    \n",
        "    macro_measures = np.nanmean(macro_measures, axis=0)\n",
        "    micro_measures = compute_metrics(micro_measures)\n",
        "    results[str(n)] = {\n",
        "        'k': n,\n",
        "        'macro': {\n",
        "            'precision': macro_measures[0],\n",
        "            'recall': macro_measures[1],\n",
        "            'f_measure': macro_measures[2]\n",
        "        },\n",
        "        'micro': {\n",
        "            'precision': micro_measures[0],\n",
        "            'recall': micro_measures[1],\n",
        "            'f_measure': micro_measures[2]\n",
        "        }\n",
        "    }\n",
        "    write_json(results, RESULTS_PATH)\n",
        "    !cp $RESULTS_PATH '/content/drive/MyDrive/master_thesis/predicates_clustering/tfidf/'$RESULTS_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08hoZkOZr6_f"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/master_thesis/predicates_clustering/tfidf/'$RESULTS_PATH $RESULTS_PATH\n",
        "\n",
        "\n",
        "results = read_json(RESULTS_PATH)\n",
        "\n",
        "#for key in results.keys():\n",
        "#  results[key]['k'] = key\n",
        "\n",
        "results_df = pd.json_normalize(results.values())\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-MZfQ790VeS"
      },
      "source": [
        "# Cluster Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9K8u-_-umaz"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "model_path = 'tfidf_agglomerative_1300.pkl'\n",
        "!gsutil cp gs://$BUCKET/$model_path $model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEqxMocqDXmO"
      },
      "outputs": [],
      "source": [
        "model_path = 'tfidf_agglomerative_1300.pkl'\n",
        "model = read_pickle(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxyNBlwIvkCN"
      },
      "outputs": [],
      "source": [
        "# min, max, avg papers per cluster\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "unique, counts = np.unique(model.labels_, return_counts=True)\n",
        "print(np.min(counts))\n",
        "print(np.max(counts))\n",
        "print(np.average(counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5VlJCEW8ner"
      },
      "outputs": [],
      "source": [
        "# min, max, avg comparisons per cluster\n",
        "train_json = read_json(TRAINING_SET_PATH)\n",
        "train_df = pd.json_normalize(train_json['instances'])\n",
        "\n",
        "if CLUSTERING_METHOD == 'agglomerative':\n",
        "  test_json = read_json(TEST_SET_PATH)\n",
        "  test_df = pd.json_normalize(test_json['instances'])\n",
        "  train_df = pd.concat([train_df, test_df])\n",
        "\n",
        "try:\n",
        "  train_df.insert(1, 'cluster_id', model.labels_)\n",
        "except:\n",
        "  print('already inserted!')\n",
        "\n",
        "clusters_comparisons = train_df[['cluster_id', 'comparison_id']].drop_duplicates()\n",
        "unique, counts = np.unique(clusters_comparisons['cluster_id'], return_counts=True)\n",
        "print(np.min(counts))\n",
        "print(np.max(counts))\n",
        "print(np.average(counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejl29UAPvrwc"
      },
      "outputs": [],
      "source": [
        "# find out how the comparisons are distributed over clusters and how much pure is the distribution\n",
        "train_json = read_json(TRAINING_SET_PATH)\n",
        "train_df = pd.json_normalize(train_json['instances'])\n",
        "\n",
        "puriteis = []\n",
        "number_of_clusters = []\n",
        "for comparison_id, number_of_papers in train_df['comparison_id'].value_counts().items():\n",
        "  paper_indices = train_df[train_df['comparison_id'] == comparison_id].index\n",
        "  clusters_labels = model.labels_[paper_indices]\n",
        "  clusters_comparisons = []\n",
        "  pure_clusters = 0\n",
        "\n",
        "  for cluster_label in np.unique(clusters_labels):\n",
        "    cluster_instances_indices = np.argwhere(model.labels_[:train_df.shape[0]] == cluster_label).squeeze(1)\n",
        "    cluster_instances = train_df.iloc[cluster_instances_indices]\n",
        "    # TODO: remove the next line if you want to ignore the fact that \"comparisons can share papers\".\n",
        "    cluster_instances = cluster_instances.drop_duplicates(subset='paper_id')\n",
        "    cluster_comparisons = cluster_instances['comparison_id'].unique()\n",
        "    clusters_comparisons.extend(cluster_comparisons)\n",
        "    if len(cluster_comparisons) == 1:\n",
        "      pure_clusters += 1\n",
        "\n",
        "  purity = pure_clusters / len(np.unique(clusters_labels))\n",
        "  puriteis.append(purity)\n",
        "  number_of_clusters.append(len(np.unique(clusters_labels)))\n",
        "  print('comparison {} with {} papers is distributed over {} clusters containing {} comparisons, where {} clusters are pure. - Purity={}'.format(comparison_id, number_of_papers, len(np.unique(clusters_labels)), len(set(clusters_comparisons)), pure_clusters, purity))\n",
        "  print('comparisons: {}'.format(set(clusters_comparisons)))\n",
        "\n",
        "print('Average purity: {:.3f}'.format(np.average(puriteis)))\n",
        "print('min clusters/comparison', np.min(number_of_clusters))\n",
        "print('max clusters/comparison', np.max(number_of_clusters))\n",
        "print('avg clusters/comparison', np.average(number_of_clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating best model against expecetd predicted results .. picking gold-instances"
      ],
      "metadata": {
        "id": "2hTfrIZJBGg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d3wWVSQI60y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "data = read_json(DATA_PATH)\n",
        "vectorizer = read_pickle(VECTORIZER_PATH)\n",
        "\n",
        "expected_predicted = {'instances': []}\n",
        "\n",
        "k = 1850 # k is the best one w.r.t. micro f-measure shown in results.json\n",
        "MODEL_PATH = MODEL_TEMPLATE_PATH.format(k) \n",
        "print('evaluating model: {}'.format(MODEL_PATH))\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    !gsutil cp gs://$BUCKET/$MODEL_PATH $MODEL_PATH\n",
        "clustering_model = read_pickle(MODEL_PATH)\n",
        "\n",
        "\n",
        "for test_instance_index, test_instance in test_df.iterrows():\n",
        "    expected_comparison_id, text = test_instance['comparison_id'], test_instance['text']\n",
        "    expected = map_to_predicates(data, [expected_comparison_id])\n",
        "    vectorized_text = vectorizer.transform([text])\n",
        "\n",
        "    predicted_comparison_ids = predict_comparisons(clustering_model, vectorized_text, test_instance_index, train_df)\n",
        "    predicted = map_to_predicates(data, predicted_comparison_ids)\n",
        "\n",
        "    expected_predicted['instances'].append({\n",
        "        'instance_id': test_instance['instance_id'],\n",
        "        'text': text,\n",
        "        'macro': evaluate_macro(expected, predicted).tolist(),\n",
        "        'expected': {\n",
        "            'comparison_ids': [expected_comparison_id],\n",
        "            'predicates': expected\n",
        "        },\n",
        "        'predicted': {\n",
        "            'comparison_ids': predicted_comparison_ids.tolist(),\n",
        "            'predicates': predicted\n",
        "        }\n",
        "    })\n",
        "\n",
        "write_json(expected_predicted, EXPECTED_PREDICTED_PATH)\n",
        "!cp $EXPECTED_PREDICTED_PATH '/content/drive/MyDrive/master_thesis/predicates_clustering/tfidf/'$EXPECTED_PREDICTED_PATH"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "predicates_clustering_tfidf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}